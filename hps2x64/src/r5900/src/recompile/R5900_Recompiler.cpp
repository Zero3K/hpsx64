/*
	Copyright (C) 2012-2030

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/


#include "R5900_Recompiler.h"
#include "ps2_system.h"
#include "R5900_Print.h"
#include "PS2DataBus.h"

using namespace Playstation2;
using namespace R5900;


#ifdef _DEBUG_VERSION_

#define INLINE_DEBUG_ENABLE

//#define INLINE_DEBUG_SPLIT


//#define INLINE_DEBUG_RECOMPILE
//#define INLINE_DEBUG_RECOMPILE2


#endif







#define ENABLE_ICACHE

// enables d-cache on R5900
// must be enabled here and in R5900_Execute.cpp, R5900_DCache.h
// note: sometimes this is required
// ***todo*** does not work perfectly yet
//#define ENABLE_R5900_DCACHE


#ifdef ENABLE_R5900_DCACHE

//#define DCACHE_FORCE_MEMPTR

//#define DCACHE_READ_MEMORY
//#define DCACHE_WRITE_MEMORY


#define ENABLE_DCACHE_DATA_READ
#define ENABLE_DCACHE_DATA_WRITE

#define ENABLE_DCACHE_TIMING_LOAD
#define ENABLE_DCACHE_TIMING_STORE

#define ENABLE_BUS_SIMULATION_CACHE_LOAD
#define ENABLE_BUS_SIMULATION_CACHE_STORE

#endif


// enables timing per register for availability
//#define ENABLE_GPR_REGISTER_TIMING

// check if next instruction is depending on current load
#define ENABLE_NEXT_DEPENDENCY_CHECK


// enables forward branching
#define USE_FORWARD_BRANCH


// combined load/store
//#define ENABLE_COMBINED_LOAD

#ifdef ENABLE_COMBINED_LOAD

#define ENABLE_COMBINED_LOAD_LB
#define ENABLE_COMBINED_LOAD_LH
#define ENABLE_COMBINED_LOAD_LW
#define ENABLE_COMBINED_LOAD_LBU
#define ENABLE_COMBINED_LOAD_LHU
#define ENABLE_COMBINED_LOAD_LWU
#define ENABLE_COMBINED_LOAD_LD
#define ENABLE_COMBINED_LOAD_LWC1
#define ENABLE_COMBINED_LOAD_LQ

#endif


//#define ENABLE_COMBINED_STORE

#ifdef ENABLE_COMBINED_STORE

#define ENABLE_COMBINED_STORE_SB
#define ENABLE_COMBINED_STORE_SH
#define ENABLE_COMBINED_STORE_SW
#define ENABLE_COMBINED_STORE_SD
#define ENABLE_COMBINED_STORE_SWC1
#define ENABLE_COMBINED_STORE_SQ

#endif




//#define ENABLE_CPU_IDLE


#define ENABLE_FPU_LATENCY


//#define ENABLE_OPTIMIZED_REG_READS


#define OPTIMIZE_RO_MULTIPLY_MUL
#define OPTIMIZE_RO_MULTIPLY_MADD


#define USE_INTEGER_BASED_MUL
#define USE_INTEGER_BASED_MULA
//#define USE_INTEGER_BASED_MADD
//#define USE_INTEGER_BASED_MADDA


#define USE_NEW_VMUL_CODE
#define USE_NEW_VMADD_CODE


#define ENABLE_CONNECT_ADJACENT_BLOCKS


#define ENABLE_R5900_BRANCH_PREDICTION
#define ENABLE_R5900_BRANCH_PREDICTION_TRAP
#define ENABLE_R5900_BRANCH_PREDICTION_SYSCALL


//#define ENABLE_AUTO_BRANCH


#define USE_SHORT_LWL_CODE

// possibly longer is better for lwr ??
//#define USE_SHORT_LWR_CODE

#define USE_SHORT_LDL_CODE
#define USE_SHORT_LDR_CODE

#define USE_SHORT_QFSRV_CODE
#define USE_SHORT_SWL_CODE
#define USE_SHORT_SWR_CODE

#define USE_SHORT_SDL_CODE
#define USE_SHORT_SDR_CODE




#define USE_NEW_LQC2_CODE
#define USE_NEW_LOAD_CODE_LWL
#define USE_NEW_LOAD_CODE_LWR
#define USE_NEW_LOAD_CODE_LDL
#define USE_NEW_LOAD_CODE_LDR
#define USE_NEW_LOAD_CODE



#define USE_NEW_SQC2_CODE
#define USE_NEW_STORE_CODE_SWL
#define USE_NEW_STORE_CODE_SWR
#define USE_NEW_STORE_CODE_SDL
#define USE_NEW_STORE_CODE_SDR
#define USE_NEW_STORE_CODE



#define ENABLE_INLINE_STORE
#define ENABLE_INLINE_LOAD




#define USE_NEW_PADDSW_CODE
#define USE_NEW_PADDUW_CODE
#define USE_NEW_PSUBSW_CODE
#define USE_NEW_PSUBUW_CODE




#define ENABLE_MULTIPLY_LATENCY
#define ENABLE_DIVIDE_LATENCY


#define USE_NEW_VLQD_CODE
#define USE_NEW_VLQI_CODE
#define USE_NEW_VSQD_CODE
#define USE_NEW_VSQI_CODE
#define USE_NEW_VILWR_CODE
#define USE_NEW_VISWR_CODE



#define USE_NEW_ADD_CODE
#define USE_NEW_ADDI_CODE
#define USE_NEW_SUB_CODE

#define USE_NEW_SYSCALL_CODE

#define USE_NEW_BEQ_CODE
#define USE_NEW_BNE_CODE
#define USE_NEW_BLTZ_CODE
#define USE_NEW_BGTZ_CODE
#define USE_NEW_BLEZ_CODE
#define USE_NEW_BGEZ_CODE

#define USE_NEW_BLTZAL_CODE
#define USE_NEW_BGEZAL_CODE

#define USE_NEW_J_CODE
#define USE_NEW_JR_CODE
#define USE_NEW_JAL_CODE
#define USE_NEW_JALR_CODE

#define ALLOW_ENCODING_DELAYSLOT
#define ENCODE_ALL_POSSIBLE_DELAYSLOTS

#define USE_NEW_DADD_CODE
#define USE_NEW_DADDI_CODE
#define USE_NEW_DSUB_CODE

#define USE_NEW_DADDU_CODE
#define USE_NEW_DADDIU_CODE
#define USE_NEW_DSUBU_CODE


#define USE_NEW_MFHI_CODE
#define USE_NEW_MFLO_CODE

#define USE_NEW_MULT_CODE
#define USE_NEW_MULTU_CODE
#define USE_NEW_DIV_CODE
#define USE_NEW_DIVU_CODE

#define USE_NEW_MULT1_CODE
#define USE_NEW_MULTU1_CODE
#define USE_NEW_DIV1_CODE
#define USE_NEW_DIVU1_CODE

#define USE_NEW_MFHI1_CODE
#define USE_NEW_MFLO1_CODE

#define USE_NEW_MADD_CODE
#define USE_NEW_MADD1_CODE
#define USE_NEW_MADDU_CODE
#define USE_NEW_MADDU1_CODE


#define USE_NEW_BEQL_CODE
#define USE_NEW_BNEL_CODE
#define USE_NEW_BLTZL_CODE
#define USE_NEW_BGTZL_CODE
#define USE_NEW_BLEZL_CODE
#define USE_NEW_BGEZL_CODE

#define USE_NEW_BLTZALL_CODE
#define USE_NEW_BGEZALL_CODE


#define USE_NEW_PAND_CODE
#define USE_NEW_POR_CODE
#define USE_NEW_PXOR_CODE
#define USE_NEW_PNOR_CODE

#define USE_NEW_PCEQB_CODE
#define USE_NEW_PCEQH_CODE
#define USE_NEW_PCEQW_CODE

#define USE_NEW_PCGTB_CODE
#define USE_NEW_PCGTH_CODE
#define USE_NEW_PCGTW_CODE

#define USE_NEW_PMINH_CODE
#define USE_NEW_PMINW_CODE
#define USE_NEW_PMAXH_CODE
#define USE_NEW_PMAXW_CODE

#define USE_NEW_PADDB_CODE
#define USE_NEW_PADDH_CODE
#define USE_NEW_PADDW_CODE

#define USE_NEW_PSUBB_CODE
#define USE_NEW_PSUBH_CODE
#define USE_NEW_PSUBW_CODE

#define USE_NEW_PABSH_CODE
#define USE_NEW_PABSW_CODE

#define USE_NEW_PADDSB_CODE
#define USE_NEW_PADDSH_CODE

#define USE_NEW_PADDUB_CODE
#define USE_NEW_PADDUH_CODE

#define USE_NEW_PSUBSB_CODE
#define USE_NEW_PSUBSH_CODE

#define USE_NEW_PSUBUB_CODE
#define USE_NEW_PSUBUH_CODE

#define USE_NEW_PSLLH_CODE
#define USE_NEW_PSLLW_CODE

#define USE_NEW_PSRAH_CODE

#define USE_NEW_PSRAW_CODE

#define USE_NEW_PSRLH_CODE
#define USE_NEW_PSRLW_CODE

#define USE_NEW_PSLLVW_CODE
#define USE_NEW_PSRAVW_CODE
#define USE_NEW_PSRLVW_CODE

#define USE_NEW_PEXTLB_CODE
#define USE_NEW_PEXTLH_CODE
#define USE_NEW_PEXTLW_CODE
#define USE_NEW_PEXTUB_CODE
#define USE_NEW_PEXTUH_CODE
#define USE_NEW_PEXTUW_CODE
#define USE_NEW_PINTH_CODE
#define USE_NEW_PINTEH_CODE

#define USE_NEW_PEXCH_CODE
#define USE_NEW_PEXCW_CODE
#define USE_NEW_PEXEH_CODE
#define USE_NEW_PEXEW_CODE

#define USE_NEW_PCPYLD_CODE
#define USE_NEW_PCPYUD_CODE
#define USE_NEW_PCPYH_CODE

#define USE_NEW_PPACB_CODE
#define USE_NEW_PPACH_CODE
#define USE_NEW_PPACW_CODE

#define USE_NEW_QFSRV_CODE

#define USE_NEW_PADSBH_CODE
#define USE_NEW_PLZCW_CODE

#define USE_NEW_PMULTH_CODE
#define USE_NEW_PMULTW_CODE
#define USE_NEW_PMULTUW_CODE

#define USE_NEW_PDIVBW_CODE
#define USE_NEW_PDIVW_CODE
#define USE_NEW_PDIVUW_CODE

#define USE_NEW_PMADDH_CODE
#define USE_NEW_PMADDW_CODE
#define USE_NEW_PMADDUW_CODE
#define USE_NEW_PMSUBH_CODE
#define USE_NEW_PMSUBW_CODE

#define USE_NEW_PHMADH_CODE
#define USE_NEW_PHMSBH_CODE

#define USE_NEW_PMFLO_CODE
#define USE_NEW_PMFHI_CODE


#define USE_NEW_PMTLO_CODE
#define USE_NEW_PMTHI_CODE

#define USE_NEW_PMFHL_LH_CODE
#define USE_NEW_PMFHL_LW_CODE
#define USE_NEW_PMFHL_SH_CODE
#define USE_NEW_PMFHL_SLW_CODE
#define USE_NEW_PMFHL_UW_CODE

#define USE_NEW_PMTHL_LW_CODE

#define USE_NEW_PEXT5_CODE
#define USE_NEW_PPAC5_CODE


#define USE_NEW_ABS_S_CODE
#define USE_NEW_MOV_S_CODE
#define USE_NEW_NEG_S_CODE
#define USE_NEW_MAX_S_CODE
#define USE_NEW_MIN_S_CODE
#define USE_NEW_C_F_S_CODE

#define USE_NEW_C_EQ_S_CODE
#define USE_NEW_C_LT_S_CODE
#define USE_NEW_C_LE_S_CODE

#define USE_NEW_MUL_S_CODE
#define USE_NEW_MULA_S_CODE

#define USE_NEW_DIV_S_CODE

#define USE_NEW_ADD_S_CODE
#define USE_NEW_ADDA_S_CODE
#define USE_NEW_SUB_S_CODE
#define USE_NEW_SUBA_S_CODE

#define USE_NEW_SQRT_S_CODE
#define USE_NEW_RSQRT_S_CODE


#define USE_NEW_CVT_S_W_CODE
#define USE_NEW_CVT_W_S_CODE

#define USE_NEW_MADD_S_CODE
#define USE_NEW_MADDA_S_CODE
#define USE_NEW_MSUB_S_CODE
#define USE_NEW_MSUBA_S_CODE





#define USE_NEW_VNOP_CODE

#define USE_NEW_VABS_CODE

#define USE_NEW_VMAX_CODE
#define USE_NEW_VMIN_CODE


#define USE_NEW_VFTOI0_CODE
#define USE_NEW_VFTOI4_CODE
#define USE_NEW_VFTOI12_CODE
#define USE_NEW_VFTOI15_CODE


#define USE_NEW_VITOF0_CODE
#define USE_NEW_VITOF4_CODE
#define USE_NEW_VITOF12_CODE
#define USE_NEW_VITOF15_CODE



#define USE_NEW_VMOVE_CODE
#define USE_NEW_VMR32_CODE


#define USE_NEW_VIADD_CODE
#define USE_NEW_VIADDI_CODE
#define USE_NEW_VIAND_CODE
#define USE_NEW_VIOR_CODE
#define USE_NEW_VISUB_CODE


#define USE_NEW_VMFIR_CODE
#define USE_NEW_VMTIR_CODE


#define USE_NEW_CFC2_NI_CODE
#define USE_NEW_CTC2_NI_CODE


#define USE_NEW_QMFC2_NI_CODE
#define USE_NEW_QMTC2_NI_CODE


#define USE_NEW_VDIV_CODE
#define USE_NEW_VRSQRT_CODE
#define USE_NEW_VSQRT_CODE


#define USE_NEW_VCLIP_CODE


#define USE_NEW_VADD_CODE
#define USE_NEW_VADDi_CODE
#define USE_NEW_VADDq_CODE
#define USE_NEW_VADDX_CODE
#define USE_NEW_VADDY_CODE
#define USE_NEW_VADDZ_CODE
#define USE_NEW_VADDW_CODE



#define USE_NEW_VADDA_CODE
#define USE_NEW_VADDAi_CODE
#define USE_NEW_VADDAq_CODE
#define USE_NEW_VADDAX_CODE
#define USE_NEW_VADDAY_CODE
#define USE_NEW_VADDAZ_CODE
#define USE_NEW_VADDAW_CODE



#define USE_NEW_VSUB_CODE
#define USE_NEW_VSUBi_CODE
#define USE_NEW_VSUBq_CODE
#define USE_NEW_VSUBX_CODE
#define USE_NEW_VSUBY_CODE
#define USE_NEW_VSUBZ_CODE
#define USE_NEW_VSUBW_CODE

#define USE_NEW_VSUBA_CODE
#define USE_NEW_VSUBAi_CODE
#define USE_NEW_VSUBAq_CODE
#define USE_NEW_VSUBAX_CODE
#define USE_NEW_VSUBAY_CODE
#define USE_NEW_VSUBAZ_CODE
#define USE_NEW_VSUBAW_CODE


#define USE_NEW_VMUL_CODE
#define USE_NEW_VMULi_CODE
#define USE_NEW_VMULq_CODE
#define USE_NEW_VMULX_CODE
#define USE_NEW_VMULY_CODE
#define USE_NEW_VMULZ_CODE
#define USE_NEW_VMULW_CODE


#define USE_NEW_VMULA_CODE
#define USE_NEW_VMULAi_CODE
#define USE_NEW_VMULAq_CODE
#define USE_NEW_VMULAX_CODE
#define USE_NEW_VMULAY_CODE
#define USE_NEW_VMULAZ_CODE
#define USE_NEW_VMULAW_CODE



#define USE_NEW_VMADD_CODE
#define USE_NEW_VMADDi_CODE
#define USE_NEW_VMADDq_CODE
#define USE_NEW_VMADDX_CODE
#define USE_NEW_VMADDY_CODE
#define USE_NEW_VMADDZ_CODE
#define USE_NEW_VMADDW_CODE



#define USE_NEW_VMADDA_CODE
#define USE_NEW_VMADDAi_CODE
#define USE_NEW_VMADDAq_CODE
#define USE_NEW_VMADDAX_CODE
#define USE_NEW_VMADDAY_CODE
#define USE_NEW_VMADDAZ_CODE
#define USE_NEW_VMADDAW_CODE


#define USE_NEW_VMSUB_CODE
#define USE_NEW_VMSUBi_CODE
#define USE_NEW_VMSUBq_CODE
#define USE_NEW_VMSUBX_CODE
#define USE_NEW_VMSUBY_CODE
#define USE_NEW_VMSUBZ_CODE
#define USE_NEW_VMSUBW_CODE


#define USE_NEW_VMSUBA_CODE
#define USE_NEW_VMSUBAi_CODE
#define USE_NEW_VMSUBAq_CODE
#define USE_NEW_VMSUBAX_CODE
#define USE_NEW_VMSUBAY_CODE
#define USE_NEW_VMSUBAZ_CODE
#define USE_NEW_VMSUBAW_CODE


#define USE_NEW_VOPMSUB_CODE
#define USE_NEW_VOPMULA_CODE





#define USE_NEW_ADDU_CODE2
#define USE_NEW_SUBU_CODE2


#define USE_NEW_AND_CODE2
#define USE_NEW_OR_CODE2
#define USE_NEW_XOR_CODE2
#define USE_NEW_NOR_CODE2



#define USE_NEW_SLT_CODE2
#define USE_NEW_SLTU_CODE2


#define USE_NEW_ADDIU_CODE2
#define USE_NEW_ANDI_CODE2
#define USE_NEW_ORI_CODE2
#define USE_NEW_XORI_CODE2

#define USE_NEW_LUI_CODE2


#define USE_NEW_SLTI_CODE2
#define USE_NEW_SLTIU_CODE2




#define USE_NEW_SLL_CODE2
#define USE_NEW_SRL_CODE2
#define USE_NEW_SRA_CODE2

#define USE_NEW_SLLV_CODE2
#define USE_NEW_SRLV_CODE2
#define USE_NEW_SRAV_CODE2



#define USE_NEW_SB_CODE2
#define USE_NEW_SH_CODE2
#define USE_NEW_SW_CODE2
#define USE_NEW_SWR_CODE2
#define USE_NEW_SWL_CODE2
#define USE_NEW_SD_CODE2
#define USE_NEW_SDR_CODE2
#define USE_NEW_SDL_CODE2


//#define USE_NEW_SQ_CODE2
//#define USE_NEW_SQC2_CODE2


#define USE_NEW_LB_CODE2
#define USE_NEW_LH_CODE2
#define USE_NEW_LW_CODE2
#define USE_NEW_LBU_CODE2
#define USE_NEW_LHU_CODE2
#define USE_NEW_LWU_CODE2
#define USE_NEW_LD_CODE2



#define USE_NEW_LWR_CODE2
#define USE_NEW_LWL_CODE2
#define USE_NEW_LDL_CODE2
#define USE_NEW_LDR_CODE2


//#define USE_NEW_LQ_CODE2
//#define USE_NEW_LQC2_CODE2



#define USE_NEW_DADDU_CODE2
#define USE_NEW_DSUBU_CODE2

#define USE_NEW_DADDIU_CODE2

#define USE_NEW_DSLL_CODE2
#define USE_NEW_DSRL_CODE2
#define USE_NEW_DSRA_CODE2

#define USE_NEW_DSLL32_CODE2
#define USE_NEW_DSRL32_CODE2
#define USE_NEW_DSRA32_CODE2

#define USE_NEW_DSLLV_CODE2
#define USE_NEW_DSRLV_CODE2
#define USE_NEW_DSRAV_CODE2

#define USE_NEW_MOVZ_CODE2
#define USE_NEW_MOVN_CODE2



#define USE_NEW_VRINIT_CODE
#define USE_NEW_VRGET_CODE
#define USE_NEW_VRXOR_CODE
#define USE_NEW_VRNEXT_CODE



#define CHECK_EVENT_AFTER_START
#define CHECK_EVENT_AFTER_START_BRANCH


//#define ENABLE_SINGLE_STEP
//#define ENABLE_SINGLE_STEP_BEFORE



#define CACHE_NOT_IMPLEMENTED


// test pc arg pass, new methodology etc
//#define TEST_NEW_CODE


// check that instructions in cached-region were not modified since last recompile
//#define CHECK_CACHED_INSTRUCTIONS


//#define USE_MEMORYPTR_FOR_CACHED_REGION


//#define USE_GETPTR_FOR_CACHED_REGION


// theoretically, anything in BIOS is read-only
//#define DONT_CHECK_BIOS_INSTRUCTIONS



//#define INCLUDE_ICACHE_RELOAD




//#define ALWAYS_USE_MEMORYPTR_FOR_ENCODING


#define ENCODE_SINGLE_RUN_PER_BLOCK


#define UPDATE_BEFORE_RETURN


// crashes unless you do this ?? Compiler dependent?
#define RESERVE_STACK_FRAME_FOR_CALL


//#define ENABLE_AUTONOMOUS_BRANCH_U
//#define ENABLE_AUTONOMOUS_BRANCH_C


//#define VERBOSE_RECOMPILE


static u32* g_pSrcCodePtr;

Debug::Log R5900::Recompiler::debug;

x64Encoder *Recompiler::e;
//ICache_Device *Recompiler::ICache;
R5900::Cpu *R5900::Recompiler::r;
s32 R5900::Recompiler::OpLevel;
u32 R5900::Recompiler::LocalPC;
u32 R5900::Recompiler::Local_LastModifiedReg;
u32 R5900::Recompiler::Local_NextPCModified;

u32 R5900::Recompiler::CurrentCount;

u32 R5900::Recompiler::isBranchDelaySlot;
u32 R5900::Recompiler::isLoadDelaySlot;

u32 R5900::Recompiler::bStopEncodingAfter;
u32 R5900::Recompiler::bStopEncodingBefore;

u32 R5900::Recompiler::NumBlocks_Mask;
u32* R5900::Recompiler::StartAddress;
u32* R5900::Recompiler::LastOffset;


//u32 Recompiler::Local_DelaySlot;
//u32 Recompiler::Local_DelayType;
//u32 Recompiler::Local_DelayCount;
//u32 Recompiler::Local_DelayCond;
//u32 Recompiler::Local_Condition;
R5900::Instruction::Format Recompiler::NextInst;

//Recompiler::RDelaySlot Recompiler::RDelaySlots [ 2 ];
//u32 Recompiler::DSIndex;
//u32 Recompiler::RDelaySlots_Valid;

u32 Recompiler::RunCount;
u32 Recompiler::RunCount2;

u64 Recompiler::MemCycles;

u64 Recompiler::LocalCycleCount;
u64 Recompiler::LocalCycleCount2;
u64 Recompiler::CacheBlock_CycleCount;

bool Recompiler::bIsBlockInICache;

u32 Recompiler::bResetCycleCount;


u32 Recompiler::CurrentBlock_StartAddress;
u32 Recompiler::NextBlock_StartAddress;

u32* Recompiler::pForwardBranchTargets;
u32 Recompiler::ForwardBranchIndex;

u8** Recompiler::pPrefix_CodeStart;
u8** Recompiler::pCodeStart;
u32* Recompiler::CycleCount;


#ifdef ENABLE_R5900_CHECKSUM
u64* Recompiler::pChecksum64;
#endif


u32 Recompiler::ulIndex_Mask;
u32 Recompiler::MaxStep;
u32 Recompiler::MaxStep_Shift;
u32 Recompiler::MaxStep_Mask;

u32 Recompiler::StartBlockIndex;
u32 Recompiler::BlockIndex;

u64 Recompiler::ullLSRegs;

// multi-pass optimization vars //
u64 Recompiler::ullSrcRegBitmap;
u64 Recompiler::ullDstRegBitmap;

// the x64 registers that are currently allocated to MIPS registers
u64 Recompiler::ullTargetAlloc;

// the MIPS registers that are currently allocated to x64 registers
u64 Recompiler::ullSrcRegAlloc;

// the MIPS registers that are currently allocated to be constants
u64 Recompiler::ullSrcConstAlloc;

// the MIPS registers that have been modified and not written back yet
u64 Recompiler::ullSrcRegsModified;

// registers that are on the stack and need to be restored when done
u64 Recompiler::ullRegsOnStack;

// registers that are needed later on in the code
u64 Recompiler::ullNeededLater;

u64 Recompiler::ullSrcRegBitmaps [ 16 ];
u64 Recompiler::ullDstRegBitmaps [ 16 ];
u64 Recompiler::ullRegsStillNeeded [ 16 ];

// the actual data stored for the register, either a reg index or a constant value
u64 Recompiler::ullTargetData [ 32 ];


// lookup that indicates what register each target index corresponds to
const int Recompiler::iRegPriority [ 13 ] = { RAX, RDX, R8, R9, R10, R11, RBX, RSI, RDI, R12, R13, R14, R15 };

// lookup that indicates if the register requires you to save it on the stack before using it
// 0: no need to save on stack, 1: save and restore on stack
const int Recompiler::iRegStackSave [ 13 ] = { 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1 };



alignas(16) static const u8 recompiler_qfsrv_shift_table [ 16 * 16 ] = {
	0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0,
	0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1,
	0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2,
	0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3,
	0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4,
	0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5,
	0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6,
	0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7,
	0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8,
	0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa, 0x9,
	0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb, 0xa,
	0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc, 0xb,
	0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd, 0xc,
	0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe, 0xd,
	0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf, 0xe,
	0xe, 0xd, 0xc, 0xb, 0xa, 0x9, 0x8, 0x7, 0x6, 0x5, 0x4, 0x3, 0x2, 0x1, 0x0, 0xf
};

// with the right as dest and left as src
alignas(16) static const u8 recompiler_qfsrv_blend_table [ 16 * 16 ] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00, 0x00,
	0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x00
};


alignas(16) static const u8 recompiler_qfsrv_shift_table_rev [ 16 * 16 ] = {
	0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf,
	0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0,
	0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1,
	0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2,
	0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3,
	0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4,
	0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5,
	0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6,
	0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7,
	0x9, 0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8,
	0xa, 0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9,
	0xb, 0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa,
	0xc, 0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb,
	0xd, 0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc,
	0xe, 0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd,
	0xf, 0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc, 0xd, 0xe
};

// with the right as dest and left as src
alignas(16) static const u8 recompiler_qfsrv_blend_table_rev [ 16 * 16 ] = {
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80,
	0x00, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80
};


//static u64 recompiler_qfsrv_temp [ 4 ] __attribute__ ((aligned (16)));
alignas(16) static u64 recompiler_r5900_temp [ 4 ];


// lookup table for op shuffles
u8 _op_r5900_shuffle_lut_1 [ 16 ] = {
0x00, // 0x0000
0x00, // 0x0001
0x55, // 0x0010
0x50, // 0x0011

0xa0, // 0x0100
0xa0, // 0x0101
0xa5, // 0x0110
0x00, // 0x0111

0xf0, // 0x1000
0xf0, // 0x1001
0xf5, // 0x1010
0x00, // 0x1011

0xfa, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};

u8 _op_r5900_shuffle_lut_2 [ 16 ] = {
0x00, // 0x0000
0x0d, // 0x0001
0x0d, // 0x0010
0x0d, // 0x0011

0x30, // 0x0100
0x31, // 0x0101
0x34, // 0x0110
0x00, // 0x0111

0xc0, // 0x1000
0xc1, // 0x1001
0xc4, // 0x1010
0x00, // 0x1011

0xd0, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};

u8 _op_r5900_add_shuffle_lut_2 [ 16 ] = {
0x00, // 0x0000
0x0a, // 0x0001
0x0a, // 0x0010
0x08, // 0x0011

0x20, // 0x0100
0x20, // 0x0101
0x20, // 0x0110
0x00, // 0x0111

0x80, // 0x1000
0x80, // 0x1001
0x80, // 0x1010
0x00, // 0x1011

0x80, // 0x1100
0x00, // 0x1101
0x00, // 0x1110
0x00, // 0x1111
};



// returns -1 if there was a problem, otherwise returns number of instructions recompiled
// level 2 recompiler
// returns the next address after level 2 block, returns -1 on error
u32 Recompiler::Recompile2 ( u32 ulBeginAddress )
{
	// the index used for looping
	int iIdx;
	int iRegIdx;
	
	// maximum number of level2 recompiled instructions in this run
	u32 ulMaxRun2;
	
	// the real number of instructions in the level 2 recompilation run
	u32 ulRealRun2;
	
	// the current address
	u32 ulAddress;
	
	Instruction::Format inst;
	u32* pSrcCodePtr;
	
	int iRet;
	
	u64 ullCombineBitmap;
	u64 ullCurAlloc;
	u64 ullBitmap;
	
	// this depends on the size of the cache blocks for the processor
	//ulMaxRun2 = MaxStep - ( ( ulBeginAddress >> MaxStep_Shift ) & MaxStep_Mask );
	ulMaxRun2 = MaxStep - ( ( ulBeginAddress >> 2 ) & MaxStep_Mask );
	
	// first go through and get the source and destination registers //
	
	// start from the begin address
	ulAddress = ulBeginAddress;
	
	// get the pointer into the instructions
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( ulAddress );
	
	// set oplevel to preprocess info
	OpLevel = -1;

#ifdef VERBOSE_RECOMPILE
	cout << "\nRecompile2: starting pass1.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nRECOMPILE2: Starting pass1.";
	debug << " ADDR:" << hex << ulAddress;
	debug << " MAXRUN=" << dec << ulMaxRun2;
	debug << " SHIFT=" << MaxStep_Shift;
	debug << " MASK=" << MaxStep_Mask;
#endif
	
	for ( iIdx = 0; iIdx < ulMaxRun2; iIdx++ )
	{
		// get the instruction
		inst.Value = *pSrcCodePtr++;
		
		// init src and dst reg bitmaps
		ullSrcRegBitmap = 0;
		ullDstRegBitmap = 0;
		
#ifdef VERBOSE_RECOMPILE
cout << "\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << ulAddress;
#endif

		// get the source and dest register bitmaps
		iRet = Recompile ( inst, ulAddress );

#ifdef VERBOSE_RECOMPILE
cout << " iRet=" << dec << iRet;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iRet=" << dec << iRet;
#endif
		
		if ( iRet < 0 ) break;

#ifdef VERBOSE_RECOMPILE
cout << " SrcBmp=" << hex << ullSrcRegBitmap;
cout << " DstBmp=" << hex << ullDstRegBitmap;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SrcBmp=" << hex << ullSrcRegBitmap;
	debug << " DstBmp=" << hex << ullDstRegBitmap;
#endif
		
		// store the bitmap data for this instruction
		ullSrcRegBitmaps [ iIdx ] = ullSrcRegBitmap;
		ullDstRegBitmaps [ iIdx ] = ullDstRegBitmap;
	}
	
	// set the actual number of instructions to be recompiled at level 2
	ulRealRun2 = iIdx;
	
	// if fewer than 2 instructions can be recompiled, there's no benefit
	if ( ulRealRun2 < 2 )
	{
		// before returning, set oplevel back to what it was
		OpLevel = 2;
		
		return -1;
	}
	
	ullCombineBitmap = 0;
	
	// fill in the bitmap for registers that are needed
	for ( iIdx = ulRealRun2 - 1; iIdx >= 0; iIdx-- )
	{
		ullRegsStillNeeded [ iIdx ] = ullCombineBitmap;
		
		ullCombineBitmap |= ullSrcRegBitmaps [ iIdx ];
	}
	
	
	// start from the begin address
	ulAddress = ulBeginAddress;
	
	// get the pointer into the instructions
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( ulAddress );
	
	// set oplevel to encode the actual instruction
	OpLevel = 2;
	
	// init bitmaps for allocation
	ullTargetAlloc = 0;
	ullSrcRegAlloc = 0;
	ullSrcConstAlloc = 0;
	
	// set r0 as a constant zero
	Alloc_Const ( 0, 0 );
	
	// now clear regs modified, including r0 modified bit
	ullSrcRegsModified = 0;
	
	// clear any regs on stack
	ullRegsOnStack = 0;


#ifdef VERBOSE_RECOMPILE
	cout << "\nRecompile2: starting pass2.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\nRecompile2: starting pass2.";
	debug << " MAXRUN=" << dec << ulRealRun2;
#endif
	
	// encode run //
	
	LocalCycleCount2 = LocalCycleCount;
	
	RunCount2 = 0;
	
	// encode the instructions ??
	for ( iIdx = 0; iIdx < ulRealRun2; iIdx++ )
	{
		// get the instruction
		inst.Value = *pSrcCodePtr++;
		
		// set the registers that are still needed later
		ullNeededLater = ullRegsStillNeeded [ iIdx ];
		
		// set the source and dest registers on source machine
		ullSrcRegBitmap = ullSrcRegBitmaps [ iIdx ];
		ullDstRegBitmap = ullDstRegBitmaps [ iIdx ];
		
#ifdef VERBOSE_RECOMPILE
cout << "\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ASM2: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << ulAddress;
#endif

		// encode the instruction
		iRet = Recompile ( inst, ulAddress );

#ifdef VERBOSE_RECOMPILE
cout << " iRet=" << dec << iRet;
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iRet=" << dec << iRet;
#endif
		
		if ( iRet <= 0 )
		{
			break;
		}
		
		// automatically remove register allocations that are no longer needed (except r0)
		// *** todo ***
//#ifdef INLINE_DEBUG_RECOMPILE2
//	debug << " ullCurAlloc=" << hex << ullCurAlloc;
//	debug << " ullNeededLater=" << hex << ullNeededLater;
//#endif
		ullCurAlloc = ( ullSrcRegAlloc ) & ~1;
		while ( ullCurAlloc & ~( ullNeededLater ) )
		{
			// get the next register that is no longer needed
			ullBitmap = ullCurAlloc & ~( ullNeededLater );
			ullBitmap &= -ullBitmap;
			
			// get its index
			//iRegIdx = __builtin_ctz( ullBitmap );
			iRegIdx = ctz64(ullBitmap);

			// remove it and remove from bitmap
			DisposeReg( iRegIdx );
			ullCurAlloc &= ~( 1ull << iRegIdx );
		}
		
		// update to the next address
		ulAddress += 4;
		
		// used by load/store/etc
		RunCount2++;
		
		// update cycles
		LocalCycleCount2 += MemCycles;
	}
	

	// if fewer than 2 instructions can be recompiled, there's no benefit
	if ( iIdx < 2 )
	{
		// before returning, set oplevel back to what it was
		OpLevel = 2;
		
		return -1;
	}

#ifdef VERBOSE_RECOMPILE
cout << "\n ***L2 ENCODED***";
#endif
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n ***L2 ENCODED***";
#endif

	// write back all registers
	WriteBackModifiedRegs ();

//#ifdef VERBOSE_RECOMPILE
//cout << "\n Restoring regs from stack";
//#endif
//#ifdef INLINE_DEBUG_RECOMPILE2
//	debug << "\r\n Restoring regs from stack";
//#endif
	
	// restore regs from stack
	RestoreRegsFromStack ();
	
	// return the number of instructions that got recompiled at level-2
	return iIdx;
}

// check for branch,jump,syscall, or anything that breaks a static load dependency check
bool Recompiler::Check_StaticDependencyOk ( R5900::Instruction::Format i )
{
	switch ( i.Opcode )
	{
		// j,jal don't have source regs
		case 0x2:
		case 0x3:
			return 0;
			break;
			
		// LUI uses only rt as source reg
		case 0xf:
			return 1;
			break;
			
		// cop0
		case 0x10:
			// mtc0 is rt
			if ( i.Rs == 4 )
			{
				return 1;
			}
			break;
			
		// cop1
		case 0x11:
			// mtc1 and ctc1 are rt
			if ( i.Rs == 4 || i.Rs == 6 )
			{
				return 1;
			}
			break;
			
		// cop2
		case 0x12:
			// qmtc2 and ctc2 are rt
			if ( i.Rs == 5 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// beq is rs and rt
		case 0x4:
		
		// bne is rs and rt
		case 0x5:
		
		// beql is rs and rt
		case 0x14:
		
		// bnel is rs and rt
		case 0x15:
		
		// SQ is rs and rt
		case 0x1f:
			return 0;
			break;
			
		// special
		case 0:
			// rows 0,3,4,7 are ok
			if ( ( i.Opcode >> 3 ) == 0 || ( i.Opcode >> 3 ) == 3 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 7 )
			{
				return 1;
			}
			
			// row 6 not ok
			if ( ( i.Opcode >> 3 ) == 6 )
			{
				return 0;
			}
			
			switch( i.Funct )
			{
				// syscall
				case 0xc:
				
				// break
				case 0xd:
				
				// sync
				case 0xf:
					return 0;
				
				// jr is rs only
				case 0x8:
				
				// jalr is rs only
				case 0x9:
					return 0;
					break;
					
				// mfhi
				case 0x10:
				
				// mflo
				case 0x12:
				
				// mfsa
				case 0x28:
				
				// mthi is rs only
				case 0x11:
				
				// mtlo is rs only
				case 0x13:
				
				// mtsa is rs only
				case 0x29:
					return 1;
					break;
					
				// remainder is rs and rt
				default:
					return 1;
					break;
			}
			
			break;
			
		// regimm is rs only
		case 0x1:
			if ( i.Rt >= 0x18 )
			{
				return 1;
			}
			break;
		
		// daddiu is rs only
		case 0x19:
			return 1;
			break;
			
		// addi
		case 0x8:
		
		// daddi is rs only
		case 0x18:
			
		// blez is rs only
		case 0x6:
		
		// bgtz is rs only
		case 0x7:
		
		// blezl is rs only
		case 0x16:
		
		// bgtzl is rs only
		case 0x17:
		
		// ldl is rs only
		case 0x1a:
		
		// ldr is rs only
		case 0x1b:
		
		// lq is rs only
		case 0x1e:
		
		// cache is rs only
		case 0x2f:
		
		// pref
		case 0x33:
		
		// swc1 is rs only
		case 0x39:
			return 0;
			break;
			
		// mmi
		case 0x1c:
			return 1;
			
			// mmix
			switch ( i.Funct )
			{
				// mmi0
				case 0x8:
					return 1;
					break;
					
				// mmi2
				case 0x9:
					return 1;
					break;
					
				// mmi1
				case 0x28:
					return 1;
					break;
					
				// mmi3
				case 0x29:
					return 1;
					break;
			}
			
			// mt is ok
			if ( ( i.Funct & 0x1 ) == 1 )
			{
				return 1;
			}
			
			break;
			
		default:
			// rest of rows 1 are ok
			if ( ( i.Opcode >> 3 ) == 1 )
			{
				return 0;
			}
			
			// rows 4 and after are not ok
			if ( ( i.Opcode >> 3 ) >= 4 )
			{
				return 0;
			}
			
			break;
			
	}
	
	return 0;
}

// get the GPR source registers for an instruction (GPR regs only)
unsigned long long Recompiler::GetGPR_SrcRegs ( R5900::Instruction::Format i )
{
	switch ( i.Opcode )
	{
		// j,jal don't have source regs
		case 0x2:
		case 0x3:
			return 0;
			break;
			
		// LUI uses only rt as source reg
		case 0xf:
			return ( 1ull << i.Rt );
			break;
			
		// cop0
		case 0x10:
			// mtc0 is rt
			if ( i.Rs == 4 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// cop1
		case 0x11:
			// mtc1 and ctc1 are rt
			if ( i.Rs == 4 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// cop2
		case 0x12:
			// qmtc2 and ctc2 are rt
			if ( i.Rs == 5 || i.Rs == 6 )
			{
				return ( 1ull << i.Rt );
			}
			break;
			
		// beq is rs and rt
		case 0x4:
		
		// bne is rs and rt
		case 0x5:
		
		// beql is rs and rt
		case 0x14:
		
		// bnel is rs and rt
		case 0x15:
		
		// SQ is rs and rt
		case 0x1f:
			return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			break;
			
		// special
		case 0:
			// rows 0,3,4,6,7 are rs and rt
			if ( ( i.Opcode >> 3 ) == 0 || ( i.Opcode >> 3 ) == 3 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 6 || ( i.Opcode >> 3 ) == 7 )
			{
				return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			}
			
			switch( i.Funct )
			{
				// syscall
				case 0xc:
				
				// break
				case 0xd:
				
				// sync
				case 0xf:
				
				// mfhi
				case 0x10:
				
				// mflo
				case 0x12:
				
				// mfsa
				case 0x28:
					return 0;
					break;
					
				// jr is rs only
				case 0x8:
				
				// jalr is rs only
				case 0x9:
				
				// mthi is rs only
				case 0x11:
				
				// mtlo is rs only
				case 0x13:
				
				// mtsa is rs only
				case 0x29:
					return ( 1ull << i.Rs );
					break;
					
				// remainder is rs and rt
				default:
					return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					break;
			}
			
			break;
			
		// regimm is rs only
		case 0x1:
		
		// blez is rs only
		case 0x6:
		
		// bgtz is rs only
		case 0x7:
		
		// blezl is rs only
		case 0x16:
		
		// bgtzl is rs only
		case 0x17:
		
		// daddi is rs only
		case 0x18:
			
		// daddiu is rs only
		case 0x19:
		
		// ldl is rs only
		case 0x1a:
		
		// ldr is rs only
		case 0x1b:
		
		// lq is rs only
		case 0x1e:
		
		// cache is rs only
		case 0x2f:
		
		// pref
		case 0x33:
		
		// swc1 is rs only
		case 0x39:
			return ( 1ull << i.Rs );
			break;
			
		// mmi
		case 0x1c:
			// lower-right corner is rt
			if ( ( i.Funct >> 3 ) >= 6 && ( i.Funct & 0x7 ) >= 4 )
			{
				return ( 1ull << i.Rt );
			}
			
			// plzcw is rs
			if ( i.Funct == 0x4 )
			{
				return ( 1ull << i.Rs );
			}
			
			// rest on rows 0,3,4 are rs and rt
			if ( ( i.Funct >> 3 ) == 0 || ( i.Funct >> 3 ) == 3 || ( i.Funct >> 3 ) == 4 )
			{
				return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			}
			
			// mmix
			switch ( i.Funct )
			{
				// mmi0
				case 0x8:
					// less than 0x1c is both, otherwise just rt
					if ( i.Shift < 0x1c )
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rt );
					}
					
					break;
					
				// mmi2
				case 0x9:
					// lower-right corner is just rt, otherwise both
					if ( ( i.Shift & 0x3 ) >= 2 && ( i.Shift >> 2 ) >= 6 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					
					break;
					
				// mmi1
				case 0x28:
					// pabsw and pabsh are rt, otherwise rs and rt
					if ( i.Shift == 1 || i.Shift == 5 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					break;
					
				// mmi3
				case 0x29:
					// pmthi/pmtlo are just rs
					if ( i.Shift == 8 || i.Shift == 9 )
					{
						return ( 1ull << i.Rs );
					}
					
					// lower-right corner is just rt, otherwise both
					if ( ( i.Shift & 0x3 ) >= 2 && ( i.Shift >> 2 ) >= 6 )
					{
						return ( 1ull << i.Rt );
					}
					else
					{
						return ( 1ull << i.Rs ) | ( 1ull << i.Rt );
					}
					break;
			}
			
			// mt is rs as source
			if ( ( i.Funct & 0x1 ) == 1 )
			{
				return ( 1ull << i.Rs );
			}
			
			break;
			
		default:
			// rows 1,4,6 are rs only
			if ( ( i.Opcode >> 3 ) == 1 || ( i.Opcode >> 3 ) == 4 || ( i.Opcode >> 3 ) == 6 )
			{
				return ( 1ull << i.Rs );
			}
			
			break;
			
	}
	
	return 0;
}


unsigned long long Recompiler::GetCop1_SrcRegs ( R5900::Instruction::Format i0 )
{
	if ( i0.Opcode == 0x39 )
	{
		return ( 1ull << i0.Ft );
	}
	
	if ( i0.Opcode == 0x11 )
	{
		// cop1 instruction //
		if ( !i0.Rs )
		{
			// mfc1 //
			return ( 1ull << i0.Fs );
		}
		else if ( i0.Rs >= 0x10 )
		{
			switch ( i0.Funct )
			{
				case 0x05:
				case 0x06:
				case 0x07:
				case 0x24:
					return ( 1ull << i0.Fs );
					break;
					
				default:
					return ( 1ull << i0.Fs ) | ( 1ull << i0.Ft );
					break;
			}
		}
	}
	
	return 0;
}


// dispose the old register but reassign the new register to the same register on target device
// returns -1 on error, otherwise returns the register on target device
int Recompiler::RenameReg ( int iNewSrcRegIdx, int iOldSrcRegIdx )
{
	int iIdx;
	int iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nRecompiler::RenameReg";
#endif

	// if the same register, then return the register on target device
	if ( iNewSrcRegIdx == iOldSrcRegIdx )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " REGS-MATCH";
#endif

		// make sure it is a register
		if ( ullSrcRegAlloc & ( 1ull << iOldSrcRegIdx ) )
		{
			// if register has been renamed, then it has been modified ??
			ullSrcRegsModified |= ( 1ull << iNewSrcRegIdx );
			
			// return the actual register on target device
			iIdx = ullTargetData [ iOldSrcRegIdx ];
			return iRegPriority [ iIdx ];
		}
		else
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR";
#endif

			// error ??
			return -1;
		}
	}
	
	// deallocate the old source register assigned to the target device register
	iIdx = DisposeReg ( iOldSrcRegIdx );
	
	// new source register is not a constant
	ullSrcConstAlloc &= ~( 1ull << iNewSrcRegIdx );
	
	// assign that register to the new source device register
	ullTargetData [ iNewSrcRegIdx ] = iIdx;
	ullSrcRegAlloc |= ( 1ull << iNewSrcRegIdx );
	ullTargetAlloc |= ( 1ull << iIdx );
	
	// if register has been renamed, then it has been modified ??
	ullSrcRegsModified |= ( 1ull << iNewSrcRegIdx );
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ullSrcRegsModified=" << hex << ullSrcRegsModified;
	debug << " TargetReg=" << dec << iRegPriority [ iIdx ];
#endif

	// return the actual register on the target device
	return iRegPriority [ iIdx ];
}



// returns -1 on error, returns id of register (not the actual register) on target device otherwise
int Recompiler::DisposeReg ( int iSrcRegIdx )
{
	int iRealRegIdx;
	u64 ullValue;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nRecompiler::DisposeReg";
	debug << " MIPSReg#" << dec << iSrcRegIdx;
#endif

	// check that register id is valid
	if ( iSrcRegIdx < 0 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR-INVALID-ID";
#endif

		return -1;
	}
	
	// check if register is allocated
	if ( ! isAlloc( iSrcRegIdx ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ERROR-NOT-ALLOCATED";
#endif

		// register not allocated, so nothing to do
		return -1;
	}
	
	// check if register is modified (means needs write back)
	if ( ullSrcRegsModified & ( 1ull << iSrcRegIdx ) )
	{
		// check if constant or not
		if ( isConst( iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " WRITE-BACK-CONST";
	debug << " Value=" << hex << ullTargetData [ iSrcRegIdx ];
#endif
			ullValue = ullTargetData [ iSrcRegIdx ];

			if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
			{
				e->MovReg64ImmX ( RCX, ullValue );
				e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, RCX );
			}
			else
			{
				// *** todo *** write back constant
				//e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullTargetData [ iSrcRegIdx ] );
				e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullValue );
			}
		}
		else
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " WRITE-BACK-REG";
#endif

			// *** todo *** write back register
			iRealRegIdx = iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
			e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, iRealRegIdx );
		}
	}
	
	// clear modified bitmap
	ullSrcRegsModified &= ~( 1ull << iSrcRegIdx );
	
	// check if register
	if ( isReg( iSrcRegIdx ) )
	{
		// clear target bitmap
		ullTargetAlloc &= ~( 1ull << ( ullTargetData [ iSrcRegIdx ] ) );
	}
	
	// clear reg bitmap
	ullSrcRegAlloc &= ~( 1ull << iSrcRegIdx );
	
	// clear const bitmap
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " RETURN=" << dec << ullTargetData [ iSrcRegIdx ];
#endif

	// return the old target register id
	return ullTargetData [ iSrcRegIdx ];
}

bool Recompiler::isAlloc ( int iSrcRegIdx )
{
	if ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isLarge ( u64 ullValue )
{
	if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isConst ( int iSrcRegIdx )
{
	// check if register is a constant
	if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isReg ( int iSrcRegIdx )
{
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isDisposable( int iSrcRegIdx )
{
	if ( ullNeededLater & ( 1ull << iSrcRegIdx ) )
	{
		return false;
	}
	else
	{
		return true;
	}
}


bool Recompiler::isBothAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isBothConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcConstAlloc & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isBothReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcRegAlloc & ullBitmap ) == ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isBothDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ! ( ullNeededLater & ullBitmap ) )
	{
		return false;
	}
	else
	{
		return true;
	}
}


// ---------------------------------------------

bool Recompiler::isEitherAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullSrcConstAlloc | ullSrcRegAlloc ) & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isEitherConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ullSrcConstAlloc & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isEitherReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ullSrcRegAlloc & ullBitmap )
	{
		return true;
	}
	
	return false;
}

bool Recompiler::isEitherDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	
	if ( ( ullNeededLater & ullBitmap ) == ullBitmap )
	{
		return false;
	}
	
	return true;
}



int Recompiler::SelectAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ( ullSrcRegAlloc | ullSrcConstAlloc );
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int Recompiler::SelectConst ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullSrcConstAlloc;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int Recompiler::SelectReg ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullSrcRegAlloc;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int Recompiler::SelectDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ~ullNeededLater;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}


int Recompiler::SelectNotAlloc ( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ~( ullSrcRegAlloc | ullSrcConstAlloc );
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}

int Recompiler::SelectNotDisposable( int iSrcRegIdx1, int iSrcRegIdx2 )
{
	u64 ullBitmap;
	ullBitmap = ( 1ull << iSrcRegIdx1 ) | ( 1ull << iSrcRegIdx2 );
	ullBitmap &= ullNeededLater;
	ullBitmap &= -ullBitmap;
	//return __builtin_ctz( ullBitmap );
	return ctz64(ullBitmap);
}



// returns -1 if error, otherwise returns index of register on target platform
// iSrcRegIdx: index of register on source platform (for example, MIPS)
int Recompiler::Alloc_SrcReg ( int iSrcRegIdx )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->Recompiler::Alloc_SrcReg";
#endif

	// make sure register id is valid
	if ( iSrcRegIdx < 0 )
	{
		return -1;
	}
	
	
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		// return the index or register on the target platform
		//__builtin_ctz ();
		return iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
	}
	
	// get the next available register on target //
	
	// there are currently 13 available registers, so make sure there is one available
	//if ( ( ullTargetAlloc & 0x1fff ) == 0x1fff )
	if ( ( ullTargetAlloc & c_ulUsableRegsBitmap ) == c_ulUsableRegsBitmap )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR*** NO MORE REGISTERS";
#endif

		cout << "\nERROR: no more registers on r5900 recompile L2.\n";

		// no more registers available
		return -1;
	}
	
	// get the next target register available
	ullBitmap = ~ullTargetAlloc;
	ullBitmap &= -ullBitmap;
	
	// get the index it is allocated to on target
	// *** gcc specific code *** //
	//iIdx = __builtin_ctz( ullBitmap );
	iIdx = ctz64(ullBitmap);


	
	// get the actual register to use from the index
	iRegIdx = iRegPriority [ iIdx ];
	
	// if the register needs to be saved, push it onto stack unless it is already saved
	if ( iRegStackSave [ iIdx ] )
	{
		if ( ! ( ullRegsOnStack & ( 1ull << iIdx ) ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SAVING-ONSTACK x64Reg#" << dec << iRegIdx;
#endif

			// push the register onto the stack //
			e->PushReg64( iRegIdx );
			
			// mark register as being on the stack
			ullRegsOnStack |= ( 1ull << iIdx );
		}
	}
	
	// check if register is a constant
	if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
	{
		//return -1;
		e->MovReg64ImmX ( iRegIdx, ullTargetData [ iSrcRegIdx ] );
	}
	else
	{
		// load in the source register (only for Alloc_SrcReg)
		e->MovRegMem64 ( iRegIdx, & r->GPR [ iSrcRegIdx ].sq0 );
	}


	// set that register as allocated to a variable reg
	ullSrcRegAlloc |= ( 1ull << iSrcRegIdx );
	
	// .. not a constant
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
	// and allocated on target
	ullTargetAlloc |= ullBitmap;
	
	// set the index it is allocated to on target
	ullTargetData [ iSrcRegIdx ] = iIdx;

	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " x64Reg#" << dec << iRegIdx << " -> " << " MIPSReg#" << dec << iSrcRegIdx;
#endif
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->Recompiler::Alloc_SrcReg";
	debug << " return=" << dec << iRegIdx;
#endif

	// done
	return iRegIdx;
}


int Recompiler::Alloc_DstReg ( int iSrcRegIdx )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->Recompiler::Alloc_DstReg";
	debug << " ullTargetAlloc=" << hex << ullTargetAlloc;
#endif

	// make sure register id is valid
	if ( iSrcRegIdx < 0 )
	{
		return -1;
	}
	
	// check if register is a constant
	//if ( ullSrcConstAlloc & ( 1 << iSrcRegIdx ) )
	//{
	//	return -1;
	//}
	
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
		// register is already allocated as a register //
		
		// make sure register is set as being modified (might have been a source reg previously)
		ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
		
		// return the index or register on the target platform
		//__builtin_ctz ();
		return iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
	}
	
	// get the next available register on target //
	
	// there are currently 13 available registers, so make sure there is one available
	//if ( ( ullTargetAlloc & 0x1fff ) == 0x1fff )
	if ( ( ullTargetAlloc & c_ulUsableRegsBitmap ) == c_ulUsableRegsBitmap )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR*** NO MORE REGISTERS";
#endif

		cout << "\nERROR: no more registers on r5900 recompile L2.\n";

		// no more registers available
		return -1;
	}
	
	// get the next target register available
	ullBitmap = ~ullTargetAlloc;
	ullBitmap &= -ullBitmap;
	
	// get the index it is allocated to on target
	// *** gcc specific code *** //
	//iIdx = __builtin_ctz( ullBitmap );
	iIdx = ctz64(ullBitmap);

	// set the register as modified, since it is a destination register
	ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
	
	// set that register as allocated to a variable reg
	ullSrcRegAlloc |= ( 1ull << iSrcRegIdx );
	
	// .. not a constant
	ullSrcConstAlloc &= ~( 1ull << iSrcRegIdx );
	
	// and allocated on target
	ullTargetAlloc |= ullBitmap;
	
	// set the index it is allocated to on target
	ullTargetData [ iSrcRegIdx ] = iIdx;
		
	// get the actual register to use from the index
	iRegIdx = iRegPriority [ iIdx ];
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " x64Reg#" << dec << iRegIdx << " -> " << "MIPSReg#" << iSrcRegIdx;
#endif

	// if the register needs to be saved, push it onto stack unless it is already saved
	if ( iRegStackSave [ iIdx ] )
	{
		if ( ! ( ullRegsOnStack & ( 1ull << iIdx ) ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " SAVING-ONSTACK x64Reg#" << dec << iRegIdx;
#endif

			// push the register onto the stack //
			e->PushReg64( iRegIdx );
			
			// mark register as being on the stack
			ullRegsOnStack |= ( 1ull << iIdx );
		}
	}
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " RETURN=" << dec << iRegIdx;
	debug << "\r\nEND->Recompiler::Alloc_DstReg";
#endif

	// done
	return iRegIdx;
}


// returns -1 if error, otherwise returns 1
// iSrcRegIdx: index of register on source platform (for example, MIPS)
int Recompiler::Alloc_Const ( int iSrcRegIdx, u64 ullValue )
{
	u64 ullBitmap;
	int iIdx, iRegIdx;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->Recompiler::Alloc_Const";
#endif

	/*
	if ( ( ( ullValue >> 32 ) != 0 ) && ( ( ullValue >> 32 ) != 0xffffffffull ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\n***ERROR: Constant is 64-bits: " << hex << iSrcRegIdx << ullValue;
#endif

		cout << "\n***ERROR: Constant is 64-bits: " << hex << iSrcRegIdx << ullValue;
	}
	*/

	// if reg is allocated, then deallocate it
	// check if register is already allocated
	if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Reg#" << dec << iSrcRegIdx << " already allocated as REGISTER. Deallocating.";
#endif
		// remove from allocation on target
		// get index of register on target
		iIdx = ullTargetData [ iSrcRegIdx ];
		
		// remove from target reg bitmap
		ullTargetAlloc &= ~( 1ull << iIdx );
		
		// clear the bit in source reg bitmap
		ullSrcRegAlloc &= ~( 1ull << iSrcRegIdx );
	}

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Allocating Const#" << dec << iSrcRegIdx << " with value: " << hex << ullValue;
#endif
	
	// set register as a constant
	ullSrcConstAlloc |= ( 1ull << iSrcRegIdx );
	
	// set the constants as modified on source device (they need to be written back)
	ullSrcRegsModified |= ( 1ull << iSrcRegIdx );
	
	// set the value of the constant
	ullTargetData [ iSrcRegIdx ] = ullValue;

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->Recompiler::Alloc_Const";
	debug << " return=" << dec << iSrcRegIdx;
#endif
	
	return iSrcRegIdx;
}

// write back any constants and registers that were modified in the run
void Recompiler::WriteBackModifiedRegs ()
{
	u64 ullBitmap;
	int iSrcRegIdx;
	int iRegIdx;
	
	u64 ullSrcRegsModified2;
	u64 ullValue;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->Recompiler::WriteBackModifiedRegs";
#endif
	
	ullSrcRegsModified2 = ullSrcRegsModified;
	
	// loop while there are source device registers (and/or constants) that need to be written back
	while ( ullSrcRegsModified2 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nullSrcRegsModified2=" << hex << ullSrcRegsModified2;
#endif

		ullBitmap = ullSrcRegsModified2 & -ullSrcRegsModified2;
		
		// get the next register on source device
		//iSrcRegIdx = __builtin_ctz( ullBitmap );
		iSrcRegIdx = ctz64(ullBitmap);

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " iSrcRegIdx=" << dec << iSrcRegIdx;
#endif
		
		// check if it is a register or constant
		if ( ullSrcConstAlloc & ( 1ull << iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Writing back Constant#" << dec << iSrcRegIdx;
	debug << " Value:" << hex << ullTargetData [ iSrcRegIdx ];
#endif

			ullValue = ullTargetData [ iSrcRegIdx ];

			// write back constant //
			if ( ( ( ullValue >> 31 ) != 0ull ) && ( ( ullValue >> 31 ) != 0x1ffffffffull ) )
			{
				e->MovReg64ImmX ( RCX, ullValue );
				e->MovMemReg64 ( &r->GPR [ iSrcRegIdx ].sq0, RCX );
			}
			else
			{
				// *** todo *** write back constant
				//e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullTargetData [ iSrcRegIdx ] );
				e->MovMemImm64 ( &r->GPR [ iSrcRegIdx ].sq0, ullValue );
			}
		}
		else if ( ullSrcRegAlloc & ( 1ull << iSrcRegIdx ) )
		{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Writing back Register#" << dec << iSrcRegIdx;
#endif

			// write back register //
			iRegIdx = iRegPriority [ ullTargetData [ iSrcRegIdx ] ];
			e->MovMemReg64 ( & r->GPR [ iSrcRegIdx ].sq0, iRegIdx );
		}
		
		// remove from bitmaps
		ullSrcRegsModified2 &= ~ullBitmap;
		//ullSrcConstAlloc &= ~ullBitmap;
		//ullSrcRegAlloc &= ~ullBitmap;
	}
	
	//ullSrcRegsModified = 0;
	//ullSrcConstAlloc = 1;
	//ullSrcRegAlloc = 0;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->Recompiler::WriteBackModifiedRegs";
#endif
}

// restore any registers that were saved on the stack to process the run
void Recompiler::RestoreRegsFromStack ()
{
	u64 ullBitmap;
	int iRegIdx;
	int iIdx;
	
	u64 ullRegsOnStack2;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nSTART->Recompiler::RestoreRegsFromStack";
#endif

	ullRegsOnStack2 = ullRegsOnStack;

	// loop while there are still registers on the stack
	while ( ullRegsOnStack2 )
	{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nullRegsOnStack2=" << hex << ullRegsOnStack2;
#endif

		// get the next register
		//ullBitmap = ullRegsOnStack2 & -ullRegsOnStack2;
		
		// get it's target device index
		//iRegIdx = __builtin_ctz( ullBitmap );
		//iRegIdx = __builtin_clz( ullRegsOnStack2 );
		iRegIdx = clz64(ullRegsOnStack2);
		iRegIdx = 31 - iRegIdx;

		iIdx = iRegPriority [ iRegIdx ];

#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " Restoring x64REG#" << dec << iIdx;
#endif

		// pop register from the stack
		e->PopReg64( iIdx );
		
		// remove register from bitmap
		//ullRegsOnStack2 &= ~ullBitmap;
		ullRegsOnStack2 &= ~( 1 << iRegIdx );
	}
	
	//ullRegsOnStack = 0;
	
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nEND->Recompiler::RestoreRegsFromStack";
#endif
}




// constructor
// NumberOfBlocks MUST be a power of 2, so 1 would mean 2, 2 would mean 4
Recompiler::Recompiler ( Cpu* R5900Cpu, u32 NumberOfBlocks, u32 BlockSize_PowerOfTwo, u32 MaxIStep_Shift )
{
#ifdef INLINE_DEBUG_ENABLE

#ifdef INLINE_DEBUG_SPLIT
	// put debug output into a separate file
	debug.SetSplit ( true );
	debug.SetCombine ( false );
#endif

	debug.Create( "PS2_R5900Recompiler_Log.txt" );
#endif
	
	BlockSize = 1 << BlockSize_PowerOfTwo;
	
	MaxStep_Shift = MaxIStep_Shift;
	MaxStep = 1 << MaxIStep_Shift;
	MaxStep_Mask = MaxStep - 1;
	
	NumBlocks = 1 << NumberOfBlocks;
	NumBlocks_Mask = NumBlocks - 1;
	
	// need a mask for referencing each encoded instruction
	ulIndex_Mask = 1 << ( NumberOfBlocks + MaxIStep_Shift );
	ulIndex_Mask -= 1;
	
	// allocate variables
	//StartAddress = new u32 [ NumBlocks ];
	//RunCount = new u8 [ NumBlocks ];
	//MaxCycles = new u64 [ NumBlocks ];
	//Instructions = new u32 [ NumBlocks * MaxStep ];
	
	// only need to compare the starting address of the entire block
	StartAddress = new u32 [ NumBlocks ];
	LastOffset = new u32 [ NumBlocks ];


#ifdef ENABLE_R5900_CHECKSUM
	// 64-bit checksum of the source - final check to determine if recompile is really needed
	pChecksum64 = new u64 [ NumBlocks ];
#endif


	pCodeStart = new u8* [ NumBlocks * MaxStep ];
	CycleCount = new u32 [ NumBlocks * MaxStep ];
	//EndAddress = new u32 [ NumBlocks * MaxStep ];



	pForwardBranchTargets = new u32 [ MaxStep ];
	
	// used internally by recompiler (in case it branches to a load/store or another branch, etc, then need to go to prefix instead)
	pPrefix_CodeStart = new u8* [ NumBlocks * MaxStep ];



	
	// create the encoder
	//e = new x64Encoder ( BlockSize_PowerOfTwo, NumBlocks );
	InstanceEncoder = new x64Encoder ( BlockSize_PowerOfTwo, NumBlocks );
	
	e = InstanceEncoder;
	
	/*
	// set the "alternate stream" with the code to clear a block
	// which should just simply return 1 (meaning to recompile the block)
	e->SwitchToAlternateStream ();
	e->MovReg32ImmX ( RAX, 1 );
	e->Ret ();
	
	// we're done in the "alternate stream"
	e->SwitchToLiveStream ();
	
	// I'd like to know the size of the code
	cout << "\nSize of alternate stream in bytes: " << dec << e->lAlternateStreamSize << " Alt Stream=" << hex << e->ullAlternateStream;
	
	// reset all the blocks
	//for ( int i = 0; i < NumBlocks; i++ ) InitBlock ( i );
	for ( int i = 0; i < NumBlocks; i++ ) e->Emit_AltStreamToBlock8 ( i );
	*/
	
	//cout << "\nAfter clear, live code stream=" << hex << (((u64*)e->LiveCodeArea) [ 0 ]);
	//cout << "\n#2=" << hex << ((u64*)e->LiveCodeArea) [ ( ( (NumBlocks-1) & e->lCodeBlockSize_Mask ) << e->lCodeBlockSize_PowerOfTwo ) >> 3 ];
	//cout << " offset=" << hex << ( ( ( 2 & e->lCodeBlockSize_Mask ) << e->lCodeBlockSize_PowerOfTwo ) >> 3 );
	
	// testing
	//pCodeStart [ 0x27e4 >> 2 ] = 0x5373b36;
	
	//ICache = IC;
	r = R5900Cpu;
	
	Reset ();
}


// destructor
Recompiler::~Recompiler ()
{
	delete e;
	
	delete StartAddress;
	
	delete pPrefix_CodeStart;
	delete pCodeStart;
	delete CycleCount;
	delete pForwardBranchTargets;
	
	// delete the variables that were allocated
	/*
	delete StartAddress;
	delete RunCount;
	delete MaxCycles;
	delete Instructions;
	*/
}


void Recompiler::Reset ()
{
	//memset ( this, 0, sizeof( Recompiler ) );	
	// initialize the address and instruction so it is known that it does not refer to anything
	memset ( pForwardBranchTargets, 0x00, sizeof( u32 ) * MaxStep );
	memset ( pPrefix_CodeStart, 0x00, sizeof( u8* ) * NumBlocks * MaxStep );
	memset ( StartAddress, 0xff, sizeof( u32 ) * NumBlocks );
	memset ( pCodeStart, 0x00, sizeof( u8* ) * NumBlocks * MaxStep );
	memset ( CycleCount, 0x00, sizeof( u32 ) * NumBlocks * MaxStep );


#ifdef ENABLE_R5900_CHECKSUM
	memset( pChecksum64, 0xff, sizeof( u64 ) * NumBlocks );
#endif


#ifdef ENABLE_ICACHE
	// reset invalidate arrays
	r->Bus->Reset_Invalidate ();
#endif
}



/** 
 * @fn static void Calc_Checksum( VU *v )
 * @brief calculate checksum for source of recompiled code and store into "ullChecksum"
 * @param v is a pointer into the CPU object state that holds the source code that was recompiled
 * @return 64-bit checksum calculated from source cpu code mem at the current point in time
 */
u64 Recompiler::Calc_Checksum( u32 StartAddress )
{
	u32* pSrcPtr32;
	u64 ullAddress;
	u64 ullCode;
	u64 ullCurChecksum;

	u64 ullLoopCount;

	// the starting address needs to be on a block boundary
	StartAddress = ( StartAddress >> ( 2 + MaxStep_Shift ) ) << ( 2 + MaxStep_Shift );

	// get pointer into the vu memory starting from beginning
	//pSrcPtr32 = RGetPointer ( r, StartAddress );
	pSrcPtr32 = & r->Bus->MainMemory.b32 [ ( StartAddress & Playstation2::DataBus::MainMemory_Mask ) >> 2 ];

	// init checksum
	ullCurChecksum = 0;

	// determine if this is vu0 or vu1
	// get the size of vu code mem based vu number etc
	ullLoopCount = 16;

	// calculate the check sum
	for ( ullAddress = 0; ullAddress < ullLoopCount; ullAddress++ )
	{
		// get the source code value
		ullCode = (u64) ( *pSrcPtr32++ );

		// multiply by the address
		ullCode *= ( ullAddress + 1 );

		ullCurChecksum += ullCode;
	}

	// go ahead and return check sum
	return ullCurChecksum;
}



// returns 1 if it is ok to have instruction in branch delay slot when recompiling, zero otherwise
bool Recompiler::isBranchDelayOk ( u32 ulInstruction, u32 Address )
{
#ifdef ENCODE_ALL_POSSIBLE_DELAYSLOTS

	u32 ulOpcode, ulFunction;
	
	ulOpcode = ulInstruction >> 26;
	
	
	// second row starting at second column is ok
	if ( ulOpcode >= 0x9 && ulOpcode <= 0xf )
	{

		// constant instructions that will never interrupt //
		//cout << "\nAddress=" << hex << Address << " Opcode=" << ulOpcode;
		return true;
	}
	
	
	
	// for R5900, DADDIU is ok //
	if ( ulOpcode == 0x19 )
	{
		return true;
	}
	
	
	
	// check special instructions
	if ( !ulOpcode )
	{
		ulFunction = ulInstruction & 0x3f;
		
		// first row is mostly ok
		if ( ( ( ulFunction >> 3 ) == 0 ) && ( ulFunction != 1 ) && ( ulFunction != 5 ) )
		{
			return true;
		}
		
		// row 4 is ok except for column 0 and column 2
		if ( ( ulFunction >> 3 ) == 4 && ulFunction != 0x20 && ulFunction != 0x22 )
		{
			return true;
		}
		
		// in row 5 for R3000A columns 2 and 3 are ok
		if ( ulFunction == 0x2a || ulFunction == 0x2b )
		{
			return true;
		}
		
		
		// in row 5 for R5900 columns 5 and 7 are ok //
		if ( ulFunction == 0x2d || ulFunction == 0x2f )
		{
			return true;
		}
		
		
		// for R5900, on row 2 MOVZ and MOVN are ok //
		if ( ulFunction == 0xa || ulFunction == 0xb )
		{
			return true;
		}
		
		
		// for R5900, on row 3 DSLLV, DSRLV, DSRAV or ok //
		if ( ulFunction == 0x14 || ulFunction == 0x16 || ulFunction == 0x17 )
		{
			return true;
		}
		
		// in last row for R5900, all is ok except columns 1 and 5 //
		if ( ( ulFunction >> 3 ) == 7 && ulFunction != 0x39 && ulFunction != 0x3d )
		{
			return true;
		}
		
	}
	
	// will leave out all store instructions for now to play it safe //
	
#else
	if ( !ulInstruction ) return true;
#endif
	
	return false;
}


u32 Recompiler::CloseOpLevel ( u32 OptLevel, u32 Address )
{
	switch  ( OptLevel )
	{
		case 0:
			break;
			
		case 1:
			// write back last modified register if in load delay slot
			//if ( isLoadDelaySlot )
			//{
				e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, Local_LastModifiedReg );
			//}
			
			// write back "NextPC" if there was no SYSCALL
			if ( !Local_NextPCModified )
			{
				e->MovMemImm32 ( (long*) & r->NextPC, Address );
			}
			break;
			
		case 2:
			// write back last modified register if in load delay slot
			//if ( isLoadDelaySlot )
			//{
				e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, Local_LastModifiedReg );
			//}
			
			// write back "NextPC" if there was no SYSCALL
			if ( !Local_NextPCModified )
			{
				e->MovMemImm32 ( (long*) & r->NextPC, Address );
			}
			break;
	}

	return true;
}


// if block has no recompiled code, then it should return 1 (meaning to recompile the instruction(s))
u32 Recompiler::InitBlock ( u32 Block )
{
	// set the encoder to use
	e = InstanceEncoder;

	// start encoding in block
	e->StartCodeBlock ( Block );
	
	// set return value 1 (return value for X64 goes in register A)
	e->LoadImm32 ( RAX, 1 );
	
	// return
	e->x64EncodeReturn ();
	
	// done encoding in block
	e->EndCodeBlock ();

	return true;
}



u32* Recompiler::RGetPointer ( u32 Address )
{

	
#ifdef VERBOSE_RECOMPILE
cout << "\nRGetPointer: NON-CACHED";
#endif

	// address is NOT cache-able //
	
	if ( ( Address & 0x1fc00000 ) == 0x1fc00000 )
	{
		// cached bios region //
		return & r->Bus->BIOS.b32 [ ( Address & r->Bus->BIOS_Mask ) >> 2 ];
	}
	
	// cached ram region //
	return & r->Bus->MainMemory.b32 [ ( Address & r->Bus->MainMemory_Mask ) >> 2 ];
}


// returns the bitmap for the source registers for instruction
// if the instruction is not supported, then it will return -1ULL
u64 Recompiler::GetSourceRegs ( R5900::Instruction::Format i, u32 Address )
{
	/*
	if ( !i.Value )
	{
		return 0;
	}
	*/
	
	// "special"
	if ( !i.Opcode )
	{
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// regimm
	if ( i.Opcode == 1 )
	{
		// rs is source reg //
		
		return ( 1ULL << i.Rs );
	}
	
	// j, jal
	if ( i.Opcode <= 3 )
	{
		return 0;
	}
	
	// beq, bne, blez, bgtz
	if ( ( i.Opcode >> 3 ) == 0 )
	{
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// immediates
	if ( ( i.Opcode >> 3 ) == 1 )
	{
		return ( 1ULL << i.Rs );
	}
	
	// stores
	if ( ( i.Opcode >> 3 ) == 5 )
	{
		return 0;
	}
	
	// loads
	if ( ( i.Opcode >> 3 ) == 4 )
	{
		return ( 1ULL << i.Rs );
	}
	
	return -1ULL;
	
	/*
	// check for "special"
	if ( !i.Opcode )
	{
		// rs,rt are source regs //
		
		// not including syscall or break, but these shouldn't cause problems
		if ( ( i.Funct == 12 ) || ( i.Funct == 13 ) )
		{
			return 0;
		}
		
		//if ( ( i.Funct >> 3 ) == 0 )
		//{
		//	return -1;
		//}
		
		return ( ( 1ULL << i.Rs ) | ( 1ULL << i.Rt ) );
	}
	
	// stores are cleared to go (runs load delay before the store)
	if ( ( i.Opcode >> 3 ) == 5 )
	{
		return 0;
	}
	
	// check for regimm, immediates, loads
	if ( ( i.Opcode == 1 ) || ( ( i.Opcode >> 3 ) == 1 ) || ( ( i.Opcode >> 3 ) == 4 ) )
	{
		// rs is source reg //
		
		return ( 1ULL << i.Rs );
	}
	
	// any other instructions are not cleared to go
	return -1ULL;
	*/
}


// returns the bitmap for the destination registers for instruction
// if the instruction is not supported, then it will return -1ULL
u64 Recompiler::Get_DelaySlot_DestRegs ( R5900::Instruction::Format i )
{
	
	/*
	// check for "special"
	if ( !i.Opcode )
	{
		// rd is dest reg //
		
		// not including syscall or break, but these shouldn't cause problems
		if ( ( i.Funct == 12 ) || ( i.Funct == 13 ) )
		{
			return 0;
		}
		
		
		return ( 1ULL << i.Rd );
	}
	
	// check for regimm
	if ( ( i.Opcode == 1 ) )
	{
		// rd is dest reg //
		
		if ( i.Rt >= 16 )
		{
			return ( 1ULL << 31 );
		}
	}
	
	// check for jal
	if ( i.Opcode == 3 )
	{
		return ( 1ULL << 31 );
	}
	
	// immediates
	if ( ( i.Opcode >> 3 ) == 1 )
	{
		return ( 1ULL << i.Rt );
	}
	*/
	
	// loads
	/*
	if ( ( i.Opcode >> 3 ) == 4 )
	{
		// rt is dest reg //
		
		return ( 1ULL << i.Rt );
	}
	*/
	
	
	
	// any other instructions are not cleared to go
	return 0;
}


/*
u64 Recompiler::ReturnZero ( void )
{
	return 0;
}


u64 Recompiler::ReturnOne ( void )
{
	return 1;
}


u64 Recompiler::ReturnTwo ( void )
{
	return 2;
}
*/




// returns number of instructions that were recompiled
u32 Recompiler::Recompile ( u32 BeginAddress )
{
	u32 Address, Block;
	s32 ret, Cycles;
	R5900::Instruction::Format inst;
	s32 reti;
	
	//u32 StartBlockIndex, BlockIndex, SaveBlockIndex;
	
	// number of instructions in current run
	//u32 RunCount;
	
	u32 RecompileCount;
	u32 MaxCount;
	
	//u32 ProjectedMaxCount;
	
	//u32 Snapshot_Address [ 4 ];
	//u32 Snapshot_RecompileCount [ 4 ];
	
	//static u64 MemCycles;
	u32 SetCycles;
	
	//u32* pInstrPtr;
	
	u32* pSrcCodePtr;
	u32* pNextCode;
	
	//u32* pCmpCodePtr;
	//u32* pSaveCodePtr;
	//u32* pSaveCmpPtr;
	
	u32 SaveReg0;
	u32 ulCacheLineCount;
	
	//u64 LocalCycleCount, CacheBlock_CycleCount;
	
	int RetJumpCounter;
	
	//char* ReturnFromCacheReload;
	
	int i;
	
	int iFillIndex;
	
	unsigned long First_LastModifiedReg;
	
	s32 MaxBlocks;
	
	u32 NextAddress;
	
	u64 ullSrcRegsBitmap, ullResultRegs, ullNextReg, ullNextRegIdx;
	
	
#ifdef VERBOSE_RECOMPILE
cout << "\nrecompile: starting recompile.";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nSTART->Recompiler::Recompile";
	debug << " BeginADDR=" << hex << BeginAddress;
#endif


	// need to first clear forward branch targets for the block
	memset ( pForwardBranchTargets, 0x00, sizeof( u32 ) * MaxStep );
	
	// initialize forward branch index
	// note: Will need a larger branch index table in the encoder object for larger code blocks than 128 instructions
	//ForwardBranchIndex = c_ulForwardBranchIndex_Start;


	// mask address
	// don't do this
	//StartAddress &= c_iAddress_Mask;
	
	// haven't crossed any cache lines yet
	ulCacheLineCount = 0;
	
	// set the encoder to use
	e = InstanceEncoder;
	
	// the starting address needs to be on a block boundary
	BeginAddress = ( BeginAddress >> ( 2 + MaxStep_Shift ) ) << ( 2 + MaxStep_Shift );
	
	// save the address?
	Address = BeginAddress;
	
	// set the start address for the current block so recompiler can access it
	CurrentBlock_StartAddress = BeginAddress;
	
	// set the start address for the next block also
	NextBlock_StartAddress = CurrentBlock_StartAddress + ( 1 << ( 2 + MaxStep_Shift ) );
	
	// set the current optimization level
	OpLevel = OptimizeLevel;
	
	// get the block to encode in
	// new formula
	//Block = ( BeginAddress >> 2 ) & NumBlocks_Mask;
	Block = ( BeginAddress >> ( 2 + MaxStep_Shift ) ) & NumBlocks_Mask;
	
	
	// set block initially to cache
	//DoNotCache [ Block ] = 0;
	
	// start in code block
	e->StartCodeBlock ( Block );
	
	// set the start address for code block
	// address must actually match exactly. No mask
	StartAddress [ Block ] = BeginAddress;

#ifdef ENABLE_R5900_CHECKSUM
	// also, go ahead and set the checksum for the block here
	pChecksum64 [ Block ] = Calc_Checksum( BeginAddress );
#endif
	
	// set the instruction
	//Instructions [ Block ] = *((u32*) SrcCode);
	//pInstrPtr = & ( Instructions [ Block << MaxStep_Shift ] );
	
	
	// start cycles at zero
	Cycles = 0;
	
	// start PC
	//LocalPC = r->PC;
	
	
	// init count of recompiled instructions
	RecompileCount = 0;
	
	
	// want to stop at cache boundaries (would need extra code there anyways)
	// this is handled in loop now
	//MaxCount = MaxStep - ( ( Address >> 2 ) & MaxStep_Mask );
	//if ( MaxCount <= 0 ) MaxCount = 1;
	// set the maximum number of instructions to encode
	MaxCount = MaxStep;
	
	
	// NextPC has not been modified yet
	Local_NextPCModified = false;
	
	// some instructions need to stop encoding either before or after the instruction, at least for now
	// if stopping before, it keeps the instruction if there is nothing before it in the run
	bStopEncodingAfter = false;
	bStopEncodingBefore = false;
	
	// don't reset the cycle count yet
	bResetCycleCount = false;


	
	// should set local last modified register to 255
	Local_LastModifiedReg = 255;
	
	reti = 1;
	
	
	

	// clear delay slot
	//RDelaySlots [ 0 ].Value = 0;
	//RDelaySlots [ 1 ].Value = 0;

	// clear delay slot valid bits
	//RDelaySlots_Valid = 0;
	

	
	/////////////////////////////////////////////////////
	// note: multiply and divide require cycle count to be updated first
	// since they take more than one cycle to complete
	// same for mfhi and mflo, because they are interlocked
	// same for COP2 instructions
	// same for load and store
	// do the same for jumps and branches
	//////////////////////////////////////////////////////

	
	
	// get the starting block to store instruction addresses and cycle counts
	StartBlockIndex = ( Address >> 2 ) & ulIndex_Mask;
	BlockIndex = StartBlockIndex;

	// zero out code start addresses
	for ( i = 0; i < MaxStep; i++ )
	{
		pCodeStart [ StartBlockIndex + i ] = NULL;
		pForwardBranchTargets [ i ] = -1;
	}
	
	// instruction count for current run
	RunCount = 0;
	ullLSRegs = 0;
	
	// current delay slot index
	//DSIndex = 0;
	
	// each instruction takes at least one cycle
	//if ( !MemCycles ) MemCycles = 1;
	
	
	
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( Address );
	
	// get the cycles per instruction
	// *** TODO FOR PS2 *** 
#ifdef ENABLE_ICACHE
	// if linking, then should not subtract the MemCycle, otherwise subtract the time to read the first instruction if exiting from recompiler
	// if linking, then should not subtract the ExeCycle for last instruction, otherwise should subtract it when exiting from recompiler
	if ( ICache_Device::isCached ( Address ) )
	{
		// address is cached //
		bIsBlockInICache = true;
		
		// one cycle to execute each instruction (unless reloading cache block)
		MemCycles = 1;
		//MemCycles = 0;
	}
	else
	{
		// address is NOT cache-able //
		bIsBlockInICache = false;
		
		// time to execute the instruction starts with the time to read it from memory
		if ( ( Address & 0x1fc00000 ) == 0x1fc00000 )
		{
			// bios region //
			MemCycles = Playstation2::DataBus::c_iBIOS_Read_Latency;
		}
		else
		{
			// ram region //
			MemCycles = Playstation2::DataBus::c_iRAM_Read_Latency;
		}
		
		// should be plus 1 like in the interpreter
		MemCycles += 1;
	}
#endif
	
	
	// *** todo ***
	// looks like cycles are set to 1 in interpreter, need to fix
	//MemCycles = 1;


	// need to keep track of cycles for run
	//LocalCycleCount = MemCycles - 1;
	//CacheBlock_CycleCount = 0;
	LocalCycleCount = 0;

	// need to know of any other jumps to return
	RetJumpCounter = 0;



	for( iFillIndex = 0; iFillIndex < MaxStep; iFillIndex++ )
	{

#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: iFillIndex=" << dec << iFillIndex << " MaxStep=" << MaxStep;
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: iFillIndex=" << dec << iFillIndex << " MaxStep=" << MaxStep;
#endif

	if ( !pCodeStart [ StartBlockIndex + iFillIndex ] )
	{
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: !pCodeStart";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: !pCodeStart";
#endif

	// need to keep track of cycles for run
	LocalCycleCount = 0;

	// need to know of any other jumps to return
	RetJumpCounter = 0;
	

	// instruction count for current run
	RunCount = 0;
	ullLSRegs = 0;

	
	// current delay slot index
	//DSIndex = 0;
	
	
	// save the address?
	//Address = BeginAddress;
	Address = BeginAddress + ( iFillIndex << 2 );
	
	// set the current optimization level
	OpLevel = OptimizeLevel;
	
	// haven't crossed any cache lines yet
	ulCacheLineCount = 0;
	
	// start cycles at zero
	Cycles = 0;
	
	
	
	// init count of recompiled instructions
	RecompileCount = 0;
	
	
	// want to stop at cache boundaries (would need extra code there anyways)
	// this is handled in loop now
	// set the maximum number of instructions to encode
	//MaxCount = MaxStep;
	MaxCount = MaxStep - iFillIndex;
	
	BlockIndex = StartBlockIndex + iFillIndex;
	
	// NextPC has not been modified yet
	Local_NextPCModified = false;
	
	// some instructions need to stop encoding either before or after the instruction, at least for now
	// if stopping before, it keeps the instruction if there is nothing before it in the run
	bStopEncodingAfter = false;
	bStopEncodingBefore = false;
	
	// don't reset the cycle count yet
	bResetCycleCount = false;


	
	// should set local last modified register to 255
	Local_LastModifiedReg = 255;
	
	reti = 1;
	
	
	// this should get pointer to the instruction
	pSrcCodePtr = RGetPointer ( Address );
	
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " START-ADDR=" << hex << Address;
	debug << " MaxCount=" << dec << MaxCount;
#endif
	
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Starting loop";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Starting loop";
#endif
	
	
	
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Starting loop";
#endif

	// for loads
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt
	// 3. check that there are no conflicts. If so, put load in delay slot, update Cycles,NextPC, then return
	// 4. encode load, then encode load delay slot
	// 5. if going across cache line and next line is not loaded, then put load in delay slot and return
	// 6. if it is a store in the delay slot, then can just process normally as if there is no delay slot and immediately load
	
	// for stores
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt
	// 3. encode store
	
	// for jumps/branches
	// 1. check that there are no events. If so, update Cycles,NextPC, then return
	// 2. check for synchronous interrupt (for jumps that might have them)
	// 3. check that there are no loads,stores,branches,delay slots, in the delay slot. If so, put branch/jump in delay slot, update Cycles,NextPC, then return
	// 4. encode jump/branch then encode delay slot
	// 5. if branching backwards within same block, if cached then make sure cache-block is loaded and then jump, implement forward jumps later?
	// 6. if not branching within same block or forward jumping before implementation, then update Cycles,NextPC, then return
	// 7. if going across cache blocks and next block not loaded, then put in delay slot and return
	
	// other delay slot instructions
	// 1. check that there are no conflicts with delay slot. If so, update Cycles,NextPC, then return
	// 2. encode instruction then encode delay slot
	// 3. if going across cache blocks and next block not loaded, then put in delay slot and return
	
	// finding source registers
	// special instructions can use rs,rt as source registers
	// stores use rs,rt as source registers
	// immediates and loads use only rs as source register



	// go ahead and set any
	
	
	//for ( i = 0; i < MaxCount; i++ )
	for ( i = iFillIndex; i < MaxStep; i++ )
	{
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiling: ADDR=" << hex << Address;
#endif


		// set the forward jumps before starting the instruction block
		// the forward jump should always be set here even if it has to redo the instruction
		Set_FJMPs ( Address );


		
		// start encoding a MIPS instruction
		e->StartInstructionBlock ();
		


			
		
#ifdef VERBOSE_RECOMPILE
cout << " INSTR#" << dec << i;
//cout << " LOC=" << hex << ((u64) e->Get_CodeBlock_CurrentPtr ());
cout << " CycleDiff=" << dec << LocalCycleCount;
#endif


		
		// get the instruction
		//inst.Value = *((u32*) SrcCode);
		inst.Value = *pSrcCodePtr;
		
		// get the next instruction
		// note: this does not work if the next address is in a new cache block and the region is cached
		NextInst.Value = *(pSrcCodePtr + 1);


		// temporary alerts //
		
		if ( inst.Opcode == 0x12 )
		{
			// alert on vdiv
			if ( ( inst.Imm11 == 0x3bc ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VDIV_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VDIV w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}

			// alert on vsqrt
			if ( ( inst.Imm11 == 0x3bd ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VSQRT_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VSQRT w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}


			// alert on vrsqrt
			if ( ( inst.Imm11 == 0x3be ) && ( NextInst.Imm11 != 0x3bf ) )
			{
#ifdef VERBOSE_VRSQRT_WO_WAITQ
				cout << "\nhps2x64: RECOMPILER: encountered VRSQRT w/o WAITQ at address:" << hex << Address;
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 1) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 2) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 3) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 4) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 5) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 6) ).c_str ();
				cout << "\n" << R5900::Instruction::Print::PrintInstruction ( *(pSrcCodePtr + 7) ).c_str ();
#endif
			}

		}


		

		g_pSrcCodePtr = pSrcCodePtr;
		
			// not in cached region //
			
			// still need to check against edge of block
			if ( ! ( ( Address + 4 ) & ( MaxStep_Mask << 2 ) ) )
			{
				// this can actually happen, so need to prevent optimizations there
				NextInst.Value = -1;
			}
		
		


#ifdef VERBOSE_RECOMPILE
cout << " OL=" << OpLevel;
#endif

		// check if a forward branch target needs to be set
		//if ( pForwardBranchTargets [ BlockIndex & MaxStep_Mask ] )
		//{
		//	// set the branch target
		//	e->SetJmpTarget ( pForwardBranchTargets [ BlockIndex & MaxStep_Mask ] );
		//}
		
		// this is internal to recompiler and says where heading for instruction starts at
		//pPrefix_CodeStart [ BlockIndex & MaxStep_Mask ] = e->Get_CodeBlock_CurrentPtr ();
		pPrefix_CodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
		
		// this can be changed by the instruction being recompiled to point to where the starting entry point should be for instruction instead of prefix
		pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
		
	
			// must add one to the cycle offset for starting point because the interpreter adds an extra cycle at the end of run
			//CycleCount [ BlockIndex ] = LocalCycleCount + 1;
			CycleCount [ BlockIndex ] = LocalCycleCount;
		
		
		//EndAddress [ BlockIndex ] = -1;
		
		
		if ( inst.Value )
		{
		
		if ( OpLevel == 2 )
		{
			ret = R5900::Recompiler::Recompile2( Address );
			
			Local_NextPCModified = false;
			bStopEncodingBefore = false;
			bStopEncodingAfter = false;

			// if encoding was successful, then do a forward jump
			// of course, meaning that more than just one instruction was encoded
			if ( ret > 1 )
			{
				// forward jump
				FJMP( Address, Address + ( ret << 2 ) );

				// act like it was all just one instruction for testing
				ret = 1;
			}
			
#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Recompile2 returns: " << dec << ret;
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Recompile2 returns: " << dec << ret;
#endif
		}
		else
		{
			
#ifdef ENABLE_GPR_REGISTER_TIMING
			// get the source registers for instruction
			ullSrcRegsBitmap = GetGPR_SrcRegs( inst );
			
			// check if a source reg might be loading from bus
			ullResultRegs = ullLSRegs & ullSrcRegsBitmap;
			while ( ullResultRegs )
			{
				ullNextReg = ullResultRegs & -ullResultRegs;
				
				ullNextRegIdx = __builtin_ctz( ullNextReg );
				
				// put in code to check for the register
				e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
				e->AddReg64ImmX ( RAX, LocalCycleCount );
				//e->MovRegReg64 ( RCX, RAX );
				e->SubRegMem64 ( RAX, (long long*) & r->ullReg_BusyUntilCycle [ ullNextRegIdx ] );
				
				e->Cqo ();
				e->AndRegReg64 ( RAX, RDX );
				e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
				
				
				// remove register
				ullResultRegs ^= ullNextReg;
			}
#endif
			
		// recompile the instruction
		ret = R5900::Recompiler::Recompile ( inst, Address );
		
#ifdef INLINE_DEBUG_RECOMPILE
	debug << "\r\nRecompiler: Recompile1 returns: " << dec << ret;
#endif

#ifdef VERBOSE_RECOMPILE
cout << " ret=" << ret;
//cout << " ENC0=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 0 ]);
//cout << " ENC1=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 1 ]);
cout << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
	debug << " ADDR:" << hex << Address;
#endif

		}	// end if ( OpLevel == 2 ) else
		
		}
		else
		{

			ret = 1;

		}	// end if ( inst.Value ) else

		
#ifdef VERBOSE_RECOMPILE
cout << " ret=" << ret;
//cout << " ENC0=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 0 ]);
//cout << " ENC1=" << hex << (((u64*) (pCodeStart [ BlockIndex ])) [ 1 ]);
cout << " ASM: " << R5900::Instruction::Print::PrintInstruction ( inst.Value ).c_str ();
cout << " IDX: " << dec << R5900::Instruction::Lookup::FindByInstruction ( inst.Value );
#endif

		if ( ret <= 0 )
		{
			// there was a problem, and recompiling is done
			
			// need to undo whatever we did for this instruction
			e->UndoInstructionBlock ();
			Local_NextPCModified = false;
			
//cout << "\nUndo: Address=" << hex << Address;
			
			// TODO: if no instructions have been encoded yet, then just try again with a lower optimization level
			if ( OpLevel > 0 )
			{
//cout << "\nNext Op Level down";

				// could not encode the instruction at optimization level, so go down a level and try again
				OpLevel--;
				
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << "\r\nREDO@OPLEVEL=" << OpLevel;
#endif

				//Address -= 4;
				
				// at this point, this should be the last instruction since we had to go down an op level
				// this shouldn't be so, actually
				//MaxCount = 1;
				
				// here we need to reset and redo the instruction
				bStopEncodingBefore = false;
				bStopEncodingAfter = false;
				Local_NextPCModified = false;
				
				bResetCycleCount = false;
				
				// redo the instruction
				i--;
				continue;
			}
			else
			{
			
				cout << "\nhps2x64: R5900: Recompiler: Error: Unable to encode instruction.";
				
				// mark block as unable to recompile if there were no instructions recompiled at all
				//if ( !Cycles ) DoNotCache [ Block ] = 1;
				
				// done
				break;
			}
		}
		
#ifdef ENABLE_SINGLE_STEP_BEFORE
			if ( !OpLevel )
			{
				bStopEncodingBefore = true;
			}
#endif
		
		
			// if this is not the first instruction, then it can halt encoding before it
			if ( RunCount && bStopEncodingBefore )
			{
#ifdef VERBOSE_RECOMPILE
cout << " bStopEncodingBefore";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " bStopEncodingBefore";
#endif

#ifdef ENCODE_SINGLE_RUN_PER_BLOCK
				// first need to take back the instruction just encoded
				e->UndoInstructionBlock ();

				// check if we are in a new icache block //
				//if ( ! ( Address & 0xf ) )
				//{
				//	// in a new cache block, so must also clear branch to take back the instruction completely
				//	e->BranchOffset [ 64 + ( i >> 2 ) ] = -1;
				//}
				

				
#ifdef UPDATE_BEFORE_RETURN
				// run count has not been updated yet for the instruction to stop encoding before
				if ( RunCount > 1 )
				{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

					// check that NextPC was not modified
					// doesn't matter here except that RunCount>=1 so it is not first instruction in run, which is handled above
					// next pc was not modified because that will be handled differently now
					//if ( RunCount > 1 && !Local_NextPCModified )
					//{
						// update NextPC
						e->MovMemImm32 ( (long*) & r->NextPC, Address );
						
					//}
					
					// update CPU CycleCount
					// here is is returning, so subtract the cycles to read the first instruction and the cycles to execute the last
					//e->AddMem64ImmX ( (long long*) & r->CycleCount, CacheBlock_CycleCount - 1 );
					e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
					//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
				}
#endif

#ifdef VERBOSE_RECOMPILE
cout << " RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif

				// return;
				reti &= e->x64EncodeReturn ();


				
				// set the current optimization level
				// note: don't do this here, because the optimization level might have been changed by current instruction
				//OpLevel = OptimizeLevel;
				
				// reset flags
				bStopEncodingBefore = false;
				bStopEncodingAfter = false;
				Local_NextPCModified = false;
				
				bResetCycleCount = false;
				
				// starting a new run
				RunCount = 0;
				ullLSRegs = 0;
				
				// restart cycle count back to zero
				LocalCycleCount = 0;
				
				// clear delay slots
				//RDelaySlots [ 0 ].Value = 0;
				//RDelaySlots [ 1 ].Value = 0;
				
				//LocalCycleCount = MemCycles - 1;
				//CacheBlock_CycleCount = 0;
				
				// need to redo this instruction at this address
				// since I needed to insert the code to stop the block at this point
				i--;
				continue;
#else

				// do not encode instruction and done encoding
				e->UndoInstructionBlock ();
				Local_NextPCModified = false;
				break;
#endif
			} // end if ( RunCount && bStopEncodingBefore )

			
			
			
			// instruction successfully encoded from MIPS into x64
			e->EndInstructionBlock ();
			
//cout << "\nCool: Address=" << hex << Address << " ret=" << dec << ret << " inst=" << hex << *pSrcCodePtr << " i=" << dec << i;

			// update number of instructions that have been recompiled
			//RecompileCount++;
			RecompileCount += ret;
			
			// update to next instruction
			//pSrcCodePtr++;
			pSrcCodePtr += ret;
			
			// add number of cycles encoded
			Cycles += ret;
			
			// update address
			//Address += 4;
			Address += ( ret << 2 );

			// update instruction count for run
			//RunCount++;
			RunCount += ret;
			
			// go to next block index
			//BlockIndex++;
			BlockIndex += ret;
			
			// update the cycles for run
			//LocalCycleCount += MemCycles;
			LocalCycleCount += ( MemCycles * ret );
			
			// need to update i also since some instructions might have been skipped over with OpLevel 2
			i += ( ret - 1 );

#ifdef ENABLE_SINGLE_STEP
			//if ( ( NextInst.Opcode == 35 ) && ( inst.Opcode == 15 ) )
			//{
				//if ( ( (Address-4) > 0x1a6200 ) && ( (Address-4) < 0x1a6300 ) )
				//{
					//cout << "\n\n***PC=" << hex << (Address-4) << "***\n\n";
				
			bStopEncodingAfter = true;
				//}
			//}
#endif

			// reset the optimization level for next instruction
			OpLevel = OptimizeLevel;
			
			



		
		// if directed to stop encoding after the instruction, then do so
		if ( bStopEncodingAfter )
		{
#ifdef VERBOSE_RECOMPILE
cout << " bStopEncodingAfter";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " bStopEncodingAfter";
#endif

#ifdef ENCODE_SINGLE_RUN_PER_BLOCK


#ifdef UPDATE_BEFORE_RETURN
			// run count has already been updated at this point, but still on instruction#1
			if ( RunCount > 1 )
			{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

				// there is more than one instruction in run //
				
				// check that NextPC was not modified and that this is not an isolated instruction
				// actually just need to check if NextPC was modified by the encoded instruction
				if ( !Local_NextPCModified )
				{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " SET-NEXTPC";
#endif

					// update NextPC
					e->MovMemImm32 ( (long*) & r->NextPC, Address );
				}
				
				// update CycleCount
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
			}
#endif

				
#ifdef VERBOSE_RECOMPILE
cout << " RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif

			// return;
			reti &= e->x64EncodeReturn ();


			// set the current optimization level
			OpLevel = OptimizeLevel;
			
			// reset flags
			bStopEncodingBefore = false;
			bStopEncodingAfter = false;
			Local_NextPCModified = false;
			
			bResetCycleCount = false;
			
			// clear delay slots
			//RDelaySlots [ 0 ].Value = 0;
			//RDelaySlots [ 1 ].Value = 0;
			
			// starting a new run
			RunCount = 0;
			ullLSRegs = 0;
			
			// restart cycle count to zero
			LocalCycleCount = 0;
			
			// cycle counts should start over
			//LocalCycleCount = MemCycles - 1;
			//CacheBlock_CycleCount = 0;
			
#else

				break;
#endif
		} // if ( bStopEncodingAfter )
			
			
			
		// reset flags
		bStopEncodingBefore = false;
		bStopEncodingAfter = false;
		Local_NextPCModified = false;
		
		bResetCycleCount = false;
		

	} // end for ( int i = 0; i < MaxStep; i++, Address += 4 )

#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Done with loop";
#endif


	// also need to set forward branches to the end
	Set_FJMPs ( Address );



#ifdef ENABLE_CONNECT_ADJACENT_BLOCKS

	u32 tBlock;
	u32 TargetAddress;
	TargetAddress = Address + 4;
	tBlock = ( TargetAddress >> ( 2 + MaxStep_Shift ) ) & NumBlocks_Mask;

	if ( !Local_NextPCModified )
	{
		
	if ( TargetAddress == ( BeginAddress + ( 16 << 2 ) ) )
	{
		
	// step 1: check if next block has been modified (if it is in main memory)
	if ( ( Address & 0x1fc00000 ) != 0x1fc00000 )
	{
		e->CmpMemImm8 ( (char*) & r->Bus->InvalidArray.b8 [ ( Address & Playstation2::DataBus::MainMemory_Mask ) >> ( 2 + r->Bus->c_iInvalidate_Shift ) ], 0 );
		e->Jmp8_NE( 0, 0 );
	}
	
	// step 2: check if next block has the correct source address
	e->CmpMem32ImmX ( (long*) & StartAddress [ ( tBlock ) & NumBlocks_Mask ], Address );
	e->Jmp8_NE( 0, 1 );
	
	// step 3: if next block is cached, check that it is in i-cache
	if ( bIsBlockInICache )
	{
		// get the cache line that address should be at
		u32 ICacheBlockIndex = ( Address >> 6 ) & 0x7f;
		
		// make room for the way
		ICacheBlockIndex <<= 1;

		e->CmpMem32ImmX ( (long*) & r->ICache.PFN [ ICacheBlockIndex ], ( Address & 0x1fffffc0 ) );
		e->Jmp8_E ( 0, 2 );

		e->CmpMem32ImmX ( (long*) & r->ICache.PFN [ ICacheBlockIndex ^ 1 ], ( Address & 0x1fffffc0 ) );
		e->Jmp8_NE ( 0, 3 );
		
		// make sure the cache line is valid and that the address is actually cached there
		// for ps2, must check way0 and way1 both
		//if ( PFN [ ICacheBlockIndex ] == ( Address & 0x1fffffc0 ) )
		//{
		//	//return & Data [ ICacheBlockIndex << 4 ];
		//	return & Data [ ( ICacheBlockIndex << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
		//}
		
		//if ( PFN [ ICacheBlockIndex ^ 1 ] == ( Address & 0x1fffffc0 ) )
		//{
		//	//return & Data [ ( ICacheBlockIndex ^ 1 ) << 4 ];
		//	return & Data [ ( ( ICacheBlockIndex ^ 1 ) << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
		//}
		
		e->SetJmpTarget8 ( 2 );
	}
	
	
	// step 0: make sure there are no pending events
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	e->AddReg64ImmX ( RAX, LocalCycleCount );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp8_AE ( 0, 4 );
	//e->Jmp_AE ( 0, 0 );
	
	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	//e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// update cycle count
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
	e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	

	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// step 4a: if all checks out, then jump to start of next block
	//e->JMP ( e->Get_XCodeBlock_StartPtr ( ( Block + 1 ) & NumBlocks_Mask ) );
	e->JmpMem64 ( (long long*) & pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
	
	// step 4b: if doesn't check out, then return
	if ( ( Address & 0x1fc00000 ) != 0x1fc00000 )
	{
	e->SetJmpTarget8 ( 0 );
	}
	e->SetJmpTarget8 ( 1 );
	e->SetJmpTarget8 ( 4 );
	if ( bIsBlockInICache )
	{
	e->SetJmpTarget8 ( 3 );
	}
	
	}
	
	}
#endif	// end ENABLE_CONNECT_ADJACENT_BLOCKS



#ifdef ENCODE_SINGLE_RUN_PER_BLOCK
	// at end of block need to return ok //
	
	// encode return if it has not already been encoded at end of block
	if ( RunCount > 1 )
	{
	
#ifdef UPDATE_BEFORE_RETURN

#ifdef INLINE_DEBUG_RECOMPILE
	debug << " Terminate@ADDR=" << hex << Address;
#endif

		// check that NextPC was not modified and that this is not an isolated instruction
		if ( !Local_NextPCModified )
		{
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " SET-NEXTPC";
#endif

			// update NextPC
			e->MovMemImm32 ( (long*) & r->NextPC, Address );
		}
		
		// update CycleCount
		// after update need to put in the minus MemCycles
		// if returning, then -MemCycles and -ExeCycles
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
#endif

	} // end if ( RunCount > 1 )

#ifdef VERBOSE_RECOMPILE
cout << "\nulCacheLineCount=" << dec << ulCacheLineCount;
#endif


#ifdef VERBOSE_RECOMPILE
cout << "\nRecompiler: Encoding RETURN";
#endif
#ifdef INLINE_DEBUG_RECOMPILE
	debug << " RETURN";
#endif


	// return;
	reti &= e->x64EncodeReturn ();
	
#endif

	}
	
	}

	
	// done encoding block
	e->EndCodeBlock ();
	
	// address is now encoded
	
	
	if ( !reti )
	{
		cout << "\nRecompiler: Out of space in code block.";
	}

#ifdef VERBOSE_RECOMPILE
//cout << "\n(when all done)TEST0=" << hex << (((u64*) (pCodeStart [ 0x27e4 >> 2 ])) [ 0 ]);
//cout << " TEST1=" << hex << (((u64*) (pCodeStart [ 0x27e4 >> 2 ])) [ 1 ]);
#endif

	
	return reti;
	//return RecompileCount;
}

/*
void Recompiler::Invalidate ( u32 Address, u32 Count )
{
	s32 StartBlock, StopBlock;
	
	u32 iBlock;
	
	
	// get the address to actually start checking from
	Address -= ( MaxStep - 1 );
	
	// update the count
	Count += ( MaxStep - 1 );
	
	// get the starting block
	iBlock = ( Address >> 2 ) & NumBlocks_Mask;
	
	while ( Count > 0 )
	{
		if ( ( StartAddress [ iBlock ] == Address ) && ( RunCount [ iBlock ] >= Count ) )
		{
			// invalidate the block
			StartAddress [ iBlock ] = 0xffffffff;
		}
		
		// update vars
		Address += 4;
		iBlock++;
		Count--;
	}
	
}
*/


// code generation //

// generate the instruction prefix to check for any pending events
// will also update NextPC,CycleCount (CPU) and return if there is an event
// will also update CycleCount (System) on a load or store
long Recompiler::Generate_Prefix_EventCheck ( u32 Address, bool bIsBranchOrJump )
{
	long ret;
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	//e->Jmp_A ( 0, 100 + RetJumpCounter++ );
	e->Jmp8_B ( 0, 0 );
	
	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	
	// done for now - return
	ret = e->Ret ();
	
	// jump to here to continue execution in code block
	e->SetJmpTarget8 ( 0 );
	
	// if it is a branch or a jump, then no need to update the System CycleCount
	if ( !bIsBranchOrJump )
	{
		// since we have not reached the next event cycle, should write back the current system cycle
		// so that the correct cycle# gets seen when the store is executed
		// no need to update the CPU cycle count until either a branch/jump is encountered or returning
		// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
		ret = e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	}

	return ret;
}


// BitTest should be 1 for SH, 3 for SW, 0 for SB, etc
long R5900::Recompiler::Generate_Normal_Store ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* StoreFunctionToCall )
{
	long ret;
	
	bool bPerformInlineStore = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );
	
	/*
	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	
	// done for now - return
	e->Ret ();
	
	// jump to here to continue execution in code block
	e->SetJmpTarget8 ( 0 );
	*/
	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
	e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	// part 3: execute the store //
	/*
	switch ( i.Opcode )
	{
		case OPSQ:
			// get address of value to store
			//e->MovRegImm64 ( RDX, &r->GPR [ i.Rt ].s );
			
			// clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;

		case OPSQC2:
			// get address of value to store
			//e->MovRegImm64 ( RDX, & VU0::_VU0->vf [ i.Ft ].sq0 );
			
			break;
			
		case OPSWC1:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Rt ].s );
			break;
			
		case OPSD:
			// get the value to store (64-bit)
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			break;
			
		case OPSWL:
			
#ifdef USE_SHORT_SWL_CODE
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
#else
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
#endif
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			
			break;
			
		case OPSWR:
#ifdef USE_SHORT_SWR_CODE
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
#else
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
#endif
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;

		case OPSDL:

#ifdef USE_SHORT_SDL_CODE
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
#else
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
#endif
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			
			break;
			
		case OPSDR:
#ifdef USE_SHORT_SDR_CODE
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
#else
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
#endif
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;

			
		default:
			// get the value to store (32-bit)
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			
			break;
			
	}
	*/
	
	
#ifdef ENABLE_INLINE_STORE

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		case OPSWC1:
		case OPSD:
		case OPSWL:
		case OPSWR:
		case OPSDL:
		case OPSDR:
		case OPSQ:
		case OPSQC2:
			bPerformInlineStore = true;
			break;
		
			
		default:
			bPerformInlineStore = false;
			break;
	}
	
	if ( bPerformInlineStore )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Write );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Write );
	
	
	switch ( i.Opcode )
	{
		case OPSQ:
		case OPSQC2:
			// load the pointer into the device into RCX
			// save RCX into R9 first, though
			//e->MovRegReg32 ( 9, RCX );
			e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
			
			// jump if zero
			//e->CmpReg64ImmX ( RDX, 0 );
			e->OrRegReg64 ( RDX, RDX );
			break;
			
		default:
			// load the pointer into the device into RCX
			// save RCX into R9 first, though
			//e->MovRegReg32 ( 9, RCX );
			e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
			
			// jump if zero
			//e->CmpReg64ImmX ( 10, 0 );
			e->OrRegReg64 ( RDX, RDX );
			break;
	}
	
	
	//e->Jmp_E ( 0, 0 );
	//e->Jmp8_E ( 0, 0 );
	
#ifdef ENABLE_R5900_DCACHE
	// if simulating DCache, then need to add latency before calling load function
	//e->Jmp_E ( 0, 16 );
	
	// not loading, data goes to store buffer - no latency
	e->Jmp_E ( 0, 0 );
#else
	// if not simulating DCache, no need to add latency, just call load function
	e->Jmp8_E ( 0, 0 );
#endif

#ifdef ENABLE_R5900_DCACHE
	e->MovRegReg32 ( 10, RCX );
#endif

	// mask address
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

#ifdef ENABLE_R5900_DCACHE
	// check if this is scratch-pad or un-cached/accelerated
	// save address in RAX
	e->TestReg32ImmX ( 10, 0x60000000 );
	e->Jmp_NE ( 0, 10 );
	
	// data is cached in DCache //
	
	// get mask address for comparison -> R10
	e->AndReg32ImmX ( 10, 0x1fffffc0 );
	
	
	// check if cache-hit or cache-miss //
	
	// mask address with appropriate mask from lookup
	
	// get the base index -> RAX
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 6 );
	e->AndReg32ImmX ( RAX, 0x3f );
	e->AddRegReg32 ( RAX, RAX );

	// CycleCount -> R8
	e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	
	// check for cache-hit #1
	e->LeaRegMem64 ( 9, (void*) & r->DCache.PFN );
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 11 );
	
	// if it's a hit, then the hit code needs to know what index the hit is at
	e->IncReg32 ( RAX );
	
	// check for cache-hit #2
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 12 );
	
	// cache-miss //
	
	// get next index -> RAX
	// get xor LRF -> R10
	e->DecReg32 ( RAX );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.LRF );
	e->MovRegFromMem8 ( 11, 9, RAX, SCALE_NONE, 0 );
	e->XorRegMem8 ( 11, 9, RAX, SCALE_NONE, 1 );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovRegFromMem16 ( 9, 9, RAX, SCALE_NONE, 0 );
	e->CmpReg16ImmX ( 9, 0x0101 );
	e->CmovERegReg32 ( 9, 11 );
	e->AndReg32ImmX ( 9, 1 );
	e->OrRegReg32 ( RAX, 9 );
	
	// mark as valid
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovMemImm8 ( 1, 9, RAX, SCALE_NONE, 0 );
	
	// calculate bus time //
	
	
#ifdef ENABLE_DCACHE_TIMING_STORE
	// LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 9, (long long*) & r->LoadFromBus_BusyUntilCycle );
	
	// if ( r->CycleCount < r->LoadFromBus_BusyUntilCycle )
	// handle condition #1 -> r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime;
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPSWC1 ) || ( i.Opcode == OPSQC2 ) )
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		
#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->MovRegMem64 ( 11, (long long*) & r->Bus->BusyUntil_Cycle );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 8 );
#else
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
#endif
	}
	else
	{
#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->MovRegMem64 ( 11, (long long*) & r->Bus->BusyUntil_Cycle );
		e->Jmp8_AE ( 0, 20 );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 8 );
		e->Jmp8 ( 0, 21 );
		
		e->SetJmpTarget8 ( 20 );
		e->AddReg64ImmX ( 9, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 9, 11 );
		e->CmovBRegReg64 ( 9, 11 );
		e->AddReg64ImmX ( 9, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 9 );
		
		// write-back R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
		e->LeaRegMem64 ( 11, (void*) & r->RefillDCache_BusyUntilCycle );
		e->MovRegToMem64 ( 9, 11, RAX, SCALE_EIGHT, 0 );
#else
		e->LeaRegRegImm64 ( 11, 9, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovBRegReg64 ( 8, 11 );
		
		// handle condition #2 -> r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime
		e->LeaRegRegImm64 ( 11, 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovAERegReg64 ( 9, 11 );
		
		// write-back R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
		// -> r->RefillDCache_BusyUntilCycle [ ulIndex ] = r->LoadFromBus_BusyUntilCycle;
		// ptr r->RefillDCache_BusyUntilCycle -> R10
		// r->RefillDCache_BusyUntilCycle [ ulIndex ] -> R10
		e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
		e->CmovBRegMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
		
		// write-back R8, R9, R11
		// write-back R11
		e->MovRegToMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
#endif

#ifdef ENABLE_BUS_SIMULATION_CACHE_STORE
		e->SetJmpTarget8 ( 21 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
#endif

	// get pointer to dirty bit before shifting index ??
	// save index in -> R8
	e->MovRegReg32 ( 8, RAX );
	
	// get cache-line pointer + index -> RAX
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Data );
	e->ShlRegImm32 ( RAX, 6 );
	e->AddRegReg64 ( RAX, 9 );

	// get masked PFN RAM offset -> R9
	e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	e->MovRegFromMem32 ( 9, 11, 8, SCALE_FOUR, 0 );
	e->AndReg32ImmX ( 9, (long) ( r->Bus->MainMemory_Mask & 0x1fffffc0 ) );
	
	// update PFN
	e->MovRegToMem32 ( 10, 11, 8, SCALE_FOUR, 0 );
	
	// update LRF
	e->LeaRegMem64 ( 11, (void*) & r->DCache.LRF );
	e->XorMemImm8 ( 1, 11, 8, SCALE_NONE, 0 );
	
	// check if cache-line is dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->XorRegReg32 ( 11, 11 );
	e->CmpRegMem8 ( 11, 10, 8, SCALE_NONE, 0 );
	
	// set dirty
	e->MovMemImm8 ( 1, 10, 8, SCALE_NONE, 0 );
	
	e->Jmp8_E ( 0, 15 );
	
	// cache-line is dirty and needs write-back //
	
	
	
#ifdef ENABLE_DCACHE_DATA_WRITE
	// get write-back pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->MainMemory.b8 );
	
	// write-back
	e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, 11, 9, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, 11, 9, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, 11, 9, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, 11, 9, SCALE_NONE, 48 );
#endif
	
	// get invalidate pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// invalidate (using RCX again below)
	//e->MovRegReg32 ( 8, RCX );
	e->ShrRegImm32 ( 9, 6 );
	e->MovMemImm8 ( 1, 11, 9, SCALE_NONE, 0 );
	
	// reload cache-line from device //
	if ( !e->SetJmpTarget8 ( 15 ) ) { cout << "\nProblem setting jump target #15\n"; }
	
	// device pointer is already in -> RDX
	// reload
	e->MovRegReg32 ( 8, RCX );
	e->AndReg32ImmX ( 8, 0x1fffffc0 );
#ifdef ENABLE_DCACHE_DATA_READ
	e->movdqa_from_mem128 ( RAX, RDX, 8, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RDX, 8, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RDX, 8, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RDX, 8, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
#endif
	
	
#ifdef DCACHE_WRITE_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> mask address -> proceed
	e->MovRegReg64 ( RDX, RAX );
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	e->Jmp ( 0, 14 );
	
	// cache-hit //
	if ( !e->SetJmpTarget ( 11 ) ) { cout << "\nProblem setting jump target #11\n"; }
	if ( !e->SetJmpTarget ( 12 ) ) { cout << "\nProblem setting jump target #12\n"; }
	
#ifdef ENABLE_DCACHE_TIMING_STORE
	// calculate the bus time
	//e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
	e->MovRegFromMem64 ( 9, 9, RAX, SCALE_EIGHT, 0 );
	e->CmpRegReg64 ( 8, 9 );
	e->CmovBRegReg64 ( 8, 9 );
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
#endif
	
	// mark cache-line as dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->MovMemImm8 ( 1, 10, RAX, SCALE_NONE, 0 );
	
#ifdef DCACHE_WRITE_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> RDX
	// index should be in -> RAX
	e->ShlRegImm32 ( RAX, 6 );
	e->LeaRegMem64 ( RDX, (void*) & r->DCache.Data );
	e->AddRegReg64 ( RDX, RAX );
	
	// only 64-bytes in cache line - mask address
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	// get invalidate pointer -> R11
	//e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// proceed to load the value from cache
	e->Jmp8 ( 0, 13 );
	
	// data is un-cached or accelerated or scratch-pad //
	if ( !e->SetJmpTarget ( 10 ) ) { cout << "\nProblem setting jump target #10\n"; }
	
#endif
	
	
	
	// get pointer into invalidate array
	e->MovRegFromMem64 ( 11, 9, RAX, SCALE_EIGHT, 16 );

	// testing
	//e->MovMemReg32 ( & r->testvar [ 0 ], 11 );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RCX );
	
	// also need to invalidate recompiler cache
	e->MovRegReg32 ( 10, RCX );
	e->ShrRegImm32 ( 10, 2 + r->Bus->c_iInvalidate_Shift );
	e->MovMemImm8 ( 1, 11, 10, SCALE_NONE, 0 );

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	
	
#ifdef ENABLE_R5900_DCACHE
	if ( !e->SetJmpTarget ( 16 ) ) { cout << "\nProblem setting jump target #16\n"; }

	/*
#ifdef ENABLE_DCACHE_TIMING_STORE
	// calculate the latency for the device and update cycle count //
	
	// get the device latency -> R10
	e->MovRegFromMem32 ( 10, 9, RAX, SCALE_EIGHT, 12 );
	
	// get CycleCount -> R8
	// get LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovRegMem64 ( 9, (long long*) & r->LoadFromBus_BusyUntilCycle );
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPSWC1 ) || ( i.Opcode == OPSQC2 ) )
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		e->AddRegReg64 ( 8, 10 );
	}
	else
	{
		// r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 9, 10 );
		e->CmovBRegReg64 ( 8, RAX );
		
		// r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 8, 10 );
		e->CmovAERegReg64 ( 9, RAX );
		
		// write-back R8, R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
#endif
	
	// jump again if device is a register
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 0 );
	*/

	// proceed to load value
	if ( !e->SetJmpTarget8 ( 13 ) ) { cout << "\nProblem setting jump target #13\n"; }
	if ( !e->SetJmpTarget ( 14 ) ) { cout << "\nProblem setting jump target #14\n"; }
#endif

	
	// store the value
	switch ( i.Opcode )
	{
		case OPSB:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSH:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSWL:
#ifdef USE_SHORT_SWL_CODE
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x3 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );
			e->MovRegFromMem32 ( 9, RDX, RCX, SCALE_NONE, -4 );
			e->MovRegToMem32 ( RAX, RDX, 8, SCALE_NONE, -3 );
			e->MovRegToMem32 ( 9, RDX, RCX, SCALE_NONE, -4 );
			break;
#endif
		case OPSWR:
#ifdef USE_SHORT_SWR_CODE
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x3 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );
			e->MovRegFromMem32 ( 9, RDX, RCX, SCALE_NONE, 4 );
			e->MovRegToMem32 ( RAX, RDX, 8, SCALE_NONE, 0 );
			e->MovRegToMem32 ( 9, RDX, RCX, SCALE_NONE, 4 );
			break;
#else
			e->AndRegReg32 ( RDX, 8 );
			e->NotReg32 ( 8 );
			e->AndRegMem32 ( 8, 10, RCX, SCALE_NONE, 0 );
			e->OrRegReg32 ( RDX, 8 );
#endif
		case OPSW:
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSWC1:
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Rt ].s );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSDL:
#ifdef USE_SHORT_SDL_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x7 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );
			e->MovRegFromMem64 ( 9, RDX, RCX, SCALE_NONE, -8 );
			e->MovRegToMem64 ( RAX, RDX, 8, SCALE_NONE, -7 );
			e->MovRegToMem64 ( 9, RDX, RCX, SCALE_NONE, -8 );
			break;
#endif
		case OPSDR:
#ifdef USE_SHORT_SDR_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->MovRegReg32 ( 8, RCX );
			e->AndReg32ImmX ( RCX, ~0x7 );
			//e->AndRegMem32 ( 8, 9, RAX, SCALE_EIGHT, 8 );
			e->MovRegFromMem64 ( 9, RDX, RCX, SCALE_NONE, 8 );
			e->MovRegToMem64 ( RAX, RDX, 8, SCALE_NONE, 0 );
			e->MovRegToMem64 ( 9, RDX, RCX, SCALE_NONE, 8 );
			break;
#else
			e->AndRegReg64 ( RDX, 8 );
			e->NotReg64 ( 8 );
			e->AndRegMem64 ( 8, 10, RCX, SCALE_NONE, 0 );
			e->OrRegReg64 ( RDX, 8 );
#endif
		case OPSD:
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSQ:
			e->movdqa_regmem ( RAX, (void*) &r->GPR [ i.Rt ].s );
			e->AndReg32ImmX ( RCX, ~0xf );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPSQC2:
			e->movdqa_regmem ( RAX, (void*) & VU0::_VU0->vf [ i.Ft ].sq0 );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
	}
	
	

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 4 ], RCX );
	
	e->Jmp8 ( 0, 1 );
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif


#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	
	if ( !e->SetJmpTarget ( 2 ) ) { cout << "\nProblem setting jump target #2\n"; }
	
	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// didn't execute the instruction, so -MemCycles AND -ExeCycles
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	// if synchronous interrupt is possible, then handle it here
	
	if ( BitTest )
	{
		if ( !e->SetJmpTarget ( 3 ) ) { cout << "\nProblem setting jump target #3\n"; }
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here the instruction is exectued, so -MemCycles, NOT -ExeCycles, but possibly +TrapCycles?
		//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (long*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADES> );
		
	}
	

	// continue processing store from here //
#ifdef ENABLE_R5900_DCACHE
	e->SetJmpTarget ( 0 );
#else
	if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting jump target #0\n"; }
#endif
	
	// call the function to store value //

	switch ( i.Opcode )
	{
		case OPSQ:
			// get address of value to store
			e->LeaRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			
			break;

		case OPSQC2:
			// get address of value to store
			e->LeaRegMem64 ( RDX, & VU0::_VU0->vf [ i.Ft ].sq0 );
			
			break;
			
		case OPSWC1:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Rt ].s );
			break;
			
		case OPSD:
			// get the value to store (64-bit)
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			break;
			
		case OPSWL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			
			break;
			
		case OPSWR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;

		case OPSDL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			
			break;
			
		case OPSDR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;

			
		default:
			// get the value to store (32-bit)
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			
			break;
			
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
	e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( StoreFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
	ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( !e->SetJmpTarget8 ( 1 ) ) { cout << "\nProblem setting jump target #1\n"; }


	return ret;
}



long Recompiler::Generate_Normal_Store_L2 ( Instruction::Format i, u32 Address, u32 BitTest, u32 BaseAddress )
{
	long ret;
	bool bPerformInlineStore;
	
	u8* pMemoryDevice8;
	u32 ulMask;
	u32 ulLatency;
	u8* pInvalidateDevice8;
	u32 ulDeviceTestMask;
	u32 Dummy;
	
	u64 lConst;
	
	int Rt;
	
	u32 StoreAddress;




	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	//e->MovRegFromMem32 ( RDX, &r->GPR [ i.Base ].s );
	//e->AddReg32ImmX ( RDX, i.sOffset );
	BaseAddress += ( (s32) i.sOffset );


	pMemoryDevice8 = (u8*) Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].pMemoryDevice;
	pInvalidateDevice8 = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].pInvalidateDevice;
	ulMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulMask;
	//ulLatency = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulLatency;
	//ulDeviceTestMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulDeviceTest;
	
	
	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BaseAddress & BitTest )
	{
		return 0;
	}

	if ( !pMemoryDevice8 )
	{
		return 0;
	}
	
	//if ( BaseAddress & ulDeviceTestMask )
	//{
	//	return 0;
	//}


	if ( i.Opcode == OPSQ )
	{
		return 0;
	}
	
	if ( i.Opcode == OPSQC2 )
	{
		return 0;
	}

	if ( i.Opcode == OPSWC1 )
	{
		return 0;
	}
	
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount2 )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RCX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount2 - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RCX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	e->Jmp_B ( 0, 0 );
	//e->Jmp8_AE ( 0, 0 );
	//e->Jmp_AE ( 0, 0 );
	

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount2 - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	WriteBackModifiedRegs ();
	
	RestoreRegsFromStack ();
	
	// done for now - return
	e->Ret ();


	//if ( !e->SetJmpTarget8 ( 0 ) )
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nhps1x64: R3000A: Recompiler: short branch0 too far!";
	}

	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RCX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	//pCodeStart [ BlockIndex ] = e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	

	
	// part 3: execute the store //
			

		
	// check isc
	//e->MovRegMem32 ( RAX, & r->CPR0.Status.Value );
	//e->BtRegImm32 ( RAX, 16 );
	//e->BtMemImm32 ( & r->CPR0.Status.Value, 16 );
	//e->Jmp8_AE ( 0, 6 );
	//e->Jmp8 ( 0, 6 );
	
	
	//e->MovMemImm32 ( & r->ICache.ICacheBlockSource [ ( BaseAddress >> 4 ) & 0xff ], -1 );


	//e->Jmp8 ( 0, 5 );


	//if ( !e->SetJmpTarget8 ( 7 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch7 too far!";
	//}




	//if ( !e->SetJmpTarget ( 6 ) )
	//if ( !e->SetJmpTarget8 ( 6 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch6 too far!";
	//}
	

	
	StoreAddress = BaseAddress & ulMask;

	
	
	
	switch ( i.Opcode )
	{
			/*
		case OPSWC2:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RCX, &r->COP2.CPR2.Regs [ i.Rt ] );
			break;
			
		case OPSWL:
			
			e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			//e->MovRegReg32 ( 8, RDX );
		
			// clear bottom two bits of address
			//e->AndReg32ImmX ( RDX, ~0x3 );
			//StoreAddress &= ~0x3;
			
			break;
			
		case OPSWR:
			e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			//e->MovRegReg32 ( 8, RDX );
		
			// clear bottom two bits of address
			//e->AndReg32ImmX ( RDX, ~0x3 );
			//StoreAddress &= ~0x3;
			break;
			*/

		default:
			// get the value to store (32-bit)
			if ( isConst( i.Rt ) )
			{
				lConst = GetConst( i.Rt );
			}
			else
			{
				Rt = Alloc_SrcReg ( i.Rt );
			}
			//e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			
			break;
			
	}

	
	// store the value
	switch ( i.Opcode )
	{
		case OPSB:
			//e->MovRegToMem8 ( RDX, 10, RCX, SCALE_NONE, 0 );
			//e->MovRegToMem8 ( RCX, 10, RDX, SCALE_NONE, 0 );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm8 ( (char*) & pMemoryDevice8 [ StoreAddress ], lConst );
			}
			else
			{
				e->MovMemReg8 ( (char*) & pMemoryDevice8 [ StoreAddress ], Rt );
			}
			break;
		case OPSH:
			//e->MovRegToMem16 ( RDX, 10, RCX, SCALE_NONE, 0 );
			//e->MovRegToMem16 ( RCX, 10, RDX, SCALE_NONE, 0 );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm16 ( (short*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg16 ( (short*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSWL:
			if ( ( StoreAddress & 3 ) == 3 )
			{
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32( (long*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32( (long*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), Rt );
				}
			}
			else
			{
				e->MovRegMem32 ( RCX, (long*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) - 4 ] ) );
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32 ( (long*) ( & pMemoryDevice8 [ StoreAddress - 3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32 ( (long*) ( & pMemoryDevice8 [ StoreAddress - 3 ] ), Rt );
				}
				e->MovMemReg32 ( (long*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) - 4 ] ), RCX );
			}
			break;
		case OPSWR:
			if ( ( StoreAddress & 3 ) == 0 )
			{
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32( (long*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), lConst );
				}
				else
				{
					e->MovMemReg32( (long*) ( & pMemoryDevice8 [ StoreAddress & ~3 ] ), Rt );
				}
			}
			else
			{
				e->MovRegMem32 ( RCX, (long*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) + 4 ] ) );
				if ( isConst( i.Rt ) )
				{
					e->MovMemImm32 ( (long*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), lConst );
				}
				else
				{
					e->MovMemReg32 ( (long*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), Rt );
				}
				e->MovMemReg32 ( (long*) ( & pMemoryDevice8 [ ( StoreAddress & ~3 ) + 4 ] ), RCX );
			}
			break;
		case OPSW:
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm32( (long*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg32( (long*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSD:
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64( (long long*) ( & pMemoryDevice8 [ StoreAddress ] ), lConst );
			}
			else
			{
				e->MovMemReg64( (long long*) ( & pMemoryDevice8 [ StoreAddress ] ), Rt );
			}
			break;
		case OPSDL:
			//e->MovRegFromMem64 ( RAX, 10, RCX, SCALE_NONE, -8 );
			//e->MovRegToMem64 ( RDX, 10, 8, SCALE_NONE, -7 );
			//e->MovRegToMem64 ( RAX, 10, RCX, SCALE_NONE, -8 );
			e->MovRegMem64 ( RCX, (long long*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) - 8 ] ) );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64 ( (long long*) ( & pMemoryDevice8 [ StoreAddress - 7 ] ), lConst );
			}
			else
			{
				e->MovMemReg64 ( (long long*) ( & pMemoryDevice8 [ StoreAddress - 7 ] ), Rt );
			}
			e->MovMemReg64 ( (long long*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) - 8 ] ), RCX );
			break;
		case OPSDR:
			//e->MovRegFromMem64 ( RAX, 10, RCX, SCALE_NONE, 8 );
			//e->MovRegToMem64 ( RDX, 10, 8, SCALE_NONE, 0 );
			//e->MovRegToMem64 ( RAX, 10, RCX, SCALE_NONE, 8 );
			e->MovRegMem64 ( RCX, (long long*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) + 8 ] ) );
			if ( isConst( i.Rt ) )
			{
				e->MovMemImm64 ( (long long*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), lConst );
			}
			else
			{
				e->MovMemReg64 ( (long long*) ( & pMemoryDevice8 [ StoreAddress - 0 ] ), Rt );
			}
			e->MovMemReg64 ( (long long*) ( & pMemoryDevice8 [ ( StoreAddress & ~7 ) + 8 ] ), RCX );
			break;
		//case OPSWC2:
		//	e->MovMemReg32( (long*) ( & pMemoryDevice8 [ StoreAddress ] ), RCX );
		//	break;
	}
	
	// also need to invalidate cache
	//e->ShrRegImm32 ( RDX, 2 + r->Bus->c_iInvalidate_Shift );
	//e->MovMemImm8 ( 1, 11, RDX, SCALE_NONE, 0 );
	e->MovMemImm8 ( (char*) & pInvalidateDevice8 [ StoreAddress >> ( 2 + r->Bus->c_iInvalidate_Shift ) ], 1 );
	
	// add additional latency
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, ulLatency );

	





	//if ( !e->SetJmpTarget8 ( 2 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch2 too far!";
	//}
	//if ( !e->SetJmpTarget8 ( 5 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch5 too far!";
	//}
	
//cout << "\nRecompile L2 Store: ADDR=" << hex << Address << " BaseAddr=" << BaseAddress << " StoreAddr=" << StoreAddress << " Const=" << lConst << dec << " Rt=" << Rt << " i.Rt=" << i.Rt;
	
	return 1;
}



// BitTest should be 1 for LH, 3 for LW, 0 for LB, etc
long Recompiler::Generate_Normal_Load ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall )
{
	long ret;
	
	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
	// check it is a non-blocking load
	DependCount = 0;
	if ( ( i.Opcode != OPLWC1 ) && ( i.Opcode != OPLQC2 ) )
	{
		
		// get start address in the next cache-line
		MaxAddress = ( Address + 64 ) & ~63;
		
		// get remaining number of instructions in cache-line
		InstCount = ( ( MaxAddress - Address ) >> 2 ) - 1;
		
		// get the count before dependency is hit
		if ( InstCount )
		{
			for ( int iIdx = 0; iIdx < InstCount; iIdx++ )
			{
				oCheckInst.Value = g_pSrcCodePtr [ iIdx + 1 ];
				
				// check if next instruction has a dependency
				if ( GetGPR_SrcRegs( oCheckInst ) & ( 1 << i.Rt ) )
				{
					DependCount = iIdx + 1;
					break;
				}
				
				if ( ! Check_StaticDependencyOk ( oCheckInst ) )
				{
					break;
				}
			}
		}
	}
#endif
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );

	
	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
	e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			//e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			//e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPLB:
		case OPLH:
		case OPLW:
		case OPLBU:
		case OPLHU:
		case OPLWU:
		case OPLWC1:
		case OPLD:
		case OPLWL:
		case OPLWR:
		case OPLDL:
		case OPLDR:
		case OPLQ:
		case OPLQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Read );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	
#ifdef ENABLE_R5900_DCACHE
	// if simulating DCache, then need to add latency before calling load function
	e->Jmp_E ( 0, 16 );
#else
	// if not simulating DCache, no need to add latency, just call load function
	e->Jmp8_E ( 0, 0 );
#endif
	
#ifdef ENABLE_R5900_DCACHE
	e->MovRegReg32 ( 10, RCX );
#endif

	// mask address
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

#ifdef ENABLE_R5900_DCACHE
	// test section x
	// start x
	// check if this is scratch-pad or un-cached/accelerated
	// save address in RAX
	e->TestReg32ImmX ( 10, 0x60000000 );
	e->Jmp_NE ( 0, 10 );
	//e->Jmp_NE ( 0, 14 );
	
	// data is cached in DCache //
	
	// get mask address for comparison -> R10
	e->AndReg32ImmX ( 10, 0x1fffffc0 );
	
	
	// check if cache-hit or cache-miss //
	
	// mask address with appropriate mask from lookup
	
	// get the base index -> RAX
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 6 );
	e->AndReg32ImmX ( RAX, 0x3f );
	e->AddRegReg32 ( RAX, RAX );

	// CycleCount -> R8
	e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	
	// check for cache-hit #1
	e->LeaRegMem64 ( 9, (void*) & r->DCache.PFN );
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 11 );
	
	// if it's a hit, then the hit code needs to know what index the hit is at
	e->IncReg32 ( RAX );
	
	// check for cache-hit #2
	e->CmpRegMem32 ( 10, 9, RAX, SCALE_FOUR, 0 );
	e->Jmp_E ( 0, 12 );
	
	// cache-miss //
	
	// testing
	//e->MovMemImm32 ( (long*) & r->testvar [ 0 ], 0 );
	
	// get next index -> RAX
	// get xor LRF -> R10
	e->DecReg32 ( RAX );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.LRF );
	e->MovRegFromMem8 ( 11, 9, RAX, SCALE_NONE, 0 );
	e->XorRegMem8 ( 11, 9, RAX, SCALE_NONE, 1 );
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovRegFromMem16 ( 9, 9, RAX, SCALE_NONE, 0 );
	e->CmpReg16ImmX ( 9, 0x0101 );
	e->CmovERegReg32 ( 9, 11 );
	e->AndReg32ImmX ( 9, 1 );
	e->OrRegReg32 ( RAX, 9 );
	
	
	// mark as valid
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Valid );
	e->MovMemImm8 ( 1, 9, RAX, SCALE_NONE, 0 );
	
	// calculate bus time //
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 9, (long long*) & r->LoadFromBus_BusyUntilCycle );
	
	// if ( r->CycleCount < r->LoadFromBus_BusyUntilCycle )
	// handle condition #1 -> r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime;
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPLWC1 ) || ( i.Opcode == OPLQC2 )
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
		//|| ( ( GetGPR_SrcRegs( NextInst ) & ( 1 << i.Rt ) ) && ( NextInst.Value != -1 ) )
		|| ( DependCount < ( r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime ) )
#endif
	)
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		
#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->MovRegMem64 ( 11, (long long*) & r->Bus->BusyUntil_Cycle );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime - DependCount );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 8 );
#else
		//e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime - DependCount );
#endif
	}
	else
	{
#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->MovRegMem64 ( 11, (long long*) & r->Bus->BusyUntil_Cycle );
		e->Jmp8_AE ( 0, 20 );
		e->AddReg64ImmX ( 8, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 8, 11 );
		e->CmovBRegReg64 ( 8, 11 );
		e->AddReg64ImmX ( 8, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 8 );
		e->Jmp8 ( 0, 21 );
		
		e->SetJmpTarget8 ( 20 );
		e->AddReg64ImmX ( 9, r->Bus->c_iRAM_Read_Latency );
		e->CmpRegReg64 ( 9, 11 );
		e->CmovBRegReg64 ( 9, 11 );
		e->AddReg64ImmX ( 9, r->c_ullCacheRefill_CycleTime );
		e->MovMemReg64 ( (long long*) & r->Bus->BusyUntil_Cycle, 9 );
		
		// write-back R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
		e->LeaRegMem64 ( 11, (void*) & r->RefillDCache_BusyUntilCycle );
		e->MovRegToMem64 ( 9, 11, RAX, SCALE_EIGHT, 0 );
#else
		e->LeaRegRegImm64 ( 11, 9, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovBRegReg64 ( 8, 11 );
		
		// handle condition #2 -> r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime
		e->LeaRegRegImm64 ( 11, 8, r->Bus->c_iRAM_Read_Latency + r->c_ullCacheRefill_CycleTime );
		e->CmovAERegReg64 ( 9, 11 );
		
		// write-back R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
		// -> r->RefillDCache_BusyUntilCycle [ ulIndex ] = r->LoadFromBus_BusyUntilCycle;
		// ptr r->RefillDCache_BusyUntilCycle -> R10
		// r->RefillDCache_BusyUntilCycle [ ulIndex ] -> R10
		e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
		e->CmovBRegMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
		
		// write-back R8, R9, R11
		// write-back R11
		e->MovRegToMem64 ( 11, 9, RAX, SCALE_EIGHT, 0 );
#endif

#ifdef ENABLE_BUS_SIMULATION_CACHE_LOAD
		e->SetJmpTarget8 ( 21 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
	
#endif	// ENABLE_DCACHE_TIMING_LOAD

	// test section
	// start
	// get pointer to dirty bit before shifting index ??
	// save index in -> R8
	e->MovRegReg32 ( 8, RAX );
	
	// get cache-line pointer + index -> RAX
	e->LeaRegMem64 ( 9, (void*) & r->DCache.Data );
	e->ShlRegImm32 ( RAX, 6 );
	e->AddRegReg64 ( RAX, 9 );

	// update LRF
	e->LeaRegMem64 ( 11, (void*) & r->DCache.LRF );
	e->XorMemImm8 ( 1, 11, 8, SCALE_NONE, 0 );
	
	// get masked PFN RAM offset -> R9
	e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	e->MovRegFromMem32 ( 9, 11, 8, SCALE_FOUR, 0 );
	
	// R9 could be a bios address *todo*
	e->AndReg32ImmX ( 9, (long) ( r->Bus->MainMemory_Mask & 0x1fffffc0 ) );

	
	// update PFN
	//e->AndReg32ImmX ( 8, 0x3f );
	//e->LeaRegMem64 ( 11, (void*) & r->DCache.PFN );
	//e->MovRegImm32 ( 10, 0xdeadbeef );
	e->MovRegToMem32 ( 10, 11, 8, SCALE_FOUR, 0 );
	
	// testing
	//e->MovMemReg32 ( (long*) & r->testvar [ 2 ], 8 );
	//e->MovMemReg32 ( (long*) & r->testvar [ 3 ], 11 );
	
	// check if cache-line is dirty
	e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	e->XorRegReg32 ( 11, 11 );
	e->CmpRegMem8 ( 11, 10, 8, SCALE_NONE, 0 );
	e->Jmp8_E ( 0, 15 );
	
	// cache-line is dirty and needs write-back //
	
	// testing
	//e->MovMemReg32 ( (long*) & r->testvar [ 4 ], 8 );
	//e->MovMemReg32 ( (long*) & r->testvar [ 5 ], 10 );
	
	// clear dirty - this is different when loading than when storing
	e->MovMemImm8 ( 0, 10, 8, SCALE_NONE, 0 );
	
	// test section end
	
#ifdef ENABLE_DCACHE_DATA_WRITE
	// get write-back pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->MainMemory.b8 );
	
	// write-back
	e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, 11, 9, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, 11, 9, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, 11, 9, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, 11, 9, SCALE_NONE, 48 );
	
#endif
	
	// get invalidate pointer -> R11
	e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// invalidate (using RCX again below)
	//e->MovRegReg32 ( 8, RCX );
	e->ShrRegImm32 ( 9, 6 );
	e->MovMemImm8 ( 1, 11, 9, SCALE_NONE, 0 );
	
	// reload cache-line from device //
	if ( !e->SetJmpTarget8 ( 15 ) ) { cout << "\nProblem setting jump target #15\n"; }

	// testing
	//e->MovMemReg32 ( (long*) & r->testvar [ 2 ], RAX );
	
	// device pointer is already in -> RDX
	// reload
#ifdef ENABLE_DCACHE_DATA_READ
	e->MovRegReg32 ( 8, RCX );
	e->AndReg32ImmX ( 8, 0x1fffffc0 );
	
	e->movdqa_from_mem128 ( RAX, RDX, 8, SCALE_NONE, 0 );
	e->movdqa_from_mem128 ( RBX, RDX, 8, SCALE_NONE, 16 );
	e->movdqa_from_mem128 ( RCX, RDX, 8, SCALE_NONE, 32 );
	e->movdqa_from_mem128 ( RDX, RDX, 8, SCALE_NONE, 48 );
	e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
	e->movdqa_to_mem128 ( RBX, RAX, NO_INDEX, SCALE_NONE, 16 );
	e->movdqa_to_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 32 );
	e->movdqa_to_mem128 ( RDX, RAX, NO_INDEX, SCALE_NONE, 48 );
#endif
	
	// testing
	/*
	e->MovRegFromMem32 ( 8, RDX, 8, SCALE_NONE, 8 );
	//e->MovRegFromMem32 ( RDX, RAX, RAX, SCALE_NONE, 8 );
	e->movdqa_regmem ( RAX, & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	e->movdqu_memreg ( & r->testvar [ 0 ], RAX );
	//e->MovMemReg32 ( & r->testvar [ 2 ], RAX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RCX );
	e->MovMemReg32 ( & r->testvar [ 4 ], RDX );
	e->MovMemReg32 ( & r->testvar [ 5 ], 8 );
	e->AddRegReg64 ( RAX, RAX );
	*/
	
#ifdef DCACHE_READ_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> mask address -> proceed
	e->MovRegReg64 ( RDX, RAX );
	e->AndReg32ImmX ( RCX, 0x3f );
#endif
	
	
	e->Jmp ( 0, 14 );
	
	// cache-hit //
	if ( !e->SetJmpTarget ( 11 ) ) { cout << "\nProblem setting jump target #11\n"; }
	if ( !e->SetJmpTarget ( 12 ) ) { cout << "\nProblem setting jump target #12\n"; }

	// testing
	//e->MovMemImm32 ( & r->testvar [ 0 ], 1 );
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// calculate the bus time
	//e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->LeaRegMem64 ( 9, (void*) & r->RefillDCache_BusyUntilCycle );
	e->MovRegFromMem64 ( 9, 9, RAX, SCALE_EIGHT, 0 );
	e->CmpRegReg64 ( 8, 9 );
	e->CmovBRegReg64 ( 8, 9 );
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
#endif
	
	// mark cache-line as dirty
	//e->LeaRegMem64 ( 10, (void*) & r->DCache.Dirty );
	//e->MovMemImm8 ( 1, 10, RAX, SCALE_NONE, 0 );
	
#ifdef DCACHE_READ_MEMORY
	// get memory pointer
#else
	// get cache-line pointer -> RDX
	// index should be in -> RAX
	e->ShlRegImm32 ( RAX, 6 );
	e->LeaRegMem64 ( RDX, (void*) & r->DCache.Data );
	e->AddRegReg64 ( RDX, RAX );
	
	// only 64-bytes in cache line - mask address
	e->AndReg32ImmX ( RCX, 0x3f );
#endif

	// testing
	/*
	e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	e->MovMemReg32 ( & r->testvar [ 4 ], 8 );
	*/
	
	// get invalidate pointer -> R11
	//e->LeaRegMem64 ( 11, (void*) & r->Bus->InvalidArray );
	
	// proceed to load the value from cache
	e->Jmp8 ( 0, 13 );
	
	// data is un-cached or accelerated or scratch-pad //
	if ( !e->SetJmpTarget ( 10 ) ) { cout << "\nProblem setting jump target #10\n"; }
	
#endif
	
	
	pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	
#ifdef ENABLE_R5900_DCACHE
	if ( !e->SetJmpTarget ( 16 ) ) { cout << "\nProblem setting jump target #16\n"; }

	// calculate the latency for the device and update cycle count //
	
#ifdef ENABLE_DCACHE_TIMING_LOAD
	// get the device latency -> R10
	e->MovRegFromMem32 ( 10, 9, RAX, SCALE_EIGHT, 12 );
	
	// get CycleCount -> R8
	// get LoadFromBus_BusyUntilCycle -> R9
	e->MovRegMem64 ( 8, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovRegMem64 ( 9, (long long*) & r->LoadFromBus_BusyUntilCycle );
	e->CmpRegReg64 ( 8, 9 );
	
	if ( ( i.Opcode == OPLWC1 ) || ( i.Opcode == OPLQC2 )
#ifdef ENABLE_NEXT_DEPENDENCY_CHECK
		|| ( ( GetGPR_SrcRegs( NextInst ) & ( 1 << i.Rt ) ) && ( NextInst.Value != -1 ) )
#endif
		)
	{
		// always blocking load //
		e->CmovBRegReg64 ( 8, 9 );
		e->AddRegReg64 ( 8, 10 );
	}
	else
	{
		// r->CycleCount = r->LoadFromBus_BusyUntilCycle + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 9, 10 );
		e->CmovBRegReg64 ( 8, RAX );
		
		// r->LoadFromBus_BusyUntilCycle = r->CycleCount + r->Bus->GetLatency();
		e->LeaRegRegReg64 ( RAX, 8, 10 );
		e->CmovAERegReg64 ( 9, RAX );
		
		// write-back R8, R9
		e->MovMemReg64 ( (long long*) & r->LoadFromBus_BusyUntilCycle, 9 );
		
#ifdef ENABLE_GPR_REGISTER_TIMING
		// the extra code involved here doesn't appear to work well
		// write-back LoadFromBus_BusyUntilCycle to reg BusyUntil cycle
		e->MovMemReg64 ( (long long*) & r->ullReg_BusyUntilCycle [ i.Rt ], 9 );
#endif
	}
	
	// write-back R8
	e->SubReg64ImmX ( 8, LocalCycleCount - MemCycles );
	e->MovMemReg64 ( (long long*) & r->CycleCount, 8 );
#endif
	
	// jump again if device is a register
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 0 );

	// proceed to load value
	if ( !e->SetJmpTarget8 ( 13 ) ) { cout << "\nProblem setting jump target #13\n"; }
	if ( !e->SetJmpTarget ( 14 ) ) { cout << "\nProblem setting jump target #14\n"; }
#endif

	// testing
	//e->MovMemReg32 ( & r->testvar [ 6 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 7 ], RDX );
	//e->LeaRegMem64 ( RAX, (long long*) & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	
	
	// store the value
	switch ( i.Opcode )
	{
		case OPLB:
			e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLBU:
			//e->MovRegFromMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		//case OPLB:
		//case OPLBU:
		//	e->MovRegFromMem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	//e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	break;
		case OPLH:
			e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLHU:
			//e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		//case OPLH:
		//case OPLHU:
		//	e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	//e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
		//	break;
		case OPLW:
			e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLWL:
		case OPLWR:
			//e->AndRegReg32 ( RDX, 8 );
			//e->NotReg32 ( 8 );
			//e->AndRegMem32 ( 8, RDX, RCX, SCALE_NONE, 0 );
			//e->OrRegReg32 ( RDX, 8 );
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~3 );
			e->MovRegFromMem32 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		//case OPLW:
		case OPLWU:
		case OPLWC1:
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLDL:
		case OPLDR:
			//e->AndRegReg64 ( RDX, 8 );
			//e->NotReg64 ( 8 );
			//e->AndRegMem64 ( 8, 10, RCX, SCALE_NONE, 0 );
			//e->OrRegReg64 ( RDX, 8 );
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~7 );
			e->MovRegFromMem64 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		case OPLD:
			e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLQ:
			//e->movdqa_regmem ( RAX, (void*) &r->GPR [ i.Rt ].s );
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
		case OPLQC2:
			//e->movdqa_regmem ( RAX, (void*) & VU0::_VU0->vf [ i.Ft ].sq0 );
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			break;
	}

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( (long*) & r->testvar [ 6 ], RAX );
	//e->MovMemReg32 ( (long*) & r->testvar [ 7 ], RCX );
	//e->MovMemReg32 ( (long*) & r->testvar [ 8 ], RDX );
	
	e->Jmp ( 0, 1 );
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	e->SetJmpTarget ( 2 );

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (long*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
		
	}


	if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting jump target #0\n"; }
	
#ifdef ENABLE_OPTIMIZED_REG_READS
	// *** check if optimized register read *** //
	
	// get address to list of register pointers
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 24 );
	
	// if can optimize reg read, then perform read like normal
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 5 );
	
	// mask address with 0xffff
	e->MovzxReg32Reg16 ( RAX, RCX );
	//e->MovRegReg32 ( RAX, RCX );
	//e->AndReg32ImmX ( RAX, 0xffff );
	
	// get just the pointer to the register (divide by 16)
	e->ShrRegImm32 ( RAX, 4 );
	
	// load the pointer
	e->MovRegFromMem64 ( RDX, RDX, RAX, SCALE_EIGHT, 0 );

	e->OrRegReg64 ( RDX, RDX );
	e->Jmp8_E ( 0, 6 );
	
	// mask the address to get offset into register
	e->AndReg32ImmX ( RCX, 0x7 );
	//e->XorRegReg32 ( RCX, RCX );
	
	e->JMP ( pJumpTarget );
	
	e->SetJmpTarget8 ( 5 );
	e->SetJmpTarget8 ( 6 );

#endif


	
	// *** perform non-optimized register read *** //

	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			//e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( LoadFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( i.Rt )
	{
		switch ( i.Opcode )
		{
			case OPLQ:
			case OPLQC2:
				e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				break;
				
			default:
				break;
		}

		// reload address if needed
		switch ( i.Opcode )
		{
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				e->AddReg32ImmX ( RCX, i.sOffset );
				break;
				
			// opcodes like lb and lh need to be sign extended! //
			case OPLB:
				//e->Cbw();
				e->MovsxReg64Reg8 ( RAX, RAX );
				break;
			case OPLH:
				//e->Cwde();
				e->MovsxReg64Reg16 ( RAX, RAX );
				break;
			case OPLW:
				e->Cdqe();
				break;
				
			case OPLBU:
				e->MovzxReg32Reg8 ( RAX, RAX );
				break;
				
			case OPLHU:
				e->MovzxReg32Reg16 ( RAX, RAX );
				break;
				
			case OPLWU:
				e->OrRegReg32 ( RAX, RAX );
				break;
		}
	}	// if ( i.Rt )




	e->SetJmpTarget ( 1 );

	// part 4: store the result //
	

	return ret;
}




//--------------------

// jump forward
void Recompiler::FJMP ( long AddressFrom, long AddressTo )
{
	int iOffsetFrom, iOffsetTo;

	// get instruction offset
	iOffsetFrom = ( AddressFrom >> 2 ) & 0xf;

	// get where to jump to
	iOffsetTo = ( AddressTo >> 2 ) & 0xf;

	// set a long jump to the index to use
	e->Jmp ( 0, c_ulForwardBranchIndex_Start + iOffsetFrom );

	// set index in table of jumps to the address
	//iCount = iForwardJumpIdxs [ iOffset ] [ 0 ];
	pForwardBranchTargets [ iOffsetFrom ] = iOffsetTo;

//cout << "\nSet forward branch from Address " << hex << AddressFrom << " to " << AddressTo << " with offsets from " << dec << iOffsetFrom << " to " << iOffsetTo;
}

// set the forward jumps for the address to jump to current position
void Recompiler::Set_FJMPs ( long AddressTo )
{
	int iOffsetTo;

	// get where to jump to
	iOffsetTo = ( AddressTo >> 2 ) & 0xf;

	// loop through branch targets checking for this target
	// note: for R3000A the 16 would be a 4
	for ( int iIdx = 0; iIdx < 16; iIdx++ )
	{
		if ( pForwardBranchTargets [ iIdx ] == iOffsetTo )
		{
			// set the forward branch target
			e->SetJmpTarget ( iIdx + c_ulForwardBranchIndex_Start );

			// now this has been already set and cleared from jump target list
			// even if the next instruction has to regenerate at a different optimization level...
			// the forward jump is still already set to the correct position theoretically
			pForwardBranchTargets [ iIdx ] = -1;

	//cout << "\nAddressing branch from offset " << dec << iIdx << " to offset " << iOffsetTo;
		}
	}
	
}

// get the count of instructions that can be included in a combined load
// iMaxCount - number of instructions in pInstructionList before you reach cache boundary or list end
// pInstructionList - pointer to the instructions to test for combined load
int Recompiler::Get_CombinedLoadCount ( R5900::Instruction::Format i, long Address, R5900::Instruction::Format* pInstructionList )
{
	int iIdx;
	int iMaxCount;
	R5900::Instruction::Format i2;

	iMaxCount = 16 - ( ( Address >> 2 ) & 0xf );

	for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )
	{
		i2 = pInstructionList [ iIdx ];

		// make sure the base registers match
		if ( i2.Base != i.Base )
		{
			// only works if the base registers are all the same
			return iIdx;
		}

		switch( i2.Opcode )
		{
			// supported
			case OPLD:
				// make sure that offset is divisible by 8
				if ( i2.sOffset & 0x7 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPLW:
			case OPLWU:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}


			case OPLH:
			case OPLHU:
				// make sure that offset is divisible by 2
				if ( i2.sOffset & 0x1 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPLB:
			case OPLBU:

			case OPLQ:

				// make sure that the base and Rt are not the same
				if ( i2.Base == i.Rt )
				{
					// can't combine the loads if the base gets overwritten
					return iIdx;
				}

				// otherwise, include this load in the combined load

				break;

			// supported
			case OPLWC1:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}

				// include this load in the combined load
				break;

			// not supported yet
			case OPLQC2:
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				return iIdx;
				break;

			default:
				return iIdx;
				break;

		}	// end switch( i2.Opcode )

	}	// end for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )

	return iIdx;
}

// get the max width of instructions in the combined load
// iLoadCount - number of instructions in the combined load (returned from Get_CombinedLoadCount)
// pLoadList - pointer to the instructions in the combined load
long Recompiler::Get_CombinedLoadMaxWidthMask ( int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int iIdx;
	long iMaxWidth;
	R5900::Instruction::Format i;

	iMaxWidth = 0;
	for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{
		i = pLoadList [ iIdx ];
		switch( i.Opcode )
		{
			// supported
			case OPLB:
			case OPLBU:
			case OPLQ:
				break;

			case OPLH:
			case OPLHU:
				iMaxWidth |= 0x1;
				break;

			case OPLW:
			case OPLWU:
				iMaxWidth |= 0x3;
				break;

			case OPLD:
				iMaxWidth |= 0x7;
				break;

			// supported
			case OPLWC1:
				iMaxWidth |= 0x3;
				break;

			// not supported yet
			case OPLQC2:
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				break;

			default:
				break;

		}	// end switch( i.Opcode )

	}	// end for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )

	return iMaxWidth;
}


long Recompiler::Generate_Combined_Load ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* LoadFunctionToCall, int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	long ret;
	R5900::Instruction::Format i2;
	
	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );

	
	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the load address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );

	// note: the offset is constant for this one
	// but still need to check the first load for a synchronous interrupt
	//e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	/*
	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
			
		default:
			break;
	}
	*/
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPLB:
		case OPLH:
		case OPLW:
		case OPLBU:
		case OPLHU:
		case OPLWU:
		case OPLWC1:
		case OPLD:
		case OPLWL:
		case OPLWR:
		case OPLDL:
		case OPLDR:
		case OPLQ:
		case OPLQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Read );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if pointer into RAM device is zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp_E ( 0, 0 );

	

	// mask address with the mask for that RAM/ROM device
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );

	
	
	//pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	// testing
	//e->MovMemReg32 ( & r->testvar [ 2 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 3 ], RDX );
	

	// testing
	//e->MovMemReg32 ( & r->testvar [ 6 ], RCX );
	//e->MovMemReg32 ( & r->testvar [ 7 ], RDX );
	//e->LeaRegMem64 ( RAX, (long long*) & r->Bus->BIOS.b32 [ 0x438c0 >> 2 ] );
	//e->MovMemReg32 ( & r->testvar [ 1 ], RAX );
	

	// loop and load multiple values //

	for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{

		i2 = pLoadList [ iIdx ];

		// only need to load the value if lwc1 or Rt!=0
		if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )
		{
	
	// load the value
	switch ( i2.Opcode )
	{
		case OPLB:
			//e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxReg64Mem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLBU:
			//e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLH:
			//e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxReg64Mem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLHU:
			//e->MovRegFromMem16 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovzxReg32Mem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLW:
			//e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovsxdReg64Mem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLWU:
			//e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;
		case OPLWC1:
			//e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg32 ( & r->CPR1 [ i2.Rt ].s, RAX );
			break;
		case OPLD:
			//e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->MovRegFromMem64 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			e->MovMemReg64 ( & r->GPR [ i2.Rt ].sq0, RAX );
			break;

		case OPLQ:
			e->LeaRegRegImm64 ( RAX, RCX, i2.sOffset );
			e->AndReg32ImmX ( RAX, ~0xf );
			e->movdqa_from_mem128 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			e->movdqa_memreg ( & r->GPR [ i2.Rt ].s, RAX );
			break;


		// note: unsure whether to include these now or later
		case OPLQC2:
			e->movdqa_from_mem128 ( RAX, RDX, RCX, SCALE_NONE, 0 );
			e->movdqa_memreg ( & VU0::_VU0->vf [ i2.Ft ].sq0, RAX );
			break;

		// note: LWL,LWR,LDL,LDR excluded from combined load for now
		case OPLWL:
		case OPLWR:
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~3 );
			e->MovRegFromMem32 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;
		case OPLDL:
		case OPLDR:
			e->MovRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, ~7 );
			e->MovRegFromMem64 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;

	}	// end switch ( i2.Opcode )

		}	// end if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )

	}	// end for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )

	// testing
	//e->MovRegMem32 ( RCX, & r->Bus->MainMemory.b32 [ ( /*Address*/ 0x588 & r->Bus->MainMemory_Mask ) >> 2 ] );
	//e->MovMemReg32 ( (long*) & r->testvar [ 6 ], RAX );
	//e->MovMemReg32 ( (long*) & r->testvar [ 7 ], RCX );
	//e->MovMemReg32 ( (long*) & r->testvar [ 8 ], RDX );


	// after loading the values, update cycles, update PC, and return //
	//***todo*** branch to the next address to execute if possible (if so, then don't update cycles or pc here)

#ifdef USE_FORWARD_BRANCH

	// use the forward branch to jump to the correct address after doing multiple instructions
	FJMP( Address, Address + ( iLoadCount << 2 ) );

#else

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address + ( iLoadCount << 2 ) );

	// update cycles (need to check math)
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles * iLoadCount ) - 1 );

	// done for now - return
	// ***todo*** in the future, skip updating pc and cycles and set forward jump to the correct code
	e->Ret ();
	//e->Jmp ( 0, 1 );

#endif
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

#ifdef CHECK_EVENT_AFTER_START

	// there is an event before first load, so need to return //

	if ( RunCount )
	{
	e->SetJmpTarget ( 2 );

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// ***TODO*** check math
	// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (long*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
		
	}


	// the address is for a register here, so it is more complicated //

	//if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting short jump target #0\n"; }
	if ( !e->SetJmpTarget ( 0 ) ) { cout << "\nProblem setting long jump target #0\n"; }

	
	// *** perform non-optimized register read *** //

	// if not adding first offset for multi-load, then need to add it for single load
	e->AddReg32ImmX ( RCX, i.sOffset );

	switch ( i.Opcode )
	{
		case OPLQ:
			// if LQ 128-bit load, then clear bottom four bits of address
			e->AndReg32ImmX ( RCX, ~0xf );
			break;
			
		case OPLWL:
		case OPLWR:
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;
			
		case OPLDL:
		case OPLDR:
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;
			
		default:
			break;
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( LoadFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	if ( i.Rt )
	{
		switch ( i.Opcode )
		{
			case OPLQ:
			case OPLQC2:
				e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				break;
				
			default:
				break;
		}

		// reload address if needed
		switch ( i.Opcode )
		{
			case OPLWL:
			case OPLWR:
			case OPLDL:
			case OPLDR:
				e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				e->AddReg32ImmX ( RCX, i.sOffset );
				break;
				
			// opcodes like lb and lh need to be sign extended! //
			case OPLB:
				//e->Cbw();
				e->MovsxReg64Reg8 ( RAX, RAX );
				break;
			case OPLH:
				//e->Cwde();
				e->MovsxReg64Reg16 ( RAX, RAX );
				break;
			case OPLW:
				e->Cdqe();
				break;
				
			case OPLBU:
				e->MovzxReg32Reg8 ( RAX, RAX );
				break;
				
			case OPLHU:
				e->MovzxReg32Reg16 ( RAX, RAX );
				break;
				
			case OPLWU:
				e->OrRegReg32 ( RAX, RAX );
				break;
		}
	}	// if ( i.Rt )




	e->SetJmpTarget ( 1 );

	// part 4: store the result //
	

	return ret;
}



// ||--------------------------------------------------

// get the count of instructions that can be included in a combined load
// iMaxCount - number of instructions in pInstructionList before you reach cache boundary or list end
// pInstructionList - pointer to the instructions to test for combined load
int Recompiler::Get_CombinedStoreCount ( R5900::Instruction::Format i, long Address, R5900::Instruction::Format* pInstructionList )
{
	int iIdx;
	int iMaxCount;
	R5900::Instruction::Format i2;

	iMaxCount = 16 - ( ( Address >> 2 ) & 0xf );

	for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )
	{
		i2 = pInstructionList [ iIdx ];

		// make sure the base registers match
		if ( i2.Base != i.Base )
		{
			// only works if the base registers are all the same
			return iIdx;
		}

		switch( i2.Opcode )
		{
			// supported
			case OPSD:
				// make sure that offset is divisible by 8
				if ( i2.sOffset & 0x7 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPSW:
			//case OPLWU:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}


			case OPSH:
			//case OPLHU:
				// make sure that offset is divisible by 2
				if ( i2.sOffset & 0x1 )
				{
					// won't bother to combine these
					return iIdx;
				}

			case OPSB:
			//case OPLBU:

			case OPSQ:

				// make sure that the base and Rt are not the same
				//if ( i2.Base == i.Rt )
				//{
				//	// can't combine the loads if the base gets overwritten
				//	return iIdx;
				//}

				// otherwise, include this load in the combined load

				break;

			// supported
			case OPSWC1:
				// make sure that offset is divisible by 4
				if ( i2.sOffset & 0x3 )
				{
					// won't bother to combine these
					return iIdx;
				}

				// include this load in the combined load
				break;

			// not supported yet
			case OPSQC2:
			case OPSWL:
			case OPSWR:
			case OPSDL:
			case OPSDR:
				return iIdx;
				break;

			default:
				return iIdx;
				break;

		}	// end switch( i2.Opcode )

	}	// end for ( iIdx = 0; iIdx < iMaxCount; iIdx++ )

	return iIdx;
}

// get the max width of instructions in the combined load
// iLoadCount - number of instructions in the combined load (returned from Get_CombinedLoadCount)
// pLoadList - pointer to the instructions in the combined load
long Recompiler::Get_CombinedStoreMaxWidthMask ( int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	int iIdx;
	long iMaxWidth;
	R5900::Instruction::Format i;

	iMaxWidth = 0;
	for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{
		i = pLoadList [ iIdx ];
		switch( i.Opcode )
		{
			// supported
			case OPSB:
			//case OPLBU:
			case OPSQ:
				break;

			case OPSH:
			//case OPLHU:
				iMaxWidth |= 0x1;
				break;

			case OPSW:
			//case OPLWU:
				iMaxWidth |= 0x3;
				break;

			case OPSD:
				iMaxWidth |= 0x7;
				break;

			// supported
			case OPSWC1:
				iMaxWidth |= 0x3;
				break;

			// not supported yet
			case OPSQC2:
			case OPSWL:
			case OPSWR:
			case OPSDL:
			case OPSDR:
				break;

			default:
				break;

		}	// end switch( i.Opcode )

	}	// end for ( iIdx = 0; iIdx < iLoadCount; iIdx++ )

	return iMaxWidth;
}


long Recompiler::Generate_Combined_Store ( R5900::Instruction::Format i, u32 Address, u32 BitTest, void* StoreFunctionToCall, int iLoadCount, R5900::Instruction::Format* pLoadList )
{
	long ret;
	R5900::Instruction::Format i2;
	
	char *pJumpTarget;
	
	u32 MaxAddress, InstCount, DependCount;
	R5900::Instruction::Format oCheckInst;
	
	bool bPerformInlineLoad = false;
	
	// set register as being recompiled into load/store
	// also needs to be reset when the runcount gets reset
	ullLSRegs |= ( 1ull << i.Rt );
	
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount )
	{
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	e->Jmp_AE ( 0, 2 );

	
	// ***todo*** math here is wrong since the cyclecount value changes for the next load/store
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RAX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	
	// get the load address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );

	// note: the offset is constant for this one
	// but still need to check the first load for a synchronous interrupt
	//e->AddReg32ImmX ( RCX, i.sOffset );

	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BitTest )
	{
		// if ( StoreAddress & 0x1 )
		e->TestReg32ImmX ( RCX, BitTest );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp_NE ( 0, 3 );
		
	}
	
	
	// part 3: execute the load //


#ifdef ENABLE_INLINE_LOAD

	// exclusions for testing
	switch ( i.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		//case OPLBU:
		//case OPLHU:
		//case OPLWU:
		case OPSWC1:
		case OPSD:
		case OPSWL:
		case OPSWR:
		case OPSDL:
		case OPSDR:
		case OPSQ:
		case OPSQC2:
			bPerformInlineLoad = true;
			break;
			
		default:
			bPerformInlineLoad = false;
			break;
	}
	
	if ( bPerformInlineLoad )
	{

	// RCX has the address
	// RDX has the value to store
	
	// get the index into the device pointer array
	e->MovRegReg32 ( RAX, RCX );
	e->ShrRegImm32 ( RAX, 22 );
	//e->AddRegReg32 ( RAX, RAX );
	e->ShlRegImm32 ( RAX, 2 );
	
	// get the pointer into the device pointer array
	//e->MovRegImm64 ( 9, (u64) & Playstation2::DataBus::LUT_DataBus_Read );
	e->LeaRegMem64 ( 9, & Playstation2::DataBus::LUT_DataBus_Write );
	
	// load the pointer into the device into RCX
	// save RCX into R9 first, though
	//e->MovRegReg32 ( 9, RCX );
	e->MovRegFromMem64 ( RDX, 9, RAX, SCALE_EIGHT, 0 );
	
	// jump if pointer into RAM device is zero
	//e->CmpReg64ImmX ( RDX, 0 );
	//e->Jmp_E ( 0, 0 );
	e->OrRegReg64 ( RDX, RDX );
	e->Jmp_E ( 0, 0 );

	

	// mask address with the mask for that RAM/ROM device
	e->AndRegMem32 ( RCX, 9, RAX, SCALE_EIGHT, 8 );



	// get pointer into invalidate array
	e->MovRegFromMem64 ( 11, 9, RAX, SCALE_EIGHT, 16 );

	
	// also need to invalidate recompiler cache
	//e->MovRegReg32 ( 10, RCX );
	//e->ShrRegImm32 ( 10, 2 + r->Bus->c_iInvalidate_Shift );
	//e->MovMemImm8 ( 1, 11, 10, SCALE_NONE, 0 );

	
	
	//pJumpTarget = e->Get_CodeBlock_CurrentPtr ();

	

	// loop and load multiple values //

	for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )
	{

		i2 = pLoadList [ iIdx ];

		// only need to load the value if lwc1 or Rt!=0
		//if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )
		//{
	
	// load the value
	switch ( i2.Opcode )
	{
		case OPSB:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem8 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSH:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem16 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSW:
			e->MovRegMem32 ( RAX, &r->GPR [ i2.Rt ].sw0 );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSWC1:
			e->MovRegMem32 ( RAX, &r->CPR1 [ i2.Rt ].s );
			e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSD:
			e->MovRegMem64 ( RAX, &r->GPR [ i2.Rt ].s );
			e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, i2.sOffset );
			break;
		case OPSQ:
			e->movdqa_regmem ( RAX, (void*) &r->GPR [ i2.Rt ].s );
			e->LeaRegRegImm64 ( RAX, RCX, i2.sOffset );
			e->AndReg32ImmX ( RAX, ~0xf );
			// ***TODO*** movdqa below does not work with R10 as base
			//e->MovRegReg64 ( RAX, 10 );
			e->movdqa_to_mem128 ( RAX, RDX, RAX, SCALE_NONE, 0 );
			break;


		// note: unsure whether to include these now or later
		case OPSQC2:
			break;

		// note: LWL,LWR,LDL,LDR excluded from combined load for now
		case OPSWL:
		case OPSWR:
			break;
		case OPSDL:
		case OPSDR:
			break;

	}	// end switch ( i2.Opcode )


	switch ( i2.Opcode )
	{
		case OPSB:
		case OPSH:
		case OPSW:
		case OPSWC1:
		case OPSD:
			e->LeaRegRegImm32 ( RAX, RCX, i2.sOffset );
			e->ShrRegImm32 ( RAX, 2 + r->Bus->c_iInvalidate_Shift );
			e->MovMemImm8 ( 1, 11, RAX, SCALE_NONE, 0 );
			break;

		case OPSQ:
			e->ShrRegImm32 ( RAX, 2 + r->Bus->c_iInvalidate_Shift );
			e->MovMemImm8 ( 1, 11, RAX, SCALE_NONE, 0 );
			break;

	}

		//}	// end if ( ( i2.Opcode == OPLWC1 ) || ( i2.Rt != 0 ) )

	}	// end for ( int iIdx = 0; iIdx < iLoadCount; iIdx++ )



	// after loading the values, update cycles, update PC, and return //
	//***todo*** branch to the next address to execute if possible (if so, then don't update cycles or pc here)

#ifdef USE_FORWARD_BRANCH

	// use the forward branch to jump to the correct address after doing multiple instructions
	FJMP( Address, Address + ( iLoadCount << 2 ) );

#else

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address + ( iLoadCount << 2 ) );

	// update cycles (need to check math)
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles * iLoadCount ) - 1 );

	// done for now - return
	// ***todo*** in the future, skip updating pc and cycles and set forward jump to the correct code
	e->Ret ();
	//e->Jmp ( 0, 1 );

#endif
	
	
	} // end if ( bPerformInlineStore )
	else
	{
	e->Jmp8 ( 0, 0 );
	}
#else
	e->Jmp8 ( 0, 0 );
#endif

#ifdef CHECK_EVENT_AFTER_START

	// there is an event before first load, so need to return //

	if ( RunCount )
	{
	e->SetJmpTarget ( 2 );

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// ***TODO*** check math
	// did not actually execute this instruction, so before return do -MemCycles and -ExeCycles
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
	}
#endif

	if ( BitTest )
	{
		// continue processing store from here //
		e->SetJmpTarget ( 3 );
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// here executed the instruction but had a trap, so -MemCycles, NOT -ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
		
		// set pc
		e->MovMemImm32 ( (long*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADES );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADES> );
		
	}


	// the address is for a register here, so it is more complicated //

	//if ( !e->SetJmpTarget8 ( 0 ) ) { cout << "\nProblem setting short jump target #0\n"; }
	if ( !e->SetJmpTarget ( 0 ) ) { cout << "\nProblem setting long jump target #0\n"; }

	
	// *** perform non-optimized register read *** //

	// if not adding first offset for multi-load, then need to add it for single load
	e->AddReg32ImmX ( RCX, i.sOffset );

	switch ( i.Opcode )
	{
		case OPSQ:
			// get address of value to store
			e->LeaRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			
			break;

		case OPSQC2:
			// get address of value to store
			e->LeaRegMem64 ( RDX, & VU0::_VU0->vf [ i.Ft ].sq0 );
			
			break;
			
		case OPSWC1:
			// get the value to store from COP1 register
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Rt ].s );
			break;
			
		case OPSD:
			// get the value to store (64-bit)
			e->MovRegMem64 ( RDX, &r->GPR [ i.Rt ].s );
			break;
			
		case OPSWL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShrRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			
			break;
			
		case OPSWR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 3 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg32ImmX ( RAX, -1 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( 8, RAX );
			e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			e->ShlRegReg32 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg32 ( RDX, RAX );
		
			// clear bottom two bits of address
			e->AndReg32ImmX ( RCX, ~0x3 );
			break;

		case OPSDL:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShrRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			
			break;
			
		case OPSDR:
			// temporarily save store address
			e->MovRegReg32 ( RDX, RCX );
			
			//e->NotReg32 ( RCX );
			e->AndReg32ImmX ( RCX, 7 );
			//e->XorReg32ImmX ( RCX, 3 );
			e->ShlRegImm32 ( RCX, 3 );
			e->MovReg64ImmX ( RAX, -1 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg64 ( 8, RAX );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
			e->ShlRegReg64 ( RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegReg64 ( RDX, RAX );
		
			// clear bottom three bits of address
			e->AndReg32ImmX ( RCX, ~0x7 );
			break;

			
		default:
			// get the value to store (32-bit)
			e->MovRegMem32 ( RDX, &r->GPR [ i.Rt ].sw0 );
			
			break;
			
	}
	
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	ret = e->Call ( StoreFunctionToCall );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif


	e->SetJmpTarget ( 1 );

	

	return ret;
}







long Recompiler::Generate_Normal_Load_L2 ( Instruction::Format i, u32 Address, u32 BitTest, u32 BaseAddress )
{
	long ret;
	bool bPerformInlineStore;
	
	u8* pMemoryDevice8;
	u32 ulMask;
	u32 ulLatency;
	u8* pInvalidateDevice8;
	u32 ulDeviceTestMask;
	u32 Dummy;
	
	u64 lConst;
	
	int Rt;
	
	u32 LoadAddress;




	// get the store address
	//u32 StoreAddress = r->GPR [ i.Base ].s + i.sOffset;
	//e->MovRegFromMem32 ( RDX, &r->GPR [ i.Base ].s );
	//e->AddReg32ImmX ( RDX, i.sOffset );
	BaseAddress += ( (s32) i.sOffset );


	pMemoryDevice8 = (u8*) Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].pMemoryDevice;
	pInvalidateDevice8 = Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].pInvalidateDevice;
	ulMask = Playstation2::DataBus::LUT_DataBus_Read [ BaseAddress >> 22 ].ulMask;
	//ulLatency = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulLatency;
	//ulDeviceTestMask = Playstation2::DataBus::LUT_DataBus_Write [ BaseAddress >> 22 ].ulDeviceTest;
	
	
	// check for synchronous interrupt
	
	// if there is a synchronous interrupt possible, then check for it
	if ( BaseAddress & BitTest )
	{
		return 0;
	}

	if ( !pMemoryDevice8 )
	{
		return 0;
	}
	
	//if ( BaseAddress & ulDeviceTestMask )
	//{
	//	return 0;
	//}


	
	switch ( i.Opcode )
	{
		//case OPLWL:
		//case OPLWR:
		//case OPLDL:
		//case OPLDR:
		case OPLWC1:
		case OPLQ:
		case OPLQC2:
			return 0;
			break;
		default:
			break;
	}
	
	
	// part 1: first check for event //
	
#ifdef CHECK_EVENT_AFTER_START
	if ( RunCount2 )
	{
	// get updated CycleCount value for CPU (the value as it would be after instruction executed)
	e->MovRegMem64 ( RCX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount2 - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RCX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	e->Jmp_B ( 0, 0 );
	//e->Jmp8_AE ( 0, 0 );
	//e->Jmp_AE ( 0, 0 );
	

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount2 - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	WriteBackModifiedRegs ();
	
	RestoreRegsFromStack ();
	
	// done for now - return
	e->Ret ();


	//if ( !e->SetJmpTarget8 ( 0 ) )
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nhps1x64: R3000A: Recompiler: short branch0 too far!";
	}

	
	// since we have not reached the next event cycle, should write back the current system cycle
	// so that the correct cycle# gets seen when the store is executed
	// no need to update the CPU cycle count until either a branch/jump is encountered or returning
	// this way, there is no need to reset the current cycle number tally unless a branch/jump is encountered
	//e->DecReg64 ( RAX );
	e->MovMemReg64 ( (long long*) & Playstation2::System::_SYSTEM->CycleCount, RCX );
	
	// part 2: check for synchronous interrupt //
	
	// this is where the entry point should be if this is the first instruction in the run
	//pCodeStart [ BlockIndex ] = e->Get_CodeBlock_CurrentPtr ();
	}
#endif
	

	
	// part 3: execute the store //
			

		
	// check isc
	//e->MovRegMem32 ( RAX, & r->CPR0.Status.Value );
	//e->BtRegImm32 ( RAX, 16 );
	//e->BtMemImm32 ( & r->CPR0.Status.Value, 16 );
	//e->Jmp8_AE ( 0, 6 );
	//e->Jmp8 ( 0, 6 );
	
	
	//e->MovMemImm32 ( & r->ICache.ICacheBlockSource [ ( BaseAddress >> 4 ) & 0xff ], -1 );


	//e->Jmp8 ( 0, 5 );


	//if ( !e->SetJmpTarget8 ( 7 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch7 too far!";
	//}





	//if ( !e->SetJmpTarget ( 6 ) )
	//if ( !e->SetJmpTarget8 ( 6 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch6 too far!";
	//}
	

	
	LoadAddress = BaseAddress & ulMask;

	
	
	switch ( i.Opcode )
	{

		default:
			Rt = Alloc_DstReg ( i.Rt );
			//e->MovRegMem32 ( RCX, &r->GPR [ i.Rt ].s );
			
			break;
			
	}

	
	// store the value
	switch ( i.Opcode )
	{
		case OPLB:
			//e->MovMemReg8 ( & pMemoryDevice8 [ StoreAddress ], Rt );
			e->MovsxReg64Mem8 ( Rt, (char*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLBU:
			e->MovzxReg64Mem8 ( Rt, (char*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLH:
			e->MovsxReg64Mem16 ( Rt, (short*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLHU:
			e->MovzxReg64Mem16 ( Rt, (short*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLWL:
			if ( ( LoadAddress & 3 ) == 3 )
			{
				e->MovsxdReg64Mem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
			}
			else
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw1 );
				e->MovRegMem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
				e->MovMemReg32 ( (long*) ( ( (u8*) & r->GPR [ i.Rt ].sw0 ) + ( ( ~LoadAddress ) & 3 ) ), Rt );
				e->MovMemReg32 ( & r->GPR [ i.Rt ].sw1, RCX );
				//e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sw0 );
				e->MovsxdReg64Mem32 ( Rt, & r->GPR [ i.Rt ].sw0 );
			}
			break;
		case OPLWR:
			if ( ( LoadAddress & 3 ) == 0 )
			{
				e->MovsxdReg64Mem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
			}
			else
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rt - 1 ].sw3 );
				e->MovRegMem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress & ~3 ] );
				e->MovMemReg32 ( (long*) ( ( (u8*) & r->GPR [ i.Rt ].sw0 ) - ( ( LoadAddress ) & 3 ) ), Rt );
				e->MovMemReg32 ( & r->GPR [ i.Rt - 1 ].sw3, RCX );
				//e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sw0 );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLW:
			e->MovsxdReg64Mem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLWU:
			e->MovRegMem32 ( Rt, (long*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLD:
			e->MovRegMem64 ( Rt, (long long*) & pMemoryDevice8 [ LoadAddress ] );
			break;
		case OPLDL:
			if ( ( LoadAddress & 7 ) == 7 )
			{
				e->MovRegMem64 ( Rt, (long long*) & pMemoryDevice8 [ LoadAddress & ~7 ] );
			}
			else
			{
				e->MovRegMem64 ( RCX, & r->GPR [ i.Rt ].sq1 );
				e->MovRegMem64 ( Rt, (long long*) & pMemoryDevice8 [ LoadAddress ] );
				e->MovMemReg64 ( (long long*) ( ( (u8*) & r->GPR [ i.Rt ].sq0 ) + ( ( ~LoadAddress ) & 7 ) ), Rt );
				e->MovMemReg64 ( & r->GPR [ i.Rt ].sq1, RCX );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLDR:
			if ( ( LoadAddress & 7 ) == 0 )
			{
				e->MovRegMem64 ( Rt, (long long*) & pMemoryDevice8 [ LoadAddress & ~7 ] );
			}
			else
			{
				e->MovRegMem64 ( RCX, & r->GPR [ i.Rt - 1 ].sq1 );
				e->MovRegMem64 ( Rt, (long long*) & pMemoryDevice8 [ LoadAddress ] );
				e->MovMemReg64 ( (long long*) ( ( (u8*) & r->GPR [ i.Rt ].sq0 ) - ( LoadAddress & 7 ) ), Rt );
				e->MovMemReg64 ( & r->GPR [ i.Rt - 1 ].sq1, RCX );
				e->MovRegMem64 ( Rt, & r->GPR [ i.Rt ].sq0 );
			}
			break;
		case OPLWC1:
			break;
		case OPLQ:
			break;
		case OPLQC2:
			break;
	}
	
	
	// add additional latency
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, ulLatency );

	





	//if ( !e->SetJmpTarget8 ( 2 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch2 too far!";
	//}
	//if ( !e->SetJmpTarget8 ( 5 ) )
	//{
	//	cout << "\nhps1x64: R3000A: Recompiler: short branch5 too far!";
	//}
	
//cout << "\nRecompile L2 Store: ADDR=" << hex << Address << " BaseAddr=" << BaseAddress << " StoreAddr=" << StoreAddress << " Const=" << lConst << dec << " Rt=" << Rt << " i.Rt=" << i.Rt;
	
	return 1;
}



static void call_stub ( u64 CycleCount, u64 NextEvent, u32 Address, u32 TargetAddress )
{
	cout << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
	//Playstation2::System::debug << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
}

static void call_stub2 ( u64 CycleCount, u64 NextEvent, u32 Address, u32 TargetAddress )
{
	//cout << "\ntesting: Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
	Playstation2::System::debug << "\ntesting(before): Address=" << hex << Address << " Target=" << TargetAddress << " Cycle#" << dec << CycleCount << " NextEvent=" << NextEvent;
}

long Recompiler::Generate_Normal_Branch ( R5900::Instruction::Format i, u32 Address, void* BranchFunctionToCall )
{
	u32 TargetAddress;
	u32 *pInst;
	bool bIdle;
	long ret;
	
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nStart";
#endif
	
	// get the target address
	switch ( i.Opcode )
	{
		case OPJR:
		//case OPJALR:
		
			// don't know what the address is since it is variable
			TargetAddress = 0;
			break;
			
		case OPJ:
		case OPJAL:
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nAddress=" << hex << Address << " JumpAddress=" << i.JumpAddress;
#endif
			TargetAddress = ( 0xf0000000 & Address ) | ( i.JumpAddress << 2 );
			break;
			
		// must be a branch
		default:
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nAddress=" << hex << Address << " sOffset=" << i.sImmediate;
#endif
			TargetAddress = 4 + Address + ( i.sImmediate << 2 );
			break;
	}
	
	
#ifdef CHECK_EVENT_AFTER_START_BRANCH
	// part 1: first check for event //
	
	// get updated CycleCount value for CPU
	e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RAX, LocalCycleCount - ( MemCycles - 1 ) );
	//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
	
	
	// want check that there are no events pending //
	
	// get the current cycle count and compare with next event cycle
	// note: actually need to either offset the next event cycle and correct when done or
	// or need to offset the next even cycle into another variable and check against that one
	e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
	// branch if current cycle is greater (or equal?) than next event cycle
	// changing this so that it branches if not returning
	// note: should probably be below or equal then jump, since the interpreter adds one to cycle
	//e->Jmp8_B ( 0, 0 );
	//e->Jmp8_AE ( 0, 3 );
	e->Jmp_AE ( 0, 3 );
	
	
	/*
		if (
			// make sure not JR
			( i.Opcode != OPJR )
			
			// make sure target address is in same cache block for now
			// staying within same cache block means this can be done purely at re-compile time
			&& ( ( TargetAddress >> 6 ) == ( Address >> 6 ) )
			
			// and also make sure we are jumping backwards
			&& ( TargetAddress < Address )
		)
		{
//static void call_stub ( u64 CycleCount, u64 NextEvent, u64 Address, u64 TargetAddress )


#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	e->MovRegMem64 ( RCX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovRegMem64 ( RDX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	e->MovReg32ImmX ( 8, Address );
	e->MovReg32ImmX ( 9, TargetAddress );
	ret = e->Call ( call_stub2 );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

		}
		*/

	// this is where the entry point should be if this is the first instruction in the run
	pCodeStart [ BlockIndex ] = (u8*) e->Get_CodeBlock_CurrentPtr ();
#endif

	// check for sychronous interrupt if applicable
	if ( i.Opcode == OPJR )
	{
		// get the address being jumped to
		e->MovRegMem32 ( RDX, & r->GPR [ i.Rs ].sw0 );
		
		// if ( StoreAddress & 0x1 )
		//e->TestReg32ImmX ( RDX, BitTest );
		e->TestReg32ImmX ( RDX, 0x3 );

		// branch if zero
		//e->Jmp8_E ( 0, 0 );
		e->Jmp8_NE ( 0, 4 );
		
	}


	// check if branching or not
	switch ( i.Opcode )
	{
		case OPBEQ:
		case OPBEQL:
			if ( i.Rs != i.Rt )
			{
			if ( !i.Rs || !i.Rt )
			{
			e->CmpMem64ImmX ( & r->GPR [ i.Rs + i.Rt ].s, 0 );
			e->Jmp_NE ( 0, 0 );
			}
			else
			{
			e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].s );
			e->CmpMemReg64 ( & r->GPR [ i.Rt ].s, RCX );
			//e->Jmp8_NE ( 0, 0 );
			e->Jmp_NE ( 0, 0 );
			}
			}
			break;
			
		case OPBNE:
		case OPBNEL:
			if ( !i.Rs || !i.Rt )
			{
			e->CmpMem64ImmX ( & r->GPR [ i.Rs + i.Rt ].s, 0 );
			e->Jmp_E ( 0, 0 );
			}
			else
			{
			e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].s );
			e->CmpMemReg64 ( & r->GPR [ i.Rt ].s, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp_E ( 0, 0 );
			}
			break;
			
		case OPBLEZ:
		case OPBLEZL:
			e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_G ( 0, 0 );
			e->Jmp_G ( 0, 0 );
			break;
			
		case OPBGTZ:
		case OPBGTZL:
			e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_LE ( 0, 0 );
			e->Jmp_LE ( 0, 0 );
			break;
			
		case OPBLTZ:
		//case OPBGEZ:
		//case OPBLTZAL:
		//case OPBGEZAL:
			switch ( i.Rt )
			{
				case RTBLTZ:
				case RTBLTZL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					//e->Jmp8_GE ( 0, 0 );
					e->Jmp_GE ( 0, 0 );
					break;
					
				case RTBGEZ:
				case RTBGEZL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					//e->Jmp8_L ( 0, 0 );
					e->Jmp_L ( 0, 0 );
					break;
			
				case RTBLTZAL:
				case RTBLTZALL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
					//e->Jmp8_GE ( 0, 0 );
					e->Jmp_GE ( 0, 0 );
					break;
			
				case RTBGEZAL:
				case RTBGEZALL:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, 0 );
					e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
					//e->Jmp8_L ( 0, 0 );
					e->Jmp_L ( 0, 0 );
					break;
			}
			
			break;
			
		case OPJAL:
			e->MovMemImm64 ( & r->GPR [ 31 ].s, Address + 8 );
			break;
			
		case OPJALR:
		
			if ( i.Funct == 9 )
			{
				// JALR //
				
				// make sure Rd is not r0
				if ( i.Rd )
				{
					// save return address in Rd
					e->MovMemImm64 ( & r->GPR [ i.Rd ].s, Address + 8 );
				}
			}
			
			break;
	}
	
	
	// branching //
	
	
	
#ifdef ALLOW_ENCODING_DELAYSLOT
	// check if target address is inside current block or not
	// for now, only check for only jumping backwards
	//if ( TargetAddress && TargetAddress >= CurrentBlock_StartAddress && TargetAddress < NextBlock_StartAddress && isBranchDelayOk ( NextInst.Value ) )
	if (
/*
#ifdef ENABLE_AUTO_BRANCH
		( TargetAddress && TargetAddress >= CurrentBlock_StartAddress && TargetAddress <= Address && isBranchDelayOk ( NextInst.Value, Address + 4 ) ) ||
#endif
*/
		// make sure the instruction in the branch delay slot is a simple one
		( isBranchDelayOk ( NextInst.Value, Address + 4 ) )
		
		// also need the branch delay slot to be in the same cache block
		&& ( ( ( Address + 4 ) >> 2 ) & 0xf )
		
		)
	{
		// target can be reached with jump in same block //
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nisBranchDelayOk";
#endif

//if ( i.Opcode == OPBNEL && NextInst.Opcode == OPADDIU )
//{
//	cout << "\nAddress=" << hex << Address << dec << " Opcode=BNEL Next= ADDIU " << R5900::Instruction::Print::PrintInstruction ( NextInst.Value );
//}

/*		
#ifndef CACHE_NOT_IMPLEMENTED
		// check if this is a cached region
		if ( bIsBlockInICache )
		{
			// region is cached //
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nbIsBlockInICache";
#endif
			
			// check if instruction in delay slot is in another cache block
			if ( ! ( ( Address + 4 ) & 0x3f ) )
			{
				// instruction in delay slot is in next cache block //
				
				// check if cache block is loaded
				e->CmpMem32ImmX ( & r->ICache.ICacheBlockSource [ ( ( Address + 4 ) >> 4 ) & 0xff ], ( Address + 4 ) & 0x1ffffff0 );
				
				// jump if the cache line is not loaded
				e->Jmp8_NE ( 0, 1 );
				
				// the cache-line is loaded //
				
			}
		
#ifdef ENABLE_AUTO_BRANCH
			// check if that cache line is loaded we are jumping to
			e->CmpMem32ImmX ( & r->ICache.ICacheBlockSource [ ( TargetAddress >> 4 ) & 0xff ], TargetAddress & 0x1ffffff0 );
			
			e->Jmp8_E ( 0, 2 );
#endif
		}
#endif
*/

//#ifndef ENABLE_AUTO_BRANCH

		// check for processor waiting
		if ( ! NextInst.Value )
		{
			// make sure not jr //
			if ( i.Opcode != OPJR )
			{
				u8* pBranchedTo;
				u8* pBranch;
				
				// get the pointer being branched to
				pBranchedTo = pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ];
				
				// get the pointer to the branch
				pBranch = pCodeStart [ ( Address >> 2 ) & ulIndex_Mask ];
				
				// check if equal
				if ( pBranchedTo == pBranch )
				{
					// update cycles
					e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );

					// update CycleCount
					// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
					//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
					e->MovRegMem64 ( RCX, (long long*) & r->CycleCount );
					e->AddReg64ImmX( RCX, LocalCycleCount );
					
					// check against the next event cycle
					e->CmpRegMem64 ( RCX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
					e->CmovBRegMem64 ( RCX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
					
					// store as the new cycle count
					e->MovMemReg64 ( (long long*) & r->CycleCount, RCX );
					
					// should be done
					e->Ret ();
					
				}
			}
		}


#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nbRecompile";
#endif
		// no auto branch, but cache line is loaded, so execute delay slot //
		// execute the instruction in delay slot
		// if it is in the same cache block or its cache block is loaded
		// note: if this is a mult/div then need to update the CPU cycles both before and after ?
		ret = Recompile ( NextInst, Address + 4 );
		
		if ( ret <= 0 )
		{
			cout << "\nR5900: Recompiler: Error encoding branch in delay slot.";
		}


#ifdef ENABLE_AUTO_BRANCH
		if (
			// make sure not JR
			( i.Opcode != OPJR )
			
			// make sure target address is in same cache block for now
			// staying within same cache block means this can be done purely at re-compile time
			//&& ( ( TargetAddress >> 6 ) == ( Address >> 6 ) )
			
			// and also make sure we are jumping backwards
			&& ( TargetAddress <= Address )
			
			//&& ( ( ( Address - TargetAddress ) >> 2 ) <= RunCount )
			
		)
		{
//static void call_stub ( u64 CycleCount, u64 NextEvent, u64 Address, u64 TargetAddress )

/*
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

	e->MovRegMem64 ( RCX, (long long*) & r->CycleCount );
	e->AddReg64ImmX ( RCX, LocalCycleCount - ( MemCycles - 1 ) );
	e->MovRegMem64 ( RDX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	e->MovReg32ImmX ( 8, Address );
	e->MovReg32ImmX ( 9, TargetAddress );
	ret = e->Call ( call_stub );

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
*/			

			// ***TODO*** before auto-branch, need to compare current cycle after delay slot with next event cycle
			// get updated CycleCount value for CPU
			/*
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			e->AddReg64ImmX ( RAX, LocalCycleCount + MemCycles + ( ExeCycles << 1 ) );
			e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
			e->Jmp8_AE ( 0, 7 );
			*/


			if (
			// make sure target address is in same cache block for now
			// staying within same cache block means this can be done purely at re-compile time
			( ( TargetAddress >> 6 ) == ( Address >> 6 ) )
			
			// and also make sure we are jumping backwards
			&& ( TargetAddress <= Address )
			)
			{
				// update the cycle count before jumping
				// +MemCycles for the delay slot memory access cycles and +1 for the delay slot execute cycles -> but +1 is already included in memcycles
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] + 1 );
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				// so, have to add in the cycles for the branch and also the delay slot
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );

			// *** todo *** check cycle count against next event
		// get updated CycleCount value for CPU (the value as it would be after instruction executed)
		e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
		e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) );
		//e->AddReg64ImmX ( RAX, LocalCycleCount - MemCycles );
		
		
		// want check that there are no events pending //
		
		// get the current cycle count and compare with next event cycle
		// note: actually need to either offset the next event cycle and correct when done or
		// or need to offset the next even cycle into another variable and check against that one
		e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp8_B ( 0, 0 );
		e->Jmp8_AE ( 0, 9 );
		//e->Jmp_AE ( 0, 0 );
		
		
		// subtract cycle count for new address
		e->MovRegMem32 ( RCX, & CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
		e->SubRegReg64 ( RAX, RCX );
		e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
				
			e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );
			
				// make the jump backwards
				//ret = e->JMP ( pPrefix_CodeStart [ ( TargetAddress >> 2 ) & MaxStep_Mask ] );
				//ret = e->JMP ( pPrefix_CodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				//ret = e->JMP ( pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				e->JmpMem64 ( (long long*) & pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				
				e->SetJmpTarget8 ( 9 );
			}
			else
			{
				// get the block to encode in
				u32 tBlock;
				tBlock = ( TargetAddress >> ( 2 + MaxStep_Shift ) ) & NumBlocks_Mask;
		
		
				// step 1: check if next block has been modified (if it is in main memory)
				if ( ( TargetAddress & 0x1fc00000 ) != 0x1fc00000 )
				{
					e->CmpMemImm8 ( & r->Bus->InvalidArray.b8 [ ( TargetAddress & Playstation2::DataBus::MainMemory_Mask ) >> ( 2 + r->Bus->c_iInvalidate_Shift ) ], 0 );
					e->Jmp8_NE( 0, 6 );
				}
				
				// step 2: check if next block has the correct source address
				e->CmpMem32ImmX ( & StartAddress [ ( tBlock ) & NumBlocks_Mask ], ( TargetAddress >> ( 2 + MaxStep_Shift ) ) << ( 2 + MaxStep_Shift ) );
				e->Jmp8_NE( 0, 7 );
				
				// step 3: if next block is cached, check that it is in i-cache
				if ( bIsBlockInICache )
				{
					// get the cache line that address should be at
					u32 ICacheBlockIndex = ( TargetAddress >> 6 ) & 0x7f;
					
					// make room for the way
					ICacheBlockIndex <<= 1;

					e->CmpMem32ImmX ( & r->ICache.PFN [ ICacheBlockIndex ], ( TargetAddress & 0x1fffffc0 ) );
					e->Jmp8_E ( 0, 8 );

					e->CmpMem32ImmX ( & r->ICache.PFN [ ICacheBlockIndex ^ 1 ], ( TargetAddress & 0x1fffffc0 ) );
					e->Jmp8_NE ( 0, 9 );
					
					// make sure the cache line is valid and that the address is actually cached there
					// for ps2, must check way0 and way1 both
					//if ( PFN [ ICacheBlockIndex ] == ( Address & 0x1fffffc0 ) )
					//{
					//	//return & Data [ ICacheBlockIndex << 4 ];
					//	return & Data [ ( ICacheBlockIndex << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
					//}
					
					//if ( PFN [ ICacheBlockIndex ^ 1 ] == ( Address & 0x1fffffc0 ) )
					//{
					//	//return & Data [ ( ICacheBlockIndex ^ 1 ) << 4 ];
					//	return & Data [ ( ( ICacheBlockIndex ^ 1 ) << 4 ) ^ ( ( Address >> 2 ) & 0xf ) ];
					//}
			
					e->SetJmpTarget8 ( 8 );
				}
		
				e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
				
				// this isn't available at re-compile time
				e->MovRegMem32 ( RCX, & CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );


				// update cycle count
				//e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) );
				e->AddReg64ImmX ( RAX, LocalCycleCount + ( MemCycles << 1 ) );
				
				
		e->CmpRegMem64 ( RAX, (long long*) & Playstation2::System::_SYSTEM->NextEvent_Cycle );
	
		// branch if current cycle is greater (or equal?) than next event cycle
		// changing this so that it branches if not returning
		// note: should probably be below or equal then jump, since the interpreter adds one to cycle
		//e->Jmp8_B ( 0, 0 );
		e->Jmp8_AE ( 0, 10 );
				
				
				
				e->SubRegReg64 ( RAX, RCX );
	
				e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );

			e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );
			
				// step 4a: if all checks out, then jump to start of next code
				e->JmpMem64 ( (long long*) & pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
				
				// step 4b: if doesn't check out, then return
				if ( ( TargetAddress & 0x1fc00000 ) != 0x1fc00000 )
				{
				e->SetJmpTarget8 ( 6 );
				}
				e->SetJmpTarget8 ( 7 );
				if ( bIsBlockInICache )
				{
				e->SetJmpTarget8 ( 9 );
				}
				e->SetJmpTarget8 ( 10 );
				
			}
		
			//cout << "\nhps2x64: R5900: recompiler: Address=" << hex << Address << " Target=" << TargetAddress;
			// return //
			// did not meet all criteria for open-auto-branch
	
			e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );
			//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles ) + ( ExeCycles ) );
			e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
			e->Ret();
		}
		else
		{
#endif
		
		// update CPU CycleCount
		// returning, so do -MemCycles, but NOT -ExeCycles since this instruction hasn't been counted, but +ExeCycles due to needing to count branch delay slot
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles << 1 ) - MemCycles - ExeCycles );
		
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nTargetAddress=" << hex << TargetAddress;
#endif
		
		if ( TargetAddress )
		{
			// update NextPC
			e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );
			
#ifdef ENABLE_R5900_BRANCH_PREDICTION
			// if target address is odd, then need to reload pipeline after branch
			if ( ( TargetAddress & 4 ) /*|| ( TargetAddress & 0x60000000 )*/ )
			{
				e->AddMem64ImmX ( (long long*) & r->CycleCount, r->c_ullLatency_BranchMisPredict );
			}
#endif
		}
		else
		{
			if ( i.Opcode == OPJR )
			{
				//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
				e->MovMemReg32 ( (long*) & r->NextPC, RDX );
				
#ifdef ENABLE_R5900_BRANCH_PREDICTION
				// jr,jalr instructions are excluded from branch prediction??
				e->AddMem64ImmX ( (long long*) & r->CycleCount, r->c_ullLatency_BranchMisPredict );
#endif
			}
			else
			{
				// ???
				cout << "\nR5900: Recompiler: Potential problem setting NextPC for branch after delay slot.";
				cout << "Address=" << hex << Address << " TargetAddress=" << hex << TargetAddress;
				
				// update NextPC
				e->MovMemImm32 ( (long*) & r->NextPC, TargetAddress );
			}
		}
		
		// done - return
		ret = e->Ret ();
		
#ifdef ENABLE_AUTO_BRANCH
		}
#endif
		
//#endif

#ifdef CHECK_EVENT_AFTER_START_BRANCH
	//if ( !e->SetJmpTarget8 ( 3 ) )
	if ( !e->SetJmpTarget ( 3 ) )
	{
		cout << "\nR5900: Recompiler: Short branch3 too far.";
	}

	// update NextPC
	e->MovMemImm32 ( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	// hasn't executed the instruction at all, so do -MemCycles, -ExeCycles
	//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
	
	// done for now - return
	e->Ret ();
#endif

	
	if ( i.Opcode == OPJR )
	{
		if ( !e->SetJmpTarget8 ( 4 ) )
		{
			//cout << "\nR5900: Recompiler: Short branch4 too far.";
		}
		
		// update CycleCount, set PC, then jump to synchronous interrupt
		// executed the instruction but had a trap, so add in the instruction +MemCycles, +ExeCycles, possibly +TrapCycles?
		//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles - ExeCycles );
		
		// set pc
		e->MovMemImm32 ( (long*) & r->PC, Address );
		
		//r->ProcessSynchronousInterrupt ( Cpu::EXC_ADEL );
		e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_ADEL> );
	}
	
		
		// the cache-line is not loaded //
		
		// also jump here from above if needed
		if ( !e->SetJmpTarget8 ( 1 ) )
		{
			cout << "\nR5900: Recompiler: Short branch1 too far.";
		}
		
		
		// put branch into delay slot
		
		// first put in the target address
		switch ( i.Opcode )
		{
			case OPJR:
			//case OPJALR:
				e->MovMemReg32 ( (long*) & r->DelaySlots [ 1 ].Data, RDX );
				break;
				
			default:
				e->MovMemImm32 ( (long*) & r->DelaySlots [ 1 ].Data, TargetAddress );
				break;
		}
		
		// put in the instruction
		e->MovMemImm32 ( (long*) & r->DelaySlots [ 1 ].Instruction.Value, i.Value );
		
		e->MovReg64ImmX ( RAX, (u64) BranchFunctionToCall );
		e->MovMemReg64 ( (long long*) & r->DelaySlots [ 1 ].cb, RAX );
		
		e->MovMemImm32 ( (long*) & r->NextDelaySlotIndex, 0 );
		e->OrMem64ImmX ( (long long*) &r->Status.Value, 2 << 8 );
		
		// important? - must update LastPC? PC? when releasing to a branch delay slot?
		e->MovMemImm32 ( (long*) & r->PC, Address );

		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
				
		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// here it is returning but has executed the branch, so -MemCycles, but NOT -ExeCycles since it has not been counted yet
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
#endif
				
		// done - return
		ret = e->Ret ();

/*		
#ifdef ENABLE_AUTO_BRANCH
		// cache-block is loaded and can continue //
		e->SetJmpTarget8 ( 2 );
		
		
		// execute the instruction in delay slot
		// if it is in the same cache block or its cache block is loaded
		// note: if this is a mult/div then need to update the CPU cycles both before and after ?
		ret = Recompile ( NextInst, Address + 4 );
		
		// update CPU CycleCount
		// note: must include both branch and delay slot ? And also must subtract the cyclecount at address, then add one since CycleCount[] is minus one
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) - CycleCount [ ( TargetAddress >> 2 ) & ulIndex_Mask ] + 1 );
		
		// check if jumping backwards or forwards
		if ( TargetAddress <= Address )
		{
			// backward branch //
			ret = e->JMP ( pCodeStart [ ( TargetAddress >> 2 ) & ulIndex_Mask ] );
		}
		else
		{
			// forward branch //
			e->Jmp ( 0, ForwardBranchIndex );
			
			// set the label for that line in code
			pForwardBranchTargets [ ( TargetAddress >> 2 ) & MaxStep_Mask ] = ForwardBranchIndex;
			
			// next time we'll use the next index
			ForwardBranchIndex++;
		}
#endif
*/


	}
	else
#endif
	{
		// not directly branching to target address right now //
#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nIntoDelaySlot";
#endif
		
		// put branch into delay slot
		//e->MovMemImm32 ( & r->DelaySlots [ 1 ].Data, TargetAddress );
		//e->MovMemImm32 ( & r->DelaySlots [ 1 ].Instruction.Value, i.Value );

		// first put in the target address
		switch ( i.Opcode )
		{
			case OPJR:
			//case OPJALR:
				e->MovMemReg32 ( (long*) & r->DelaySlots [ 1 ].Data, RDX );
				break;
				
			default:
				e->MovMemImm32 ( (long*) & r->DelaySlots [ 1 ].Data, TargetAddress );
				break;
		}
		
		// put in the instruction
		e->MovMemImm32 ( (long*) & r->DelaySlots [ 1 ].Instruction.Value, i.Value );

		
		e->MovReg64ImmX ( RAX, (u64) BranchFunctionToCall );
		e->MovMemReg64 ( (long long*) & r->DelaySlots [ 1 ].cb, RAX );
		
		e->MovMemImm32 ( (long*) & r->NextDelaySlotIndex, 0 );
		e->OrMem64ImmX ( (long long*) &r->Status.Value, 2 << 8 );
		
		// important? - must update LastPC? PC? when releasing to a branch delay slot?
		e->MovMemImm32 ( (long*) & r->PC, Address );

		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
				
		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// returning so -MemCycles, but NOT -ExeCycles because did not count the branch instruction yet even though it was executed
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
#endif
				
		// done - return
		ret = e->Ret ();
	}
	
	// if inside current block, then check if cache line is loaded
	// if cache line is loaded, then jump to it, otherwise put branch in delay slot and return
	
	// not branching //
	/*
	if ( !e->SetJmpTarget8 ( 0 ) )
	{
		cout << "\nR5900: Recompiler: Short branch0 too far.";
	}
	*/
	
	if ( !e->SetJmpTarget ( 0 ) )
	{
		cout << "\nR5900: Recompiler: Short branch0 too far.";
	}

	// check for likely branch
	if ( i.Opcode >= 0x14 || ( i.Opcode == 1 && ( i.Rt & 0x7 ) >= 2 ) )
	{
		// likely branch //
		
		// update NextPC,CycleCount
#ifdef UPDATE_BEFORE_RETURN
		// update NextPC
		// it should have already returned if NextPC was modified through other means so this should be ok
		// NextPC is Address+4 here because the current instruction was already executed
		//e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
		e->MovMemImm32 ( (long*) & r->NextPC, Address + 8 );

		// update CycleCount
		// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
		// this is for a branch likely, so need to count the branch and also the skipped delay slot, but not the ExeCycles for the delay slot
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
		//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + ( MemCycles << 1 ) + ( ExeCycles ) - MemCycles );
#endif

		// done - return
		ret = e->Ret ();
	}


#ifdef VERBOSE_NORMAL_BRANCH
cout << "\nEND";
#endif

	// done
	return ret;
}


long Recompiler::Generate_Normal_Trap ( R5900::Instruction::Format i, u32 Address )
{
	// step 1: check for trap condition //
	
	switch ( i.Opcode )
	{
		case OPSPECIAL:
		
			switch ( i.Funct )
			{
				case SPTGE:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_L ( 0, 0 );
					break;
					
				case SPTGEU:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_B ( 0, 0 );
					break;
					
				case SPTLT:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_GE ( 0, 0 );
					break;
					
				case SPTLTU:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_AE ( 0, 0 );
					break;
					
				case SPTEQ:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_NE ( 0, 0 );
					break;
					
				case SPTNE:
					e->MovRegMem64 ( RAX, & r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
					e->Jmp8_E ( 0, 0 );
					break;
			}
			
			break;
			
		case OPREGIMM:
			
			switch ( i.Rt )
			{
				case RTTGEI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_L ( 0, 0 );
					break;
					
				case RTTGEIU:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_B ( 0, 0 );
					break;
					
				case RTTLTI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_GE ( 0, 0 );
					break;
					
				case RTTLTIU:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_AE ( 0, 0 );
					break;
					
				case RTTEQI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_NE ( 0, 0 );
					break;
					
				case RTTNEI:
					e->CmpMem64ImmX ( & r->GPR [ i.Rs ].s, i.sImmediate );
					e->Jmp8_E ( 0, 0 );
					break;
			}
			
			break;
	}
	
	// step 2: trap //
	
#ifdef UPDATE_BEFORE_RETURN
	// update NextPC
	// it should have already returned if NextPC was modified through other means so this should be ok
	// NextPC is Address+4 here because the current instruction was already executed
	//e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
	e->MovMemImm32 ( (long*) & r->PC, Address );

	// update CycleCount
	// ***todo*** should be the cycles plus one instruction since branch into delay slot has already been executed
#ifdef ENABLE_R5900_BRANCH_PREDICTION_TRAP
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + r->c_ullLatency_BranchMisPredict );
#else
		e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
#endif

#endif

	e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_TRAP> );
	
	// no trap taken
	e->SetJmpTarget8 ( 0 );
	
	return true;
}



// regular arithemetic //

// *** todo *** no need to save LastModifiedRegister unless instruction is KNOWN to be in a delay slot on run
long Recompiler::ADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s + r->GPR [ i.Rt ].u;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ADDU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs | i.Rt ].sw0 );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					e->AddRegReg32 ( RAX, RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->AddMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].s );
					//ret = e->AddMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_ADDU_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( GetConst( i.Rs ) + GetConst( i.Rt ) ) ) );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( ( Reg1 == i.Rd ) ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->AddReg32ImmX( Rd, lConst );
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							e->LeaRegRegImm32( Rd, Rs, lConst );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							e->AddReg32ImmX ( Rd, lConst );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) || ( i.Rs == i.Rt ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AddRegReg32( Rd, Rs );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AddRegMem32 ( Rd, & r->GPR [ Reg1 ].sw0 );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->AddRegReg32( Rd, Rs );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->LeaRegRegReg32( Rd, Rs, Rt );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32 ( Rd, Rs );
							}
							
							e->AddRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							
							
							e->MovRegMem32( Rd, & r->GPR [ i.Rs ].sw0 );
							e->AddRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
							e->MovsxdReg64Reg32 ( Rd, Rd );
							
						}
					}
				}
			}
				
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

long Recompiler::SUBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SUBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUBU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s - r->GPR [ i.Rt ].u;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SUBU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rs )
				{
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->NegReg64 ( RAX );
					e->NegReg32 ( RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rs )
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->SubMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->SubRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_SUBU_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					Alloc_Const ( i.Rd, 0 );
				}
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( GetConst( i.Rs ) - GetConst( i.Rt ) ) ) );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if( Reg1 == i.Rs )
						{
							e->SubReg32ImmX( Rd, lConst );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							e->NegReg32( Rd );
							e->AddReg32ImmX( Rd, lConst );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if( Reg1 == i.Rs )
							{
								e->LeaRegRegImm32( Rd, Rs, -lConst );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								e->MovRegReg32( Rd, Rs );
								e->NegReg32( Rd );
								e->AddReg32ImmX( Rd, lConst );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else
						{
							e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							
							if( Reg1 == i.Rs )
							{
								e->SubReg32ImmX( Rd, lConst );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								e->NegReg32( Rd );
								e->AddReg32ImmX( Rd, lConst );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );

							if( i.Rd == i.Rs )
							{
								e->SubRegReg32( Rd, Rs );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								e->NegReg32( Rd );
								e->AddRegReg32( Rd, Rs );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if( i.Rd == i.Rs )
							{
								e->SubRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								e->NegReg32( Rd );
								e->AddRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg1 == i.Rs )
								{
									e->SubRegReg32 ( Rd, Rs );
									e->MovsxdReg64Reg32 ( Rd, Rd );
								}
								else
								{
									e->NegReg32( Rd );
									e->AddRegReg32( Rd, Rs );
									e->MovsxdReg64Reg32 ( Rd, Rd );
								}
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								
								e->MovRegReg32( Rd, Rs );
								e->SubRegReg32( Rd, Rt );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->SubRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								e->NegReg32( Rd );
								e->AddRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( Rd, & r->GPR [ i.Rs ].sw0 );
							e->SubRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

long Recompiler::AND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "AND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::AND;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //AND );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					//ret = e->MovMemImm32 ( &r->GPR [ i.Rd ].s, 0 );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rs != i.Rd )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					if ( i.Rt != i.Rd )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						//ret = e->AndMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->AndMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rt )
				{
					if ( i.Rs != i.Rd )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//ret = e->AndMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->AndMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->AndRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_AND_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( ( i.Rd == i.Rs ) && ( i.Rd == i.Rt ) )
				{
					// do nothing
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rs ) & GetConst( i.Rt ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( !lConst )
					{
						Alloc_Const( i.Rd, 0 );
					}
					else
					{
						if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
						{
							if ( Reg1 == i.Rd )
							{
								Rd = Alloc_SrcReg( i.Rd );
								Rd = Alloc_DstReg( i.Rd );
							}
							else
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							
							e->AndReg64ImmX( Rd, lConst );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							
							if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
							{
								Rs = Alloc_SrcReg( Reg1 );
								e->MovRegReg64( Rd, Rs );
								e->AndReg64ImmX( Rd, lConst );
							}
							else
							{
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
								e->AndReg64ImmX ( Rd, lConst );
							}
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AndRegReg64( Rd, Rs );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AndRegMem64 ( Rd, & r->GPR [ Reg1 ].s );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->AndRegReg64( Rd, Rs );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64( Rd, Rs );
								e->AndRegReg64( Rd, Rt );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							e->AndRegMem64( Rd, & r->GPR [ Reg2 ].s );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->AndRegMem64( Rd, & r->GPR [ i.Rt ].s );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

long Recompiler::OR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "OR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::OR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //OR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					if ( i.Rd != ( i.Rs | i.Rt ) )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					if ( i.Rd != i.Rt )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						//ret = e->OrMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->OrMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//ret = e->OrMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->OrMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->OrRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_OR_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( ( i.Rd == i.Rs ) && ( i.Rd == i.Rt ) )
				{
					// do nothing
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rs ) | GetConst( i.Rt ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( ( Reg1 == i.Rd ) && lConst ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->OrReg64ImmX( Rd, lConst );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							e->MovRegReg64( Rd, Rs );
							e->OrReg64ImmX( Rd, lConst );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->OrReg64ImmX ( Rd, lConst );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->OrRegReg64( Rd, Rs );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->OrRegMem64 ( Rd, & r->GPR [ Reg1 ].s );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->OrRegReg64( Rd, Rs );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64( Rd, Rs );
								e->OrRegReg64( Rd, Rt );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							e->OrRegMem64( Rd, & r->GPR [ Reg2 ].s );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->OrRegMem64( Rd, & r->GPR [ i.Rt ].s );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	
	return 1;
}

long Recompiler::XOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "XOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::XOR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //XOR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rs )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->XorMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->XorMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//ret = e->XorMemReg32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->XorMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->XorRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->XorRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_XOR_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					Alloc_Const ( i.Rd, 0 );
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rs ) ^ GetConst( i.Rt ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( ( Reg1 == i.Rd ) && lConst ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->XorReg64ImmX( Rd, lConst );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							e->MovRegReg64( Rd, Rs );
							e->XorReg64ImmX( Rd, lConst );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->XorReg64ImmX ( Rd, lConst );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->XorRegReg64( Rd, Rs );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->XorRegMem64 ( Rd, & r->GPR [ Reg1 ].s );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->XorRegReg64( Rd, Rs );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64( Rd, Rs );
								e->XorRegReg64( Rd, Rt );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							e->XorRegMem64( Rd, & r->GPR [ Reg2 ].s );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->XorRegMem64( Rd, & r->GPR [ i.Rt ].s );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "NOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::NOR;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //NOR );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, -1 );
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					if ( i.Rd != i.Rs )
					{
						//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						//e->NotReg32 ( RAX );
						e->NotReg64 ( RAX );
						//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						e->NotMem64 ( &r->GPR [ i.Rd ].s );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->OrRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//e->NotReg32 ( RAX );
					e->NotReg64 ( RAX );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_NOR_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ~( GetConst( i.Rs ) | GetConst( i.Rt ) ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->OrReg64ImmX( Rd, lConst );
						e->NotReg64( Rd );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							e->MovRegReg64( Rd, Rs );
							e->OrReg64ImmX( Rd, lConst );
							e->NotReg64( Rd );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->OrReg64ImmX ( Rd, lConst );
							e->NotReg64( Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) || ( Reg1 == i.Rd ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->OrRegReg64( Rd, Rs );
							e->NotReg64( Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->OrRegMem64 ( Rd, & r->GPR [ Reg1 ].s );
							e->NotReg64( Rd );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->OrRegReg64( Rd, Rs );
								e->NotReg64( Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64( Rd, Rs );
								e->OrRegReg64( Rd, Rt );
								e->NotReg64( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							e->OrRegMem64( Rd, & r->GPR [ Reg2 ].s );
							e->NotReg64( Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->OrRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->NotReg64( Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SLT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLT;
	
	//r->GPR [ i.Rd ].s = r->GPR [ i.Rs ].s < r->GPR [ i.Rt ].s ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLT );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rt )
				{
					// ***todo*** implement ShrMemImm64
					//if ( i.Rd == i.Rs )
					//{
					//	e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
					//}
					//else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//e->Cqo ();
						//e->NegReg32 ( RDX );
						e->ShrRegImm64 ( RAX, 63 );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					// this should zero-extend to 64 bits
					e->XorRegReg32 ( RCX, RCX );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->Set_L ( RCX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RCX );
				}
				
			}
			break;
			
#ifdef USE_NEW_SLT_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					Alloc_Const( i.Rd, 0 );
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( ( (s64) GetConst( i.Rs ) ) < ( (s64) GetConst( i.Rt ) ) ) ? 1 : 0 );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->CmpReg64ImmX( Rd, lConst );
						
						if ( Reg1 == i.Rs )
						{
							e->Set_L( Rd );
						}
						else
						{
							e->Set_G( Rd );
						}
						
						e->AndReg32ImmX( Rd, 1 );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							e->CmpReg64ImmX( Rs, lConst );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_L( Rd );
							}
							else
							{
								e->Set_G( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->CmpReg64ImmX ( Rd, lConst );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_L( Rd );
							}
							else
							{
								e->Set_G( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->CmpRegReg64( Rd, Rs );
							
							if ( Reg1 == i.Rt )
							{
								e->Set_L( Rd );
							}
							else
							{
								e->Set_G( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->CmpRegMem64( Rd, & r->GPR [ Reg1 ].s );
							
							if ( Reg1 == i.Rt )
							{
								e->Set_L( Rd );
							}
							else
							{
								e->Set_G( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg2 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
								
								e->CmpRegReg64( Rs, Rt );
								
								Rd = RenameReg( i.Rd, Reg2 );
								
								e->Set_L ( Rd );
								e->AndReg32ImmX( Rd, 1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								
								e->XorRegReg32( Rd, Rd );
								e->CmpRegReg64( Rs, Rt );
								e->Set_L ( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							e->CmpRegMem64( Rs, & r->GPR [ Reg2 ].s );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_L( Rd );
							}
							else
							{
								e->Set_G( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->CmpRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->Set_L( Rd );
							e->AndReg32ImmX( Rd, 1 );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SLTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTU;
	
	//r->GPR [ i.Rd ].u = r->GPR [ i.Rs ].s < r->GPR [ i.Rt ].s ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( ( !i.Rt ) || ( i.Rs == i.Rt ) )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					// this should zero-extend to 64 bits
					e->XorRegReg32 ( RCX, RCX );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->CmpRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					//e->Set_B ( RCX );
					e->AdcRegReg32 ( RCX, RCX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RCX );
				}
				
			}
			break;
			
#ifdef USE_NEW_SLTU_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					Alloc_Const( i.Rd, 0 );
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( ( (u64) GetConst( i.Rs ) ) < ( (u64) GetConst( i.Rt ) ) ) ? 1 : 0 );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						e->CmpReg64ImmX( Rd, lConst );
						
						if ( Reg1 == i.Rs )
						{
							e->Set_B( Rd );
						}
						else
						{
							e->Set_A( Rd );
						}
						
						e->AndReg32ImmX( Rd, 1 );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							e->CmpReg64ImmX( Rs, lConst );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_B( Rd );
							}
							else
							{
								e->Set_A( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->CmpReg64ImmX ( Rd, lConst );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_B( Rd );
							}
							else
							{
								e->Set_A( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->CmpRegReg64( Rd, Rs );
							
							if ( Reg1 == i.Rt )
							{
								e->Set_B( Rd );
							}
							else
							{
								e->Set_A( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->CmpRegMem64( Rd, & r->GPR [ Reg1 ].s );
							
							if ( Reg1 == i.Rt )
							{
								e->Set_B( Rd );
							}
							else
							{
								e->Set_A( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg2 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
								
								e->CmpRegReg64( Rs, Rt );
								
								Rd = RenameReg( i.Rd, Reg2 );
								
								e->Set_B ( Rd );
								e->AndReg32ImmX( Rd, 1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								
								e->XorRegReg32( Rd, Rd );
								e->CmpRegReg64( Rs, Rt );
								e->Set_B ( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							e->CmpRegMem64( Rs, & r->GPR [ Reg2 ].s );
							
							if ( Reg1 == i.Rs )
							{
								e->Set_B( Rd );
							}
							else
							{
								e->Set_A( Rd );
							}
							
							e->AndReg32ImmX( Rd, 1 );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->CmpRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->Set_B( Rd );
							e->AndReg32ImmX( Rd, 1 );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}


////////////////////////////////////////////
// I-Type Instructions (non-interrupt)



long Recompiler::ADDIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADDIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDIU;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s + i.sImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ADDIU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.sImmediate );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				else if ( !i.sImmediate )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				/*
				else if ( i.Rt == i.Rs )
				{
					e->AddMem64ImmX ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				*/
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
					e->AddReg32ImmX ( RAX, i.sImmediate );
					//e->AddReg64ImmX ( RAX, i.sImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					e->Cdqe ();
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_ADDIU_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{

					// both registers are constant //
					Alloc_Const ( i.Rt, (s64) ( (s32) ( GetConst( i.Rs ) + ( (s32) i.sImmediate ) ) ) );
					
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					// note: need to sign extend here
					//if ( i.sImmediate )
					//{
						Rt = Alloc_SrcReg( i.Rt );
						Rt = Alloc_DstReg( i.Rt );
					
						e->AddReg32ImmX( Rt, i.sImmediate );
						e->MovsxdReg64Reg32 ( Rt, Rt );
					//}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							e->AddReg32ImmX( Rt, i.sImmediate );
							e->MovsxdReg64Reg32 ( Rt, Rt );
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ***ADDIU***";
	debug << " i.Rs=" << dec << i.Rs;
	debug << " i.sImmed=" << dec << i.sImmediate;
	debug << " i.Rt=" << dec << i.Rt;
	debug << " Rt=" << dec << Rt;
#endif
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							if( i.sImmediate )
							{
								e->LeaRegRegImm32( Rt, Rs, i.sImmediate );
								e->MovsxdReg64Reg32 ( Rt, Rt );
							}
							else
							{
								//e->MovRegReg32( Rt, Rs );
								e->MovsxdReg64Reg32 ( Rt, Rs );
							}
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegMem32( Rt, & r->GPR [ i.Rs ].sw0 );
						e->AddReg32ImmX( Rt, i.sImmediate );
						e->MovsxdReg64Reg32 ( Rt, Rt );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ADDIU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::ANDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ANDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ANDI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s & i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ANDI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( ( !i.Rs ) || ( !i.uImmediate ) )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, 0 );
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, 0 );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->AndMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					ret = e->AndMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.uImmediate == 0xff )
				{
					e->MovzxReg32Mem8 ( RAX, (char*) &r->GPR [ i.Rs ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				else if ( i.uImmediate == 0xffff )
				{
					e->MovzxReg32Mem16 ( RAX, (short*) &r->GPR [ i.Rs ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->AndReg32ImmX ( RAX, i.uImmediate );
					e->AndReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_ANDI_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, GetConst( i.Rs ) & i.uImmediate );
				}
				else if ( !i.uImmediate )
				{
					Alloc_Const( i.Rt, 0 );
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					Rt = Alloc_SrcReg( i.Rt );
					Rt = Alloc_DstReg( i.Rt );
					e->AndReg64ImmX( Rt, i.uImmediate );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							e->AndReg64ImmX( Rt, i.uImmediate );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							e->MovRegReg64( Rt, Rs );
							e->AndReg64ImmX( Rt, i.uImmediate );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegMem64( Rt, & r->GPR [ i.Rs ].s );
						e->AndReg64ImmX( Rt, i.uImmediate );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ADDIU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::ORI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ORI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ORI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s | i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //ORI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->OrMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->OrMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( !i.uImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->OrReg32ImmX ( RAX, i.uImmediate );
					e->OrReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_ORI_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, GetConst( i.Rs ) | i.uImmediate );
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					if ( i.sImmediate )
					{
						Rt = Alloc_SrcReg( i.Rt );
						Rt = Alloc_DstReg( i.Rt );
						e->OrReg64ImmX( Rt, i.uImmediate );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							e->OrReg64ImmX( Rt, i.uImmediate );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							e->MovRegReg64 ( Rt, Rs );
							e->OrReg64ImmX( Rt, i.uImmediate );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegMem64( Rt, & r->GPR [ i.Rs ].s );
						e->OrReg64ImmX( Rt, i.uImmediate );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ADDIU instruction.\n";
		return -1;
	}
	
	return 1;
}

long Recompiler::XORI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "XORI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::XORI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s ^ i.uImmediate;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //XORI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					//e->MovMemImm32 ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					//e->XorMem32ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
					e->XorMem64ImmX ( &r->GPR [ i.Rt ].s, i.uImmediate );
				}
				else if ( !i.uImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].s );
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					//e->XorReg32ImmX ( RAX, i.uImmediate );
					e->XorReg64ImmX ( RAX, i.uImmediate );
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rt ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
				
			}
			break;
			
#ifdef USE_NEW_XORI_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, GetConst( i.Rs ) ^ i.uImmediate );
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					if ( i.uImmediate )
					{
						Rt = Alloc_SrcReg( i.Rt );
						Rt = Alloc_DstReg( i.Rt );
						e->XorReg64ImmX( Rt, i.uImmediate );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							e->XorReg64ImmX( Rt, i.uImmediate );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							e->MovRegReg64 ( Rt, Rs );
							e->XorReg64ImmX( Rt, i.uImmediate );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegMem64( Rt, & r->GPR [ i.Rs ].s );
						e->XorReg64ImmX( Rt, i.uImmediate );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nError encoding ADDIU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SLTI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLTI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTI;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s < i.sImmediate ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( !i.sImmediate )
				{
					// ***todo*** implement ShrMemImm64
					//if ( i.Rt == i.Rs )
					//{
					//	e->ShrMemImm64 ( &r->GPR [ i.Rs ].s, 63 );
					//}
					//else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						//e->Cqo ();
						//e->NegReg32 ( RDX );
						e->ShrRegImm64 ( RAX, 63 );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					// this should zero-extend to 64-bits
					e->XorRegReg32 ( RAX, RAX );
					e->CmpMemImm64 ( &r->GPR [ i.Rs ].s, i.sImmediate );
					e->Set_L ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SLTI_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, ( ( (s64) GetConst( i.Rs ) ) < ( (s64) i.sImmediate ) ) ? 1 : 0 );
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					Rt = Alloc_SrcReg( i.Rt );
					Rt = Alloc_DstReg( i.Rt );
				
					e->CmpReg64ImmX( Rt, i.sImmediate );
					e->Set_L( Rt );
					e->AndReg32ImmX ( Rt, 1 );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							
							e->CmpReg64ImmX( Rt, i.sImmediate );
							e->Set_L( Rt );
							e->AndReg32ImmX ( Rt, 1 );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							e->XorRegReg32( Rt, Rt );
							e->CmpReg64ImmX( Rs, i.sImmediate );
							e->Set_L( Rt );
							//e->AndReg32ImmX ( Rt, 1 );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						
						e->XorRegReg32 ( Rt, Rt );
						e->CmpMem64ImmX( & r->GPR [ i.Rs ].s, i.sImmediate );
						e->Set_L( Rt );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SLTIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLTIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLTIU;
	
	//r->GPR [ i.Rt ].s = r->GPR [ i.Rs ].s < ((u32) ((s32) i.sImmediate)) ? 1 : 0;
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLTIU );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				if ( !i.sImmediate )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, 0 );
				}
				else
				{
					// this should zero-extend to 64-bits
					e->XorRegReg32 ( RAX, RAX );
					e->CmpMemImm64 ( &r->GPR [ i.Rs ].s, i.sImmediate );
					//e->Set_B ( RAX );
					e->AdcRegReg32 ( RAX, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SLTIU_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, ( ( (u64) GetConst( i.Rs ) ) < ( (u64) ( (s64) i.sImmediate ) ) ) ? 1 : 0 );
				}
				else if ( !i.sImmediate )
				{
					Alloc_Const ( i.Rt, 0 );
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					Rt = Alloc_SrcReg( i.Rt );
					Rt = Alloc_DstReg( i.Rt );
				
					e->CmpReg64ImmX( Rt, i.sImmediate );
					e->Set_B( Rt );
					e->AndReg32ImmX ( Rt, 1 );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							
							e->CmpReg64ImmX( Rt, i.sImmediate );
							e->Set_B( Rt );
							e->AndReg32ImmX ( Rt, 1 );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							e->XorRegReg32 ( Rt, Rt );
							e->CmpReg64ImmX( Rs, i.sImmediate );
							e->Set_B( Rt );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						
						e->XorRegReg32 ( Rt, Rt );
						e->CmpMem64ImmX( & r->GPR [ i.Rs ].s, i.sImmediate );
						e->Set_B( Rt );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::LUI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LUI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LUI;
	
	//r->GPR [ i.Rt ].s = ( i.uImmediate << 16 );
	//CHECK_DELAYSLOT ( i.Rt );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// destination register is Rt
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			if ( i.Rt )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //LUI );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rt )
			{
				//ret = e->MovMemImm32 ( &r->GPR [ i.Rt ].s, ( i.uImmediate << 16 ) );
				ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, ( i.uImmediate << 16 ) );
			}
			break;
			
#ifdef USE_NEW_LUI_CODE2
		case 2:
			if ( i.Rt )
			{
				Alloc_Const( i.Rt, (s64) ( (s32) ( i.sImmediate << 16 ) ) );
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LUI instruction.\n";
		return -1;
	}
	return 1;
}







//////////////////////////////////////////////////////////
// Shift instructions



long Recompiler::SLL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLL;
	
	//r->GPR [ i.Rd ].u = ( r->GPR [ i.Rt ].s << i.Shift );
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLL );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					
					e->ShlRegImm32 ( RAX, (u32) i.Shift );
					
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SLL_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( GetConst( i.Rt ) << i.Shift ) ) );
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						e->ShlRegImm32( Rd, i.Shift );
					}
					
					e->MovsxdReg64Reg32 ( Rd, Rd );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->ShlRegImm32( Rd, i.Shift );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg32 ( Rd, Rt );
							e->ShlRegImm32( Rd, i.Shift );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
						e->ShlRegImm32( Rd, i.Shift );
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SLL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SRL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SRL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRL );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
				
					e->ShrRegImm32 ( RAX, (u32) i.Shift );
					//e->Cdqe ();
				
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SRL_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( ( (u32) GetConst( i.Rt ) ) >> i.Shift ) ) );
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						e->ShrRegImm32( Rd, i.Shift );
					}
					else
					{
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							if ( i.Shift )
							{
								e->ShrRegImm32( Rd, i.Shift );
							}
							else
							{
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( i.Shift )
							{
								e->MovRegReg32 ( Rd, Rt );
								e->ShrRegImm32( Rd, i.Shift );
							}
							else
							{
								e->MovsxdReg64Reg32 ( Rd, Rt );
							}
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
						
						if ( i.Shift )
						{
							e->ShrRegImm32( Rd, i.Shift );
						}
						else
						{
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SRA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SRA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRA;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRA );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->SarRegImm32 ( RAX, (u32) i.Shift );
					
					e->SarRegImm64 ( RAX, (u32) i.Shift );
					
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SRA_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (s32) GetConst( i.Rt ) ) >> i.Shift );
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						e->SarRegImm32( Rd, i.Shift );
					}
					
					e->MovsxdReg64Reg32 ( Rd, Rd );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->SarRegImm32( Rd, i.Shift );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg32 ( Rd, Rt );
							e->SarRegImm32( Rd, i.Shift );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
						e->SarRegImm32( Rd, i.Shift );
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SLLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SLLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SLLV;
	
	//r->GPR [ i.Rd ].u = ( r->GPR [ i.Rt ].s << ( r->GPR [ i.Rs ].s & 0x1f ) );
	//CHECK_DELAYSLOT ( i.Rd );
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SLLV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].s );
				
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShlRegReg32 ( RAX );
				
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SLLV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( GetConst( i.Rt ) << ( GetConst( i.Rs ) & 0x1f ) ) ) );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							//e->MovReg32ImmX( RCX, lConst & 0x1f );
							e->ShlRegImm32( Rd, lConst & 0x1f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg32ImmX( Rd, lConst );
							e->ShlRegReg32( Rd );
						}
						
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovReg32ImmX( Rd, lConst );
								e->ShlRegReg32( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegReg32( Rd, Rs );
								e->ShlRegImm32( Rd, lConst & 0x1f );
							}
							
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg32ImmX( Rd, lConst );
								e->ShlRegReg32( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
								e->ShlRegImm32( Rd, lConst & 0x1f );
							}
							
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->ShlRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							}
							
							e->ShlRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg32( Rd, Rs );
								}
								
								e->ShlRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg32( Rd, Rt );
								e->ShlRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->ShlRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
							e->ShlRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SRLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SRLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRLV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShrRegReg32 ( RAX );
					e->Cdqe ();
					//ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SRLV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( (s32) ( ( (u32) GetConst( i.Rt ) ) >> ( GetConst( i.Rs ) & 0x1f ) ) ) );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							e->ShrRegImm32( Rd, lConst & 0x1f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg32ImmX( Rd, lConst );
							e->ShrRegReg32( Rd );
						}
						
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovReg32ImmX( Rd, lConst );
								e->ShrRegReg32( Rd );
							}
							else
							{
								e->MovRegReg32( Rd, Rs );
								e->ShrRegImm32( Rd, lConst & 0x1f );
							}
							
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg32ImmX( Rd, lConst );
								e->ShrRegReg32( Rd );
							}
							else
							{
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
								e->ShrRegImm32( Rd, lConst & 0x1f );
							}
							
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->ShrRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							}
							
							e->ShrRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );

								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg32( Rd, Rs );
								}
								
								e->ShrRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg32( Rd, Rt );
								e->ShrRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->ShrRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
							e->ShrRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SRAV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SRAV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SRAV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	//bStopEncodingAfter = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

				// load arguments
				e->LoadImm32 ( RCX, i.Value );
				ret = e->Call ( c_vFunction ); //SRAV );
				
#ifdef RESERVE_STACK_FRAME_FOR_CALL
				ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					//e->MovsxdReg64Mem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegFromMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					
					// must shift right 32-bits here and do cdqe, otherwise need to mask the shift count to a 32-bit shift
					e->SarRegReg32 ( RAX );
					//e->SarRegReg64 ( RAX );
					e->Cdqe ();
					
					//e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
					e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_SRAV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, (s64) ( ( (s32) GetConst( i.Rt ) ) >> ( GetConst( i.Rs ) & 0x1f ) ) );
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							//e->MovReg32ImmX( RCX, lConst & 0x1f );
							e->SarRegImm32( Rd, lConst & 0x1f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg32ImmX( Rd, lConst );
							e->SarRegReg32( Rd );
						}
						
						e->MovsxdReg64Reg32 ( Rd, Rd );
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovReg32ImmX( Rd, lConst );
								e->SarRegReg32( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegReg32( Rd, Rs );
								e->SarRegImm32( Rd, lConst & 0x1f );
							}
							
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg32ImmX( Rd, lConst );
							}
							else
							{
								e->MovReg32ImmX( RCX, lConst );
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							}
							
							e->SarRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->SarRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem32( Rd, & r->GPR [ Reg1 ].sw0 );
							}
							
							e->SarRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg32( Rd, Rs );
								}
								
								e->SarRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg32( Rd, Rt );
								e->SarRegReg32( Rd );
								e->MovsxdReg64Reg32 ( Rd, Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem32( Rd, & r->GPR [ Reg2 ].sw0 );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg32( Rd, Rs );
							}
							
							e->SarRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem32( Rd, & r->GPR [ i.Rt ].sw0 );
							e->SarRegReg32( Rd );
							e->MovsxdReg64Reg32 ( Rd, Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	} // end switch ( OpLevel )
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDU instruction.\n";
		return -1;
	}
	return 1;
}


//----------------------------------------------------------------------------


////////////////////////////////////////////
// Jump/Branch Instructions



long Recompiler::J ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "J";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::J;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_Jump;
	//r->Status.DelaySlot_Valid |= 0x1;
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;

			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// load arguments
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //J );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_J_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJ> );
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //J instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::JR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "JR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JR;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_JumpRegister;
	//r->DelaySlot0.Data = r->GPR [ i.Rs ].s & ~3;
	//r->Status.DelaySlot_Valid |= 0x1;
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// has to stop encoding before AND after here due to the posible synchronous interrupt
			// so it has to have PC,LastPC updated (or could set it and move up the entry point)
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// could potentially encounter a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JR );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_JR_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJR> );
#else
			return -1;
#endif

			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->MovRegToMem32 ( &r->DelaySlot0.Data, 0 );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JR instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::JAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "JAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JAL;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.cb = r->_cb_Jump;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->GPR [ 31 ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( 31 );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// there is no synchronous interrupt possible here, so only needs to stop encoding after
			bStopEncodingAfter = true;
			
			// also have to stop before because need an updated NextPC so you get the correct link value
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			break;
			
		case 1:
#ifdef USE_NEW_JAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJAL> );
#else
			return -1;
#endif

			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->MovMemImm32 ( &r->GPR [ 31 ].u, Address + 8 );
			//ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, 31 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JAL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::JALR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "JALR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::JALR;
	
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.Data = r->GPR [ i.Rs ].s & ~3;
	//r->DelaySlot0.cb = r->_cb_JumpRegister;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->GPR [ i.Rd ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( i.Rd );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// has to stop encoding before AND after here due to the posible synchronous interrupt
			// so it has to have PC,LastPC updated (or could set it and move up the entry point)
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
			// could potentially encounter a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //JALR );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_JALR_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPJALR> );
#else
			return -1;
#endif
			
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->MovRegToMem32 ( &r->DelaySlot0.Data, 0 );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//if ( i.Rd )
			//{
			//	e->MovMemImm32 ( &r->GPR [ i.Rd ].s, Address + 8 );
			//	ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, i.Rd );
			//}
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //JALR instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BEQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BEQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BEQ;
	
	//if ( r->GPR [ i.Rs ].s == r->GPR [ i.Rt ].s )
	//{
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;

			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BEQ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BEQ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBEQ> );
#else
			return -1;
#endif
			
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->CmpRegMem32 ( 0, &r->GPR [ i.Rt ].s );
			//e->Jmp8_NE ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BEQ instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BNE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BNE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BNE;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BNE );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BNE_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBNE> );
#else
			return -1;
#endif
			
			//e->MovRegFromMem32 ( 0, &r->GPR [ i.Rs ].s );
			//e->CmpRegMem32 ( 0, &r->GPR [ i.Rt ].s );
			//e->Jmp8_E ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BNE instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BLEZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLEZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLEZ;
	
	//if ( r->GPR [ i.Rs ].s <= 0 )
	//{
	//	// next instruction is in the branch delay slot
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLEZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLEZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLEZ> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_G ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLEZ instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BGTZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGTZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGTZ;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGTZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGTZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGTZ> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_LE ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGTZ instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BLTZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLTZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLTZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZ> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_GE ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLTZ instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BGEZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGEZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZ;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			bStopEncodingAfter = true;
			
			// *MUST* update PC if branch will return to delay slot (at least for now)
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGEZ );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZ_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZ> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_L ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//ret = e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGEZ instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BLTZAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLTZAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZAL;
	
	//if ( r->GPR [ i.Rs ].s < 0 )
	//{
	//	r->DelaySlot0.Instruction = i;
	//	r->DelaySlot0.cb = r->_cb_Branch;
	//	r->Status.DelaySlot_Valid |= 0x1;
	//}
	//r->GPR [ 31 ].u = r->PC + 8;
	//CHECK_DELAYSLOT ( 31 );
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// needs to also stop encoding before at level 0, because it requires an updated PC to link
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BLTZAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZAL> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_GE ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			//e->MovMemImm32 ( &r->GPR [ 31 ].u, Address + 8 );
			//ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, 31 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BLTZAL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BGEZAL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGEZAL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZAL;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// needs to also stop encoding before at level 0, because it requires an updated PC to link
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BGEZAL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZAL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZAL> );
#else
			return -1;
#endif
			
			//e->CmpMemImm32 ( &r->GPR [ i.Rs ].s, 0 );
			//e->Jmp8_L ( 0, 0 );
			//e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			//e->OrMemImm64 ( &r->Status.Value, 1 );
			//e->SetJmpTarget8 ( 0 );
			//e->MovMemImm32 ( &r->GPR [ 31 ].u, Address + 8 );
			//ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, 31 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BGEZAL instruction.\n";
		return -1;
	}
	return 1;
}


/////////////////////////////////////////////////////////////
// Multiply/Divide Instructions

long Recompiler::MULT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MULT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULT;
	
	/*
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;
	*/
	
	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
	//{
	//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
	//}
	//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
	//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
	//{
	//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
	//}
	//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
	//{
	//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
	//}
	// multiply signed Lo,Hi = rs * rt
	//r->HiLo.sValue = ((s64) (r->GPR [ i.Rs ].s)) * ((s64) (r->GPR [ i.Rt ].s));
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// need to stop encoding before at level 0 to get an updated CycleCount
			// need to stop encoding after at level 0 because it updates CycleCount
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MULT );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULT_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.s, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MULT instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::MULTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MULTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULTU;
	
	// if rs is between 0 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;
	
	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// need to stop encoding before at level 0 to get an updated CycleCount
			// need to stop encoding after at level 0 because it updates CycleCount
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MULTU );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULTU_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.s, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MULTU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::DIV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DIV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV;
	
	static const int c_iDivideCycles = 36 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DIV );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
		case 1:
#ifdef USE_NEW_DIV_CODE
			//bResetCycleCount = true;
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_DIVIDE_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			
			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide signed: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	// if rs = 0x80000000 and rt = -1 then hi = 0 and lo = 0x80000000
			//	if ( r->GPR [ i.Rs ].s == 0x80000000 && r->GPR [ i.Rt ].s == -1 )
			//	{
			//		r->HiLo.uHi = 0;
			//		r->HiLo.uLo = 0x80000000;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].s;
			//		r->HiLo.sHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].s;
			//	}
			//}
			//else
			//{
			//	if ( r->GPR [ i.Rs ].s < 0 )
			//	{
			//		r->HiLo.sLo = 1;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = -1;
			//	}
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			//e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].s );
			//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			
			//e->MovReg64ImmX ( RCX, -1 );
			//e->MovReg64ImmX ( RDX, 1 );
			//e->OrRegReg32 ( RAX, RAX );
			//e->CmovSRegReg64 ( RCX, RDX );
			e->Cqo ();
			e->NotReg64 ( RDX );
			e->OrReg64ImmX ( RDX, 1 );
			
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			//e->MovRegReg64 ( RDX, RAX );
			//e->SarRegImm64 ( RDX, 63 );
			//e->Cqo ();
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			//e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			//e->MovMemReg64 ( & r->HI.s, RDX );
			//e->Jmp8 ( 0, 1 );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemReg64 ( & r->HI.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.uLo, RCX );
			e->MovMemReg64 ( & r->LO.s, RDX );
			
			//e->SetJmpTarget8 ( 1 );
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DIV instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::DIVU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DIVU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIVU;
	
	static const int c_iDivideCycles = 36 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			// actually needs to stop encoding before for now, because the correct current cycle count is needed
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DIVU );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIVU_CODE
			//bResetCycleCount = true;
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_DIVIDE_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide unsigned: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	r->HiLo.uLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].u;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].u;
			//}
			//else
			//{
			//	r->HiLo.sLo = -1;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			e->MovReg64ImmX ( RDX, -1 );
			
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			//e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			//e->MovMemReg64 ( & r->HI.s, RDX );
			//e->Jmp8 ( 0, 1 );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovMemImm32 ( & r->HiLo.sLo, -1 );
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			//e->MovMemImm64 ( & r->LO.s, -1 );
			e->MovMemReg64 ( & r->LO.s, RDX );
			e->MovMemReg64 ( & r->HI.s, RAX );
			
			//e->SetJmpTarget8 ( 1 );
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DIVU instruction.\n";
		return -1;
	}
	return 1;
}



long Recompiler::MFHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFHI;
	
	//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
	//{
	//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
	//}
	//r->GPR [ i.Rd ].u = r->HiLo.uHi;
	//CHECK_DELAYSLOT ( i.Rd );
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction (can update CycleCount)
			bStopEncodingAfter = true;
			
			// for now, stop encoding before, because an updated CycleCount is needed to determine if Mul/Div is done
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFHI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_MFHI_CODE
			/*
			e->MovRegFromMem64 ( RAX, (long long*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (long long*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uHi );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			// move from Hi register
			//r->GPR [ i.Rd ].u = r->HiLo.uHi;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uHi );
				e->MovRegMem64 ( RAX, & r->HI.s );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFHI instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::MFLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFLO;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction (can update CycleCount)
			bStopEncodingAfter = true;
			
			// for now, stop encoding before, because an updated CycleCount is needed to determine if Mul/Div is done
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFLO );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// make sure Rd is not r0
			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_MFLO_CODE
			/*
			e->MovRegFromMem64 ( RAX, (long long*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (long long*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uLo );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			// move from Lo register
			//r->GPR [ i.Rd ].u = r->HiLo.uLo;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uLo );
				e->MovRegMem64 ( RAX, & r->LO.s );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFLO instruction.\n";
		return -1;
	}
	return 1;
}




long Recompiler::MTHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTHI;
	
	//r->HiLo.uHi = r->GPR [ i.Rs ].u;
	
	// ***TODO*** should this sync with mul/div unit??
	
	int ret = 1;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTHI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uHi, RAX );
			ret = e->MovMemReg64 ( &r->HI.s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTHI instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::MTLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTLO;
	
	//r->HiLo.uLo = r->GPR [ i.Rs ].u;
	
	// ***TODO*** should this sync with mul/div unit??
	
	int ret = 1;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTLO );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uLo, RAX );
			ret = e->MovMemReg64 ( &r->LO.s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTLO instruction.\n";
		return -1;
	}
	return 1;
}








////////////////////////////////////////////////////////
// Instructions that can cause Synchronous Interrupts //
////////////////////////////////////////////////////////


long Recompiler::ADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADD;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //ADD );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			
			break;
			
		case 1:
#ifdef USE_NEW_ADD_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			
			if ( i.Rs && i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADD instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::ADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDI;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //ADDI );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rt )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			
			break;
			
		case 1:
#ifdef USE_NEW_ADDI_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			//e->AddRegMem32 ( RAX, &r->GPR [ i.Rt ].s );
			e->AddReg32ImmX ( RAX, i.sImmediate );
			
			if ( i.Rs && i.sImmediate )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rt )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //ADDI instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUB;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SUB );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			if ( !i.Rd )
			{
				// make sure r0 stays at zero
				ret = e->MovMemImm64 ( &r->GPR [ 0 ].s, 0 );
			}
			break;
			
		case 1:
#ifdef USE_NEW_SUB_CODE
			e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->SubRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
			
			if ( i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
				//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SUB instruction.\n";
		return -1;
	}
	return 1;
}




long Recompiler::SYSCALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SYSCALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SYSCALL;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	
	switch ( OpLevel )
	{
		case 0:
			
			// stop encoding before due to synchronous interrupt (needs updated PC,LastPC)
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int and stopped encoding before
			//e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SYSCALL );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			
#ifdef USE_NEW_SYSCALL_CODE
			// update CycleCount, set PC, then jump to synchronous interrupt
#ifdef ENABLE_R5900_BRANCH_PREDICTION_SYSCALL
			e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles + r->c_ullLatency_BranchMisPredict );
#else
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
			e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount + MemCycles );
#endif
			
			// set pc
			e->MovMemImm32 ( (long*) & r->PC, Address );
			
			//r->ProcessSynchronousInterrupt ( Cpu::EXC_SYSCALL );
			e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_SYSCALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SYSCALL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::BREAK ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BREAK";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BREAK;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// also need to stop encoding before, because it needs both PC and LastPC updated first
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int
			//e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //BREAK );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //BREAK instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::Invalid ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "Invalid";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::Invalid;
	
	int ret = 1;
	
	// stop encoding after since it is an unconditional synchronous interrupt
	bStopEncodingAfter = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// also need to stop encoding before, because it needs both PC and LastPC updated first
			bStopEncodingBefore = true;
			
			// update NextPC before executing instruction at level 0 since it may do a sync int
			// note: no need for this since it is an unconditional sync int
			//e->MovMemImm32 ( (long*) & r->NextPC, Address + 4 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //Invalid );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //Invalid instruction.\n";
		return -1;
	}
	return 1;
}





long Recompiler::MFC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFC0;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// should put something in delay slot, so return after this instruction at level 0
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegImm32 ( RCX, i.Rd );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Call ( (void*) R5900::Cpu::Read_MFC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Cdqe ();
			e->MovMemReg64 ( & r->GPR [ i.Rt ].s, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFC0 instruction.\n";
		return -1;
	}
	return 1;
}




long Recompiler::MTC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTC0;
	
	int ret = 1;
	
	// *testing*
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// should put something in delay slot, so return after this instruction at level 0
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			break;
			
		case 1:
			e->MovRegImm32 ( RCX, i.Rd );
			e->MovRegMem32 ( RDX, & r->GPR [ i.Rt ].sw0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->Call ( (void*) R5900::Cpu::Write_MTC0 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTC0 instruction.\n";
		return -1;
	}
	return 1;
}








long Recompiler::CFC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CFC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	//bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	//bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CFC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CFC2 instruction.\n";
		return -1;
	}
	return 1;
}



long Recompiler::CTC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CTC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	//bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	//bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CTC2 instruction.\n";
		return -1;
	}
	return 1;
}



long Recompiler::CFC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CFC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC2_NI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// to keep accurate cycle count, update minus 1 after the instruction
			bResetCycleCount = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CFC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CFC2_NI_CODE
		case 1:
			if ( i.Rt )
			{
				switch ( i.Rd )
				{
					case 0:
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq0, 0 );
						break;
						
					case 28:
						e->MovRegMem32 ( RAX, &VU0::_VU0->vi [ i.Rd ].s );
						e->AndReg32ImmX ( RAX, 0xc0c );
						e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
						break;
						
					default:
						e->MovsxdReg64Mem32 ( RAX, &VU0::_VU0->vi [ i.Rd ].s );
						e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CFC2 instruction.\n";
		return -1;
	}
	return 1;
}



long Recompiler::CTC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CTC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC2_NI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			
			// probably needs an updated CycleCount, so need to stop encoding before too for now
			bStopEncodingBefore = true;
			
			// to keep accurate cycle count, update minus 1 after the instruction
			bResetCycleCount = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_CTC2_NI_CODE
		case 1:
			if ( i.Rd )
			{
				if ( i.Rd == 28 )
				{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
					e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

					e->LoadImm32 ( RCX, i.Value );
					ret = e->Call ( c_vFunction ); //CTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
					ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
				}
				else if ( i.Rd == 16 )
				{
					e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
					e->MovRegMem32 ( RCX, &VU0::_VU0->vi [ i.Rd ].s );
					e->AndReg32ImmX ( RAX, 0xfc0 );
					e->AndReg32ImmX ( RCX, 0x3f );
					e->OrRegReg32 ( RAX, RCX );
					e->MovMemReg32 ( &VU0::_VU0->vi [ i.Rd ].s, RAX );
				}
				else
				{
					if ( !i.Rt )
					{
						e->MovMemImm32 ( &VU0::_VU0->vi [ i.Rd ].s, 0 );
					}
					else
					{
						e->MovRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
						e->MovMemReg32 ( &VU0::_VU0->vi [ i.Rd ].s, RAX );
					}
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CTC2 instruction.\n";
		return -1;
	}
	return 1;
}




// Load/Store - will need to use address translation to get physical addresses when needed

//////////////////////////////////////////////////////////////////////////
// store instructions

// store instructions
long Recompiler::SB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SB;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
	// should be able to stop before, but continue after
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SB_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
		
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SB );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_COMBINED_STORE_SB
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0xffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write_t<0xffULL> );
			}
#else

			ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write_t<0xffULL> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SB

#else

			return -1;

#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SB_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SB instruction.\n";
		return -1;
	}
	return 1;
}





long Recompiler::SH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SH;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SH_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SH );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_COMBINED_STORE_SH
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0xffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0x1, (void*) Playstation2::DataBus::Write_t<0xffffULL> );
			}
#else

			ret = Generate_Normal_Store ( i, Address, 0x1, (void*) Playstation2::DataBus::Write_t<0xffffULL> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SH

#else

			return -1;

#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SH_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SH instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SW;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SW_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SW );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_COMBINED_STORE_SW
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0xffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0x3, (void*) Playstation2::DataBus::Write_t<0xffffffffULL> );
			}
#else

			ret = R5900::Recompiler::Generate_Normal_Store ( i, Address, 0x3, (void*) Playstation2::DataBus::Write_t<0xffffffffULL> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SW

#else

			return -1;

#endif	// end #ifdef USE_NEW_STORE_CODE

			break;
			
#ifdef USE_NEW_SW_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SW instruction.\n";
		return -1;
	}
	return 1;
}





long Recompiler::SWL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SWL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWL;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SWL_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SWL );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		
#ifdef USE_NEW_STORE_CODE_SWL
		case 1:
			ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write );

			break;
#endif
			
#ifdef USE_NEW_SWL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SWL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWR;
	
	int ret = 1;
	
/*
	// for now, stop encoding after this instruction
#ifndef ENABLE_STORE_PREFIX
	bStopEncodingBefore = true;
#endif
#ifndef ENABLE_STORE_SUFFIX
	bStopEncodingAfter = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SWR_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// can just stop encoding before and ignore the prefix requirement at level 0 for testing
			bStopEncodingBefore = true;
			//bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SWR );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_STORE_CODE_SWR
		case 1:
			ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write );

			break;
#endif

#ifdef USE_NEW_SWR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SWR instruction.\n";
		return -1;
	}
	return 1;
}



/////////////////////////////////////////////////
// load instructions

// load instructions with delay slot
// *** todo *** it is also possible to this and just process load after load delay slot has executed - would still need previous load address before delay slot
// *** todo *** could also skip delay slot zero and put straight into delay slot 1 after next instruction, or just process load delay slot after next instruction
long Recompiler::LB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LB;
	
	//LoadAddress = r->GPR [ i.Base ].s + i.sOffset;
	//r->DelaySlot0.Instruction = i;
	//r->DelaySlot0.Data = LoadAddress;
	//r->DelaySlot0.cb = LB_DelaySlot_Callback_Bus;
	//r->Status.DelaySlot_Valid |= 0x1;
	//r->LastModifiedRegister = 255;
	int ret = 1;

/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LB_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;

			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			// need to do a before/after adjust on the CycleCount when calling from recompiler?
#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LB );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LB
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xff>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xff> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xff> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// sign-extend from byte to 64-bits ??
				//e->Cbw ();
				//e->Cwde ();
				//e->Cdqe ();
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LB_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}






long Recompiler::LH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LH;
	
	int ret = 1;

/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LH_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LH );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LH
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffff>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x1, (void*) Playstation2::DataBus::Read_t<0xffff> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x1, (void*) Playstation2::DataBus::Read_t<0xffff> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// sign-extend from byte to 64-bits ??
				//e->Cwde ();
				//e->Cdqe ();
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LH_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}








long Recompiler::LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LW;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LW_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LW );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LW
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// sign-extend from byte to 64-bits ??
				//e->Cdqe ();
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LW_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::LBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LBU;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LBU_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LBU );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LBU
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xff>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xff> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xff> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// zero-extend 16-bit value to 64-bits
				//e->AndReg32ImmX ( RAX, 0xff );
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LBU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LBU instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::LHU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LHU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LHU;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LHU_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LHU );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LHU
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffff>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x1, (void*) Playstation2::DataBus::Read_t<0xffff> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x1, (void*) Playstation2::DataBus::Read_t<0xffff> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// zero-extend 16-bit value to 64-bits
				//e->AndReg32ImmX ( RAX, 0xffff );
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
#ifdef USE_NEW_LHU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x1, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}





// load instructions without load-delay slot
long Recompiler::LWL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LWL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWL;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LWL_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LWL );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE_LWL
		case 1:
			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );
			
			if ( i.Rt )
			{
#ifdef USE_SHORT_LWL_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].s );
				//e->MovRegFromMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 3 );
				e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				//e->MovRegToMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->MovsxdReg64Mem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 0 );
				e->MovRegToMem64 ( RAX, RDX, NO_INDEX, SCALE_NONE, 0 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 3 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShlRegReg32 ( RAX );
				e->MovRegReg32 ( RDX, RAX );
				e->MovReg32ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShlRegReg32 ( RAX );
				e->NotReg32 ( RAX );
				e->AndRegMem32 ( RAX, &r->GPR [ i.Rt ].sw0 );
				e->OrRegReg32 ( RAX, RDX );
				e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif
			
#ifdef USE_NEW_LWL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LB instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::LWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWR;
	
	int ret = 1;
	
/*
#ifndef ENABLE_LOAD_SUFFIX
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
#endif
*/
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LWR_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LWR );
			
#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE_LWR
		case 1:
			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );
			
			if ( i.Rt )
			{
#ifdef USE_SHORT_LWR_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].s );
				e->MovRegFromMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, -4 );
				e->AndReg32ImmX ( RCX, 3 );
				e->NegReg64 ( RCX );
				e->MovRegToMem32 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				e->MovRegToMem32 ( 8, RDX, NO_INDEX, SCALE_NONE, -4 );
				e->SarRegImm32 ( RAX, 31 );
				e->CmovERegMem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 4 );
				e->MovRegToMem32 ( RAX, RDX, NO_INDEX, SCALE_NONE, 4 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->AndReg32ImmX ( RCX, 3 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg32ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
#endif
			}

			break;
#endif
			
#ifdef USE_NEW_LWR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LWR instruction.\n";
		return -1;
	}
	return 1;
}



// R3000A ONLY INSTRUCTIONS //

///////////////////////////
// GTE instructions

/*

long Recompiler::MFC2 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MFC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MFC2 instruction.\n";
		return -1;
	}
	return 1;
}


long Recompiler::MTC2 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	
	// probably needs an updated CycleCount, so need to stop encoding before too for now
	bStopEncodingBefore = true;
	
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MTC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MTC2 instruction.\n";
		return -1;
	}
	return 1;
}


long Recompiler::LWC2 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingBefore = true;
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //LWC2 );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			return -1;
			e->MovRegImm32 ( 0, i.sOffset );
			e->AddRegMem32 ( 0, &r->GPR [ i.Base ].u );
			e->MovMemImm32 ( &r->DelaySlot0.Instruction.Value, i.Value );
			e->MovRegToMem32 ( &r->DelaySlot0.Data, 0 );
			e->OrMemImm64 ( &r->Status.Value, 1 );
			ret = e->MovMemImm32 ( (s32*) &r->LastModifiedRegister, 255 );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //LWC2 instruction.\n";
		return -1;
	}
	return 1;
}


long Recompiler::SWC2 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	
	// for now, stop encoding after this instruction
	// and before
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SWC2 );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SWC2 instruction.\n";
		return -1;
	}
	return 1;
}


long Recompiler::RFE ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	
	// *testing*
	bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //RFE );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //RFE instruction.\n";
		return -1;
	}
	return 1;
}


long Recompiler::RTPS ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //RTPS );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //RTPS instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCLIP ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCLIP );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCLIP instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::OP ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //OP );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //OP instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::DPCS ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DPCS );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DPCS instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::INTPL ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //INTPL );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //INTPL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::MVMVA ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //MVMVA );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //MVMVA instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCDS ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCDS );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCDS instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::CDP ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CDP );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CDP instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCDT ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCDT );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCDT instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCCS ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCCS );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCCS instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::CC ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //CC );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //CC instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCS ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCS );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCS instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCT ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCT );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCT instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::SQR ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //SQR );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //SQR instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::DCPL ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DCPL );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DCPL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::DPCT ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //DPCT );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //DPCT instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::AVSZ3 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //AVSZ3 );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //AVSZ3 instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::AVSZ4 ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //AVSZ4 );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //AVSZ4 instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::RTPT ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //RTPT );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //RTPT instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::GPF ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //GPF );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //GPF instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::GPL ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //GPL );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //GPL instruction.\n";
		return -1;
	}
	return 1;
}

long Recompiler::NCCT ( R5900::Instruction::Format i, u32 Address )
{
	int ret = 1;
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	// to keep accurate cycle count, update minus 1 after the instruction
	bResetCycleCount = true;
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction ); //NCCT );
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //NCCT instruction.\n";
		return -1;
	}
	return 1;
}
*/


long Recompiler::COP2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "COP2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::COP2;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



//// ***** R5900 INSTRUCTIONS ***** ////

// arithemetic instructions //

long R5900::Recompiler::DADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADD_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->AddRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			
			if ( i.Rs && i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n"; //" << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDI_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->AddReg64ImmX ( RAX, i.sImmediate );
			
			if ( i.Rs && i.sImmediate )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rt )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDU_CODE
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					if ( i.Rd != ( i.Rs | i.Rt ) )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs | i.Rt ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rd == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddRegReg64 ( RAX, RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_DADDU_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rs ) + GetConst( i.Rt ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
					//return -1;
						if ( Reg1 == i.Rd )
						{
							if ( lConst )
							{
								Rd = Alloc_SrcReg( i.Rd );
								Rd = Alloc_DstReg( i.Rd );
								e->AddReg64ImmX( Rd, lConst );
							}
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
							e->AddReg64ImmX( Rd, lConst );
						}
						

					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							//e->LeaRegRegImm32( Rd, Rs, lConst );
							e->MovRegReg64 ( Rd, Rs );
							e->AddReg64ImmX ( Rd, lConst );
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							e->AddReg64ImmX ( Rd, lConst );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) || ( i.Rs == i.Rt ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AddRegReg64( Rd, Rs );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->AddRegMem64 ( Rd, & r->GPR [ Reg1 ].s );
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								e->AddRegReg64( Rd, Rs );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->LeaRegRegReg64( Rd, Rs, Rt );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							e->AddRegMem64( Rd, & r->GPR [ Reg2 ].s );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->AddRegMem64( Rd, & r->GPR [ i.Rt ].s );
						}
					}
				}
			}
				
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	
	return 1;
}

long R5900::Recompiler::DADDIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DADDIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DADDIU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DADDIU_CODE
			if ( i.Rt )
			{
				if ( !i.Rs )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rt ].s, i.sImmediate );
				}
				else if ( i.Rt == i.Rs )
				{
					if ( i.sImmediate )
					{
						ret = e->AddMem64ImmX ( &r->GPR [ i.Rt ].s, i.sImmediate );
					}
				}
				else if ( !i.sImmediate )
				{
					if ( i.Rt != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
					}
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->AddReg64ImmX ( RAX, i.sImmediate );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_DADDIU_CODE2
		case 2:
			if ( i.Rt )
			{
				if ( isConst( i.Rs ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rt, GetConst( i.Rs ) + ( (s64) i.sImmediate ) );
					
					lConst = GetConst( i.Rt );
					if ( isLarge( lConst ) )
					{
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegImm64 ( Rt, lConst );
					}
				}
				else if ( ( i.Rt == i.Rs ) )
				{
					// only one source reg and it could be same as destination //
					
					if ( i.sImmediate )
					{
						Rt = Alloc_SrcReg( i.Rt );
						Rt = Alloc_DstReg( i.Rt );
					
						e->AddReg64ImmX( Rt, i.sImmediate );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
					{
						if ( isDisposable( i.Rs ) )
						{
							// rs is disposable //
							
							Rt = RenameReg( i.Rt, i.Rs );
							e->AddReg64ImmX( Rt, i.sImmediate );
						}
						else
						{
							// rs is NOT disposable //
							
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_DstReg( i.Rt );
							
							if( i.sImmediate )
							{
								//e->LeaRegRegImm32( Rt, Rs, i.sImmediate );
								e->MovRegReg64( Rt, Rs );
								e->AddReg64ImmX( Rt, i.sImmediate );
							}
							else
							{
								e->MovRegReg64( Rt, Rs );
							}
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rt = Alloc_DstReg( i.Rt );
						e->MovRegMem64( Rt, & r->GPR [ i.Rs ].s );
						e->AddReg64ImmX( Rt, i.sImmediate );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSUB;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// go ahead and say that it modifies NextPC since it might, even if it does not this time around
			// but only if instruction is actually encoded
			Local_NextPCModified = true;
			
			// need to stop encoding before, because if it sync ints, that requires PC to be updated
			bStopEncodingBefore = true;
			
			// need to stop encoding after because if it sync ints, then it needs to "jump"
			bStopEncodingAfter = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DSUB_CODE
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			e->SubRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
			
			if ( i.Rt )
			{
				// branch if not signed overflow
				e->Jmp8_NO ( 0, 0 );
				
				// update CycleCount, set PC, then jump to synchronous interrupt
				e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
				
				// set pc
				e->MovMemImm32 ( (long*) & r->PC, Address );
				
				//r->ProcessSynchronousInterrupt ( Cpu::EXC_OV );
				e->JMP ( (void*) Cpu::ProcessSynchronousInterrupt_t<Cpu::EXC_OV> );
				
				// continue processing store from here //
				e->SetJmpTarget8 ( 0 );
			}
			
			// check if destination is r0
			if ( i.Rd )
			{
				// store result if not signed overflow
				ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSUBU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSUBU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSUBU;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DSUBU_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						ret = e->NegMem64 ( &r->GPR [ i.Rd ].s );
					}
					else
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						e->NegReg64 ( RAX );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rd == i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->SubMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				/*
				else if ( i.Rd == i.Rt )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					ret = e->AddMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				*/
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
					e->SubRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_DSUBU_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					Alloc_Const ( i.Rd, 0 );
				}
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rs ) - GetConst( i.Rt ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if( Reg1 == i.Rs )
						{
							e->SubReg64ImmX( Rd, lConst );
						}
						else
						{
							e->NegReg64( Rd );
							e->AddReg64ImmX( Rd, lConst );
						}
						
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if( Reg1 == i.Rs )
							{
								e->LeaRegRegImm32( Rd, Rs, -lConst );
							}
							else
							{
								e->MovRegReg64( Rd, Rs );
								e->NegReg64( Rd );
								e->AddReg64ImmX( Rd, lConst );
							}
						}
						else
						{
							e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							
							if( Reg1 == i.Rs )
							{
								e->SubReg64ImmX( Rd, lConst );
							}
							else
							{
								e->NegReg64( Rd );
								e->AddReg64ImmX( Rd, lConst );
							}
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );

							if( i.Rd == i.Rs )
							{
								e->SubRegReg64( Rd, Rs );
							}
							else
							{
								e->NegReg64( Rd );
								e->AddRegReg64( Rd, Rs );
							}
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if( i.Rd == i.Rs )
							{
								e->SubRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
							else
							{
								e->NegReg64( Rd );
								e->AddRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
						}
						
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg1 == i.Rs )
								{
									e->SubRegReg64 ( Rd, Rs );
								}
								else
								{
									e->NegReg64( Rd );
									e->AddRegReg64( Rd, Rs );
								}
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								
								e->MovRegReg64( Rd, Rs );
								e->SubRegReg64( Rd, Rt );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg64 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->SubRegMem64( Rd, & r->GPR [ Reg2 ].s );
							}
							else
							{
								e->NegReg64( Rd );
								e->AddRegMem64( Rd, & r->GPR [ Reg2 ].s );
							}
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( Rd, & r->GPR [ i.Rs ].s );
							e->SubRegMem64( Rd, & r->GPR [ i.Rt ].s );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSLL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSLL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					ret = e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Shift )
				{
					if ( i.Rd != i.Rt )
					{
						e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
						ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					e->ShlRegImm64 ( RAX, (u32) i.Shift );
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSLL_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (u64) GetConst( i.Rt ) ) << i.Shift );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						Rd = Alloc_SrcReg( i.Rd );
						Rd = Alloc_DstReg( i.Rd );
						e->ShlRegImm64( Rd, i.Shift );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->ShlRegImm64( Rd, i.Shift );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->ShlRegImm64( Rd, i.Shift );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->ShlRegImm64( Rd, i.Shift );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSLL32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSLL32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLL32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->ShlRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSLL32_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " ***DSLL32***";
	debug << " shift=" << dec << i.Shift;
	debug << " i.Rt=" << dec << i.Rt;
	debug << " Rt=" << hex << GetConst( i.Rt );
	//debug << " i.sImmed=" << dec << i.sImmediate;
#endif

					// both registers are constant //
					Alloc_Const ( i.Rd, ( (u64) GetConst( i.Rt ) ) << ( ( (u64) i.Shift ) + 32ull ) );
					
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " i.Rd=" << dec << i.Rd;
	debug << " Rd=" << hex << GetConst( i.Rd );
#endif

					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
#ifdef INLINE_DEBUG_RECOMPILE2
	debug << " LARGE";
#endif
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					e->ShlRegImm64( Rd, (u32) i.Shift + 32 );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->ShlRegImm64( Rd, (u32) i.Shift + 32 );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->ShlRegImm64( Rd, (u32) i.Shift + 32 );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->ShlRegImm64( Rd, (u32) i.Shift + 32 );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSLLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSLLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSLLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShlRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSLLV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, GetConst( i.Rt ) << ( GetConst( i.Rs ) & 0x3f ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							//e->MovReg32ImmX( RCX, lConst & 0x1f );
							e->ShlRegImm64( Rd, lConst & 0x3f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg64ImmX( Rd, lConst );
							e->ShlRegReg64( Rd );
						}
						
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg64( RCX, Rs );
								e->MovReg64ImmX( Rd, lConst );
								e->ShlRegReg64( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegReg64( Rd, Rs );
								e->ShlRegImm64( Rd, lConst & 0x3f );
							}
							
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg64ImmX( Rd, lConst );
								e->ShlRegReg64( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
								e->ShlRegImm64( Rd, lConst & 0x3f );
							}
							
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->ShlRegReg64( Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
							
							e->ShlRegReg64( Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg64( Rd, Rs );
								}
								
								e->ShlRegReg64( Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg64( Rd, Rt );
								e->ShlRegReg64( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem64( Rd, & r->GPR [ Reg2 ].s );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->ShlRegReg64( Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->ShlRegReg64( Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRA;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					if ( i.Shift )
					{
						e->SarRegImm64 ( RAX, (u32) i.Shift );
					}
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRA_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (s64) GetConst( i.Rt ) ) >> i.Shift );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						Rd = Alloc_SrcReg( i.Rd );
						Rd = Alloc_DstReg( i.Rd );
						e->SarRegImm64( Rd, i.Shift );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->SarRegImm64( Rd, i.Shift );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->SarRegImm64( Rd, i.Shift );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->SarRegImm64( Rd, i.Shift );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRA32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRA32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRA32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->SarRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRA32_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (s64) GetConst( i.Rt ) ) >> ( i.Shift + 32 ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					e->SarRegImm64( Rd, i.Shift + 32 );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->SarRegImm64( Rd, i.Shift + 32 );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->SarRegImm64( Rd, i.Shift + 32 );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->SarRegImm64( Rd, i.Shift + 32 );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRAV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRAV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRAV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->SarRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRAV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (s64) GetConst( i.Rt ) ) >> ( GetConst( i.Rs ) & 0x3f ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							//e->MovReg32ImmX( RCX, lConst & 0x1f );
							e->SarRegImm64( Rd, lConst & 0x3f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg64ImmX( Rd, lConst );
							e->SarRegReg64( Rd );
						}
						
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovReg64ImmX( Rd, lConst );
								e->SarRegReg64( Rd );
							}
							else
							{
								//e->MovReg32ImmX( RCX, lConst );
								e->MovRegReg64( Rd, Rs );
								e->SarRegImm64( Rd, lConst & 0x3f );
							}
							
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg64ImmX( Rd, lConst );
							}
							else
							{
								e->MovReg32ImmX( RCX, lConst );
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
							
							e->SarRegReg64( Rd );
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->SarRegReg64( Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
							
							e->SarRegReg64( Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg64( Rd, Rs );
								}
								
								e->SarRegReg64( Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg32( Rd, Rt );
								e->SarRegReg32( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem64( Rd, & r->GPR [ Reg2 ].s );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->SarRegReg64( Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->SarRegReg64( Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRL;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					
					if ( i.Shift )
					{
						e->ShrRegImm64 ( RAX, (u32) i.Shift );
					}
					
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRL_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (u64) GetConst( i.Rt ) ) >> i.Shift );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					// only need to do anything if immediate is not zero
					if ( i.Shift )
					{
						Rd = Alloc_SrcReg( i.Rd );
						Rd = Alloc_DstReg( i.Rd );
						e->ShrRegImm64( Rd, i.Shift );
					}
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->ShrRegImm64( Rd, i.Shift );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->ShrRegImm64( Rd, i.Shift );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->ShrRegImm64( Rd, i.Shift );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRL32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRL32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRL32;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1 << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->ShrRegImm64 ( RAX, (u32) i.Shift + 32 );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRL32_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isConst( i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (u64) GetConst( i.Rt ) ) >> ( i.Shift + 32 ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( ( i.Rd == i.Rt ) )
				{
					// only one source reg and it could be same as destination //
					
					Rd = Alloc_SrcReg( i.Rd );
					Rd = Alloc_DstReg( i.Rd );
					e->ShrRegImm64( Rd, i.Shift + 32 );
				}
				else
				{
					// all registers are different //
					
					if ( isAlloc( i.Rt ) || ( ! isDisposable( i.Rt ) ) )
					{
						if ( isDisposable( i.Rt ) )
						{
							// rs is disposable //
							
							Rd = RenameReg( i.Rd, i.Rt );
							e->ShrRegImm64( Rd, i.Shift + 32 );
						}
						else
						{
							// rs is NOT disposable //
							
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegReg64 ( Rd, Rt );
							e->ShrRegImm64( Rd, i.Shift + 32 );
						}
					}
					else
					{
						// Rs is not allocated and is disposable //
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
						e->ShrRegImm64( Rd, i.Shift + 32 );
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DSRLV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DSRLV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DSRLV;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->MovMemImm64 ( &r->GPR [ i.Rd ].s, 0 );
				}
				else if ( !i.Rs )
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->MovRegMem64 ( RAX, &r->GPR [ i.Rt ].s );
					e->MovRegMem32 ( RCX, &r->GPR [ i.Rs ].sw0 );
					e->ShrRegReg64 ( RAX );
					ret = e->MovMemReg64 ( &r->GPR [ i.Rd ].s, RAX );
				}
			}
			break;
			
#ifdef USE_NEW_DSRLV_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					Alloc_Const ( i.Rd, ( (u64) GetConst( i.Rt ) ) >> ( GetConst( i.Rs ) & 0x3f ) );
					
					lConst = GetConst( i.Rd );
					if ( isLarge( lConst ) )
					{
						Rd = Alloc_DstReg( i.Rd );
						e->MovRegImm64 ( Rd, lConst );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
					// get const in Reg2
					Reg2 = SelectConst( i.Rs, i.Rt );
					
					// get the other register in Reg1
					if ( Reg2 == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
					// get the constnnt
					lConst = GetConst( Reg2 );
					
					if ( ( Reg1 == i.Rd ) || ( isAlloc( Reg1 ) && isDisposable( Reg1 ) ) )
					{
						if ( Reg1 == i.Rd )
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
						}
						else
						{
							Rd = RenameReg( i.Rd, Reg1 );
						}
						
						if ( Reg2 == i.Rs )
						{
							e->ShrRegImm64( Rd, lConst & 0x3f );
						}
						else
						{
							e->MovRegReg32( RCX, Rd );
							e->MovReg64ImmX( Rd, lConst );
							e->ShrRegReg64( Rd );
						}
						
					}
					else
					{
						Rd = Alloc_DstReg( i.Rd );
						
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovReg64ImmX( Rd, lConst );
								e->ShrRegReg64( Rd );
							}
							else
							{
								e->MovRegReg64( Rd, Rs );
								e->ShrRegImm64( Rd, lConst & 0x3f );
							}
							
						}
						else
						{
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
								e->MovReg64ImmX( Rd, lConst );
								e->ShrRegReg64( Rd );
							}
							else
							{
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
								e->ShrRegImm64( Rd, lConst & 0x3f );
							}
							
						}
					}
				}
				else
				{
					// all registers, no constants //
					
					if ( ( i.Rd == i.Rs ) || ( i.Rd == i.Rt ) )
					{
						// 2 op, all registers //
						
						if ( i.Rd == i.Rs ) Reg1 = i.Rt; else Reg1 = i.Rs;
					
						if ( isAlloc( Reg1 ) || ( !isDisposable( Reg1 ) ) )
						{
							Rs = Alloc_SrcReg( Reg1 );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->ShrRegReg64( Rd );
						}
						else
						{
							// register is not alloc and is disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg1 ].sw0 );
							}
							else
							{
								e->MovRegReg32( RCX, Rd );
								e->MovRegMem64( Rd, & r->GPR [ Reg1 ].s );
							}
							
							e->ShrRegReg64( Rd );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							
							if ( isEitherDisposable( i.Rs, i.Rt ) )
							{
								Reg1 = SelectDisposable( i.Rs, i.Rt );
								
								if ( Reg1 == i.Rs ) Reg2 = i.Rt; else Reg2 = i.Rs;
								
								Rs = Alloc_SrcReg( Reg2 );
								
								Rd = RenameReg( i.Rd, Reg1 );
								
								if ( Reg2 == i.Rs )
								{
									e->MovRegReg32( RCX, Rs );
								}
								else
								{
									e->MovRegReg32( RCX, Rd );
									e->MovRegReg64( Rd, Rs );
								}
								
								e->ShrRegReg64( Rd );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								e->MovRegReg32( RCX, Rs );
								e->MovRegReg64( Rd, Rt );
								e->ShrRegReg64( Rd );
							}
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							Rs = Alloc_SrcReg( Reg1 );
							
							if ( isDisposable ( Reg1 ) )
							{
								Rd = RenameReg( i.Rd, Reg1 );
							}
							else
							{
								Rd = Alloc_DstReg( i.Rd );
								//e->MovRegReg32 ( Rd, Rs );
							}
							
							if ( Reg1 == i.Rs )
							{
								e->MovRegReg32( RCX, Rs );
								e->MovRegMem64( Rd, & r->GPR [ Reg2 ].s );
							}
							else
							{
								e->MovRegMem32( RCX, & r->GPR [ Reg2 ].sw0 );
								e->MovRegReg64( Rd, Rs );
							}
							
							e->ShrRegReg64( Rd );
						}
						else
						{
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem32( RCX, & r->GPR [ i.Rs ].sw0 );
							e->MovRegMem64( Rd, & r->GPR [ i.Rt ].s );
							e->ShrRegReg64( Rd );
						}
					}
				}
			}
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::MULT1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MULT1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULT1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;
	
	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULT1_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MULTU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MULTU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULTU1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;
	
	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MULTU1_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DIV1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DIV1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV1;
	
	static const int c_iDivideCycles = 36 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIV1_CODE
			//bResetCycleCount = true;
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_DIVIDE_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide signed: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	// if rs = 0x80000000 and rt = -1 then hi = 0 and lo = 0x80000000
			//	if ( r->GPR [ i.Rs ].s == 0x80000000 && r->GPR [ i.Rt ].s == -1 )
			//	{
			//		r->HiLo.uHi = 0;
			//		r->HiLo.uLo = 0x80000000;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].s;
			//		r->HiLo.sHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].s;
			//	}
			//}
			//else
			//{
			//	if ( r->GPR [ i.Rs ].s < 0 )
			//	{
			//		r->HiLo.sLo = 1;
			//	}
			//	else
			//	{
			//		r->HiLo.sLo = -1;
			//	}
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			//e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].s );
			//e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].s );
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			//e->MovReg64ImmX ( RCX, -1 );
			//e->MovReg64ImmX ( RDX, 1 );
			//e->OrRegReg32 ( RAX, RAX );
			//e->CmovSRegReg64 ( RCX, RDX );
			e->Cqo ();
			e->NotReg64 ( RDX );
			e->OrReg64ImmX ( RDX, 1 );
			
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			//e->MovRegReg64 ( RDX, RAX );
			//e->SarRegImm64 ( RDX, 63 );
			//e->Cqo ();
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			//e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			//e->MovMemReg64 ( & r->HI.sq1, RDX );
			//e->Jmp8 ( 0, 1 );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.uLo, RCX );
			e->MovMemReg64 ( & r->LO.sq1, RDX );
			
			//e->SetJmpTarget8 ( 1 );
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DIVU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DIVU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIVU1;
	
	static const int c_iDivideCycles = 36 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_DIVU1_CODE
			//bResetCycleCount = true;
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_DIVIDE_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// mult/div unit is busy now
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iDivideCycles;
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddReg64ImmX ( RAX, c_iDivideCycles );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RAX );
			
			// divide unsigned: Lo = rs / rt; Hi = rs % rt
			//if ( r->GPR [ i.Rt ].s != 0 )
			//{
			//	r->HiLo.uLo = r->GPR [ i.Rs ].s / r->GPR [ i.Rt ].u;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].s % r->GPR [ i.Rt ].u;
			//}
			//else
			//{
			//	r->HiLo.sLo = -1;
			//	r->HiLo.uHi = r->GPR [ i.Rs ].u;
			//}
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			e->MovReg64ImmX ( RDX, -1 );
			
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			//e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			//e->MovMemReg64 ( & r->HI.sq1, RDX );
			//e->Jmp8 ( 0, 1 );
			e->XchgRegReg64 ( RAX, RDX );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovMemImm32 ( & r->HiLo.sLo, -1 );
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			//e->MovMemImm64 ( & r->LO.sq1, -1 );
			e->MovMemReg64 ( & r->LO.sq1, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
			
			//e->SetJmpTarget8 ( 1 );
			
			// done //
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADD_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw0 );
			e->AdcRegMem32 ( RDX, & r->HI.sw0 );
			
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq0, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq0, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADD1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADD1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADD1_CODE
			//bResetCycleCount = true;
			
			// calculate cycles mul/div unit will be busy for
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 && r->GPR [ i.Rs ].s >= -0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 && r->GPR [ i.Rs ].s >= -0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegReg32 ( RAX, RCX );
			e->XorReg32ImmX ( RAX, -1 );
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->ImulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw2 );
			e->AdcRegMem32 ( RDX, & r->HI.sw2 );
			
			// *** TODO FOR PS2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//ret = e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADDU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADDU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDU;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MADDU_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw0 );
			e->AdcRegMem32 ( RDX, & r->HI.sw0 );
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq0, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq0, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADDU1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADDU1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDU1;
	
	// if rs is between -0x800 and 0x7ff, then multiply takes 6 cycles
	static const int c_iMultiplyCycles_Fast = 6;
	
	// if rs is between 0x800 and 0xfffff or between -0x7ff and -0x100000, then multiply takes 9 cycles
	static const int c_iMultiplyCycles_Med = 9;
	
	// otherwise, multiply takes 13 cycles
	static const int c_iMultiplyCycles_Slow = 13;

	// constant multiply cycles for PS2
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MADDU1_CODE
			//bResetCycleCount = true;
			
			//r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Slow;
			//if ( r->GPR [ i.Rs ].s < 0x800 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Fast;
			//}
			//else if ( r->GPR [ i.Rs ].s < 0x100000 )
			//{
			//	r->MulDiv_BusyUntil_Cycle = r->CycleCount + c_iMultiplyCycles_Med;
			//}
			/*
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovReg32ImmX ( RDX, c_iMultiplyCycles_Slow );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Med );
			e->CmpReg32ImmX ( RAX, 0x100000 );
			e->CmovBRegReg32 ( RDX, RCX );
			e->MovReg32ImmX ( RCX, c_iMultiplyCycles_Fast );
			e->CmpReg32ImmX ( RAX, 0x800 );
			e->CmovBRegReg32 ( RDX, RCX );
			*/
			
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			e->MovRegReg64 ( RCX, RAX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			//e->XorRegReg64 ( RDX, RDX );
			//e->SubRegReg64 ( RAX, RCX );
			//e->CmovBRegReg64 ( RDX, RAX );
			
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// or, no need to subtract one if we don't count the cycle for the instruction (can subtract one when resetting the cycle count)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			
			// add the REAL CycleCount (CPU) to the cycles for the multiply and store to the BusyUntil Cycle for Mul/Div unit
			//e->AddRegReg64 ( RDX, RAX );
			e->SubRegReg64 ( RCX, RDX );
			
#ifdef ENABLE_MULTIPLY_LATENCY
			// add in the latency for multiply
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
#endif

			// write back the new busy until cycle
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// do the multiply
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MulRegMem32 ( & r->GPR [ i.Rt ].sw0 );
			
			// for MADD, add to LO,HI
			e->AddRegMem32 ( RAX, & r->LO.sw2 );
			e->AdcRegMem32 ( RDX, & r->HI.sw2 );
			
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			ret = e->MovMemReg64 ( & r->HI.sq1, RDX );
			
			// *note*: the R5900 additionally writes to a destination register
			if ( i.Rd )
			{
				ret = e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// Load/Store instructions //

long R5900::Recompiler::SD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SD;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SD_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_COMBINED_STORE_SD
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0xffffffffffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0x7, (void*) Playstation2::DataBus::Write_t<0xffffffffffffffffULL> );
			}
#else

			ret = Generate_Normal_Store ( i, Address, 0x7, (void*) Playstation2::DataBus::Write_t<0xffffffffffffffffULL> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SD

#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_SD_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x7, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::LD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LD;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LD_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LD
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffffffffffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x7, (void*) Playstation2::DataBus::Read_t<0xffffffffffffffffULL> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x7, (void*) Playstation2::DataBus::Read_t<0xffffffffffffffffULL> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// sign-extend from byte to 64-bits ??
				//e->Cbw ();
				//e->Cwde ();
				//e->Cdqe ();
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_LD_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x7, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::LWU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LWU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LWU
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
		//cout << "\nCOMBINED-LWU - Address: " << hex << Address << " Count=" << dec << iLoadCount << " Mask=" << hex << uMaxWidthMask;
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				// zero-extend 32-bit value to 64-bits
				//e->AndReg32ImmX ( RAX, 0xff );
				
				// store
				ret = e->MovMemReg64 ( & r->GPR [ i.Rt ].sq0, RAX );
			}
#else
			return -1;
#endif
			break;
			
#ifdef USE_NEW_LWU_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x3, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SDL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SDL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SDL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SDL_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_STORE_CODE_SDL
		case 1:
			ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write );

			break;
#endif

#ifdef USE_NEW_SDL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SDR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SDR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SDR;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_SDR_CODE2
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt );
			
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_STORE_CODE_SDR
		case 1:
			ret = Generate_Normal_Store ( i, Address, 0x0, (void*) Playstation2::DataBus::Write );

			break;
#endif

#ifdef USE_NEW_SDR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Store_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::LDL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LDL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LDL;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LDL_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_LOAD_CODE_LDL
		case 1:
			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xffffffffffffffffULL> );
			
			if ( i.Rt )
			{
#ifdef USE_SHORT_LDL_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].sw0 );
				e->NotReg32( RCX );
				e->AndReg32ImmX ( RCX, 7 );
				
				e->MovRegFromMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, 8 );
				
				e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				
				e->MovRegToMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, 8 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 7 );
				e->NotReg32 ( RCX );
				e->AndReg32ImmX ( RCX, 7 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShlRegReg64 ( RAX );
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg64ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShlRegReg64 ( RAX );
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif

#ifdef USE_NEW_LDL_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::LDR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LDR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LDR;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
#ifdef USE_NEW_LDR_CODE2
		case -1:
			// source registers are Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rt );
			break;
#endif
			
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_LOAD_CODE_LDR
		case 1:
			ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0xffffffffffffffffULL> );
			
			if ( i.Rt )
			{
#ifdef USE_SHORT_LDR_CODE
				e->LeaRegMem64 ( RDX, & r->GPR [ i.Rt ].sw0 );
				e->AndReg32ImmX ( RCX, 7 );
				e->NegReg64( RCX );
				
				e->MovRegFromMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, -8 );
				
				e->MovRegToMem64 ( RAX, RDX, RCX, SCALE_NONE, 0 );
				
				e->MovRegToMem64 ( 8, RDX, NO_INDEX, SCALE_NONE, -8 );
#else
				//e->MovRegFromMem32 ( RCX, &r->GPR [ i.Base ].sw0 );
				//e->AddReg32ImmX ( RCX, i.sOffset );
				
				//e->XorReg32ImmX ( RCX, 3 );
				e->AndReg32ImmX ( RCX, 7 );
				e->ShlRegImm32 ( RCX, 3 );
				e->ShrRegReg64 ( RAX );
				//e->Cdqe ();
				e->MovRegReg64 ( RDX, RAX );
				e->MovReg64ImmX ( RAX, -1 );
				//e->SubReg32ImmX ( RCX, 32 );
				//e->NegReg32 ( RCX );
				e->ShrRegReg64 ( RAX );
				//e->Cdqe ();
				e->NotReg64 ( RAX );
				e->AndRegMem64 ( RAX, &r->GPR [ i.Rt ].sq0 );
				e->OrRegReg64 ( RAX, RDX );
				//e->Cdqe ();
				ret = e->MovMemReg64 ( &r->GPR [ i.Rt ].sq0, RAX );
#endif
			}

			break;
#endif

#ifdef USE_NEW_LDR_CODE2
		case 2:
			if ( isConst ( i.Rs ) )
			{
				ret = Generate_Normal_Load_L2 ( i, Address, 0x0, GetConst( i.Rs ) );
				if ( !ret ) return -1;
			}
			else
			{
				return -1;
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::LQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
		case 1:
#ifdef USE_NEW_LOAD_CODE

#ifdef ENABLE_COMBINED_LOAD_LQ
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x0, (void*) Playstation2::DataBus::Read_t<0> );
			}
#else

			ret = Generate_Normal_Load ( i, Address, 0, (void*) Playstation2::DataBus::Read_t<0> );

#endif
			
			// store result //
			
			if ( i.Rt )
			{
				
				// store
				//e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rt ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_STORE_CODE

#ifdef ENABLE_COMBINED_STORE_SQ
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0, (void*) Playstation2::DataBus::Write_t<0> );
			}
#else

			ret = Generate_Normal_Store ( i, Address, 0, (void*) Playstation2::DataBus::Write_t<0> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SQ

#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::MOVZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MOVZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOVZ;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt ) | ( 1ull << i.Rd );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( i.Rd != i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RCX, RCX );
						e->CmovERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					if ( i.Rs == i.Rt )
					{
						e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RAX, RAX );
						e->CmovERegReg64 ( RCX, RAX );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else
					{
						e->CmpMem64ImmX ( & r->GPR [ i.Rt ].s, 0 );
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						//e->OrRegReg64 ( RAX, RAX );
						e->CmovERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
				}
			}
			break;
			
#ifdef USE_NEW_MOVZ_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rd == i.Rs )
				{
					// do nothing //
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					if ( ! GetConst( i.Rt ) )
					{
						Alloc_Const ( i.Rd, GetConst( i.Rs ) );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
				//return -1;
					if ( isConst( i.Rt ) )
					{
						if ( ! GetConst( i.Rt ) )
						{
							if ( isAlloc( i.Rs ) || ( !isDisposable( i.Rs ) ) )
							{
								if ( isDisposable( i.Rs ) )
								{
									RenameReg( i.Rd, i.Rs );
								}
								else
								{
									Rs = Alloc_SrcReg( i.Rs );
									Rd = Alloc_DstReg( i.Rd );
									e->MovRegReg64( Rd, Rs );
								}
							}
							else
							{
								// rs is not allocated and disposable //
								Rd = Alloc_DstReg ( i.Rd );
								e->MovRegMem64( Rd, & r->GPR [ i.Rs ].sq0 );
							}
						}
					}
					else
					{
						lConst = GetConst ( i.Rs );
						
						if ( isAlloc( i.Rt ) || ( !isDisposable( i.Rt ) ) )
						{
							// even if rt is disposable, can't dispose it here //
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->MovReg64ImmX ( RCX, lConst );
							e->OrRegReg64 ( Rt, Rt );
							e->CmovERegReg64( Rd, RCX );
						}
						else
						{
							// rt not allocated and disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( RCX, & r->GPR [ i.Rt ].sq0 );
							e->OrRegReg64 ( RCX, RCX );
							e->MovReg64Imm32 ( RCX, lConst );
							e->CmovERegReg64 ( Rd, RCX );
						}
					}
					
				}
				else
				{
				//return -1;
					// all registers, no constants //
					
					if ( i.Rd == i.Rt )
					{
					//return -1;
						if ( isAlloc ( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
						{
							Rs = Alloc_SrcReg ( i.Rs );
							Rd = Alloc_SrcReg ( i.Rd );
							Rd = Alloc_DstReg ( i.Rd );
							
							e->OrRegReg64 ( Rd, Rd );
							e->CmovERegReg64 ( Rd, Rs );
						}
						else
						{
							// rs not alloc and disposable //
							Rd = Alloc_SrcReg ( i.Rd );
							Rd = Alloc_DstReg ( i.Rd );
							
							e->OrRegReg64 ( Rd, Rd );
							e->CmovERegMem64 ( Rd, & r->GPR [ i.Rs ].sq0 );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->OrRegReg64 ( Rt, Rt );
							e->CmovERegReg64 ( Rd, Rs );
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							if ( isDisposable ( Reg2 ) )
							{
								if ( Reg1 == i.Rs )
								{
									// rs is allocated, rt is disposable //
									Rs = Alloc_SrcReg( Reg1 );
									Rd = Alloc_SrcReg( i.Rd );
									Rd = Alloc_DstReg( i.Rd );
									
									e->MovRegMem64 ( RCX, & r->GPR [ i.Rt ].sq0 );
									e->OrRegReg64 ( RCX, RCX );
									e->CmovERegReg64 ( Rd, Rs );
								}
								else
								{
					//return -1;
									// rt is allocated, rs is disposable //
									//Rt = Alloc_SrcReg( Reg1 );
									//Rs = Alloc_SrcReg( i.Rs );
									Rt = Alloc_SrcReg( i.Rt );
									Rd = Alloc_SrcReg( i.Rd );
									Rd = Alloc_DstReg( i.Rd );
									//e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].sq0 );
									e->OrRegReg64 ( Rt, Rt );
									//e->CmovERegReg64 ( Rd, RCX );
									e->CmovERegMem64 ( Rd, & r->GPR [ i.Rs ].sq0 );
									//e->CmovERegReg64 ( Rd, Rs );
									
								}
							}
							else
							{
								Rs = Alloc_SrcReg( i.Rs );
								Rt = Alloc_SrcReg( i.Rt );
								Rd = Alloc_SrcReg( i.Rd );
								Rd = Alloc_DstReg( i.Rd );
								
								e->OrRegReg64 ( Rt, Rt );
								e->CmovERegReg64 ( Rd, Rs );
							}
						}
						else
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegMem64( RCX, & r->GPR [ i.Rt ].sq0 );
							e->OrRegReg64( RCX, RCX );
							ret = e->CmovERegMem64( Rd, & r->GPR [ i.Rs ].sq0 );
						}
					}
				}
			}
				
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MOVN ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MOVN";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOVN;
	
	int Rd, Rs, Rt;
	int Reg1, Reg2;
	s64 lConst;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case -1:
			// source registers are Rs and Rt
			ullSrcRegBitmap |= ( 1ull << i.Rs ) | ( 1ull << i.Rt ) | ( 1ull << i.Rd );
			
			// destination register is Rd
			ullDstRegBitmap |= ( 1ull << i.Rd );
			break;
			
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			if ( i.Rd )
			{
				if ( i.Rd != i.Rs )
				{
					if ( i.Rd == i.Rt )
					{
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RCX, RCX );
						e->CmovNERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					if ( i.Rs == i.Rt )
					{
						e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						e->OrRegReg64 ( RAX, RAX );
						e->CmovNERegReg64 ( RCX, RAX );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
					else
					{
						e->CmpMem64ImmX ( & r->GPR [ i.Rt ].s, 0 );
						//e->MovRegMem64 ( RAX, & r->GPR [ i.Rt ].s );
						e->MovRegMem64 ( RCX, & r->GPR [ i.Rd ].s );
						//e->OrRegReg64 ( RAX, RAX );
						e->CmovNERegMem64 ( RCX, & r->GPR [ i.Rs ].s );
						e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RCX );
					}
				}
			}
			break;
			
#ifdef USE_NEW_MOVN_CODE2
		case 2:
			if ( i.Rd )
			{
				if ( i.Rd == i.Rs )
				{
					// do nothing //
				}
				else if ( isBothConst( i.Rs, i.Rt ) )
				{
					// both registers are constant //
					if ( GetConst( i.Rt ) )
					{
						Alloc_Const ( i.Rd, GetConst( i.Rs ) );
					}
				}
				else if ( isEitherConst ( i.Rs, i.Rt ) )
				{
				//return -1;
					if ( isConst( i.Rt ) )
					{
						if ( GetConst( i.Rt ) )
						{
							if ( isAlloc( i.Rs ) || ( !isDisposable( i.Rs ) ) )
							{
								if ( isDisposable( i.Rs ) )
								{
									RenameReg( i.Rd, i.Rs );
								}
								else
								{
									Rs = Alloc_SrcReg( i.Rs );
									Rd = Alloc_DstReg( i.Rd );
									e->MovRegReg64( Rd, Rs );
								}
							}
							else
							{
								// rs is not allocated and disposable //
								Rd = Alloc_DstReg ( i.Rd );
								e->MovRegMem64( Rd, & r->GPR [ i.Rs ].sq0 );
							}
						}
					}
					else
					{
					//return -1;
						lConst = GetConst ( i.Rs );
						
						if ( isAlloc( i.Rt ) || ( !isDisposable( i.Rt ) ) )
						{
							// even if rt is disposable, can't dispose it here //
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->MovReg64ImmX ( RCX, lConst );
							e->OrRegReg64 ( Rt, Rt );
							e->CmovNERegReg64( Rd, RCX );
						}
						else
						{
							// rt not allocated and disposable //
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							e->MovRegMem64( RCX, & r->GPR [ i.Rt ].sq0 );
							e->OrRegReg64 ( RCX, RCX );
							e->MovReg64Imm32 ( RCX, lConst );
							e->CmovNERegReg64 ( Rd, RCX );
						}
					}
					
				}
				else
				{
					// all registers, no constants //
					
					if ( i.Rd == i.Rt )
					{
						if ( isAlloc ( i.Rs ) || ( ! isDisposable( i.Rs ) ) )
						{
							Rs = Alloc_SrcReg ( i.Rs );
							Rd = Alloc_SrcReg ( i.Rd );
							Rd = Alloc_DstReg ( i.Rd );
							
							e->OrRegReg64 ( Rd, Rd );
							e->CmovNERegReg64 ( Rd, Rs );
						}
						else
						{
							// rs not alloc and disposable //
							Rd = Alloc_SrcReg ( i.Rd );
							Rd = Alloc_DstReg ( i.Rd );
							
							e->OrRegReg64 ( Rd, Rd );
							e->CmovNERegMem64 ( Rd, & r->GPR [ i.Rs ].sq0 );
						}
					}
					else
					{
						// 3 op, all different registers //
						
						if ( isBothAlloc( i.Rs, i.Rt ) || ( ! isEitherDisposable( i.Rs, i.Rt ) ) )
						{
							Rs = Alloc_SrcReg( i.Rs );
							Rt = Alloc_SrcReg( i.Rt );
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->OrRegReg64 ( Rt, Rt );
							e->CmovNERegReg64 ( Rd, Rs );
						}
						else if ( isEitherAlloc( i.Rs, i.Rt ) )
						{
							Reg1 = SelectAlloc ( i.Rs, i.Rt );
							Reg2 = SelectNotAlloc( i.Rs, i.Rt );
							
							if ( isDisposable ( Reg2 ) )
							{
								if ( Reg1 == i.Rs )
								{
									// rs is allocated, rt is disposable //
									Rs = Alloc_SrcReg( Reg1 );
									Rd = Alloc_SrcReg( i.Rd );
									Rd = Alloc_DstReg( i.Rd );
									
									e->MovRegMem64 ( RCX, & r->GPR [ i.Rt ].sq0 );
									e->OrRegReg64 ( RCX, RCX );
									e->CmovNERegReg64 ( Rd, Rs );
								}
								else
								{
									// rt is allocated, rs is disposable //
									Rt = Alloc_SrcReg( Reg1 );
									Rd = Alloc_SrcReg( i.Rd );
									Rd = Alloc_DstReg( i.Rd );
									//e->MovRegMem64 ( RCX, & r->GPR [ i.Rs ].sq0 );
									e->OrRegReg64 ( Rt, Rt );
									//>CmovERegReg64 ( Rd, RCX );
									e->CmovNERegMem64 ( Rd, & r->GPR [ i.Rs ].sq0 );
									
								}
							}
							else
							{
								Rs = Alloc_SrcReg( i.Rs );
								Rt = Alloc_SrcReg( i.Rt );
								Rd = Alloc_SrcReg( i.Rd );
								Rd = Alloc_DstReg( i.Rd );
								
								e->OrRegReg64 ( Rt, Rt );
								e->CmovNERegReg64 ( Rd, Rs );
							}
						}
						else
						{
							Rd = Alloc_SrcReg( i.Rd );
							Rd = Alloc_DstReg( i.Rd );
							
							e->MovRegMem64( RCX, & r->GPR [ i.Rt ].sq0 );
							e->OrRegReg64( RCX, RCX );
							ret = e->CmovNERegMem64( Rd, & r->GPR [ i.Rs ].sq0 );
						}
					}
				}
			}
				
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::MFHI1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFHI1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFHI1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MFHI1_CODE
			/*
			e->MovRegFromMem64 ( RAX, (long long*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (long long*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uHi );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			// move from Hi register
			//r->GPR [ i.Rd ].u = r->HiLo.uHi;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uHi );
				e->MovRegMem64 ( RAX, & r->HI.sq1 );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTHI1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTHI1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTHI1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uHi, RAX );
			ret = e->MovMemReg64 ( &r->HI.sq1, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MFLO1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFLO1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFLO1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_MFLO1_CODE
			/*
			e->MovRegFromMem64 ( RAX, (long long*) & r->CycleCount );
			e->CmpRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			e->CmovBRegMem64 ( RAX, &r->MulDiv_BusyUntil_Cycle );
			ret = e->MovRegToMem64 ( (long long*) & r->CycleCount, RAX );
			if ( i.Rd )
			{
				e->MovRegFromMem32 ( RAX, &r->HiLo.uLo );
				ret = e->MovRegToMem32 ( &r->GPR [ i.Rd ].s, RAX );
			}
			Local_LastModifiedReg = i.Rd;
			*/
			
			// this instruction interlocks if multiply/divide unit is busy
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			//e->XorRegReg64 ( RDX, RDX );
			e->SubRegMem64 ( RAX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			//e->CmovBRegReg64 ( RDX, RAX );
			e->Cqo ();
			e->AndRegReg64 ( RDX, RAX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			//e->MovMemReg64 ( (long long*) & r->CycleCount, RAX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			
			// move from Lo register
			//r->GPR [ i.Rd ].u = r->HiLo.uLo;
			//CHECK_DELAYSLOT ( i.Rd );
			if ( i.Rd )
			{
				//e->MovRegMem32 ( RAX, & r->HiLo.uLo );
				e->MovRegMem64 ( RAX, & r->LO.sq1 );
				//e->MovMemReg32 ( & r->GPR [ i.Rd ].s, RAX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTLO1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTLO1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTLO1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			//e->MovRegFromMem32 ( RAX, &r->GPR [ i.Rs ].sw0 );
			e->MovRegMem64 ( RAX, &r->GPR [ i.Rs ].s );
			//ret = e->MovRegToMem32 ( &r->HiLo.uLo, RAX );
			ret = e->MovMemReg64 ( &r->LO.sq1, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::MFSA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFSA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFSA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, (long*) & r->SA );
			e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTSA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTSA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->AndReg32ImmX ( RAX, 0xf );
			e->MovMemReg32 ( (long*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTSAB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTSAB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSAB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->XorReg32ImmX ( RAX, i.uImmediate );
			e->AndReg32ImmX ( RAX, 0xf );
			e->MovMemReg32 ( (long*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTSAH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTSAH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTSAH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->XorReg32ImmX ( RAX, i.uImmediate );
			e->AndReg32ImmX ( RAX, 0x7 );
			e->AddRegReg32 ( RAX, RAX );
			e->MovMemReg32 ( (long*) & r->SA, RAX );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// Branch instructions //

long R5900::Recompiler::BEQL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BEQL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BEQL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BEQL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBEQL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BNEL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BNEL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BNEL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BNEL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBNEL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BGEZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGEZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BLEZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLEZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLEZL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLEZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLEZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BGTZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGTZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGTZL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGTZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGTZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BLTZL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLTZL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::BLTZALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BLTZALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BLTZALL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BLTZALL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBLTZALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BGEZALL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BGEZALL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BGEZALL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_BGEZALL_CODE
			ret = Generate_Normal_Branch ( i, Address, (void*) Cpu::ProcessBranchDelaySlot_t<OPBGEZALL> );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::BC0T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC0T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0T;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC0TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC0TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0TL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC0F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC0F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0F;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC0FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC0FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC0FL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC1T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC1T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1T;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC1TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC1TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1TL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC1F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC1F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1F;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC1FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC1FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC1FL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC2T ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC2T";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2T;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC2TL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC2TL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2TL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC2F ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC2F";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2F;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::BC2FL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "BC2FL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::BC2FL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	bStopEncodingBefore = true;
	
	// this instruction always has a synchronous interrupt
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






long R5900::Recompiler::TGEI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TGEI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TGEIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TGEIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEIU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLTI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLTI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLTIU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLTIU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTIU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TEQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TEQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TEQI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TNEI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TNEI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TNEI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::TGE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TGE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGE;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TGEU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TGEU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TGEU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLT;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLTU ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLTU";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLTU;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TEQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TEQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TEQ;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TNE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TNE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TNE;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// this instruction might have a synchronous interrupt
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			ret = Generate_Normal_Trap ( i, Address );
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


















// * R5900 Parallel (SIMD) instructions * //


long R5900::Recompiler::PADSBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADSBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADSBH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADSBH_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->movdqa_regmem ( RDX, & r->GPR [ i.Rt ].s );
					e->movdqa_regreg ( RCX, RAX );
					
					e->paddwregreg ( RAX, RDX );
					e->psubwregreg ( RCX, RDX );
					e->pblendwregregimm ( RAX, RCX, 0xf );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PABSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PABSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PABSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PABSH_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->pabswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PABSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PABSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PABSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PABSW_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->pabsdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PAND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PAND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PAND;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PAND_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pandregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PXOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PXOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PXOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PXOR_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rs )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pxorregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::POR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "POR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::POR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_POR_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->porregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PNOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PNOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PNOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PNOR_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pcmpeqdregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pcmpeqdregreg ( RAX, RAX );
						e->pxorregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqdregreg ( RAX, RAX );
					e->pxorregmem ( RAX, & r->GPR [ i.Rs ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqdregreg ( RAX, RAX );
					e->pxorregmem ( RAX, & r->GPR [ i.Rs ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqdregreg ( RCX, RCX );
					e->porregmem ( RAX, & r->GPR [ i.Rt ].s );
					e->pxorregreg ( RAX, RCX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PLZCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PLZCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PLZCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PLZCW_CODE
			if ( i.Rd )
			{
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
				e->MovReg32ImmX ( RCX, -1 );
				e->Cdq ();
				e->XorRegReg32 ( RAX, RDX );
				e->BsrRegReg32 ( RAX, RAX );
				e->CmovERegReg32 ( RAX, RCX );
				e->NegReg32 ( RAX );
				e->AddReg32ImmX ( RAX, 30 );
				e->MovMemReg32 ( & r->GPR [ i.Rd ].sw0, RAX );
				
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw1 );
				e->Cdq ();
				e->XorRegReg32 ( RAX, RDX );
				e->BsrRegReg32 ( RAX, RAX );
				e->CmovERegReg32 ( RAX, RCX );
				e->NegReg32 ( RAX );
				e->AddReg32ImmX ( RAX, 30 );
				e->MovMemReg32 ( & r->GPR [ i.Rd ].sw1, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PMFHL_LH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHL_LH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_LH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHL_LH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->LO.s );
				e->movdqa_regmem ( RBX, & r->HI.s );
				
				e->pshuflwregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
				e->pshufhwregregimm ( RCX, RCX, ( 2 << 2 ) + ( 0 << 0 ) );
				e->pshuflwregregimm ( RDX, RBX, ( 3 << 6 ) + ( 1 << 4 ) );
				e->pshufhwregregimm ( RDX, RDX, ( 3 << 6 ) + ( 1 << 4 ) );
				e->pblendwregregimm ( RCX, RDX, 0xcc );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMFHL_LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHL_LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_LW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHL_LW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				//e->movdqa_regmem ( RBX, & r->HI.s );
				e->movdqa_regmem ( RAX, & r->LO.s );
				
				//e->pshufdregregimm ( RCX, RBX, ( 2 << 6 ) + ( 0 << 2 ) );
				e->pshufdregmemimm ( RCX, & r->HI.s, ( 2 << 6 ) + ( 0 << 2 ) );
				e->pblendwregregimm ( RAX, RCX, 0xcc );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMFHL_UW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHL_UW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_UW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHL_UW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->movdqa_regmem ( RBX, & r->HI.s );
				//e->movdqa_regmem ( RAX, & r->LO.s );
				
				//e->pshufdregregimm ( RCX, RAX, ( 3 << 4 ) + ( 1 << 0 ) );
				e->pshufdregmemimm ( RCX, & r->LO.s, ( 3 << 4 ) + ( 1 << 0 ) );
				e->pblendwregregimm ( RBX, RCX, 0x33 );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RBX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMTHL_LW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMTHL_LW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTHL_LW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMTHL_LW_CODE
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw1 );
			e->MovRegMem32 ( RDX, & r->GPR [ i.Rs ].sw2 );
			
			e->MovMemReg32 ( & r->LO.sw0, RAX );
			
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw3 );
			
			e->MovMemReg32 ( & r->HI.sw0, RCX );
			e->MovMemReg32 ( & r->LO.sw2, RDX );
			e->MovMemReg32 ( & r->HI.sw2, RAX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PMFHL_SH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHL_SH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_SH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHL_SH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->movdqa_regmem ( RBX, & r->HI.s );
				e->movdqa_regmem ( RAX, & r->LO.s );
				
				e->pshufdregregimm ( RCX, RBX, ( 1 << 6 ) + ( 0 << 4 ) );
				e->pblendwregregimm ( RCX, RAX, 0x0f );
				
				e->pshufdregregimm ( RDX, RAX, ( 3 << 2 ) + ( 2 << 0 ) );
				e->pblendwregregimm ( RDX, RBX, 0xf0 );
				
				e->packssdwregreg ( RCX, RDX );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PMFHL_SLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHL_SLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHL_SLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHL_SLW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->MovRegMem32 ( RAX, & r->HI.sw0 );
				e->Cdq ();
				e->MovRegImm32 ( RCX, 0x7fffffff );
				e->XorRegReg32 ( RCX, RDX );
				e->CmpRegReg32 ( RAX, RDX );
				e->CmovERegMem32 ( RCX, & r->LO.sw0 );
				e->MovsxdReg64Reg32 ( RCX, RCX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RCX );
				
				e->MovRegMem32 ( RAX, & r->HI.sw2 );
				e->Cdq ();
				e->MovRegImm32 ( RCX, 0x7fffffff );
				e->XorRegReg32 ( RCX, RDX );
				e->CmpRegReg32 ( RAX, RDX );
				e->CmovERegMem32 ( RCX, & r->LO.sw2 );
				e->MovsxdReg64Reg32 ( RCX, RCX );
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq1, RCX );
				
				/*
				e->movdqa_regmem ( RBX, & r->HI.s );
				e->movdqa_regmem ( RAX, & r->LO.s );
				
				pshufdregregimm ( RCX, RBX, ( 1 << 6 ) + ( 0 << 4 ) );
				pblendwregregimm ( RCX, RAX, 0x0f );
				
				pshufdregregimm ( RDX, RAX, ( 3 << 2 ) + ( 2 << 0 ) );
				pblendwregregimm ( RDX, RBX, 0xf0 );
				
				e->packssdwregreg ( RCX, RDX );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
				*/
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PSLLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSLLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSLLH_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift & 0xf ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->psllwregimm ( RAX, i.Shift & 0xf );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSLLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSLLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSLLW_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->pslldregimm ( RAX, i.Shift );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSRLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRLH_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift & 0xf ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->psrlwregimm ( RAX, i.Shift & 0xf );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSRLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRLW_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->psrldregimm ( RAX, i.Shift );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PSRAH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRAH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRAH_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift & 0xf ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->psrawregimm ( RAX, i.Shift & 0xf );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSRAW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRAW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRAW_CODE
			if ( i.Rd )
			{
				if ( !i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !( i.Shift ) )
				{
					if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->psradregimm ( RAX, i.Shift );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSLLVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSLLVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSLLVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSLLVW_CODE
			if ( i.Rd )
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw0 );
				e->ShlRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RAX );
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw2 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw2 );
				e->ShlRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq1, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSRLVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRLVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRLVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRLVW_CODE
			if ( i.Rd )
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw0 );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RAX );
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw2 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw2 );
				e->ShrRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq1, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSRAVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSRAVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSRAVW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSRAVW_CODE
			if ( i.Rd )
			{
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw0 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw0 );
				e->SarRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq0, RAX );
				e->MovRegMem32 ( RCX, & r->GPR [ i.Rs ].sw2 );
				e->MovRegMem32 ( RAX, & r->GPR [ i.Rt ].sw2 );
				e->SarRegReg32 ( RAX );
				e->Cdqe ();
				e->MovMemReg64 ( & r->GPR [ i.Rd ].sq1, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PADDB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddbregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddwregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddwregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDW_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->padddregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->padddregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSUBB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubbregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSUBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubwregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubwregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSUBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBW_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubdregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PADDSB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDSB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDSB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddsbregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddsbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDSH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddswregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PADDSW_CODE
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					
					/*
					e->pcmpeqbregreg ( RDX, RDX );
					e->movdqa_regreg ( 4, RDX );
					e->psrldregimm ( RDX, 1 );
					
					e->movdqa_regreg ( RCX, RAX );
					e->movdqa_regreg ( RBX, RAX );
					e->padddregreg ( RBX, RCX );
					
					e->psrldregimm ( RAX, 31 );
					e->padddregreg ( RAX, RDX );
					e->movdqa_regreg ( RDX, RAX );
					
					e->pxorregreg ( RAX, RCX );
					e->pxorregreg ( RCX, RBX );
					e->pxorregreg ( RCX, 4 );
					e->porregreg ( RAX, RCX );
					e->psradregimm ( RAX, 31 );
					
					e->pblendvbregreg ( RDX, RBX );
					*/
					
					// get max -> VR4
					e->pcmpeqbregreg ( 4, 4 );
					e->psrldregimm ( 4, 1 );
					
					// overflow = ~(a^b) & (a^(a+b))
					
					// A -> RCX
					e->movdqa_regreg ( RCX, RAX );
					
					// b -> RBX
					e->movdqa_regreg ( RBX, RCX );
					
					// (a+b) -> RCX,RDX
					e->padddregreg ( RCX, RAX );
					e->movdqa_regreg ( RDX, RCX );
					
					// (a^(a+b)) -> RCX
					e->pxorregreg ( RCX, RAX );
					// (a^b) -> RAX
					e->pxorregreg ( RAX, RBX );
					// ~(a^b) & (a^(a+b)) -> RAX
					e->pandnregreg ( RAX, RCX );
					e->psradregimm ( RAX, 31 );
					
					// get sat
					e->psrldregimm ( RBX, 31 );
					e->padddregreg ( 4, RBX );
					
					// blend
					e->pblendvbregreg ( RDX, 4 );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RDX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
					
					/*
					e->pcmpeqbregreg ( RDX, RDX );
					e->movdqa_regreg ( 4, RDX );
					e->psrldregimm ( RDX, 1 );
					
					//e->movdqa_regreg ( RCX, RAX );
					e->movdqa_regreg ( RBX, RAX );
					e->padddregreg ( RBX, RCX );
					
					e->psrldregimm ( RAX, 31 );
					e->padddregreg ( RAX, RDX );
					e->movdqa_regreg ( RDX, RAX );
					
					e->pxorregreg ( RAX, RCX );
					e->pxorregreg ( RCX, RBX );
					e->pxorregreg ( RCX, 4 );
					e->porregreg ( RAX, RCX );
					e->psradregimm ( RAX, 31 );
					
					e->pblendvbregreg ( RDX, RBX );
					*/
					
					// get max -> VR4
					e->pcmpeqbregreg ( 4, 4 );
					e->psrldregimm ( 4, 1 );
					
					// overflow = ~(a^b) & (a^(a+b))
					
					// b -> RBX
					e->movdqa_regreg ( RBX, RCX );
					
					// (a+b) -> RCX,RDX
					e->padddregreg ( RCX, RAX );
					e->movdqa_regreg ( RDX, RCX );
					
					// (a^(a+b)) -> RCX
					e->pxorregreg ( RCX, RAX );
					// (a^b) -> RAX
					e->pxorregreg ( RAX, RBX );
					// ~(a^b) & (a^(a+b)) -> RAX
					e->pandnregreg ( RAX, RCX );
					e->psradregimm ( RAX, 31 );
					
					// get sat
					e->psrldregimm ( RBX, 31 );
					e->padddregreg ( 4, RBX );
					
					// blend
					e->pblendvbregreg ( RDX, 4 );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RDX );
				}
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PSUBSB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBSB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBSB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubsbregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubsbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PSUBSH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBSH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBSH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubswregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PSUBSW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBSW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBSW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PSUBSW_CODE
		case 1:
			if ( i.Rd )
			{
				/*
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else
					{
						//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						e->pxorregreg ( RAX, RAX );
						e->psubdregmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else
				*/
				if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
					
					// get max -> VR4
					e->pcmpeqbregreg ( 4, 4 );
					
					// overflow = ~(a^b) & (a^(a+b))
					
					// a -> VR5
					e->movdqa_regreg ( 5, RAX );
					
					// b -> RBX
					e->movdqa_regreg ( RBX, RCX );
					
					
					// (a+b) -> RCX,RDX
					e->pxorregreg ( RCX, 4 );
					e->psubdregreg ( RCX, 4 );
					e->padddregreg ( RCX, RAX );
					//x->psubdregreg ( RCX, RAX );
					e->movdqa_regreg ( RDX, RCX );

					e->psrldregimm ( 4, 1 );
					
					// (a^(a+b)) -> RCX
					e->pxorregreg ( RCX, RAX );
					// (a^b) -> RAX
					e->pxorregreg ( RAX, RBX );
					// ~(a^b) & (a^(a+b)) -> RAX
					//x->pandnregreg ( RAX, RCX );
					e->pandregreg ( RAX, RCX );
					e->psradregimm ( RAX, 31 );
					
					// get sat
					e->psrldregimm ( 5, 31 );
					e->padddregreg ( 4, 5 );
					
					// blend
					e->pblendvbregreg ( RDX, 4 );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RDX );
				}
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PADDUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDUB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddusbregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->paddusbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PADDUH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->padduswregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->padduswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PADDUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PADDUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PADDUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PADDUW_CODE
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					if ( !i.Rt )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rt )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					
					e->pcmpeqbregreg ( RDX, RDX );
					e->pslldregimm ( RDX, 31 );
					
					e->movdqa_regreg ( RCX, RAX );
					e->padddregreg ( RAX, RCX );
					
					e->pxorregreg ( RAX, RDX );
					e->pxorregreg ( RCX, RDX );
					e->pcmpgtdregreg ( RCX, RAX );
					e->pxorregreg ( RAX, RDX );
					
					e->porregreg ( RAX, RCX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
					
					e->pcmpeqbregreg ( RDX, RDX );
					e->pslldregimm ( RDX, 31 );
					
					//e->movdqa_regreg ( RCX, RAX );
					e->padddregreg ( RAX, RCX );
					
					e->pxorregreg ( RAX, RDX );
					e->pxorregreg ( RCX, RDX );
					e->pcmpgtdregreg ( RCX, RAX );
					e->pxorregreg ( RAX, RDX );
					
					e->porregreg ( RAX, RCX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PSUBUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBUB_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubusbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSUBUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PSUBUH_CODE
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( !i.Rt )
				{
					if ( !i.Rs )
					{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
					else if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->psubuswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PSUBUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PSUBUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PSUBUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;

#ifdef USE_NEW_PSUBUW_CODE
		case 1:
			if ( i.Rd )
			{
				if ( !i.Rs )
				{
					//if ( !i.Rt )
					//{
						e->pxorregreg ( RAX, RAX );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					//}
					//else if ( i.Rd != i.Rt )
					//{
					//	e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					//	ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					//}
				}
				else if ( !i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
					
					e->pcmpeqbregreg ( RDX, RDX );
					e->pslldregimm ( RDX, 31 );
					e->movdqa_regreg ( RBX, RDX );
					
					e->pxorregreg ( RBX, RAX );
					e->pxorregreg ( RDX, RCX );
					e->pcmpgtdregreg ( RBX, RDX );
					
					e->psubdregreg ( RAX, RCX );
					
					e->pandregreg ( RAX, RBX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PMAXH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMAXH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMAXH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMAXH_CODE
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					e->pmaxswregmem ( RAX, & r->GPR [ i.Rs | i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pmaxswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMAXW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMAXW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMAXW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMAXW_CODE
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					e->pmaxsdregmem ( RAX, & r->GPR [ i.Rs | i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pmaxsdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMINH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMINH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMINH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMINH_CODE
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					e->pminswregmem ( RAX, & r->GPR [ i.Rs | i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pminswregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMINW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMINW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMINW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMINW_CODE
			if ( i.Rd )
			{
				if ( ( !i.Rs ) && ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else if ( i.Rs == i.Rt )
				{
					if ( i.Rd != i.Rs )
					{
						e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
						ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
					}
				}
				else if ( ( !i.Rs ) || ( !i.Rt ) )
				{
					e->pxorregreg ( RAX, RAX );
					e->pminsdregmem ( RAX, & r->GPR [ i.Rs | i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pminsdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::PPACB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PPACB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		
		case 1:
#ifdef USE_NEW_PPACB_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					
					e->psllwregimm ( RAX, 8 );
					e->psrlwregimm ( RAX, 8 );
					
					e->packuswbregreg ( RAX, RAX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
					
					e->psllwregimm ( RAX, 8 );
					e->psrlwregimm ( RAX, 8 );
					e->psllwregimm ( RCX, 8 );
					e->psrlwregimm ( RCX, 8 );

					e->packuswbregreg ( RAX, RCX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PPACH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PPACH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PPACH_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					
					e->pxorregreg ( RDX, RDX );
					e->pblendwregregimm ( RAX, RDX, 0xaa );
					
					e->packusdwregreg ( RAX, RAX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
					
					e->pxorregreg ( RDX, RDX );
					e->pblendwregregimm ( RAX, RDX, 0xaa );
					e->pblendwregregimm ( RCX, RDX, 0xaa );

					e->packusdwregreg ( RAX, RCX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PPACW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PPACW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPACW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PPACW_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					//e->pshufdregregimm ( RAX, RAX, ( 2 << 6 ) + ( 0 << 4 ) + ( 2 << 2 ) + 0 );
					e->pshufdregmemimm ( RAX, & r->GPR [ i.Rs ].s, ( 2 << 6 ) + ( 0 << 4 ) + ( 2 << 2 ) + 0 );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
					//e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
					
					//e->pshufdregregimm ( RAX, RAX, ( 2 << 2 ) + 0 );
					//e->pshufdregregimm ( RCX, RCX, ( 2 << 6 ) + ( 0 << 4 ) );
					e->pshufdregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 2 << 2 ) + 0 );
					e->pshufdregmemimm ( RCX, & r->GPR [ i.Rs ].s, ( 2 << 6 ) + ( 0 << 4 ) );

					e->pblendwregregimm ( RAX, RCX, 0xf0 );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PEXT5 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXT5";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXT5;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXT5_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				
				// get a
				e->movdqa_regreg ( RBX, RAX );
				e->psrldregimm ( RBX, 15 );
				e->pslldregimm ( RBX, 31 );
				
				// get c3
				e->movdqa_regreg ( RCX, RAX );
				e->psrldregimm ( RCX, 10 );
				e->pslldregimm ( RCX, 27 );
				e->psrldregimm ( RCX, 8 );
				
				// get c2
				e->movdqa_regreg ( RDX, RAX );
				e->psrldregimm ( RDX, 5 );
				e->pslldregimm ( RDX, 27 );
				e->psrldregimm ( RDX, 16 );
				
				// get c1
				e->pslldregimm ( RAX, 27 );
				e->psrldregimm ( RAX, 24 );
				
				// combine
				e->porregreg ( RAX, RBX );
				e->porregreg ( RAX, RCX );
				e->porregreg ( RAX, RDX );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PPAC5 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PPAC5";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PPAC5;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PPAC5_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				
				// get c1
				e->movdqa_regreg ( RBX, RAX );
				e->pslldregimm ( RBX, 24 );
				e->psrldregimm ( RBX, 27 );
				
				// get c2
				e->movdqa_regreg ( RCX, RAX );
				e->pslldregimm ( RCX, 16 );
				e->psrldregimm ( RCX, 27 );
				e->pslldregimm ( RCX, 5 );
				
				// get c3
				e->movdqa_regreg ( RDX, RAX );
				e->pslldregimm ( RDX, 8 );
				e->psrldregimm ( RDX, 27 );
				e->pslldregimm ( RDX, 10 );
				
				// get a
				e->psrldregimm ( RAX, 31 );
				e->pslldregimm ( RAX, 15 );
				
				// combine
				e->porregreg ( RAX, RBX );
				e->porregreg ( RAX, RCX );
				e->porregreg ( RAX, RDX );
				
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PCGTB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCGTB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCGTB_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpgtbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PCGTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCGTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCGTH_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpgtwregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PCGTW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCGTW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCGTW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCGTW_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pxorregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpgtdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PCEQB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCEQB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCEQB_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pcmpeqdregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqbregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PCEQH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCEQH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCEQH_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pcmpeqdregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqwregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PCEQW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCEQW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCEQW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCEQW_CODE
			if ( i.Rd )
			{
				if ( i.Rs == i.Rt )
				{
					e->pcmpeqdregreg ( RAX, RAX );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
				else
				{
					e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
					e->pcmpeqdregmem ( RAX, & r->GPR [ i.Rt ].s );
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
				}
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::PEXTLB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTLB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTLB_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpcklbwregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXTLH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTLH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTLH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpcklwdregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXTLW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTLW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTLW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTLW_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpckldqregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXTUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTUB_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpckhbwregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXTUH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTUH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTUH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpckhwdregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXTUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXTUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXTUW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXTUW_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpckhdqregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}








long R5900::Recompiler::PMFLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFLO;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFLO_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->LO.s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMFHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMFHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMFHI;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PMFHI_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			//e->MovRegReg64 ( RCX, RAX );
			//e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			//e->SubRegReg64 ( RCX, RAX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			//e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->HI.s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PINTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PINTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PINTH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PINTH_CODE
			if ( i.Rd )
			{
				//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufdregregimm ( RAX, RAX, ( 1 << 6 ) + ( 0 << 4 ) );
				e->pshufdregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 1 << 6 ) + ( 0 << 4 ) );
				e->punpckhwdregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PINTEH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PINTEH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PINTEH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PINTEH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
				e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
				e->pslldregimm ( RAX, 16 );
				e->pblendwregregimm ( RAX, RCX, 0x55 );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// multimedia multiply //


long R5900::Recompiler::PMADDH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMADDH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMADDH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			e->movdqa_regreg ( RBX, RAX );
			
			// put low values in A and high values in B
			e->pmullwregreg ( RAX, RCX );
			e->pmulhwregreg ( RBX, RCX );
			
			// get the values to add with Rd
			//e->movdqa_regmem ( RDX, & r->LO.s );
			//e->movdqa_regmem ( RCX, & r->HI.s );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RDX, & r->LO.s, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RCX, & r->HI.s, ( 2 << 2 ) + 0 );
			e->punpckhdqregreg ( RDX, RCX );
			
			e->movdqa_regreg ( RCX, RBX );
			e->pslldregimm ( RCX, 16 );
			e->pblendwregregimm ( RCX, RAX, 0x55 );
			
			// do the add
			e->padddregreg ( RCX, RDX );
				
			if ( i.Rd )
			{
				// store Rd
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
			}
				
			e->pshufdregregimm ( RCX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			e->pshufdregregimm ( RDX, RBX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			
			// store hi
			e->movdqa_regreg ( RAX, RCX );
			e->punpckhwdregreg ( RAX, RDX );
			
			// add with hi
			e->padddregmem ( RAX, & r->HI.s );
			
			// store to hi
			e->movdqa_memreg ( & r->HI.s, RAX );
			
			// store lo
			e->punpcklwdregreg ( RCX, RDX );
			
			// add with lo
			e->padddregmem ( RCX, & r->LO.s );
			
			// store to lo
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMADDW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMADDW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMADDW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply
			e->pmuldqregreg ( RAX, RCX );
			
			// get the values to add from hi/lo
			//e->movdqa_regmem ( RCX, & r->LO.s );
			//e->movdqa_regmem ( RDX, & r->HI.s );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RCX, & r->LO.s, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RDX, & r->HI.s, ( 2 << 2 ) + 0 );
			e->punpckldqregreg ( RCX, RDX );
			
			// add the values
			e->paddqregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store 64-bit results
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get the hi result
			e->pshufdregregimm ( RCX, RAX, ( 3 << 2 ) + ( 1 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get the lo result
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMADDUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMADDUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMADDUW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMADDUW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply
			e->pmuludqregreg ( RAX, RCX );
			
			// get the values to add from hi/lo
			//e->movdqa_regmem ( RCX, & r->LO.s );
			//e->movdqa_regmem ( RDX, & r->HI.s );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RCX, & r->LO.s, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RDX, & r->HI.s, ( 2 << 2 ) + 0 );
			e->punpckldqregreg ( RCX, RDX );
			
			// add the values
			e->paddqregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store 64-bit results
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get the hi result
			e->pshufdregregimm ( RCX, RAX, ( 3 << 2 ) + ( 1 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get the lo result
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PMSUBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMSUBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMSUBH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMSUBH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			e->movdqa_regreg ( RBX, RAX );
			
			// put low values in A and high values in B
			e->pmullwregreg ( RAX, RCX );
			e->pmulhwregreg ( RBX, RCX );
			
			// get the values to add with Rd
			//e->movdqa_regmem ( RDX, & r->LO.s );
			//e->movdqa_regmem ( RCX, & r->HI.s );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RDX, & r->LO.s, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RCX, & r->HI.s, ( 2 << 2 ) + 0 );
			e->punpckhdqregreg ( RDX, RCX );
			
			e->movdqa_regreg ( RCX, RBX );
			e->pslldregimm ( RCX, 16 );
			e->pblendwregregimm ( RCX, RAX, 0x55 );
			
			// do the sub
			e->psubdregreg ( RDX, RCX );
				
			if ( i.Rd )
			{
				// store Rd
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RDX );
			}
				
			e->pshufdregregimm ( RCX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			e->pshufdregregimm ( RDX, RBX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			
			// store hi
			e->movdqa_regreg ( RAX, RCX );
			e->punpckhwdregreg ( RAX, RDX );
			
			// sub with hi
			e->movdqa_regmem ( RBX, & r->HI.s );
			e->psubdregreg ( RBX, RAX );
			
			// store to hi
			e->movdqa_memreg ( & r->HI.s, RBX );
			
			// store lo
			e->punpcklwdregreg ( RCX, RDX );
			
			// sub with lo
			e->movdqa_regmem ( RBX, & r->HI.s );
			e->psubdregreg ( RBX, RCX );
			
			// store to lo
			ret = e->movdqa_memreg ( & r->LO.s, RBX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PMSUBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMSUBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMSUBW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMSUBW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply
			e->pmuldqregreg ( RAX, RCX );
			
			// get the values to add from hi/lo
			//e->movdqa_regmem ( RCX, & r->LO.s );
			//e->movdqa_regmem ( RDX, & r->HI.s );
			//e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) + 0 );
			//e->pshufdregregimm ( RDX, RDX, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RCX, & r->LO.s, ( 2 << 2 ) + 0 );
			e->pshufdregmemimm ( RDX, & r->HI.s, ( 2 << 2 ) + 0 );
			e->punpckldqregreg ( RCX, RDX );
			
			// add the values
			e->psubqregreg ( RCX, RAX );
				
			if ( i.Rd )
			{
				// store 64-bit results
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
			}
				
			// get the hi result
			e->pshufdregregimm ( RAX, RCX, ( 3 << 2 ) + ( 1 << 0 ) );
			e->pmovsxdqregreg ( RAX, RAX );
			e->movdqa_memreg ( & r->HI.s, RAX );
			
			// get the lo result
			e->pshufdregregimm ( RAX, RCX, ( 2 << 2 ) + ( 0 << 0 ) );
			e->pmovsxdqregreg ( RAX, RAX );
			ret = e->movdqa_memreg ( & r->LO.s, RAX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMULTH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMULTH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTH;
	
	static const int c_iMultiplyCycles = 4 / 2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMULTH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			e->movdqa_regreg ( RBX, RAX );
			
			// put low values in A and high values in B
			e->pmullwregreg ( RAX, RCX );
			e->pmulhwregreg ( RBX, RCX );
				
			if ( i.Rd )
			{
				e->movdqa_regreg ( RCX, RBX );
				e->pslldregimm ( RCX, 16 );
				e->pblendwregregimm ( RCX, RAX, 0x55 );
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
			}
				
			e->pshufdregregimm ( RCX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			e->pshufdregregimm ( RDX, RBX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + 0 );
			
			// store hi
			e->movdqa_regreg ( RAX, RCX );
			e->punpckhwdregreg ( RAX, RDX );
			e->movdqa_memreg ( & r->HI.s, RAX );
			
			// store lo
			e->punpcklwdregreg ( RCX, RDX );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMULTW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMULTW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMULTW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply
			e->pmuldqregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store 64-bit results
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get the hi result
			e->pshufdregregimm ( RCX, RAX, ( 3 << 2 ) + ( 1 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get the lo result
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMULTUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMULTUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMULTUW;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMULTUW_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply
			e->pmuludqregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store 64-bit results
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get the hi result
			e->pshufdregregimm ( RCX, RAX, ( 3 << 2 ) + ( 1 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get the lo result
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			e->pmovsxdqregreg ( RCX, RCX );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






long R5900::Recompiler::PHMADH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PHMADH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PHMADH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PHMADH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// do the multiply-add
			e->pmaddwdregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store result to Rd
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get hi result and store to hi
			e->pshufdregregimm ( RCX, RAX, ( 1 << 2 ) + ( 3 << 0 ) );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get lo result and store to lo
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PHMSBH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PHMSBH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PHMSBH;
	
	static const int c_iMultiplyCycles = 4 / 2;

	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PHMSBH_CODE
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iMultiplyCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
			e->movdqa_regmem ( RCX, & r->GPR [ i.Rt ].s );
			
			// even 16-bit values on the right side need to be negated
			e->pxorregreg ( RDX, RDX );
			e->psubwregreg ( RDX, RCX );
			e->pblendwregregimm ( RCX, RDX, 0x55 );
			
			// do the multiply-add
			e->pmaddwdregreg ( RAX, RCX );
				
			if ( i.Rd )
			{
				// store result to Rd
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
				
			// get hi result and store to hi
			e->pshufdregregimm ( RCX, RAX, ( 1 << 2 ) + ( 3 << 0 ) );
			e->movdqa_memreg ( & r->HI.s, RCX );
			
			// get lo result and store to lo
			e->pshufdregregimm ( RCX, RAX, ( 2 << 2 ) + ( 0 << 0 ) );
			ret = e->movdqa_memreg ( & r->LO.s, RCX );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// multimedia divide //

long R5900::Recompiler::PDIVW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PDIVW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PDIVW_CODE
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			// now do the division //
			
			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			//e->MovRegReg64 ( RDX, RAX );
			//e->SarRegImm64 ( RDX, 63 );
			//e->Cqo ();
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.s, RDX );
			e->Jmp8 ( 0, 1 );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovReg32ImmX ( RCX, -1 );
			//e->MovReg32ImmX ( RDX, 1 );
			e->MovReg64ImmX ( RCX, -1 );
			e->MovReg64ImmX ( RDX, 1 );
			e->OrRegReg32 ( RAX, RAX );
			//e->CmovSRegReg32 ( RCX, RDX );
			e->CmovSRegReg64 ( RCX, RDX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemReg64 ( & r->HI.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.uLo, RCX );
			e->MovMemReg64 ( & r->LO.s, RCX );
			
			e->SetJmpTarget8 ( 1 );

			e->MovsxdReg64Mem32 ( RCX, & r->GPR [ i.Rt ].sw2 );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw2 );
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			//e->MovRegReg64 ( RDX, RAX );
			//e->SarRegImm64 ( RDX, 63 );
			//e->Cqo ();
			e->Cdq ();
			//e->IdivRegReg64 ( RCX );
			e->IdivRegReg32 ( RCX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RDX );
			e->Jmp8 ( 0, 1 );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovReg32ImmX ( RCX, -1 );
			//e->MovReg32ImmX ( RDX, 1 );
			e->MovReg64ImmX ( RCX, -1 );
			e->MovReg64ImmX ( RDX, 1 );
			e->OrRegReg32 ( RAX, RAX );
			//e->CmovSRegReg32 ( RCX, RDX );
			e->CmovSRegReg64 ( RCX, RDX );
			// *** todo for ps2 *** //
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.uLo, RCX );
			e->MovMemReg64 ( & r->LO.sq1, RCX );
			
			e->SetJmpTarget8 ( 1 );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PDIVUW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PDIVUW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVUW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PDIVUW_CODE
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			// now do the division //
			
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.s, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.s, RDX );
			e->Jmp8 ( 0, 1 );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovMemImm32 ( & r->HiLo.sLo, -1 );
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemImm64 ( & r->LO.s, -1 );
			e->MovMemReg64 ( & r->HI.s, RAX );
			
			e->SetJmpTarget8 ( 1 );

			
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw2 );
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw2 );
			//e->OrRegReg64 ( RCX, RCX );
			//e->Jmp8_E ( 0, 0 );
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->XorRegReg32 ( RDX, RDX );
			e->DivRegReg32 ( RCX );
			//e->MovMemReg32 ( & r->HiLo.sLo, RAX );
			e->Cdqe ();
			e->MovMemReg64 ( & r->LO.sq1, RAX );
			//e->MovMemReg32 ( & r->HiLo.sHi, RDX );
			e->MovsxdReg64Reg32 ( RDX, RDX );
			e->MovMemReg64 ( & r->HI.sq1, RDX );
			e->Jmp8 ( 0, 1 );
			
			e->SetJmpTarget8 ( 0 );
			
			//e->MovMemImm32 ( & r->HiLo.sLo, -1 );
			//e->MovMemReg32 ( & r->HiLo.uHi, RAX );
			e->MovMemImm64 ( & r->LO.sq1, -1 );
			e->MovMemReg64 ( & r->HI.sq1, RAX );
			
			e->SetJmpTarget8 ( 1 );

#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PDIVBW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PDIVBW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PDIVBW;
	
	// 37 cycles
	// divide by 2 here since r5900 is currently only running at bus speed for testing
	static const int c_iDivideCycles = 37 / 2;
	
	int ret = 1;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PDIVBW_CODE
			// check if mul/div unit is in use
			//if ( r->MulDiv_BusyUntil_Cycle > r->CycleCount )
			//{
			//	// for now, just add onto memory latency
			//	r->CycleCount = r->MulDiv_BusyUntil_Cycle;
			//}
			
			// get maximum of busy until cycle in RDX (to be used as the cycle# Mul/Div unit is busy until)
			e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->MovRegMem64 ( RDX, (long long*) & r->MulDiv_BusyUntil_Cycle1 );
			e->CmpRegReg64 ( RDX, RCX );
			e->CmovBRegReg64 ( RDX, RCX );
			
			// get current cyclecount in RAX
			e->MovRegMem64 ( RAX, (long long*) & r->CycleCount );
			//e->MovRegMem64 ( RCX, (long long*) & r->MulDiv_BusyUntil_Cycle );
			e->AddReg64ImmX ( RAX, LocalCycleCount );
			
			// save current cyclecount into RCX + cycles for divide
			e->MovRegReg64 ( RCX, RAX );
			e->AddReg64ImmX ( RCX, c_iDivideCycles );
			
			// get any cycles between current cyclecount and when Mul/Div unit is available
			e->SubRegReg64 ( RAX, RDX );
			e->Cqo ();
			e->AndRegReg64 ( RAX, RDX );
			
			// store the current cyclecount + time to Mul/Div unit available + cycles for divide
			e->SubRegReg64 ( RCX, RAX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle, RCX );
			e->MovMemReg64 ( (long long*) & r->MulDiv_BusyUntil_Cycle1, RCX );
			
			// store cycle count minus one to the current cycle (because it adds one on return from recompiler for now)
			// offset current cyclecount with the number of cycles until mul/div unit is available
			//e->SubMemReg64 ( (long long*) & r->CycleCount, RDX );
			e->SubMemReg64 ( (long long*) & r->CycleCount, RAX );
			
			// now do the division //
			
			e->MovRegMem32 ( RCX, & r->GPR [ i.Rt ].sw0 );
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw0 );
			
			// sign-extend the word
			e->MovsxReg64Reg16 ( RCX, RCX );
			
			e->Jmp8_ECXZ ( 0, 0 );
			
			e->Cqo ();
			e->IdivRegReg64 ( RCX );
			
			e->MovMemReg32 ( & r->LO.sw0, RAX );
			
			e->MovsxReg32Reg16 ( RDX, RDX );
			e->MovMemReg32 ( & r->HI.sw0, RDX );
			e->Jmp8 ( 0, 1 );
			
			e->SetJmpTarget8 ( 0 );
			
			e->pcmpeqbregreg ( RCX, RCX );
			e->movdqa_regreg ( RDX, RCX );
			e->psrldregimm ( RDX, 31 );
			e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].sw0 );
			e->movdqa_regreg ( RBX, RAX );
			e->psradregimm ( RAX, 31 );
			e->pblendvbregreg ( RCX, RDX );
			
			e->movdqa_memreg ( & r->LO.sw0, RCX );
			//e->pmovsxwdregreg ( RBX, RBX );
			e->movdqa_memreg ( & r->HI.sw0, RBX );


			/*
			e->MovReg32ImmX ( RCX, -1 );
			e->MovReg32ImmX ( RDX, 1 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovSRegReg32 ( RCX, RDX );
			
			e->Cwde ();
			e->MovMemReg32 ( & r->HI.sw0, RAX );
			e->MovMemReg32 ( & r->LO.sw0, RCX );
			
			
			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw1 );
			e->MovReg32ImmX ( RCX, -1 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovSRegReg32 ( RCX, RDX );
			e->Cwde ();
			e->MovMemReg32 ( & r->HI.sw0, RAX );
			e->MovMemReg32 ( & r->LO.sw0, RCX );

			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw2 );
			e->MovReg32ImmX ( RCX, -1 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovSRegReg32 ( RCX, RDX );
			e->Cwde ();
			e->MovMemReg32 ( & r->HI.sw0, RAX );
			e->MovMemReg32 ( & r->LO.sw0, RCX );

			e->MovRegMem32 ( RAX, & r->GPR [ i.Rs ].sw3 );
			e->MovReg32ImmX ( RCX, -1 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovSRegReg32 ( RCX, RDX );
			e->Cwde ();
			e->MovMemReg32 ( & r->HI.sw0, RAX );
			e->MovMemReg32 ( & r->LO.sw0, RCX );
			*/
			
			e->Jmp8 ( 0, 0 );
			
			e->SetJmpTarget8 ( 1 );

			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw1 );
			
			e->Cqo ();
			e->IdivRegReg64 ( RCX );
			
			e->MovMemReg32 ( & r->LO.sw1, RAX );
			e->MovsxReg32Reg16 ( RDX, RDX );
			e->MovMemReg32 ( & r->HI.sw1, RDX );
			
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw2 );
			
			e->Cqo ();
			e->IdivRegReg64 ( RCX );
			
			e->MovMemReg32 ( & r->LO.sw2, RAX );
			e->MovsxReg32Reg16 ( RDX, RDX );
			e->MovMemReg32 ( & r->HI.sw2, RDX );
			
			e->MovsxdReg64Mem32 ( RAX, & r->GPR [ i.Rs ].sw3 );
			
			e->Cqo ();
			e->IdivRegReg64 ( RCX );
			
			e->MovMemReg32 ( & r->LO.sw3, RAX );
			e->MovsxReg32Reg16 ( RDX, RDX );
			e->MovMemReg32 ( & r->HI.sw3, RDX );
			
			e->SetJmpTarget8 ( 0 );
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::PREVH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PREVH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PREVH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PREVH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufhwregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 0 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 3 ) );
				e->pshufhwregregimm ( RAX, RAX, ( 0 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 3 ) );
				e->pshuflwregregimm ( RAX, RAX, ( 0 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 3 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::PEXEH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXEH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXEH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXEH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufhwregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 3 << 6 ) + ( 0 << 4 ) + ( 1 << 2 ) + ( 2 ) );
				e->pshufhwregregimm ( RAX, RAX, ( 3 << 6 ) + ( 0 << 4 ) + ( 1 << 2 ) + ( 2 ) );
				e->pshuflwregregimm ( RAX, RAX, ( 3 << 6 ) + ( 0 << 4 ) + ( 1 << 2 ) + ( 2 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXEW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXEW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXEW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXEW_CODE
			if ( i.Rd )
			{
				//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufdregregimm ( RAX, RAX, ( 3 << 6 ) + ( 0 << 4 ) + ( 1 << 2 ) + ( 2 ) );
				e->pshufdregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 3 << 6 ) + ( 0 << 4 ) + ( 1 << 2 ) + ( 2 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PROT3W ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PROT3W";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PROT3W;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PROT3W_CODE
			if ( i.Rd )
			{
				//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufdregregimm ( RAX, RAX, ( 3 << 6 ) + ( 0 << 4 ) + ( 2 << 2 ) + ( 1 ) );
				e->pshufdregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 3 << 6 ) + ( 0 << 4 ) + ( 2 << 2 ) + ( 1 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PMTHI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMTHI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTHI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMTHI_CODE
			if ( i.Rs )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->HI.s, RAX );
			}
			else
			{
				e->pxorregreg ( RAX, RAX );
				ret = e->movdqa_memreg ( & r->HI.s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PMTLO ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PMTLO";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PMTLO;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
#ifdef USE_NEW_PMTLO_CODE
			if ( i.Rs )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->LO.s, RAX );
			}
			else
			{
				e->pxorregreg ( RAX, RAX );
				ret = e->movdqa_memreg ( & r->LO.s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::PCPYLD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCPYLD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYLD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCPYLD_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				e->punpcklqdqregmem ( RAX, & r->GPR [ i.Rs ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PCPYUD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCPYUD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYUD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCPYUD_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rs ].s );
				e->punpckhqdqregmem ( RAX, & r->GPR [ i.Rt ].s );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PCPYH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PCPYH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PCPYH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PCPYH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufhwregmemimm ( RAX, & r->GPR [ i.Rt ].s, 0 );
				e->pshufhwregregimm ( RAX, RAX, 0 );
				e->pshuflwregregimm ( RAX, RAX, 0 );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::PEXCH ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXCH";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXCH;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXCH_CODE
			if ( i.Rd )
			{
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufhwregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 0 ) );
				e->pshufhwregregimm ( RAX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 0 ) );
				e->pshuflwregregimm ( RAX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 0 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PEXCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PEXCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PEXCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_PEXCW_CODE
			if ( i.Rd )
			{
				//e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				//e->pshufdregregimm ( RAX, RAX, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 0 ) );
				e->pshufdregmemimm ( RAX, & r->GPR [ i.Rt ].s, ( 3 << 6 ) + ( 1 << 4 ) + ( 2 << 2 ) + ( 0 ) );
				ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
			}
#else
			return -1;
#endif
			break;

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::QFSRV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "QFSRV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QFSRV;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			if ( i.Rd )
			{
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			}
			break;
			
		case 1:
#ifdef USE_NEW_QFSRV_CODE
			if ( i.Rd )
			{
#ifdef USE_SHORT_QFSRV_CODE
				e->LeaRegMem64 ( RAX, recompiler_r5900_temp );
				e->movdqa_regmem ( RAX, & r->GPR [ i.Rt ].s );
				
				if ( i.Rs != i.Rt )
				{
				e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
				}
				
				e->MovRegMem32 ( RCX, (long*) &r->SA );
				
				e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 0 );
				
				if ( i.Rs == i.Rt )
				{
				e->movdqa_to_mem128 ( RAX, RAX, NO_INDEX, SCALE_NONE, 16 );
				}
				else
				{
				e->movdqa_to_mem128 ( RCX, RAX, NO_INDEX, SCALE_NONE, 16 );
				}
				
				e->movdqu_from_mem128 ( RAX, RAX, RCX, SCALE_NONE, 0 );
				e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RAX );
#else
				if ( i.Rs == i.Rt )
				{
					e->MovRegMem32 ( RCX, (long*) &r->SA );
					//e->MovRegImm64 ( RAX, (long long) recompiler_qfsrv_shift_table_rev );
					e->LeaRegMem64 ( RAX, recompiler_qfsrv_shift_table_rev );
					e->AddRegReg32 ( RCX, RCX );
					e->movdqa_from_mem128 ( RBX, RAX, RCX, SCALE_EIGHT, 0 );
					
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
					
					e->pshufbregreg ( RCX, RBX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RCX );
				}
				else
				{
					e->MovRegMem32 ( RCX, & r->SA );
					//e->MovRegImm64 ( RAX, (long long) recompiler_qfsrv_shift_table_rev );
					e->LeaRegMem64 ( RAX, recompiler_qfsrv_shift_table_rev );
					e->AddRegReg32 ( RCX, RCX );
					e->movdqa_from_mem128 ( RBX, RAX, RCX, SCALE_EIGHT, 0 );
					
					//e->MovRegImm64 ( RAX, (long long) recompiler_qfsrv_blend_table_rev );
					e->LeaRegMem64 ( RAX, recompiler_qfsrv_blend_table_rev );
					
					e->movdqa_regmem ( RDX, & r->GPR [ i.Rt ].s );
					e->movdqa_regmem ( RCX, & r->GPR [ i.Rs ].s );
					
					e->movdqa_from_mem128 ( RAX, RAX, RCX, SCALE_EIGHT, 0 );
					
					e->pshufbregreg ( RDX, RBX );
					e->pshufbregreg ( RCX, RBX );
					
					e->pblendvbregreg ( RDX, RCX );
					
					ret = e->movdqa_memreg ( & r->GPR [ i.Rd ].s, RDX );
				}
#endif
			}
#else
			return -1;
#endif
			
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// * R5900 COP0 instructions * //


long R5900::Recompiler::EI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "EI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::EI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::DI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::CFC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CFC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::CTC0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CTC0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::SYNC ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SYNC";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SYNC;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		//case 1:
			// this instruction doesn't do anything currently
			//break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::CACHE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CACHE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CACHE;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::PREF ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "PREF";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::PREF;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLBR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLBR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLBWI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLBWI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBWI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLBWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLBWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::TLBP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "TLBP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::TLBP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::ERET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ERET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ERET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	// this instruction always modifies the NextPC
	Local_NextPCModified = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::DERET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DERET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DERET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::WAIT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "WAIT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::WAIT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		case 1:
			// this instruction doesn't do anything currently
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// * COP1 (floating point) instructions * //


long R5900::Recompiler::MFC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MFC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MFC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MTC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MTC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MTC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::CFC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CFC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CFC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::CTC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CTC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CTC1;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::LWC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LWC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LWC1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			//bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_LOAD_CODE
		case 1:

#ifdef ENABLE_COMBINED_LOAD_LWC1
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedLoadCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedLoadMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Load ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Read_t<0xffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );
			}
#else

			Generate_Normal_Load ( i, Address, 0x3, (void*) Playstation2::DataBus::Read_t<0xffffffffULL> );

#endif

			
			// store result //
			
			// store
			ret = e->MovMemReg32 ( & r->CPR1 [ i.Rt ].s, RAX );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SWC1 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SWC1";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SWC1;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			//bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_STORE_CODE
		case 1:

#ifdef ENABLE_COMBINED_STORE_SWC1
			int iLoadCount;
			long uMaxWidthMask;

			iLoadCount = Get_CombinedStoreCount ( i, Address, (R5900::Instruction::Format*) g_pSrcCodePtr );
			if ( iLoadCount > 1 )
			{
				uMaxWidthMask = Get_CombinedStoreMaxWidthMask ( iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
				ret = Generate_Combined_Store ( i, Address, uMaxWidthMask, (void*) Playstation2::DataBus::Write_t<0xffffffffULL>, iLoadCount, (R5900::Instruction::Format*) g_pSrcCodePtr );
			}
			else
			{
				ret = Generate_Normal_Store ( i, Address, 0x3, (void*) Playstation2::DataBus::Write_t<0xffffffffULL> );
			}
#else

			ret = Generate_Normal_Store ( i, Address, 0x3, (void*) Playstation2::DataBus::Write_t<0xffffffffULL> );

#endif	// end #ifdef ENABLE_COMBINED_STORE_SWC1

			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





long R5900::Recompiler::ABS_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ABS_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ABS_S;
	
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_ABS_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].s & 0x7fffffff;
			// flags affected:
			// clears flags o,u (bits 14,15)
			//r->CPC1 [ 31 ] &= ~0x0000c000;
			if ( i.Fd == i.Fs )
			{
				e->AndMem32ImmX ( &r->CPR1 [ i.Fs ].s, 0x7fffffff );
				//e->BtrMem32Imm ( &r->CPR1 [ i.Fs ].s, 31 );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			else
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				e->AndReg32ImmX ( RAX, 0x7fffffff );
				//e->BtrRegImm32 ( RAX, 31 );
				e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::ADD_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADD_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADD_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_ADD_S_CODE
		case 1:
		
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
		
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::ADDA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "ADDA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::ADDA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_ADDA_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->dACC.l, RAX );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::CVT_S_W ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CVT_S_W";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CVT_S_W;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CVT_S_W_CODE
		case 1:
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			
			// convert single precision to signed 
			e->cvtsi2sd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			
			e->MovReg64ImmX ( RCX, 896ull << 23 );
			e->Cqo();
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RDX );
			e->SubRegReg64 ( RAX, RCX );
			
			
			//e->CmovSRegReg32 ( RAX, RDX );
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::SUB_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SUB_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUB_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SUB_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->subsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MUL_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MUL_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MUL_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MUL_S_CODE
		case 1:
		
#ifdef USE_INTEGER_BASED_MUL

			//long es, et, ed;
			//unsigned long long ms, mt, md;
			//long ext;
			//long sign;
			//long fd;
			
			// load fs,ft
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			
			// init constant
			e->MovReg32ImmX ( 10, 127 );
			
			// sign is always a xor
			//fd = ( fs ^ ft ) & -0x80000000;
			e->MovRegReg32 ( 11, RAX );
			e->XorRegReg32 ( 11, RCX );
			
			
			// get the initial exponent
			//es = ( fs >> 23 ) & 0xff;
			//et = ( ft >> 23 ) & 0xff;
			//ed = es + et - 127;
			e->LeaRegRegReg32 ( 8, RAX, RAX );
			e->LeaRegRegReg32 ( 9, RCX, RCX );
			
			
			// check for zero
			e->ShrRegImm32 ( 8, 24 );
			e->CmovERegReg32 ( 10, 8 );
			e->ShrRegImm32 ( 9, 24 );
			e->CmovERegReg32 ( 10, 9 );


			// debug
			//e->MovMemReg32 ( &a1, 8 );
			//e->MovMemReg32 ( &a2, 9 );

			
			e->AddRegReg32 ( 8, 9 );
			e->SubRegReg32 ( 8, 10 );

			
			// debug
			//e->MovMemReg32 ( &a3, 8 );
			//e->MovMemReg32 ( &a4, 10 );

			// ft needs to mask from top bit
			e->MovRegReg32 ( RDX, RCX );
			e->ShrRegImm32 ( RDX, 22 );
			e->AndReg32ImmX ( RDX, 1 );
			e->NotReg32 ( RDX );
			e->AndRegReg32 ( RCX, RDX );
			
			// get the mantissa and add the hidden bit
			//ms = fs & 0x007fffff;
			//mt = ft & 0x007fffff;
			// add hidden bit
			//ms |= 0x00800000;
			//mt |= 0x00800000;
			e->ShlRegImm32 ( RAX, 8 );
			e->ShlRegImm32 ( RCX, 8 );
			e->OrReg32ImmX ( RAX, -0x80000000 );
			e->OrReg32ImmX ( RCX, -0x80000000 );
			
			// do the multiply
			//md = ms * mt;
			e->MulRegReg32 ( RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RAX );
			//e->MovMemReg32 ( &a6, RDX );
			
			
			// get bit 47
			//ext = md >> 47;
			e->MovRegReg32 ( RCX, RDX );
			e->ShrRegImm32 ( RCX, 31 );
			
			
			// get the result
			//md >>= ( 23 + ext );
			e->ShrRegImm32 ( RDX, 7 );
			e->ShrRegReg32 ( RDX );
			
			// remove the hidden bit
			//md &= 0x7fffff;
			e->AndReg32ImmX ( RDX, 0x7fffff );
			
			
			// clear RAX
			e->XorRegReg32 ( RAX, RAX );
			
			
			// update exponent
			//ed += ext;
			e->AddRegReg32 ( RCX, 8 );
			
			// check for zero
			e->CmovERegReg32 ( 10, RCX );
			
			// check for underflow (value negative)
			e->CmovSRegReg32 ( 9, RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RCX );
			//e->MovMemReg32 ( &a6, RDX );
			

			// also, no overflow if underflow (even if actually zero)
			e->CmovSRegReg32 ( RCX, RAX );
			
			
			// also set zero if underflow
			e->CmovSRegReg32 ( 10, RAX );
			
			
			
			// combine mantissa, exponent
			e->ShlRegImm32 ( RCX, 23 );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a7, RAX );
			
			
			// not overflow if zero (one or the other only)
			// clear if result should be zero
			e->OrRegReg32 ( 10, 10 );
			
			// if zero, then clear result (RAX), underflow (R9), and overflow (R8)
			e->CmovERegReg32 ( RAX, 10 );
			
			// if underflow, clear zero and result
			
			// debug
			//e->MovMemReg32 ( &a8, 9 );
			
			// maximize on overflow
			e->Cdq ();
			e->OrRegReg32 ( RAX, RDX );
			
			
			// clear sign
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			
			// combine with sign
			e->AndReg32ImmX ( 11, -0x80000000 );
			e->OrRegReg32 ( RAX, 11 );
			
			// done
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set the flags
			e->MovRegMem32 ( RCX, &r->CPC1 [ 31 ] );
			
				
			// get overflow flag
			e->AndReg32ImmX ( RDX, 0x8010 );
			
			// combine with underflow flag
			e->SarRegImm32 ( 9, 31 );
			e->AndReg32ImmX ( 9, 0x4008 );
			e->OrRegReg32 ( RDX, 9 );
			
			
			// clear non sticky flags
			e->AndReg32ImmX ( RCX, ~0xc000 );
			e->OrRegReg32 ( RCX, RDX );
			e->MovMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			//if ( ed > 0xff )
			//{
			//	fd |= 0x7fffffff;
			//}
			//else if ( ( ed > 0 ) && es && et )
			//{
			//	// put in exponent
			//	fd |= ( ed << 23 ) | md;
			//}
			
			//return fd;

			/*
			// load fs,ft
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegMem32 ( RDX, &r->CPR1 [ i.Ft ].s );
			
			// sign is always a xor
			//fd = ( fs ^ ft ) & -0x80000000;
			e->MovRegReg32 ( 11, RAX );
			e->XorRegReg32 ( 11, RDX );
			
			
			// get the initial exponent
			//es = ( fs >> 23 ) & 0xff;
			//et = ( ft >> 23 ) & 0xff;
			//ed = es + et - 127;
			e->LeaRegRegReg32 ( 8, RAX, RAX );
			e->LeaRegRegReg32 ( 9, RDX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a1, 8 );
			//e->MovMemReg32 ( &a2, 9 );
			
			
			// check for zero
			e->ShrRegImm32 ( 8, 24 );
			e->Set_E ( RCX );
			e->ShrRegImm32 ( 9, 24 );
			e->Set_E ( 10 );
			e->OrRegReg32 ( 10, RCX );
			
			e->AddRegReg32 ( 8, 9 );
			e->SubReg32ImmX ( 8, 127 );
			
			// get the mantissa and add the hidden bit
			//ms = fs & 0x007fffff;
			//mt = ft & 0x007fffff;
			// add hidden bit
			//ms |= 0x00800000;
			//mt |= 0x00800000;
			e->ShlRegImm32 ( RAX, 8 );
			e->ShlRegImm32 ( RDX, 8 );
			e->OrReg32ImmX ( RAX, -0x80000000 );
			e->OrReg32ImmX ( RDX, -0x80000000 );
			
			// do the multiply
			//md = ms * mt;
			//e->ShlRegImm32 ( RAX, 8 );
			e->MulRegReg32 ( RDX );
			
			// debug
			//e->MovMemReg32 ( &a3, RAX );
			//e->MovMemReg32 ( &a4, RDX );
			
			// get bit 47
			//ext = md >> 47;
			e->MovRegReg32 ( RCX, RDX );
			e->ShrRegImm32 ( RCX, 31 );
			
			
			// get the result
			//md >>= ( 23 + ext );
			e->ShrRegImm32 ( RDX, 7 );
			e->ShrRegReg32 ( RDX );
			
			// remove the hidden bit
			//md &= 0x7fffff;
			e->AndReg32ImmX ( RDX, 0x7fffff );
			
			// update exponent
			//ed += ext;
			e->AddRegReg32 ( RCX, 8 );
			
			// check for underflow (value negative)
			//e->BtRegImm32 ( RCX, 31 );
			e->Set_S ( 8 );
			
			// debug
			//e->MovMemReg32 ( &a5, RCX );
			//e->MovMemReg32 ( &a6, RDX );
			
			// check for zero
			e->Set_E ( 9 );
			e->OrRegReg32 ( 9, 10 );
			
			// clear underflow if zero
			e->MovRegReg32 ( 10, 9 );
			e->NotReg32 ( 10 );
			e->AndRegReg32 ( 8, 10 );
			
			// if underflow, should set result to zero also
			//e->ShrRegImm32 ( 10, 31 );
			//e->OrRegReg32 ( 9, 10 );
			e->OrRegReg32 ( 9, 8 );
			
			// check for underflow (value negative)
			//e->MovRegReg32 ( 9, RCX );
			
			
			// combine mantissa, exponent
			//e->MovRegReg32 ( RAX, RCX );
			e->ShlRegImm32 ( RCX, 23 );
			//e->OrRegReg32 ( RDX, RAX );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a7, RAX );
			
			
			// not overflow if zero (one or the other only)
			// clear if result should be zero
			e->ShlRegImm32 ( 9, 31 );
			e->SarRegImm32 ( 9, 31 );
			e->NotReg32 ( 9 );
			e->AndRegReg32 ( RAX, 9 );
			
			// debug
			//e->MovMemReg32 ( &a8, 9 );
			
			// maximize on overflow
			//e->SarRegImm32 ( RAX, 31 );
			//e->OrRegReg32 ( RDX, RAX );
			e->Cdq ();
			e->OrRegReg32 ( RAX, RDX );
			
			
			// get overflow flag
			//e->ShrRegImm32 ( RAX, 31 );
			//e->AddRegReg32 ( RAX, RAX );
			e->AndReg32ImmX ( RDX, 0x2 );
			
			// combine with underflow flag
			e->OrRegReg32 ( RDX, 8 );
			e->AndReg32ImmX ( RDX, 0x3 );
			
			
			
			// clear sign
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			
			// combine with sign
			e->AndReg32ImmX ( 11, -0x80000000 );
			e->OrRegReg32 ( RAX, 11 );
			
			// done
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set the flags
			e->MovRegMem32 ( RCX, &r->CPC1 [ 31 ] );
			e->ShlRegImm32 ( RDX, 3 );
			e->MovRegReg32 ( RAX, RDX );
			e->ShlRegImm32 ( RAX, 11 );
			e->OrRegReg32 ( RAX, RDX );
			
			// clear non sticky flags
			e->AndReg32ImmX ( RCX, ~0xc000 );
			e->OrRegReg32 ( RAX, RCX );
			e->MovMemReg32 ( &r->CPC1 [ 31 ], RAX );
			*/
#else
			
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			//e->MovRegReg32 ( 9, RAX );
			e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->AddRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			// debug
			//e->MovMemReg64 ( &ll0, RAX );
			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( RDX, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll1, RAX );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll2, RAX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );

			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );
			
			
			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->MovReg32ImmX ( 8, 0x4008 );
			e->LeaRegRegReg32 ( RAX, RAX, 10 );
			e->CmovLERegReg32 ( RAX, 11 );
			//e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( 8, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );
			
			// debug
			//e->MovMemReg64 ( &ll3, RAX );
			
			// check for overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			e->CmovARegReg32 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, RDX );
			e->MovReg32ImmX ( RDX, 0x8010 );
			e->CmovBERegReg32 ( RDX, 8 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RDX );
			
			
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MULA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MULA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MULA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_MULA_S_CODE
		case 1:
			
#ifdef USE_INTEGER_BASED_MULA

			//long es, et, ed;
			//unsigned long long ms, mt, md;
			//long ext;
			//long sign;
			//long fd;
			
			// load fs,ft
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			
			
			// init constant
			e->MovReg32ImmX ( 10, 127 );
			
			
			// sign is always a xor
			//fd = ( fs ^ ft ) & -0x80000000;
			e->MovRegReg32 ( 11, RAX );
			e->XorRegReg32 ( 11, RCX );
			
			
			// get the initial exponent
			//es = ( fs >> 23 ) & 0xff;
			//et = ( ft >> 23 ) & 0xff;
			//ed = es + et - 127;
			e->LeaRegRegReg32 ( 8, RAX, RAX );
			e->LeaRegRegReg32 ( 9, RCX, RCX );
			
			
			// check for zero
			e->ShrRegImm32 ( 8, 24 );
			e->CmovERegReg32 ( 10, 8 );
			e->ShrRegImm32 ( 9, 24 );
			e->CmovERegReg32 ( 10, 9 );


			// debug
			//e->MovMemReg32 ( &a1, 8 );
			//e->MovMemReg32 ( &a2, 9 );

			
			e->AddRegReg32 ( 8, 9 );
			e->SubRegReg32 ( 8, 10 );

			
			// debug
			//e->MovMemReg32 ( &a3, 8 );
			//e->MovMemReg32 ( &a4, 10 );

			// ft needs to mask from top bit
			e->MovRegReg32 ( RDX, RCX );
			e->ShrRegImm32 ( RDX, 22 );
			e->AndReg32ImmX ( RDX, 1 );
			e->NotReg32 ( RDX );
			e->AndRegReg32 ( RCX, RDX );

			// get the mantissa and add the hidden bit
			//ms = fs & 0x007fffff;
			//mt = ft & 0x007fffff;
			// add hidden bit
			//ms |= 0x00800000;
			//mt |= 0x00800000;
			e->ShlRegImm32 ( RAX, 8 );
			e->ShlRegImm32 ( RCX, 8 );
			e->OrReg32ImmX ( RAX, -0x80000000 );
			e->OrReg32ImmX ( RCX, -0x80000000 );
			
			// do the multiply
			//md = ms * mt;
			e->MulRegReg32 ( RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RAX );
			//e->MovMemReg32 ( &a6, RDX );
			
			
			// get bit 47
			//ext = md >> 47;
			e->MovRegReg32 ( RCX, RDX );
			e->ShrRegImm32 ( RCX, 31 );
			
			
			// get the result
			//md >>= ( 23 + ext );
			e->ShrRegImm32 ( RDX, 7 );
			e->ShrRegReg32 ( RDX );
			
			// remove the hidden bit
			//md &= 0x7fffff;
			e->AndReg32ImmX ( RDX, 0x7fffff );
			
			
			// clear RAX
			e->XorRegReg32 ( RAX, RAX );
			
			
			// update exponent
			//ed += ext;
			e->AddRegReg32 ( RCX, 8 );
			
			// check for zero
			e->CmovERegReg32 ( 10, RCX );
			
			// check for underflow (value negative)
			e->CmovSRegReg32 ( 9, RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RCX );
			//e->MovMemReg32 ( &a6, RDX );
			

			// also, no overflow if underflow (even if actually zero)
			e->CmovSRegReg32 ( RCX, RAX );
			
			
			// also set zero if underflow
			e->CmovSRegReg32 ( 10, RAX );
			
			
			
			// combine mantissa, exponent
			e->ShlRegImm32 ( RCX, 23 );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a7, RAX );
			
			
			// not overflow if zero (one or the other only)
			// clear if result should be zero
			e->OrRegReg32 ( 10, 10 );
			
			// if zero, then clear result (RAX), underflow (R9), and overflow (R8)
			e->CmovERegReg32 ( RAX, 10 );
			
			// if underflow, clear zero and result
			
			// debug
			//e->MovMemReg32 ( &a8, 9 );
			
			// maximize on overflow
			e->Cdq ();
			e->OrRegReg32 ( RAX, RDX );
			
			
			// clear sign
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			
			// combine with sign
			e->AndReg32ImmX ( 11, -0x80000000 );
			e->OrRegReg32 ( RAX, 11 );
			
			// done
			e->MovMemReg32 ( &r->dACC.l, RAX );
			
			// set the flags
			e->MovRegMem32 ( RCX, &r->CPC1 [ 31 ] );
			
				
			// get overflow flag
			e->AndReg32ImmX ( RDX, 0x8010 );
			
			// combine with underflow flag
			e->SarRegImm32 ( 9, 31 );
			e->AndReg32ImmX ( 9, 0x4008 );
			e->OrRegReg32 ( RDX, 9 );
			
			
			// clear non sticky flags
			e->AndReg32ImmX ( RCX, ~0xc000 );
			e->OrRegReg32 ( RCX, RDX );
			e->MovMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
#else
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			//e->MovRegReg32 ( 9, RAX );
			e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->AddRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			// debug
			//e->MovMemReg64 ( &ll0, RAX );
			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( RDX, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll1, RAX );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll2, RAX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );

			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );
			
			
			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->MovReg32ImmX ( 8, 0x4008 );
			e->LeaRegRegReg32 ( RAX, RAX, 10 );
			e->CmovLERegReg32 ( RAX, 11 );
			//e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( 8, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );
			
			// debug
			//e->MovMemReg64 ( &ll3, RAX );
			
			// check for overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			e->CmovARegReg32 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, RDX );
			e->MovReg32ImmX ( RDX, 0x8010 );
			e->CmovBERegReg32 ( RDX, 8 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RDX );
			
			
			
			// set result
			ret = e->MovMemReg32 ( &r->dACC.l, RAX );
#endif
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::DIV_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "DIV_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::DIV_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 8;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_DIV_S_CODE
		case 1:
			
			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );		// r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg32ImmX ( 8, 0x00030060 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			//e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( 8, 11 );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RCX, RAX );
			
			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			//e->MovReg64ImmX ( RCX, 896ULL << 23 );
			//e->XorRegReg32 ( 8, RAX );
			e->XorRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			//e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 9, 0x00010020 );
			e->MovReg32ImmX ( 10, 0x00020040 );
			e->CmovERegReg32 ( 9, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RAX, RAX );

			
			// get sign in R8
			e->AndReg32ImmX ( RDX, 0x80000000 );
			
			// set flags
			e->AndRegReg32 ( 8, 9 );
			e->OrMemReg32 ( &r->CPC1 [ 31 ], 8 );
			
			// perform div
			e->divsd ( RAX, RCX );


			// get result
			e->movq_from_sse ( RAX, RAX );

			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// clear on underflow or zero
			e->TestReg32ImmX ( RAX, 0xff800000 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmovSRegReg32 ( RAX, RCX );
			
			// or if any flags are set
			e->OrRegReg32 ( 8, 8 );
			e->CmovNERegReg32 ( RAX, RCX );
			
			// set sign
			e->OrRegReg32 ( RAX, RDX );
			

			// store result
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );

			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SQRT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SQRT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQRT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 8;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SQRT_S_CODE
		case 1:
			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x20040 );
			
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg32 ( RDX, RAX );
			e->CmovNERegReg64 ( RAX, 8 );
			e->ShlRegImm64 ( RAX, 29 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RDX );
			
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			
			// sqrt
			e->sqrtsd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			// ??
			e->AddReg64ImmX ( RAX, 0x10000000 );
			
			
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// if zero, then clear RCX
			e->CmovERegReg64 ( RCX, RAX );
			
			// subtract exponent
			e->SubRegReg64 ( RAX, RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::RSQRT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "RSQRT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::RSQRT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 14;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_RSQRT_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x20040 );
			
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 8, 0x10020 );
			e->CmovNERegReg32 ( 8, RDX );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], 8 );
			
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			
			// sqrt
			e->sqrtsd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			// ??
			e->AddReg64ImmX ( RAX, 0x10000000 );
			e->AndReg64ImmX ( RAX, ~0x1fffffff );
			

			e->movq_to_sse ( RCX, RAX );


			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			//e->MovRegReg32 ( RCX, RAX );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 10, 31 );
			//e->ShlRegImm64 ( 10, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, 10 );
			e->movq_to_sse ( RAX, RAX );

			
			// divide
			e->divsd ( RAX, RCX );
			
			
			// get result
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// subtract exponent
			//e->XorRegReg32 ( 10, 10 );
			//e->MovRegReg32 ( RDX, RAX );
			//e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->SubRegReg64 ( RAX, RCX );
			e->TestReg32ImmX ( RAX, 0xff800000 );
			
			// clear on underflow or zero
			//e->CmovLERegReg32 ( RAX, 10 );
			//e->CmovLERegReg32 ( RDX, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			//e->OrRegReg32 ( RDX, RDX );
			e->CmovSRegReg32 ( RAX, RCX );
			
			
			// or if any flags are set indicating denominator is zero
			e->AndReg32ImmX ( 8, 0x00020 );
			e->CmovNERegReg32 ( RAX, RCX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );
			e->OrRegReg32 ( RAX, RDX );
			

			// store result
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




long R5900::Recompiler::MOV_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MOV_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MOV_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MOV_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].u;
			// flags affected: none
			if ( i.Fd != i.Fs )
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::NEG_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "NEG_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::NEG_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_NEG_S_CODE
		case 1:
			//r->CPR1 [ i.Fd ].s = r->CPR1 [ i.Fs ].s ^ 0x80000000;
			// flags affected:
			// clears flags o,u (bits 14,15)
			//r->CPC1 [ 31 ] &= ~0x0000c000;
			if ( i.Fd == i.Fs )
			{
				e->XorMem32ImmX ( &r->CPR1 [ i.Fs ].s, 0x80000000 );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			else
			{
				e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
				e->XorReg32ImmX ( RAX, 0x80000000 );
				e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
				ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



long R5900::Recompiler::SUBA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SUBA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SUBA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SUBA_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->subsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->dACC.l, RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADD_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADD_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADD_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_MADD_S_CODE
		case 1:

#ifdef USE_INTEGER_BASED_MADD

			//long es, et, ed;
			//unsigned long long ms, mt, md;
			//long ext;
			//long sign;
			//long fd;
			
			// load fs,ft
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			
			// init constant
			e->MovReg32ImmX ( 10, 127 );
			
			// sign is always a xor
			//fd = ( fs ^ ft ) & -0x80000000;
			e->MovRegReg32 ( 11, RAX );
			e->XorRegReg32 ( 11, RCX );
			
			
			// get the initial exponent
			//es = ( fs >> 23 ) & 0xff;
			//et = ( ft >> 23 ) & 0xff;
			//ed = es + et - 127;
			e->LeaRegRegReg32 ( 8, RAX, RAX );
			e->LeaRegRegReg32 ( 9, RCX, RCX );
			
			
			// check for zero
			e->ShrRegImm32 ( 8, 24 );
			e->CmovERegReg32 ( 10, 8 );
			e->ShrRegImm32 ( 9, 24 );
			e->CmovERegReg32 ( 10, 9 );


			// debug
			//e->MovMemReg32 ( &a1, 8 );
			//e->MovMemReg32 ( &a2, 9 );

			
			e->AddRegReg32 ( 8, 9 );
			e->SubRegReg32 ( 8, 10 );

			
			// debug
			//e->MovMemReg32 ( &a3, 8 );
			//e->MovMemReg32 ( &a4, 10 );

			// ft needs to mask from top bit
			e->MovRegReg32 ( RDX, RCX );
			e->ShrRegImm32 ( RDX, 22 );
			e->AndReg32ImmX ( RDX, 1 );
			e->NotReg32 ( RDX );
			e->AndRegReg32 ( RCX, RDX );
			
			// get the mantissa and add the hidden bit
			//ms = fs & 0x007fffff;
			//mt = ft & 0x007fffff;
			// add hidden bit
			//ms |= 0x00800000;
			//mt |= 0x00800000;
			e->ShlRegImm32 ( RAX, 8 );
			e->ShlRegImm32 ( RCX, 8 );
			e->OrReg32ImmX ( RAX, -0x80000000 );
			e->OrReg32ImmX ( RCX, -0x80000000 );
			
			// do the multiply
			//md = ms * mt;
			e->MulRegReg32 ( RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RAX );
			//e->MovMemReg32 ( &a6, RDX );
			
			
			// get bit 47
			//ext = md >> 47;
			e->MovRegReg32 ( RCX, RDX );
			e->ShrRegImm32 ( RCX, 31 );
			
			
			// get the result
			//md >>= ( 23 + ext );
			e->ShrRegImm32 ( RDX, 7 );
			e->ShrRegReg32 ( RDX );
			
			// remove the hidden bit
			//md &= 0x7fffff;
			e->AndReg32ImmX ( RDX, 0x7fffff );
			
			
			// clear RAX
			e->XorRegReg32 ( RAX, RAX );
			
			
			// update exponent
			//ed += ext;
			e->AddRegReg32 ( RCX, 8 );
			
			// check for zero
			e->CmovERegReg32 ( 10, RCX );
			
			// check for underflow (value negative)
			e->CmovSRegReg32 ( 9, RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RCX );
			//e->MovMemReg32 ( &a6, RDX );
			

			// also, no overflow if underflow (even if actually zero)
			e->CmovSRegReg32 ( RCX, RAX );
			
			
			// also set zero if underflow
			e->CmovSRegReg32 ( 10, RAX );
			
			
			
			// combine mantissa, exponent
			e->ShlRegImm32 ( RCX, 23 );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a7, RAX );
			
			
			// not overflow if zero (one or the other only)
			// clear if result should be zero
			e->OrRegReg32 ( 10, 10 );
			
			// if zero, then clear result (RAX), underflow (R9), and overflow (R8)
			e->CmovERegReg32 ( RAX, 10 );
			
			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// on overflow, copy over ACC
			e->OrRegReg32 ( RCX, RCX );
			e->CmovSRegReg32 ( 8, RCX );
			
			
			// if underflow, clear zero and result
			
			// debug
			//e->MovMemReg32 ( &a8, 9 );
			
			// maximize on overflow
			e->Cdq ();
			e->OrRegReg32 ( RAX, RDX );
			
			// get constant for later
			e->MovReg32ImmX ( RDX, 0x7fffffff );
			
			// clear sign
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->AndRegReg32 ( RAX, RDX );
			
			// combine with sign
			e->AndReg32ImmX ( 11, -0x80000000 );
			//e->OrRegReg32 ( RAX, 11 );
			
			// done
			//e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set the flags
			e->MovRegMem32 ( RCX, &r->CPC1 [ 31 ] );
			
				
			// get overflow flag
			//e->AndReg32ImmX ( RDX, 0x8010 );
			
			// combine with underflow flag
			e->SarRegImm32 ( 9, 31 );
			e->AndReg32ImmX ( 9, 0x0008 );
			//e->OrRegReg32 ( RDX, 9 );
			
			
			// clear non sticky flags
			e->AndReg32ImmX ( RCX, ~0xc000 );
			//e->OrRegReg32 ( RCX, RDX );
			e->OrRegReg32 ( RCX, 9 );
			e->MovMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			// if acc is in overflow state (??) then copy over result
			e->MovRegReg32 ( RCX, 8 );
			e->AndRegReg32 ( RCX, RDX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovERegReg32 ( RAX, 8 );
#else
		
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
#endif
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 10, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 8, RAX );
			e->CmovNERegReg32 ( RAX, 10 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::MSUB_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MSUB_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MSUB_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MSUB_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );

			// reverse sign for sub
			e->XorReg32ImmX ( 9, 0x80000000 );
			
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
			
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 10, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 8, RAX );
			e->CmovNERegReg32 ( RAX, 10 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			break;
#endif

			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MSUBA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MSUBA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MSUBA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MSUBA_S_CODE
		case 1:
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );
			
			// reverse sign for sub
			e->XorReg32ImmX ( 9, 0x80000000 );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
			
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 10, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 8, RAX );
			e->CmovNERegReg32 ( RAX, 10 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->dACC.l, RAX );
			break;
#endif


			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MADDA_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MADDA_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MADDA_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_MADDA_S_CODE
		case 1:
		
#ifdef USE_INTEGER_BASED_MADDA

			//long es, et, ed;
			//unsigned long long ms, mt, md;
			//long ext;
			//long sign;
			//long fd;
			
			// load fs,ft
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			
			// init constant
			e->MovReg32ImmX ( 10, 127 );
			
			// sign is always a xor
			//fd = ( fs ^ ft ) & -0x80000000;
			e->MovRegReg32 ( 11, RAX );
			e->XorRegReg32 ( 11, RCX );
			
			
			// get the initial exponent
			//es = ( fs >> 23 ) & 0xff;
			//et = ( ft >> 23 ) & 0xff;
			//ed = es + et - 127;
			e->LeaRegRegReg32 ( 8, RAX, RAX );
			e->LeaRegRegReg32 ( 9, RCX, RCX );
			
			
			// check for zero
			e->ShrRegImm32 ( 8, 24 );
			e->CmovERegReg32 ( 10, 8 );
			e->ShrRegImm32 ( 9, 24 );
			e->CmovERegReg32 ( 10, 9 );


			// debug
			//e->MovMemReg32 ( &a1, 8 );
			//e->MovMemReg32 ( &a2, 9 );

			
			e->AddRegReg32 ( 8, 9 );
			e->SubRegReg32 ( 8, 10 );

			
			// debug
			//e->MovMemReg32 ( &a3, 8 );
			//e->MovMemReg32 ( &a4, 10 );

			// ft needs to mask from top bit
			e->MovRegReg32 ( RDX, RCX );
			e->ShrRegImm32 ( RDX, 22 );
			e->AndReg32ImmX ( RDX, 1 );
			e->NotReg32 ( RDX );
			e->AndRegReg32 ( RCX, RDX );

			// get the mantissa and add the hidden bit
			//ms = fs & 0x007fffff;
			//mt = ft & 0x007fffff;
			// add hidden bit
			//ms |= 0x00800000;
			//mt |= 0x00800000;
			e->ShlRegImm32 ( RAX, 8 );
			e->ShlRegImm32 ( RCX, 8 );
			e->OrReg32ImmX ( RAX, -0x80000000 );
			e->OrReg32ImmX ( RCX, -0x80000000 );
			
			// do the multiply
			//md = ms * mt;
			e->MulRegReg32 ( RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RAX );
			//e->MovMemReg32 ( &a6, RDX );
			
			
			// get bit 47
			//ext = md >> 47;
			e->MovRegReg32 ( RCX, RDX );
			e->ShrRegImm32 ( RCX, 31 );
			
			
			// get the result
			//md >>= ( 23 + ext );
			e->ShrRegImm32 ( RDX, 7 );
			e->ShrRegReg32 ( RDX );
			
			// remove the hidden bit
			//md &= 0x7fffff;
			e->AndReg32ImmX ( RDX, 0x7fffff );
			
			
			// clear RAX
			e->XorRegReg32 ( RAX, RAX );
			
			
			// update exponent
			//ed += ext;
			e->AddRegReg32 ( RCX, 8 );
			
			// check for zero
			e->CmovERegReg32 ( 10, RCX );
			
			// check for underflow (value negative)
			e->CmovSRegReg32 ( 9, RCX );
			
			
			// debug
			//e->MovMemReg32 ( &a5, RCX );
			//e->MovMemReg32 ( &a6, RDX );
			

			// also, no overflow if underflow (even if actually zero)
			e->CmovSRegReg32 ( RCX, RAX );
			
			
			// also set zero if underflow
			e->CmovSRegReg32 ( 10, RAX );
			
			
			
			// combine mantissa, exponent
			e->ShlRegImm32 ( RCX, 23 );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			
			// debug
			//e->MovMemReg32 ( &a7, RAX );
			
			
			// not overflow if zero (one or the other only)
			// clear if result should be zero
			e->OrRegReg32 ( 10, 10 );
			
			// if zero, then clear result (RAX), underflow (R9), and overflow (R8)
			e->CmovERegReg32 ( RAX, 10 );
			
			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// on overflow, copy over ACC
			e->OrRegReg32 ( RCX, RCX );
			e->CmovSRegReg32 ( 8, RCX );
			
			
			// if underflow, clear zero and result
			
			// debug
			//e->MovMemReg32 ( &a8, 9 );
			
			// maximize on overflow
			e->Cdq ();
			e->OrRegReg32 ( RAX, RDX );
			
			// get constant for later
			e->MovReg32ImmX ( RDX, 0x7fffffff );
			
			// clear sign
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->AndRegReg32 ( RAX, RDX );
			
			// combine with sign
			e->AndReg32ImmX ( 11, -0x80000000 );
			//e->OrRegReg32 ( RAX, 11 );
			
			// done
			//e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set the flags
			e->MovRegMem32 ( RCX, &r->CPC1 [ 31 ] );
			
				
			// get overflow flag
			//e->AndReg32ImmX ( RDX, 0x8010 );
			
			// combine with underflow flag
			e->SarRegImm32 ( 9, 31 );
			e->AndReg32ImmX ( 9, 0x0008 );
			//e->OrRegReg32 ( RDX, 9 );
			
			
			// clear non sticky flags
			e->AndReg32ImmX ( RCX, ~0xc000 );
			//e->OrRegReg32 ( RCX, RDX );
			e->OrRegReg32 ( RCX, 9 );
			e->MovMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			// if acc is in overflow state (??) then copy over result
			e->MovRegReg32 ( RCX, 8 );
			e->AndRegReg32 ( RCX, RDX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovERegReg32 ( RAX, 8 );
#else
		
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x0000c000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, &r->dACC.l );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
#endif
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 10, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 8, RAX );
			e->CmovNERegReg32 ( RAX, 10 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &r->dACC.l, RAX );
			break;
#endif


			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::CVT_W_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "CVT_W_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::CVT_W_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_CVT_W_S_CODE
		case 1:
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			
			//e->MovRegReg32 ( RCX, RAX );
			//e->AndReg32ImmX ( RAX, 0x7f800000 );
			//e->CmovNERegReg32 ( RAX, RCX );
			
			// move the registers now to floating point unit
			e->movd_to_sse ( RAX, RAX );
			
			// convert single precision to signed 
			e->cvttss2si ( RCX, RAX );
			
			
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			//e->CmovERegReg32 ( RDX, RAX );
			e->XorReg32ImmX ( RDX, 0x7fffffff );
			
			// compare exponent of magnitude and maximize if needed
			e->CmpReg32ImmX ( RAX, 0x4e800000 );
			//e->MovReg32ImmX ( RAX, 0x7fffffff );
			//e->CmovLERegReg32 ( RAX, RCX );
			e->CmovLERegReg32 ( RDX, RCX );
			//e->ShlRegImm32 ( RDX, 31 );
			//e->OrRegReg32 ( RAX, RDX );
			
			// set result
			ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RDX );
			
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MAX_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MAX_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MAX_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MAX_S_CODE
		case 1:
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovGRegReg32 ( 8, 9 );
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, 8 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::MIN_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "MIN_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::MIN_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
#ifdef ENABLE_FPU_LATENCY
	static constexpr unsigned long long c_ullLatency = 4;
	
	// check if next instruction uses dest from this one
	if ( ( 1ull << i.Fd ) & GetCop1_SrcRegs( NextInst ) )
	{
		// add latency
		LocalCycleCount += ( c_ullLatency - 2 ) >> 1;
	}
#endif

	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_MIN_S_CODE
		case 1:
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs < lft ) ? fs : ft );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovLRegReg32 ( 8, 9 );
			e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, 8 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::C_F_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "C_F_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_F_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_F_S_CODE
		case 1:
			// clears bit 23 in FCR31
			//r->CPC1 [ 31 ] &= ~0x00800000;
			ret = e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::C_EQ_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "C_EQ_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_EQ_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_EQ_S_CODE
		case 1:
			//inline static long FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs == lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );
			
			/*
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			*/
			e->MovRegMem32 ( RCX, &r->CPR1 [ i.Ft ].s );
			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			
			e->MovRegReg32 ( RDX, RCX );
			e->AndReg32ImmX ( RCX, 0x7f800000 );
			e->CmovNERegReg32 ( RCX, RDX );
			//e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->XorRegReg32 ( RAX, RDX );

			//e->MovRegReg32 ( RCX, RAX );

			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			//e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->XorRegReg32 ( RAX, RDX );
			
			e->CmpRegReg32 ( RAX, RCX );
			e->Set_E ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::C_LT_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "C_LT_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_LT_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_LT_S_CODE
		case 1:
			//inline static long FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs < lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->MovRegReg32 ( RCX, RAX );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			//e->XorRegReg32 ( RDX, RDX );
			e->CmpRegReg32 ( RAX, RCX );
			//e->MovReg32ImmX ( RCX, 0x00800000 );
			e->Set_L ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			//e->MovMemReg32 ( &r->testvar [ 7 ], RAX );

			//e->NegReg32 ( RDX );
			//e->AndReg32ImmX ( RDX, 0x00800000 );
			//e->CmovLRegReg32 ( RDX, RCX );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::C_LE_S ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "C_LE_S";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::C_LE_S;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_C_LE_S_CODE
		case 1:
			//inline static long FlushConvertToComparableInt_f ( float& f1 )
			//if ( ! ( lf1 & c_lFloat_ExpMask ) ) lf1 = 0;
			//if ( lf1 < 0 ) lf1 = -( lf1 & 0x7fffffff );
		
			//fs = r->CPR1 [ i.Fs ].f;
			//ft = r->CPR1 [ i.Ft ].f;
			//lfs = PS2Float::FlushConvertToComparableInt_f ( fs );
			//lft = PS2Float::FlushConvertToComparableInt_f ( ft );
			//if ( lfs <= lft ) r->CPC1 [ 31 ] |= 0x00800000; else r->CPC1 [ 31 ] &= ~0x00800000;
			
			// clear the flag first
			e->AndMem32ImmX ( &r->CPC1 [ 31 ], ~0x00800000 );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->MovRegReg32 ( RCX, RAX );

			e->MovRegMem32 ( RAX, &r->CPR1 [ i.Fs ].s );
			e->MovRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( RAX, RDX );
			e->Cdq ();
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->ShrRegImm32 ( RDX, 1 );
			e->XorRegReg32 ( RAX, RDX );
			
			e->CmpRegReg32 ( RAX, RCX );
			e->Set_LE ( RAX );
			e->Cbw ();
			e->ShlRegImm32 ( RAX, 23 );
			ret = e->OrMemReg32 ( &r->CPC1 [ 31 ], RAX );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// * COP2 (VU0) instrutions * //



// PS2 has LQC2/SQC2 instead of LWC2/SWC2 //
long R5900::Recompiler::LQC2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "LQC2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::LQC2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_LQC2_CODE
		case 1:
			ret = Generate_Normal_Load ( i, Address, 0xf, (void*) Playstation2::DataBus::Read_t<0> );
			
			// store result //
			
			if ( i.Ft )
			{
				// store
				//e->movdqa_from_mem128 ( RAX, RAX, NO_INDEX, 0, 0 );
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sq0, RAX );
			}
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::SQC2 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "SQC2";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::SQC2;
	
	int ret = 1;
	
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

#ifdef ENABLE_R5900_DCACHE
			e->AddMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );

#ifdef ENABLE_R5900_DCACHE
			e->SubMemImm64 ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
#endif
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_SQC2_CODE
		case 1:
			ret = Generate_Normal_Store ( i, Address, 0xf, (void*) Playstation2::DataBus::Write_t<0> );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


long R5900::Recompiler::QMFC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "QMFC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMFC2_NI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_QMFC2_NI_CODE
		case 1:
			if ( i.Rt )
			{
				switch ( i.Rd )
				{
					case 0:
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq0, 0 );
						e->MovMemImm64 ( &r->GPR [ i.Rt ].sq1, 0 );
						e->MovMemImm32 ( &r->GPR [ i.Rt ].sw3, 0x3f800000 );
						break;
						
					default:
						e->movdqa_regmem ( RAX, &VU0::_VU0->vf [ i.Rd ].s );
						e->movdqa_memreg ( &r->GPR [ i.Rt ].s, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::QMFC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "QMFC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMFC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::QMTC2_NI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "QMTC2_NI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMTC2_NI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_QMTC2_NI_CODE
		case 1:
			if ( i.Rd )
			{
				switch ( i.Rt )
				{
					case 0:
						e->pxorregreg ( RAX, RAX );
						e->movdqa_memreg ( &VU0::_VU0->vf [ i.Rd ].s, RAX );
						break;
						
					default:
						e->movdqa_regmem ( RAX, &r->GPR [ i.Rt ].s );
						e->movdqa_memreg ( &VU0::_VU0->vf [ i.Rd ].s, RAX );
						break;
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::QMTC2_I ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "QMTC2_I";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::QMTC2_I;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


//long R5900::Recompiler::COP2 ( R5900::Instruction::Format i, u32 Address )
//{
//}

long R5900::Recompiler::Generate_VPrefix ( u32 Address )
{
	long ret;
	
	ret = 1;
	
	//if ( VU0::_VU0->VifRegs.STAT.VEW )
	//{
	//	// vu#0 is running //
	e->BtMemImm32 ( (long*) & VU0::_VU0->VifRegs.STAT.Value, 2 );
	e->Jmp8_AE( 0, 0 );
		
	//	// don't go anywhere until it is done for now
	//	r->NextPC = r->PC;
	e->MovMemImm32( (long*) & r->NextPC, Address );
	
	// update CPU CycleCount
	//e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount - MemCycles );
	e->AddMem64ImmX ( (long long*) & r->CycleCount, LocalCycleCount );
	
	// done for now - return
	e->Ret ();
	
	//}
	
	e->SetJmpTarget8( 0 );
	
	return true;
}

long R5900::Recompiler::Generate_VABSp ( R5900::Instruction::Format i )
{
	long ret;
	
	ret = 1;
	
	if ( i.Ft && i.xyzw )
	{
		if ( !i.Fs )
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
			
			if ( i.xyzw != 0xf )
			{
				//e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
		else
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
			
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}
			
			//e->pslldregimm ( RCX, 1 );
			e->padddregreg ( RCX, RCX );
			e->psrldregimm ( RCX, 1 );
			
			if ( i.xyzw != 0xf )
			{
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
	}
	
	return ret;
}

long R5900::Recompiler::Generate_VABS ( R5900::Instruction::Format i, u32 Address, u32 Component )
{
	long ret;
	
	ret = 1;
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( Component ^ 3 ) + 21 ) ) )
	{
		if ( !i.Ft )
		{
			// can't write to register zero
			return 1;
		}
		else if ( !i.Fs )
		{
			if ( Component < 3 )
			{
				ret = e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + Component, 0 );
			}
			else
			{
				ret = e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + Component, 0x3f800000 );
			}
		}
		else if ( i.Ft == i.Fs )
		{
			ret = e->AndMem32ImmX ( ( & VU0::_VU0->vf [ i.Fs ].sw0 ) + Component, 0x7fffffff );
		}
		else if ( i.Fd )
		{
			e->MovRegMem32 ( RAX, ( & VU0::_VU0->vf [ i.Fs ].sw0 ) + Component );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + Component, RAX );
		}
		
	}
	
	return ret;
}



long R5900::Recompiler::Generate_VMAXp ( R5900::Instruction::Format i, u32 *pFt, u32 FtComponent )
{
	//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
	//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
	// compare as integer and return original value?
	//fResult = ( ( lfs > lft ) ? fs : ft );
	long ret;
	
	ret = 1;
	
	
	if ( i.Fd && i.xyzw )
	{
		e->movdqa_regmem ( RBX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( !pFt )
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		else
		{
			e->movd_regmem( RCX, (long*) pFt );
		}
		
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
		//}
		
		/*
		e->movdqa_regreg ( RDX, RBX );
		e->movdqa_regreg ( 4, RBX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RDX, 4 );
		*/
		e->movdqa_regreg ( RDX, RBX );
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( RDX, 1 );
		e->psradregimm ( RDX, 31 );
		e->psrldregimm ( RDX, 1 );
		e->pxorregreg ( RDX, RBX );
		
		if ( pFt )
		{
			// need to "broadcast" the value in sse ??
			e->pshufdregregimm ( RCX, RCX, 0 );
		}
		
		/*
		e->movdqa_regreg ( RAX, RCX );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RAX, 4 );
		*/
		e->movdqa_regreg ( RAX, RCX );
		//e->movdqa_regreg ( 4, RCX );
		//e->pslldregimm ( RAX, 1 );
		e->psradregimm ( RAX, 31 );
		e->psrldregimm ( RAX, 1 );
		e->pxorregreg ( RAX, RCX );
		
		e->pcmpgtdregreg ( RAX, RDX );
		e->pblendvbregreg ( RBX, RCX );
		
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RBX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RBX, & VU0::_VU0->vf [ i.Fd ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, RBX );
	}
	
	
	return ret;
}



long R5900::Recompiler::Generate_VMINp ( R5900::Instruction::Format i, u32 *pFt, u32 FtComponent )
{
	//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
	//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
	// compare as integer and return original value?
	//fResult = ( ( lfs > lft ) ? fs : ft );
	long ret;
	
	ret = 1;
	
	if ( i.Fd && i.xyzw )
	{
		e->movdqa_regmem ( RBX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( !pFt )
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		else
		{
			e->movd_regmem( RCX, (long*) pFt );
		}
		
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
		//}
		
		/*
		e->movdqa_regreg ( RAX, RBX );
		e->movdqa_regreg ( 4, RBX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RAX, 4 );
		*/
		e->movdqa_regreg ( RAX, RBX );
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( RAX, 1 );
		e->psradregimm ( RAX, 31 );
		e->psrldregimm ( RAX, 1 );
		e->pxorregreg ( RAX, RBX );

		if ( pFt )
		{
			// need to "broadcast" the value in sse ??
			e->pshufdregregimm ( RCX, RCX, 0 );
		}
		
		/*
		e->movdqa_regreg ( RDX, RCX );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 1 );
		e->psradregimm ( 4, 31 );
		e->pxorregreg ( RDX, 4 );
		*/
		e->movdqa_regreg ( RDX, RCX );
		//e->movdqa_regreg ( 4, RCX );
		//e->pslldregimm ( RDX, 1 );
		e->psradregimm ( RDX, 31 );
		e->psrldregimm ( RDX, 1 );
		e->pxorregreg ( RDX, RCX );
		
		e->pcmpgtdregreg ( RAX, RDX );
		e->pblendvbregreg ( RBX, RCX );
		
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RBX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RBX, & VU0::_VU0->vf [ i.Fd ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, RBX );
	}
	
	
	return ret;
}



long R5900::Recompiler::Generate_VFTOIXp ( R5900::Instruction::Format i, u32 IX )
{
	long ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
		e->movdqa_regmem ( RBX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
		//}

		if ( IX )
		{
			e->MovRegImm32 ( RAX, IX << 23 );
			e->movd_to_sse ( RCX, RAX );
			e->pshufdregregimm ( RCX, RCX, 0 );
			e->padddregreg ( RCX, RBX );
		}
		else
		{
			//e->MovRegReg32 ( RCX, RAX );
			e->movdqa_regreg ( RCX, RBX );
		}
		
		// move the registers now to floating point unit
		//e->movd_to_sse ( RAX, RCX );
		
		// convert single precision to signed 
		//e->cvttss2si ( RCX, RAX );
		e->cvttps2dq_regreg ( RCX, RCX );
		
		//e->Cdq ();
		//e->AndReg32ImmX ( RAX, 0x7f800000 );
		//e->CmovERegReg32 ( RDX, RAX );
		
		
		// compare exponent of magnitude and maximize if needed
		//e->CmpReg32ImmX ( RAX, 0x4e800000 - ( IX << 23 ) );
		//e->MovReg32ImmX ( RAX, 0x7fffffff );
		//e->CmovLERegReg32 ( RAX, RCX );
		//e->ShlRegImm32 ( RDX, 31 );
		//e->OrRegReg32 ( RAX, RDX );
		e->MovRegImm32 ( RAX, 0x4f000000 - ( IX << 23 ) - 1 );
		e->movd_to_sse ( RDX, RAX );
		e->pshufdregregimm ( RDX, RDX, 0 );
		e->pcmpeqbregreg ( RAX, RAX );
		e->psrldregimm ( RAX, 1 );
		
		e->movdqa_regreg ( 5, RAX );
		
		e->pandregreg ( RAX, RBX );
		
		e->psrldregimm ( RBX, 31 );
		e->padddregreg ( RBX, 5 );

		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
		//}
		
		e->pcmpgtdregreg ( RAX, RDX );
		
		e->pblendvbregreg ( RCX, RBX );
		
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RCX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		// set result
		//ret = e->MovMemReg32 ( ( & v->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
	}

	return ret;
}


long R5900::Recompiler::Generate_VITOFXp ( R5900::Instruction::Format i, u64 FX )
{
	long ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
		e->movdqa_regmem ( RBX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		// convert single precision to signed 
		//e->cvtsi2sd ( RAX, RAX );
		//e->movq_from_sse ( RAX, RAX );
		e->cvtdq2pd ( RCX, RBX );
				
				
		//e->MovReg64ImmX ( RCX, ( 896 << 23 ) + ( FX << 23 ) );
		//e->Cqo();
		e->MovReg64ImmX ( RAX, ( 896ull << 23 ) + ( FX << 23 ) );
		e->movq_to_sse ( RDX, RAX );
		e->movddup_regreg ( RDX, RDX );
		
		//e->ShrRegImm64 ( RAX, 29 );
		//e->CmovERegReg64 ( RCX, RDX );
		//e->SubRegReg64 ( RAX, RCX );
		e->movdqa_regreg ( 4, RCX );
		e->psrlqregimm ( 4, 63 );
		e->pslldregimm ( 4, 31 );
		e->psrlqregimm ( RCX, 29 );
		e->psubqregreg ( RCX, RDX );
		e->porregreg ( RCX, 4 );
		
		e->pshufdregregimm ( 5, RBX, ( 3 << 2 ) | ( 2 << 0 ) );
		e->cvtdq2pd ( 5, 5 );

		e->movdqa_regreg ( RAX, 5 );
		e->psrlqregimm ( RAX, 63 );
		e->pslldregimm ( RAX, 31 );
		e->psrlqregimm ( 5, 29 );
		e->psubqregreg ( 5, RDX );
		e->porregreg ( 5, RAX );
		
		// combine RCX (bottom) and 5 (top)
		e->pshufdregregimm ( RCX, RCX, ( 2 << 2 ) | ( 0 << 0 ) );
		e->pshufdregregimm ( RDX, 5, ( 2 << 6 ) | ( 0 << 4 ) );
		e->pblendwregregimm ( RCX, RDX, 0xf0 );
		
		// load destination register
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Ft ].sw0 );
		//}
		
		// clear zeros
		e->pxorregreg ( RAX, RAX );
		e->pcmpeqdregreg ( RAX, RBX );
		e->pandnregreg ( RAX, RCX );
		
		// select result
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RAX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		// store result
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RAX );
		
		//e->ShlRegImm32 ( RDX, 31 );
		//e->OrRegReg32 ( RAX, RDX );
				
		// set result
		//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
	}

	return ret;
}



long R5900::Recompiler::Generate_VMOVEp ( R5900::Instruction::Format i )
{
	long ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( i.xyzw != 0xf )
		{
			//e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
	}

	return ret;
}


long R5900::Recompiler::Generate_VMR32p ( R5900::Instruction::Format i )
{
	long ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		//if ( i.xyzw != 0xf )
		//{
		//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		//}
		
		//e->pshufdregregimm ( RCX, RCX, ( 0 << 6 ) | ( 3 << 4 ) | ( 2 << 2 ) | ( 1 << 0 ) );
		e->pshufdregmemimm ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0, ( 0 << 6 ) | ( 3 << 4 ) | ( 2 << 2 ) | ( 1 << 0 ) );
		
		if ( i.xyzw != 0xf )
		{
			//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
	}

	return ret;
}



long R5900::Recompiler::Generate_VMFIRp ( R5900::Instruction::Format i )
{
	long ret;
	
	ret = 1;

	if ( i.Ft && i.xyzw )
	{
		// flush ps2 float to zero
		if ( !( i.is & 0xf ) )
		{
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}
			
			e->pxorregreg ( RCX, RCX );
			
			if ( i.xyzw != 0xf )
			{
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
		else
		{
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ i.is & 0xf ].s ) );
			
			//if ( i.xyzw != 0xf )
			//{
			//	e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
			//}
			
			// sign-extend from 16-bit to 32-bit
			e->Cwde();
			
			e->movd_to_sse ( RCX, RAX );
			e->pshufdregregimm ( RCX, RCX, 0 );
			
			if ( i.xyzw != 0xf )
			{
				//e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				e->pblendwregmemimm ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			// set result
			//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
		}
		
	}

	return ret;
}




long R5900::Recompiler::Generate_VMTIRp ( R5900::Instruction::Format i )
{
	long ret;
	
	ret = 1;

	if ( ( i.it & 0xf ) )
	{
		//v->Set_IntDelaySlot ( i.it & 0xf, (u16) v->vf [ i.Fs ].vsw [ i.fsf ] );
		
		// flush ps2 float to zero
		if ( ( !i.Fs ) && ( i.fsf < 3 ) )
		{
			//e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
			e->MovMemImm32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, 0 );
		}
		else
		{
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, & VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			e->AndRegImm32 ( RAX, 0xffff );
			
			// set result
			ret = e->MovMemReg32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
		}
		
	}

	return ret;
}


// set bSub to 1 for subtraction
long R5900::Recompiler::Generate_VADDp ( u32 bSub, R5900::Instruction::Format i, u32 FtComponent, void *pFd, u32 *pFt )
{
	static const u64 c_lUpperBound = ( 24LL << 32 ) | ( 24LL );
	static const u64 c_lLowerBound = ( 0xffffffe8LL << 32 ) | ( 0xffffffe8LL );
	static const u64 c_lUFTest = ( 0x800000LL << 32 ) | ( 0x800000LL );
	long ret;
	
	ret = 1;


	if ( i.xyzw )
	{
		// load source regs
		// but they need to be shuffled into reverse on load
		e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( pFt )
		{
			e->movd_regmem ( RCX, (long*) pFt );
		}
		else
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		
		
		//e->pshufdregmemimm ( RAX, & va, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		//e->pshufdregmemimm ( RCX, & vb, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		e->pshufdregregimm ( RAX, RAX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		
		if ( FtComponent < 4 )
		{
			e->pshufdregregimm ( RCX, RCX, ( FtComponent << 6 ) | ( FtComponent << 4 ) | ( FtComponent << 2 ) | ( FtComponent << 0 ) );
		}
		else
		{
			e->pshufdregregimm ( RCX, RCX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		}
		
		// get exponents
		e->movdqa_regreg ( RDX, RAX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 24 );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 24 );

		
		// debug
		//e->movdqa_memreg ( & v0, RDX );

		// debug
		//e->movdqa_memreg ( & v1, 4 );

		// clear zero exponents ??
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, RDX );
		e->psrldregimm ( RBX, 1 );
		e->pandnregreg ( RBX, RAX );
		e->movdqa_regreg ( RAX, RBX );
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, 4 );
		e->psrldregimm ( RBX, 1 );
		e->pandnregreg ( RBX, RCX );
		e->movdqa_regreg ( RCX, RBX );
		
		
		// get difference
		e->psubdregreg ( RDX, 4 );
		
		
		// if positive 24 or greater then zero Ft
		e->movddup_regmem ( 5, (long long*) &c_lUpperBound );
		e->pcmpgtdregreg ( 5, RDX );
		e->pandregreg ( RCX, 5 );


		// if negative 24 or less, then zero Fs
		e->movddup_regmem ( 5, (long long*) &c_lLowerBound );
		e->pcmpgtdregreg ( RDX, 5 );
		e->pandregreg ( RAX, RDX );

		
		//if ( ( __builtin_popcount ( i.xyzw ) < 3 ) )
		if ( ( popcnt32 ( i.xyzw ) < 3 ) )
		{
			e->pshufdregregimm ( RDX, RAX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );

				//e->movdqa_regreg ( RDX, RAX );
				//e->movdqa_regreg ( 4, RAX );
				e->movdqa_regreg ( 4, RDX );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );
				
			e->pshufdregregimm ( 5, RCX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
				
				//e->movdqa_regreg ( 5, RCX );
				//e->movdqa_regreg ( 4, RCX );
				e->movdqa_regreg ( 4, 5 );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );
				
				
				if ( bSub )
				{
					// subtract (round1)
					e->subpdregreg ( RDX, 5 );
				}
				else
				{
					// add (round1)
					e->addpdregreg ( RDX, 5 );
				}
				
				
				// merge result (round1) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->pslldregimm ( 4, 31 );
				
				e->psrlqregimm ( RDX, 29 );
				
				//e->pblendwregregimm ( RAX, RDX, 0x33 );
				//e->movdqa_regreg ( RBX, 4 );
			
			e->pshufdregregimm ( RAX, RDX, _op_r5900_add_shuffle_lut_2 [ i.xyzw ] );
			e->pshufdregregimm ( RBX, 4, _op_r5900_add_shuffle_lut_2 [ i.xyzw ] );
		}
		else
		{
			if ( i.xyzw & 0x5 )
			{
				// convert to double (round1)
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RAX );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );
				
				
				e->movdqa_regreg ( 5, RCX );
				e->movdqa_regreg ( 4, RCX );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );
				
				
				if ( bSub )
				{
					// subtract (round1)
					e->subpdregreg ( RDX, 5 );
				}
				else
				{
					// add (round1)
					e->addpdregreg ( RDX, 5 );
				}
				
				
				// merge result (round1) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->pslldregimm ( 4, 31 );
				//e->psllqregimm ( RDX, 4 );
				e->psrlqregimm ( RDX, 29 );
				e->pblendwregregimm ( RAX, RDX, 0x33 );
				e->movdqa_regreg ( RBX, 4 );
			}
			
			if ( i.xyzw & 0xa )
			{
				// convert to double (round2)
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RAX );
				e->psrlqregimm ( RDX, 32 );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );

				
				e->movdqa_regreg ( 5, RCX );
				e->movdqa_regreg ( 4, RCX );
				e->psrlqregimm ( 5, 32 );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );


				// debug
				//e->movdqa_memreg ( & v4, RAX );
				//e->movdqa_memreg ( & v5, RCX );
				
				if ( bSub )
				{
					// subtract (round2)
					e->subpdregreg ( RDX, 5 );
				}
				else
				{
					// add (round2)
					e->addpdregreg ( RDX, 5 );
				}
				
				// merge result (round2) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->psllqregimm ( RDX, 3 );
				//e->psrlqregimm ( RDX, 1 );
				e->pblendwregregimm ( RAX, RDX, 0xcc );
				e->pblendwregregimm ( RBX, 4, 0xcc );
			}
		}
		
		// pull overflow flags
		e->movmskpsregreg ( RAX, RAX );
		
		// if overflow, then maximize result
		e->movdqa_regreg ( RCX, RAX );
		e->psradregimm ( RCX, 31 );
		//e->psrldregimm ( RCX, 1 );
		e->porregreg ( RAX, RCX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );

		// debug
		//e->movdqa_memreg ( & v1, RCX );

		// test for zero (also zero flag on underflow)
		e->pxorregreg ( RCX, RCX );
		e->pcmpeqdregreg ( RCX, RAX );

		// test for underflow
		e->movddup_regmem ( RDX, (long long*) &c_lUFTest );
		e->pcmpgtdregreg ( RDX, RAX );
		
		// if underflow, then clear result (but keep sign ??)
		e->movdqa_regreg ( 4, RDX );
		e->pandnregreg ( 4, RAX );
		
		
		// combine result with sign now
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 1 );
		e->porregreg ( 4, RBX );

		// not underflow if it is zero
		// puts underflow in RAX
		e->movdqa_regreg ( RAX, RCX );
		e->pandnregreg( RAX, RDX );
		
		
		
		// clear sign flag if signed zero ?? unless underflow ??
		// but test for underflow before testing for zero
		// so and not zero, then and underflow
		e->movdqa_regreg ( RDX, RCX );
		e->pandnregreg ( RDX, RBX );
		//e->pandregreg ( RDX, RAX );
		
		// pull sign flags
		// RDX = sign flag
		e->movmskpsregreg ( RCX, RDX );
		
		// zero flag is also set when underflow
		// RAX = underflow flag, RCX = zero flag
		e->porregreg ( RCX, RAX );
		
		// pull zero flags
		e->movmskpsregreg ( RDX, RCX );
		
		// pull underflow flags
		// RAX = underflow flag
		e->movmskpsregreg ( 8, RAX );
		
		// set result
		if ( i.xyzw != 0xf )
		{
			if ( pFd )
			{
				e->movdqa_regmem ( 5, pFd );
			}
			else
			{
				e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
			}
		}
		
		e->pshufdregregimm ( 4, 4, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		
		if ( i.xyzw != 0xf )
		{
			e->pblendwregregimm ( 4, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		if ( pFd )
		{
			e->movdqa_memreg ( (long*) pFd, 4 );
		}
		else
		{
			if ( i.Fd )
			{
				e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, 4 );
			}
		}
		
		// clear flags for vu units that do not operate
		if ( i.xyzw != 0xf )
		{
			e->AndReg32ImmX ( RAX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RCX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RDX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( 8, ( i.Value >> 21 ) & 0xf );
		}

		// combine MAC flags
		e->ShlRegImm32 ( RCX, 4 );
		e->ShlRegImm32 ( 8, 8 );
		e->ShlRegImm32 ( RAX, 12 );
		
		e->OrRegReg32 ( RDX, RAX );
		e->OrRegReg32 ( RDX, RCX );
		e->OrRegReg32 ( RDX, 8 );

		// set MAC flags (RAX)
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, RDX );

		
		// set status flags
		// RAX=overflow, RCX=sign, RDX=zero, 8=underflow
		
		// restore RDX
		e->AndReg32ImmX ( RDX, 0xf );
		
		// set overflow status flag
		e->NegReg32 ( RAX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set underflow status flag
		e->NegReg32 ( 8 );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set sign status flag
		e->NegReg32 ( RCX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set zero status flag
		e->NegReg32 ( RDX );
		e->AdcRegReg32 ( RAX, RAX );
		
		e->MovRegMem32 ( RDX, &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s );
		e->AndReg32ImmX ( RAX, 0xf );
		e->MovRegReg32 ( RCX, RAX );
		e->ShlRegImm32 ( RAX, 6 );
		e->OrRegReg32 ( RAX, RCX );
		e->AndReg32ImmX ( RDX, ~0xf );
		e->OrRegReg32 ( RAX, RDX );
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
		
	}
	
	
	return ret;
}



//long R5900::Recompiler::Generate_VMULp ( R5900::Instruction::Format i, u32 FtComponent, void *pFd, u32 *pFt )
long R5900::Recompiler::Generate_VMULp ( R5900::Instruction::Format i, u32 FtComponentp, void *pFd, u32 *pFt, u32 FsComponentp )
{
	static const unsigned long long c_llMinExpDbl = ( 896LL << 52 );
	static const unsigned long long c_llExpMask = ( 0xffLL << 23 ) | ( 0xffLL << ( 23 + 32 ) );
	static const u64 c_lUFTest = ( 0x800000LL << 32 ) | ( 0x800000LL );
	
	long ret;
	
	ret = 1;


	if ( i.xyzw )
	{
		// load source regs
		// but they need to be shuffled into reverse on load
		e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( pFt )
		{
			e->movd_regmem ( RCX, (long*) pFt );
		}
		else
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		
		//e->pshufdregmemimm ( RAX, & va, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		//e->pshufdregmemimm ( RCX, & vb, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		e->pshufdregregimm ( RAX, RAX, FsComponentp );
		
		e->pshufdregregimm ( RCX, RCX, FtComponentp );

#ifdef OPTIMIZE_RO_MULTIPLY_MUL
		// if fs or ft is r0 then the computation is easier/quicker
		if ( !pFt && ( ( ! i.Fs ) || ( ! i.Ft ) ) )
		{
			// if fs is not the r0 register then it has the value we want in RAX
			// and the r0 value is in RCX
			if ( i.Fs )
			{
				//e->movdqa_regreg ( RBX, RCX );
				e->movdqa_regreg ( RDX, RCX );
				e->movdqa_regreg ( 4, RAX );
			}
			else
			{
				// otherwise RAX/Fs has the r0 value
				//e->movdqa_regreg ( RBX, RAX );
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RCX );
			}
			
			
			// check which values are zero/non-zero in r0
			e->pxorregreg ( RBX, RBX );
			e->pcmpeqdregreg ( RDX, RBX );
			
			// check if the operand has any zeros and flush
			//e->movdqa_regreg ( 4, RCX );
			e->pslldregimm ( 4, 1 );
			e->psrldregimm ( 4, 24 );
			e->pcmpeqdregreg ( RBX, 4 );
			
			// combine zero flags
			e->porregreg ( RDX, RBX );
			
			
			// get zero flags
			e->movmskpsregreg ( RDX, RDX );
			
			// get multiply result
			e->psrldregimm ( RDX, 1 );
			if ( i.Fs )
			{
				// multiply r0 with fs/rax
				e->pandnregreg ( RDX, RAX );
			}
			else
			{
				// multiply r0 with ft/rcx
				e->pandnregreg ( RDX, RCX );
			}
			
			// get sign flags
			e->movmskpsregreg ( RCX, RDX );
			
			// set result
			if ( i.xyzw != 0xf )
			{
				if ( pFd )
				{
					e->movdqa_regmem ( 5, pFd );
				}
				else
				{
					e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
				}
			}
			
			e->pshufdregregimm ( RDX, RDX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
			
			if ( i.xyzw != 0xf )
			{
				e->pblendwregregimm ( RDX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			if ( pFd )
			{
				e->movdqa_memreg ( (long*) pFd, RDX );
			}
			else
			{
				if ( i.Fd )
				{
					e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, RDX );
				}
			}
			
			// clear flags for vu units that do not operate
			if ( i.xyzw != 0xf )
			{
				e->AndReg32ImmX ( RCX, ( i.Value >> 21 ) & 0xf );
				e->AndReg32ImmX ( RDX, ( i.Value >> 21 ) & 0xf );
			}
			
#ifdef ENABLE_SET_SIGN_FLAG_ON_ZERO
			// clear sign flags where result is zero
			e->NotReg32 ( RDX );
			e->AndRegReg32 ( RCX, RDX );
			e->NotReg32 ( RDX );
#endif

			// combine MAC flags
			e->ShlRegImm32 ( RCX, 4 );
			
			//e->OrRegReg32 ( RDX, RCX );
			e->LeaRegRegReg32 ( RAX, RCX, RDX );
			
			// set MAC flags (RAX)
			//ret = e->MovMemReg32 ( &v->vi [ VU::REG_MACFLAG ].s, RDX );
			ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, RAX );
			
			
			// set status flags
			// RAX=overflow, RCX=sign, RDX=zero, 8=underflow
			
			// check if the lower instruction set stat flag already (there's only like one instruction that does this)
			//if ( !SetStatus_Flag )
			//{
				// restore RDX
				//e->AndReg32ImmX ( RDX, 0xf );
				e->XorRegReg32 ( RAX, RAX );
				
				// set sign status flag
				e->NegReg32 ( RCX );
				e->AdcRegReg32 ( RAX, RAX );
				
				// set zero status flag
				e->NegReg32 ( RDX );
				e->AdcRegReg32 ( RAX, RAX );
				
				e->MovRegMem32 ( RDX, &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s );
				//e->AndReg32ImmX ( RAX, 0x3 );
				e->MovRegReg32 ( RCX, RAX );
				e->ShlRegImm32 ( RAX, 6 );
				e->OrRegReg32 ( RAX, RCX );
				e->AndReg32ImmX ( RDX, ~0xf );
				e->OrRegReg32 ( RAX, RDX );
				ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
				
			//}
			
			return ret;
		}
#endif

#ifdef USE_NEW_VMUL_CODE

		// get the initial exponent
		//es = ( fs >> 23 ) & 0xff;
		e->movdqa_regreg( RDX, RAX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 24 );
		
		// check for zero
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, RDX );
		
		//et = ( ft >> 23 ) & 0xff;
		e->movdqa_regreg( 4, RCX );
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 24 );
		
		// check for zero
		// puts what should be zero in r5
		e->pxorregreg ( 5, 5 );
		e->pcmpeqdregreg ( 5, 4 );
		e->porregreg ( 5, RBX );
		
		//ed = es + et - 127;
		e->pcmpeqbregreg ( RBX, RBX );
		e->padddregreg ( 4, RDX );
		e->psrldregimm ( RBX, 25 );
		e->psubdregreg ( 4, RBX );
		
		
		// add hidden bit
		//ms |= 0x00800000;
		//mt |= 0x00800000;
		e->pslldregimm ( RBX, 31 );


		// get sign into RDX
		// sign is always a xor
		//fd = ( fs ^ ft ) & -0x80000000;
		e->movdqa_regreg ( RDX, RAX );
		e->pxorregreg ( RDX, RCX );
		e->pandregreg ( RDX, RBX );
		
		
		
		// get the mantissa and add the hidden bit
		//ms = fs & 0x007fffff;
		//mt = ft & 0x007fffff;
		e->pslldregimm ( RAX, 8 );
		e->pslldregimm ( RCX, 8 );
		e->porregreg ( RAX, RBX );
		e->porregreg ( RCX, RBX );
		
		
		//e->movdqa_memreg ( & v0, RAX );
		//e->movdqa_memreg ( & v1, RCX );
		
		//if ( __builtin_popcount ( i.xyzw ) < 3 )
		if ( popcnt32 ( i.xyzw ) < 3 )
		{
			e->pshufdregregimm ( RBX, RAX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
			e->pshufdregregimm ( RCX, RCX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
			e->pmuludqregreg ( RBX, RCX );
			e->pshufdregregimm ( RBX, RBX, _op_r5900_shuffle_lut_2 [ i.xyzw ] );
		}
		else
		{
			// do the multiply
			//md = ms * mt;
			if ( i.xyzw & 0x5 )
			{
				e->movdqa_regreg ( RBX, RAX );
				e->pmuludqregreg ( RBX, RCX );
				e->psrlqregimm ( RBX, 32 );
			}
			
			if ( i.xyzw & 0xa )
			{
				e->psrlqregimm ( RAX, 32 );
				e->psrlqregimm ( RCX, 32 );
				e->pmuludqregreg ( RAX, RCX );
				e->pblendwregregimm ( RBX, RAX, 0xcc );
			}
		}

		//e->movdqa_memreg ( & v2, RAX );
		//e->movdqa_memreg ( & v3, RBX );

		
		// first shift right by the 23
		// shift and combine
		
		// get bit 47
		//ext = md >> 47;
		e->movdqa_regreg ( RAX, RBX );
		e->psradregimm ( RAX, 31 );
		
		// get the result
		//md >>= ( 23 + ext );
		e->movdqa_regreg ( RCX, RBX );
		e->psrldregimm ( RCX, 1 );
		e->pblendvbregreg ( RBX, RCX );
		
		
		//e->movdqa_memreg ( & v4, RAX );
		//e->movdqa_memreg ( & v5, RBX );
		
		// remove the hidden bit
		//md &= 0x7fffff;
		e->pslldregimm ( RBX, 2 );
		e->psrldregimm ( RBX, 9 );
		
		// update exponent
		//ed += ext;
		e->psubdregreg ( 4, RAX );
		
		// check if result is zero
		e->pxorregreg ( RAX, RAX );
		e->pcmpeqdregreg ( RAX, 4 );
		e->porregreg ( 5, RAX );
		
		// only under flow if not zero!
		e->movdqa_regreg ( RAX, 5 );
		e->pandnregreg ( RAX, 4 );
		
		// get exponent underflow into RCX
		e->movmskpsregreg ( 8, RAX );
		
		// set to zero for under flow
		//e->movdqa_regreg ( RAX, 4 );
		e->psradregimm ( RAX, 31 );
		e->porregreg ( 5, RAX );
		
		// get exponent overflow into R8 (*note* remove the underflow from the bits, can only have one or the other)
		e->pslldregimm ( 4, 23 );
		
		// only if not under flow
		e->movdqa_regreg ( RAX, 5 );
		e->pandnregreg ( RAX, 4 );
		
		// pull overflow flags
		e->movmskpsregreg ( RAX, RAX );
		
		
		// check if ( es == 0 ) || ( et == 0 ) || ( ed <= 0 )
		// puts zero exponent mask in RDX
		// puts exponent underflow in RBX
		
		// add in the exponent
		e->porregreg ( RBX, 4 );
		
		// maximize on overflow
		e->psradregimm ( RAX, 31 );
		e->porregreg ( RBX, RAX );
		
		// clear sign
		e->pslldregimm ( RBX, 1 );
		e->psrldregimm ( RBX, 1 );
		
		// get the sign flags into RAX
		e->movmskpsregreg ( RCX, RDX );
		
		// get exponent zero flags into RDX
		e->movmskpsregreg ( RDX, 5 );
		
		// clear the zero results
		e->pandnregreg ( 5, RBX );
		
		// add in the sign (sign is in RDX)
		e->porregreg ( RDX, 5 );

#else

		// get signs into RBX
		e->movdqa_regreg ( RBX, RAX );
		e->pxorregreg ( RBX, RCX );
		
		// clear signs
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->pslldregimm ( RCX, 1 );
		e->psrldregimm ( RCX, 1 );
		
		// clear zero exponents
		e->pcmpeqbregreg ( RDX, RDX );
		e->psrldregimm ( RDX, 9 );
		e->movdqa_regreg ( 5, RAX );
		e->pcmpgtdregreg ( 5, RDX );
		e->pandregreg ( RAX, 5 );
		e->pandregreg ( RCX, 5 );
		e->movdqa_regreg ( 4, RCX );
		e->pcmpgtdregreg ( 4, RDX );
		e->pandregreg ( RAX, 4 );
		e->pandregreg ( RCX, 4 );
		
		// get the non-zero results with logical and
		e->pandregreg ( 4, 5 );
		
		// load constant into R5
		e->movddup_regmem ( 5, & c_llMinExpDbl );
		
		// stuff into RBX with the signs for now
		//e->psrldregimm ( 4, 1 );
		//e->porregreg ( RBX, 4 );
		
		// get the non-zero flags
		e->movmskpsregreg ( 8, 4 );

		

		
		if ( i.xyzw & 0x5 )
		{
			// convert to double (round1)
			e->movdqa_regreg ( RDX, RAX );
			//e->movdqa_regreg ( 4, RAX );
			e->psllqregimm ( RDX, 33 );
			e->psrlqregimm ( RDX, 1 + 11 - 8 );
			//e->psrldregimm ( 4, 31 );
			//e->psllqregimm ( 4, 63 );
			//e->porregreg ( RDX, 4 );
			
			
			e->movdqa_regreg ( 4, RCX );
			//e->movdqa_regreg ( 5, RCX );
			e->psllqregimm ( 4, 33 );
			e->psrlqregimm ( 4, 1 + 11 - 8 );
			//e->psrldregimm ( 5, 31 );
			//e->psllqregimm ( 5, 63 );
			//e->porregreg ( 4, 5 );




			// add to one arg
			e->paddqregreg ( RDX, 5 );


			
			// multiply (round1)
			e->mulpdregreg ( RDX, 4 );

			

			
			// merge result (round1) without sign into RAX, and sign into RCX
			//e->movdqa_regreg ( 4, RDX );
			//e->psrlqregimm ( 4, 63 );
			//e->pslldregimm ( 4, 31 );
			e->psrlqregimm ( RDX, 29 );
			e->pblendwregregimm ( RAX, RDX, 0x33 );
			//e->movdqa_regreg ( RBX, 4 );
		}
		
		if ( i.xyzw & 0xa )
		{
			// convert to double (round2)
			e->movdqa_regreg ( RDX, RAX );
			//e->movdqa_regreg ( 4, RAX );
			e->psrlqregimm ( RDX, 32 );
			//e->psllqregimm ( RDX, 33 );
			//e->psrlqregimm ( RDX, 1 + 11 - 8 );
			e->psllqregimm ( RDX, 29 );
			//e->psrlqregimm ( 4, 63 );
			//e->psllqregimm ( 4, 63 );
			//e->porregreg ( RDX, 4 );

			
			e->movdqa_regreg ( 4, RCX );
			//e->movdqa_regreg ( 5, RCX );
			e->psrlqregimm ( 4, 32 );
			//e->psllqregimm ( 4, 33 );
			//e->psrlqregimm ( 4, 1 + 11 - 8 );
			e->psllqregimm ( 4, 29 );
			//e->psrlqregimm ( 5, 63 );
			//e->psllqregimm ( 5, 63 );
			//e->porregreg ( 4, 5 );

			
			// debug
			//e->movdqa_memreg ( & v4, RAX );
			//e->movdqa_memreg ( & v5, RCX );
			
			// add to one arg
			e->paddqregreg ( RDX, 5 );
			
			// multiply (round2)
			e->mulpdregreg ( RDX, 4 );

			

			
			// merge result (round2) without sign into RAX, and sign into RCX
			//e->movdqa_regreg ( 4, RDX );
			//e->psrlqregimm ( 4, 63 );
			//e->psllqregimm ( 4, 63 );
			e->psllqregimm ( RDX, 3 );
			//e->psrlqregimm ( RDX, 1 );
			e->pblendwregregimm ( RAX, RDX, 0xcc );
			//e->pblendwregregimm ( RBX, 4, 0xcc );
		}
		
		// debug
		//e->movdqa_memreg ( & v0, RDX );
		
		// debug
		//e->movdqa_memreg ( & v1, 4 );

		
		// pull overflow flags
		e->movmskpsregreg ( RAX, RAX );
		
		// if overflow, then maximize result
		e->movdqa_regreg ( RCX, RAX );
		e->psradregimm ( RCX, 31 );
		//e->psrldregimm ( RCX, 1 );
		e->porregreg ( RAX, RCX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );

		// debug
		//e->movdqa_memreg ( & v1, RCX );

		// test for zero (also zero flag on underflow)
		//e->pxorregreg ( RCX, RCX );
		//e->pcmpeqdregreg ( RCX, RAX );

		// test for zero
		// puts zero flag in RDX
		e->movddup_regmem ( RDX, &c_lUFTest );
		e->pcmpgtdregreg ( RDX, RAX );
		
		// pull zero flags
		e->movmskpsregreg ( RDX, RDX );

		
		// pull sign flags
		e->movmskpsregreg ( RCX, RBX );
		
		
		// pull non-zero op flags
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( 4, 31 );
		//e->movmskpsregreg ( 8, 4 );
		
		
		// and non-zero op flags with zero flags
		e->AndRegReg32 ( 8, RDX );
		
		// clear sign flags where result is zero but not overflow
		e->MovRegReg32 ( 9, 8 );
		e->NotReg32 ( 9 );
		e->AndRegReg32 ( 9, RDX );
		e->NotReg32 ( 9 );
		e->AndRegReg32 ( RCX, 9 );
		
		// check zero flag against non-zero ops
		// zero flag is now in RDX
		// puts underflow flag in R4
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( 4, 31 );
		//e->pandregreg ( 4, RDX );
		
		// if zero/underflow, then clear result (but keep sign ??)
		// puts result in RDX
		//e->movdqa_regreg ( 4, RDX );
		e->pandnregreg ( RDX, RAX );
		
		
		// combine result with sign now
		//e->pslldregimm ( RDX, 1 );
		//e->psrldregimm ( RDX, 1 );
		e->psrldregimm ( RBX, 31 );
		e->pslldregimm ( RBX, 31 );
		e->porregreg ( RDX, RBX );

#endif
		
		// set result
		if ( i.xyzw != 0xf )
		{
			if ( pFd )
			{
				e->movdqa_regmem ( 5, pFd );
			}
			else
			{
				e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
			}
		}
		
		e->pshufdregregimm ( RDX, RDX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		
		if ( i.xyzw != 0xf )
		{
			e->pblendwregregimm ( RDX, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		if ( pFd )
		{
			e->movdqa_memreg ( (long*) pFd, RDX );
		}
		else
		{
			if ( i.Fd )
			{
				e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, RDX );
			}
		}

		
		// clear flags for vu units that do not operate
		if ( i.xyzw != 0xf )
		{
			e->AndReg32ImmX ( RAX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RCX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RDX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( 8, ( i.Value >> 21 ) & 0xf );
		}

		// combine MAC flags
		e->ShlRegImm32 ( RCX, 4 );
		e->ShlRegImm32 ( 8, 8 );
		e->ShlRegImm32 ( RAX, 12 );
		
		e->OrRegReg32 ( RDX, RAX );
		e->OrRegReg32 ( RDX, RCX );
		e->OrRegReg32 ( RDX, 8 );

		// set MAC flags (RAX)
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, RDX );
		
		// set status flags
		// RAX=overflow, RCX=sign, RDX=zero, 8=underflow
		
		// restore RDX
		e->AndReg32ImmX ( RDX, 0xf );
		
		// set overflow status flag
		e->NegReg32 ( RAX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set underflow status flag
		e->NegReg32 ( 8 );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set sign status flag
		e->NegReg32 ( RCX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set zero status flag
		e->NegReg32 ( RDX );
		e->AdcRegReg32 ( RAX, RAX );
		
		e->MovRegMem32 ( RDX, &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s );
		e->AndReg32ImmX ( RAX, 0xf );
		e->MovRegReg32 ( RCX, RAX );
		e->ShlRegImm32 ( RAX, 6 );
		e->OrRegReg32 ( RAX, RCX );
		e->AndReg32ImmX ( RDX, ~0xf );
		e->OrRegReg32 ( RAX, RDX );
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
		
	}
	
	return ret;
}



long R5900::Recompiler::Generate_VMADDp ( u32 bSub, R5900::Instruction::Format i, u32 FtComponentp, void *pFd, u32 *pFt, u32 FsComponentp )
{
	static const unsigned long long c_llMinExpDbl = ( 896LL << 52 );
	static const unsigned long long c_llExpMask = ( 0xffLL << 23 ) | ( 0xffLL << ( 23 + 32 ) );
	static const u64 c_lUFTest = ( 0x800000LL << 32 ) | ( 0x800000LL );
	
	static const u64 c_lUpperBound = ( 24LL << 32 ) | ( 24LL );
	static const u64 c_lLowerBound = ( 0xffffffe8LL << 32 ) | ( 0xffffffe8LL );
	
	long ret;
	
	ret = 1;


	if ( i.xyzw )
	{
		// load source regs
		// but they need to be shuffled into reverse on load
		e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );
		
		if ( pFt )
		{
			e->movd_regmem ( RCX, (long*) pFt );
		}
		else
		{
			e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
		}
		
		//e->pshufdregmemimm ( RAX, & va, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		//e->pshufdregmemimm ( RCX, & vb, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 0 << 0 ) );
		e->pshufdregregimm ( RAX, RAX, FsComponentp );
		
		e->pshufdregregimm ( RCX, RCX, FtComponentp );
		
#ifdef OPTIMIZE_RO_MULTIPLY_MADD
		// if fs or ft is r0 then the computation is easier/quicker
		if ( !pFt && ( ( ! i.Fs ) || ( ! i.Ft ) ) )
		{
			// if fs is not the r0 register then it has the value we want in RAX
			// and the r0 value is in RCX
			if ( i.Fs )
			{
				//e->movdqa_regreg ( RBX, RCX );
				e->movdqa_regreg ( RDX, RCX );
				e->movdqa_regreg ( 4, RAX );
			}
			else
			{
				// otherwise RAX/Fs has the r0 value
				//e->movdqa_regreg ( RBX, RAX );
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RCX );
			}
			
			
			// check which values are zero/non-zero in r0
			e->pxorregreg ( RBX, RBX );
			e->pcmpeqdregreg ( RDX, RBX );
			
			// check if the operand has any zeros and flush
			//e->movdqa_regreg ( 4, RCX );
			e->pslldregimm ( 4, 1 );
			e->psrldregimm ( 4, 24 );
			e->pcmpeqdregreg ( RBX, 4 );
			
			// combine zero flags
			e->porregreg ( RDX, RBX );
			
			
			// get zero flags
			//e->movmskpsregreg ( RDX, RDX );
			
			// get multiply result
			e->psrldregimm ( RDX, 1 );
			if ( i.Fs )
			{
				// multiply r0 with fs/rax
				e->pandnregreg ( RDX, RAX );
			}
			else
			{
				// multiply r0 with ft/rcx
				e->pandnregreg ( RDX, RCX );
			}
			
			// get sign flags
			//e->movmskpsregreg ( RCX, RDX );
			
			
			// this line has a multi-purpose
			e->pcmpeqbregreg ( 4, 4 );
			
			// if MSUB and not MADD, then toggle sign
			if ( bSub )
			{
				e->pcmpeqbregreg ( RBX, RBX );
				e->pslldregimm ( RBX, 31 );
				e->pxorregreg ( RDX, RBX );
			}
			
			
			// combine result with sign now
			//e->psrldregimm ( RBX, 31 );
			//e->pslldregimm ( RBX, 31 );
			//e->porregreg ( RDX, RBX );

			
			// get multiply underflow sticky status flag
			e->XorRegReg32 ( 11, 11 );
			
			// no overflow
			e->pxorregreg ( RAX, RAX );

		}
		else
#endif
		{

#ifdef USE_NEW_VMADD_CODE

		// get the initial exponent
		//es = ( fs >> 23 ) & 0xff;
		e->movdqa_regreg( RDX, RAX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 24 );
		
		// check for zero
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, RDX );
		
		//et = ( ft >> 23 ) & 0xff;
		e->movdqa_regreg( 4, RCX );
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 24 );
		
		// check for zero
		// puts what should be zero in r5
		e->pxorregreg ( 5, 5 );
		e->pcmpeqdregreg ( 5, 4 );
		e->porregreg ( 5, RBX );
		
		//ed = es + et - 127;
		e->pcmpeqbregreg ( RBX, RBX );
		e->padddregreg ( 4, RDX );
		e->psrldregimm ( RBX, 25 );
		e->psubdregreg ( 4, RBX );
		
		
		// add hidden bit
		//ms |= 0x00800000;
		//mt |= 0x00800000;
		e->pslldregimm ( RBX, 31 );


		// get sign into RDX
		// sign is always a xor
		//fd = ( fs ^ ft ) & -0x80000000;
		e->movdqa_regreg ( RDX, RAX );
		e->pxorregreg ( RDX, RCX );
		
		// if doing MSUB, then also need to toggle the sign
		if ( bSub )
		{
			e->pxorregreg ( RDX, RBX );
		}
		
		e->pandregreg ( RDX, RBX );
		
		
		
		// get the mantissa and add the hidden bit
		//ms = fs & 0x007fffff;
		//mt = ft & 0x007fffff;
		e->pslldregimm ( RAX, 8 );
		e->pslldregimm ( RCX, 8 );
		e->porregreg ( RAX, RBX );
		e->porregreg ( RCX, RBX );
		
		
		//e->movdqa_memreg ( & v0, RAX );
		//e->movdqa_memreg ( & v1, RCX );
		
		//if ( __builtin_popcount ( i.xyzw ) < 3 )
		if ( popcnt32 ( i.xyzw ) < 3 )
		{
			e->pshufdregregimm ( RBX, RAX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
			e->pshufdregregimm ( RCX, RCX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
			e->pmuludqregreg ( RBX, RCX );
			e->pshufdregregimm ( RBX, RBX, _op_r5900_shuffle_lut_2 [ i.xyzw ] );
		}
		else
		{
			// do the multiply
			//md = ms * mt;
			if ( i.xyzw & 0x5 )
			{
				e->movdqa_regreg ( RBX, RAX );
				e->pmuludqregreg ( RBX, RCX );
				e->psrlqregimm ( RBX, 32 );
			}
			
			if ( i.xyzw & 0xa )
			{
				e->psrlqregimm ( RAX, 32 );
				e->psrlqregimm ( RCX, 32 );
				e->pmuludqregreg ( RAX, RCX );
				e->pblendwregregimm ( RBX, RAX, 0xcc );
			}
		}

		//e->movdqa_memreg ( & v2, RAX );
		//e->movdqa_memreg ( & v3, RBX );

		
		// first shift right by the 23
		// shift and combine
		
		// get bit 47
		//ext = md >> 47;
		e->movdqa_regreg ( RAX, RBX );
		e->psradregimm ( RAX, 31 );
		
		// get the result
		//md >>= ( 23 + ext );
		e->movdqa_regreg ( RCX, RBX );
		e->psrldregimm ( RCX, 1 );
		e->pblendvbregreg ( RBX, RCX );
		
		
		//e->movdqa_memreg ( & v4, RAX );
		//e->movdqa_memreg ( & v5, RBX );
		
		// remove the hidden bit
		//md &= 0x7fffff;
		e->pslldregimm ( RBX, 2 );
		e->psrldregimm ( RBX, 9 );
		
		// update exponent
		//ed += ext;
		e->psubdregreg ( 4, RAX );
		
		// check if result is zero
		e->pxorregreg ( RAX, RAX );
		e->pcmpeqdregreg ( RAX, 4 );
		e->porregreg ( 5, RAX );
		
		// only under flow if not zero!
		e->movdqa_regreg ( RAX, 5 );
		e->pandnregreg ( RAX, 4 );
		
		// get exponent underflow into RCX
		e->movmskpsregreg ( 11, RAX );
		
		// set to zero for under flow
		//e->movdqa_regreg ( RAX, 4 );
		e->psradregimm ( RAX, 31 );
		e->porregreg ( 5, RAX );
		
		// get exponent overflow into R8 (*note* remove the underflow from the bits, can only have one or the other)
		e->pslldregimm ( 4, 23 );
		
		// only if not under flow
		e->movdqa_regreg ( RAX, 5 );
		e->pandnregreg ( RAX, 4 );
		
		// pull overflow flags
		//e->movmskpsregreg ( RAX, RAX );
		
		
		// check if ( es == 0 ) || ( et == 0 ) || ( ed <= 0 )
		// puts zero exponent mask in RDX
		// puts exponent underflow in RBX
		
		// add in the exponent
		e->porregreg ( RBX, 4 );
		
		// maximize on overflow
		e->psradregimm ( RAX, 31 );
		e->porregreg ( RBX, RAX );
		
		// clear sign
		e->pslldregimm ( RBX, 1 );
		e->psrldregimm ( RBX, 1 );
		
		// get the sign flags into RAX
		//e->movmskpsregreg ( RCX, RDX );
		
		// get exponent zero flags into RDX
		//e->movmskpsregreg ( RDX, 5 );
		
		// clear the zero results
		e->pandnregreg ( 5, RBX );
		
		// add in the sign (sign is in RDX)
		e->porregreg ( RDX, 5 );
		

		// this line has a multi-purpose (MADD only)
		e->pcmpeqbregreg ( 4, 4 );
#else

		// get signs into RBX
		e->movdqa_regreg ( RBX, RAX );
		e->pxorregreg ( RBX, RCX );
		
		// clear signs
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );
		e->pslldregimm ( RCX, 1 );
		e->psrldregimm ( RCX, 1 );
		
		// clear zero exponents
		e->pcmpeqbregreg ( RDX, RDX );
		e->psrldregimm ( RDX, 9 );
		e->movdqa_regreg ( 5, RAX );
		e->pcmpgtdregreg ( 5, RDX );
		e->pandregreg ( RAX, 5 );
		e->pandregreg ( RCX, 5 );
		e->movdqa_regreg ( 4, RCX );
		e->pcmpgtdregreg ( 4, RDX );
		e->pandregreg ( RAX, 4 );
		e->pandregreg ( RCX, 4 );
		
		// get the non-zero results with logical and
		e->pandregreg ( 4, 5 );
		
		// load constant into R5
		e->movddup_regmem ( 5, & c_llMinExpDbl );
		
		// stuff into RBX with the signs for now
		//e->psrldregimm ( 4, 1 );
		//e->porregreg ( RBX, 4 );
		
		// get the non-zero flags
		e->movmskpsregreg ( 10, 4 );




		

		
		if ( i.xyzw & 0x5 )
		{
			// convert to double (round1)
			e->movdqa_regreg ( RDX, RAX );
			//e->movdqa_regreg ( 4, RAX );
			e->psllqregimm ( RDX, 33 );
			e->psrlqregimm ( RDX, 1 + 11 - 8 );
			//e->psrldregimm ( 4, 31 );
			//e->psllqregimm ( 4, 63 );
			//e->porregreg ( RDX, 4 );
			
			
			e->movdqa_regreg ( 4, RCX );
			//e->movdqa_regreg ( 5, RCX );
			e->psllqregimm ( 4, 33 );
			e->psrlqregimm ( 4, 1 + 11 - 8 );
			//e->psrldregimm ( 5, 31 );
			//e->psllqregimm ( 5, 63 );
			//e->porregreg ( 4, 5 );




			// add to one arg
			e->paddqregreg ( RDX, 5 );


			
			// multiply (round1)
			e->mulpdregreg ( RDX, 4 );

			

			
			// merge result (round1) without sign into RAX, and sign into RCX
			//e->movdqa_regreg ( 4, RDX );
			//e->psrlqregimm ( 4, 63 );
			//e->pslldregimm ( 4, 31 );
			e->psrlqregimm ( RDX, 29 );
			e->pblendwregregimm ( RAX, RDX, 0x33 );
			//e->movdqa_regreg ( RBX, 4 );
		}
		
		if ( i.xyzw & 0xa )
		{
			// convert to double (round2)
			e->movdqa_regreg ( RDX, RAX );
			//e->movdqa_regreg ( 4, RAX );
			e->psrlqregimm ( RDX, 32 );
			//e->psllqregimm ( RDX, 33 );
			//e->psrlqregimm ( RDX, 1 + 11 - 8 );
			e->psllqregimm ( RDX, 29 );
			//e->psrlqregimm ( 4, 63 );
			//e->psllqregimm ( 4, 63 );
			//e->porregreg ( RDX, 4 );

			
			e->movdqa_regreg ( 4, RCX );
			//e->movdqa_regreg ( 5, RCX );
			e->psrlqregimm ( 4, 32 );
			//e->psllqregimm ( 4, 33 );
			//e->psrlqregimm ( 4, 1 + 11 - 8 );
			e->psllqregimm ( 4, 29 );
			//e->psrlqregimm ( 5, 63 );
			//e->psllqregimm ( 5, 63 );
			//e->porregreg ( 4, 5 );

			
			// debug
			//e->movdqa_memreg ( & v4, RAX );
			//e->movdqa_memreg ( & v5, RCX );
			
			// add to one arg
			e->paddqregreg ( RDX, 5 );
			
			// multiply (round2)
			e->mulpdregreg ( RDX, 4 );

			

			
			// merge result (round2) without sign into RAX, and sign into RCX
			//e->movdqa_regreg ( 4, RDX );
			//e->psrlqregimm ( 4, 63 );
			//e->psllqregimm ( 4, 63 );
			e->psllqregimm ( RDX, 3 );
			//e->psrlqregimm ( RDX, 1 );
			e->pblendwregregimm ( RAX, RDX, 0xcc );
			//e->pblendwregregimm ( RBX, 4, 0xcc );
		}
		
		// debug
		//e->movdqa_memreg ( & v0, RDX );
		
		// debug
		//e->movdqa_memreg ( & v1, 4 );

		
		// pull overflow flags
		
		// if overflow, then maximize result
		// puts multiply overflow flag into RAX
		// puts result into after overflow check into RCX
		e->movdqa_regreg ( RCX, RAX );
		e->psradregimm ( RAX, 31 );
		
		// save overflow flags for multiply result
		//e->movdqa_memreg ( vOverflow, RCX );
		
		//e->psrldregimm ( RCX, 1 );
		e->porregreg ( RCX, RAX );
		e->pslldregimm ( RCX, 1 );
		e->psrldregimm ( RCX, 1 );

		// debug
		//e->movdqa_memreg ( & v1, RCX );

		// test for zero (also zero flag on underflow)
		//e->pxorregreg ( RCX, RCX );
		//e->pcmpeqdregreg ( RCX, RAX );

		// test for zero
		// puts zero flag in RDX
		e->movddup_regmem ( RDX, &c_lUFTest );
		e->pcmpgtdregreg ( RDX, RCX );


		// save zero flags into R11
		e->movmskpsregreg ( 11, RDX );
		
		
		// check zero flag against non-zero ops
		// zero flag is now in RDX
		// puts underflow flag in R4
		//e->movdqa_regreg ( 4, RBX );
		//e->pslldregimm ( 4, 31 );
		//e->pandregreg ( 4, RDX );
		
		// if zero/underflow, then clear result (but keep sign ??)
		// puts result in RDX
		//e->movdqa_regreg ( 4, RDX );
		e->pandnregreg ( RDX, RCX );
		
		
		// if result should be non-zero but is zero, then underflow
		// underflow = nonzero and zero
		// this puts underflow in RAX
		//e->pandregreg ( RCX, 4 );
		
		// save flags for multiply underflow into R11
		//e->movdqa_memreg ( & vUnderflow, RCX );
		//e->movmskpsregreg ( 11, RCX );
		
		// this line has a multi-purpose
		e->pcmpeqbregreg ( 4, 4 );
		
		// if MSUB and not MADD, then toggle sign
		if ( bSub )
		{
			e->pxorregreg ( RBX, 4 );
		}
		
		
		// combine result with sign now
		//e->pslldregimm ( RDX, 1 );
		//e->psrldregimm ( RDX, 1 );
		e->psrldregimm ( RBX, 31 );
		e->pslldregimm ( RBX, 31 );
		e->porregreg ( RDX, RBX );

		
		
		
		// get multiply underflow sticky status flag
		e->AndRegReg32 ( 11, 10 );
		
#endif
		
		}


		// -----------------------------ADD ---------------------------


		// load source regs
		// but they need to be shuffled into reverse on load
		//e->movdqa_regmem ( RAX, & va );
		//e->movdqa_regmem ( RAX, RDX );
		
		


		
		//e->movdqa_regmem ( RCX, & vb );
		e->movdqa_regmem ( RCX, &VU0::_VU0->dACC[ 0 ].l );
		
		//e->pshufdregregimm ( RAX, RAX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		e->pshufdregregimm ( RCX, RCX, ( 0 << 6 ) | ( 1 << 4 ) | ( 2 << 2 ) | ( 3 << 0 ) );
		
		// check for multiply overflow
		e->pblendvbregreg ( RCX, RDX );

		
		// debug
		//e->movdqa_memreg ( & v0, RAX );
		
		// debug
		//e->movdqa_memreg ( & v1, RCX );


		
		// check for accumulator +/-max
		
		// the multi-purpose line from above
		//e->pcmpeqbregreg ( 4, 4 );
		
		e->psrldregimm ( 4, 1 );
		e->movdqa_regreg ( RAX, 4 );
		e->pandregreg ( 4, RCX );
		e->pcmpeqdregreg ( RAX, 4 );
		e->pblendvbregreg ( RDX, RCX );
		
		
		
		
		// get exponents
		
		// no need to move into RDX in this case because it was here previously
		e->movdqa_regreg ( RAX, RDX );
		e->pslldregimm ( RDX, 1 );
		e->psrldregimm ( RDX, 24 );
		e->movdqa_regreg ( 4, RCX );
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 24 );

		


		// clear zero exponents ??
		/*
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, RDX );
		e->psrldregimm ( RBX, 1 );
		e->pandnregreg ( RBX, RAX );
		e->movdqa_regreg ( RAX, RBX );
		e->pxorregreg ( RBX, RBX );
		e->pcmpeqdregreg ( RBX, 4 );
		e->psrldregimm ( RBX, 1 );
		e->pandnregreg ( RBX, RCX );
		e->movdqa_regreg ( RCX, RBX );
		*/
		
		
		// get difference
		e->psubdregreg ( RDX, 4 );
		
		
		// if positive 24 or greater then zero Ft
		e->movddup_regmem ( 5, (long long*) &c_lUpperBound );
		e->pcmpgtdregreg ( 5, RDX );
		e->pandregreg ( RCX, 5 );


		// if negative 24 or less, then zero Fs
		e->movddup_regmem ( 5, (long long*) &c_lLowerBound );
		e->pcmpgtdregreg ( RDX, 5 );
		e->pandregreg ( RAX, RDX );

		//if ( ( __builtin_popcount ( i.xyzw ) < 3 ) )
		if ( ( popcnt32 ( i.xyzw ) < 3 ) )
		{
			e->pshufdregregimm ( RDX, RAX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );

				//e->movdqa_regreg ( RDX, RAX );
				//e->movdqa_regreg ( 4, RAX );
				e->movdqa_regreg ( 4, RDX );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );
				
			e->pshufdregregimm ( 5, RCX, _op_r5900_shuffle_lut_1 [ i.xyzw ] );
				
				//e->movdqa_regreg ( 5, RCX );
				//e->movdqa_regreg ( 4, RCX );
				e->movdqa_regreg ( 4, 5 );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );
				
				
				// add (round1)
				e->addpdregreg ( RDX, 5 );
				
				
				// merge result (round1) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->pslldregimm ( 4, 31 );
				
				e->psrlqregimm ( RDX, 29 );
				
				//e->pblendwregregimm ( RAX, RDX, 0x33 );
				//e->movdqa_regreg ( RBX, 4 );
			
			e->pshufdregregimm ( RAX, RDX, _op_r5900_add_shuffle_lut_2 [ i.xyzw ] );
			e->pshufdregregimm ( RBX, 4, _op_r5900_add_shuffle_lut_2 [ i.xyzw ] );
		}
		else
		{
			if ( i.xyzw & 0x5 )
			{
				// convert to double (round1)
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RAX );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );
				
				
				e->movdqa_regreg ( 5, RCX );
				e->movdqa_regreg ( 4, RCX );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrldregimm ( 4, 31 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );
				
				
				// add (round1)
				e->addpdregreg ( RDX, 5 );
				
				
				// merge result (round1) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->pslldregimm ( 4, 31 );
				//e->psllqregimm ( RDX, 4 );
				e->psrlqregimm ( RDX, 29 );
				e->pblendwregregimm ( RAX, RDX, 0x33 );
				e->movdqa_regreg ( RBX, 4 );
			}
			
			if ( i.xyzw & 0xa )
			{
				// convert to double (round2)
				e->movdqa_regreg ( RDX, RAX );
				e->movdqa_regreg ( 4, RAX );
				e->psrlqregimm ( RDX, 32 );
				e->psllqregimm ( RDX, 33 );
				e->psrlqregimm ( RDX, 1 + 11 - 8 );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( RDX, 4 );

				
				e->movdqa_regreg ( 5, RCX );
				e->movdqa_regreg ( 4, RCX );
				e->psrlqregimm ( 5, 32 );
				e->psllqregimm ( 5, 33 );
				e->psrlqregimm ( 5, 1 + 11 - 8 );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->porregreg ( 5, 4 );


				// debug
				//e->movdqa_memreg ( & v4, RAX );
				//e->movdqa_memreg ( & v5, RCX );
				
				
				// add (round2)
				e->addpdregreg ( RDX, 5 );

				
				// merge result (round2) without sign into RAX, and sign into RCX
				e->movdqa_regreg ( 4, RDX );
				e->psrlqregimm ( 4, 63 );
				e->psllqregimm ( 4, 63 );
				e->psllqregimm ( RDX, 3 );
				//e->psrlqregimm ( RDX, 1 );
				
				// want to merge into RDX in this case since pblendvb is coming up
				e->pblendwregregimm ( RAX, RDX, 0xcc );
				
				
				e->pblendwregregimm ( RBX, 4, 0xcc );
			}
		}
		
		
		// pull overflow flags
		e->movmskpsregreg ( RAX, RAX );
		
		// if overflow, then maximize result
		e->movdqa_regreg ( RCX, RAX );
		e->psradregimm ( RCX, 31 );
		//e->psrldregimm ( RCX, 1 );
		e->porregreg ( RAX, RCX );
		e->pslldregimm ( RAX, 1 );
		e->psrldregimm ( RAX, 1 );

		// debug
		//e->movdqa_memreg ( & v1, RCX );

		// test for zero (also zero flag on underflow)
		e->pxorregreg ( RCX, RCX );
		e->pcmpeqdregreg ( RCX, RAX );

		// test for underflow
		e->movddup_regmem ( RDX, (long long*) &c_lUFTest );
		e->pcmpgtdregreg ( RDX, RAX );
		
		// if underflow, then clear result (but keep sign ??)
		e->movdqa_regreg ( 4, RDX );
		e->pandnregreg ( 4, RAX );
		
		
		// combine result with sign now
		e->pslldregimm ( 4, 1 );
		e->psrldregimm ( 4, 1 );
		e->porregreg ( 4, RBX );

		// not underflow if it is zero
		// puts underflow in RAX
		e->movdqa_regreg ( RAX, RCX );
		e->pandnregreg( RAX, RDX );
		
		
		
		// clear sign flag if signed zero ?? unless underflow ??
		// but test for underflow before testing for zero
		// so and not zero, then and underflow
		e->movdqa_regreg ( RDX, RCX );
		e->pandnregreg ( RDX, RBX );
		//e->pandregreg ( RDX, RAX );
		
		// pull sign flags
		// RDX = sign flag
		e->movmskpsregreg ( RCX, RDX );
		
		// zero flag is also set when underflow
		// RAX = underflow flag, RCX = zero flag
		e->porregreg ( RCX, RAX );
		
		// pull zero flags
		e->movmskpsregreg ( RDX, RCX );
		
		// pull underflow flags
		// RAX = underflow flag
		e->movmskpsregreg ( 8, RAX );
		
		// set result
		if ( i.xyzw != 0xf )
		{
			if ( pFd )
			{
				e->movdqa_regmem ( 5, pFd );
			}
			else
			{
				e->movdqa_regmem ( 5, & VU0::_VU0->vf [ i.Fd ].sw0 );
			}
		}
		
		e->pshufdregregimm ( 4, 4, 0x1b );	//FdComponentp );
		
		if ( i.xyzw != 0xf )
		{
			e->pblendwregregimm ( 4, 5, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
		}
		
		if ( pFd )
		{
			e->movdqa_memreg ( (long*) pFd, 4 );
		}
		else
		{
			if ( i.Fd )
			{
				e->movdqa_memreg ( & VU0::_VU0->vf [ i.Fd ].sw0, 4 );
			}
		}

		
		// clear flags for vu units that do not operate
		if ( i.xyzw != 0xf )
		{
			e->AndReg32ImmX ( RAX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RCX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( RDX, ( i.Value >> 21 ) & 0xf );
			e->AndReg32ImmX ( 8, ( i.Value >> 21 ) & 0xf );
		
			// this is for madd/msub
			e->AndReg32ImmX ( 11, ( i.Value >> 21 ) & 0xf );
		}

		// combine MAC flags
		e->ShlRegImm32 ( RCX, 4 );
		e->ShlRegImm32 ( 8, 8 );
		e->ShlRegImm32 ( RAX, 12 );
		
		e->OrRegReg32 ( RDX, RAX );
		e->OrRegReg32 ( RDX, RCX );
		e->OrRegReg32 ( RDX, 8 );

		// set MAC flags (RAX)
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, RDX );
		
		// set status flags
		// RAX=overflow, RCX=sign, RDX=zero, 8=underflow
		
		// restore RDX
		e->AndReg32ImmX ( RDX, 0xf );
		
		// set overflow status flag
		e->NegReg32 ( RAX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set underflow status flag
		e->NegReg32 ( 8 );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set sign status flag
		e->NegReg32 ( RCX );
		e->AdcRegReg32 ( RAX, RAX );
		
		// set zero status flag
		e->NegReg32 ( RDX );
		e->AdcRegReg32 ( RAX, RAX );
		
		e->MovRegMem32 ( RDX, &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s );
		e->AndReg32ImmX ( RAX, 0xf );
		e->MovRegReg32 ( RCX, RAX );
		e->ShlRegImm32 ( RAX, 6 );
		e->OrRegReg32 ( RAX, RCX );
		
		// for madd/msub
		e->NegReg32 ( 11 );
		e->AdcRegReg32 ( RCX, RCX );
		e->AndReg32ImmX ( RCX, 1 );
		e->ShlRegImm32 ( RCX, 8 );
		e->OrRegReg32 ( RAX, RCX );
		
		e->AndReg32ImmX ( RDX, ~0xf );
		e->OrRegReg32 ( RAX, RDX );
		ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
		
	}
	
	return ret;
}




long R5900::Recompiler::Generate_VMAX ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFt )
{
	long ret;
	
	ret = 1;
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fd )
		{
			// can't write to register zero
			return 1;
		}
		else
		{
			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + Component );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + Component, RAX );
			
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->XorRegReg32 ( RAX, RAX );
				}
				else
				{
					e->MovRegImm32 ( RAX, 0x3f800000 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				if ( !i.Ft )
				{
					if ( FtComponent < 3 )
					{
						e->XorRegReg32 ( RAX, RAX );
					}
					else
					{
						e->MovRegImm32 ( RAX, 0x3f800000 );
					}
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovGRegReg32 ( 8, 9 );
			ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 8 );
		}
		
	}
	
	return ret;
}



long R5900::Recompiler::Generate_VMIN ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFt )
{
	long ret;
	
	ret = 1;
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fd )
		{
			// can't write to register zero
			return 1;
		}
		else
		{
			//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + Component );
			//e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + Component, RAX );
			
			//lfs = ( lfs >= 0 ) ? lfs : ~( lfs & 0x7fffffff );
			//lft = ( lft >= 0 ) ? lft : ~( lft & 0x7fffffff );
			// compare as integer and return original value?
			//fResult = ( ( lfs > lft ) ? fs : ft );
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->XorRegReg32 ( RAX, RAX );
				}
				else
				{
					e->MovRegImm32 ( RAX, 0x3f800000 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 9, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->MovRegReg32 ( RCX, RDX );
			
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				if ( !i.Ft )
				{
					if ( FtComponent < 3 )
					{
						e->XorRegReg32 ( RAX, RAX );
					}
					else
					{
						e->MovRegImm32 ( RAX, 0x3f800000 );
					}
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
			}
			
			e->Cdq ();
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->XorRegReg32 ( RDX, RAX );
			e->CmpRegReg32 ( RCX, RDX );
			e->CmovLRegReg32 ( 8, 9 );
			ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 8 );
		}
		
	}
	
	return ret;
}


long R5900::Recompiler::Generate_VFTOI0 ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					//e->XorRegReg32 ( RAX, RAX );
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					//e->MovRegImm32 ( RAX, 1 );
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 1 );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].sw0 );
				
				//e->MovRegReg32 ( RCX, RAX );
				//e->AndReg32ImmX ( RAX, 0x7f800000 );
				//e->CmovNERegReg32 ( RAX, RCX );
				
				// move the registers now to floating point unit
				e->movd_to_sse ( RAX, RAX );
				
				// convert single precision to signed 
				e->cvttss2si ( RCX, RAX );
				
				
				e->Cdq ();
				e->AndReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RDX, RAX );
				
				// compare exponent of magnitude and maximize if needed
				e->CmpReg32ImmX ( RAX, 0x4e800000 );
				e->MovReg32ImmX ( RAX, 0x7fffffff );
				e->CmovLERegReg32 ( RAX, RCX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



long R5900::Recompiler::Generate_VFTOIX ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent, u32 IX )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 1 << IX );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				//e->MovRegReg32 ( RCX, RAX );
				//e->AndReg32ImmX ( RAX, 0x7f800000 );
				//e->CmovNERegReg32 ( RAX, RCX );
				
				e->MovRegReg32 ( RCX, RAX );
				e->AddReg32ImmX ( RCX, IX << 23 );
				
				// move the registers now to floating point unit
				e->movd_to_sse ( RAX, RCX );
				
				// convert single precision to signed 
				e->cvttss2si ( RCX, RAX );
				
				
				e->Cdq ();
				e->AndReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RDX, RAX );
				//e->CmovERegReg32 ( RCX, RAX );
				
				// compare exponent of magnitude and maximize if needed
				e->CmpReg32ImmX ( RAX, 0x4e800000 - ( IX << 23 ) );
				e->MovReg32ImmX ( RAX, 0x7fffffff );
				e->CmovLERegReg32 ( RAX, RCX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



long R5900::Recompiler::Generate_VITOFX ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent, u64 FX )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x4e7e0000 );
				}
			}
			else
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// convert single precision to signed 
				e->cvtsi2sd ( RAX, RAX );
				e->movq_from_sse ( RAX, RAX );
				
				
				e->MovReg64ImmX ( RCX, ( 896ull << 23 ) + ( FX << 23 ) );
				e->Cqo();
				e->ShrRegImm64 ( RAX, 29 );
				e->CmovERegReg64 ( RCX, RDX );
				e->SubRegReg64 ( RAX, RCX );
				
				
				//e->CmovSRegReg32 ( RAX, RDX );
				e->ShlRegImm32 ( RDX, 31 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}



long R5900::Recompiler::Generate_VMOVE ( R5900::Instruction::Format i, u32 Address, u32 FtComponent, u32 FsComponent )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				}
			}
			else if ( i.Ft != i.Fs )
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


long R5900::Recompiler::Generate_VMR32_Load ( R5900::Instruction::Format i, u32 Address, u32 FsComponent )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FsComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				//if ( FsComponent < 3 )
				//{
				//	e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				//}
				//else
				//{
				//	e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				//}
			}
			else
			{
				switch ( FsComponent )
				{
					case 0:
						e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
				
					case 1:
						e->MovRegMem32 ( RCX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
					case 2:
						e->MovRegMem32 ( RDX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
					case 3:
						e->MovRegMem32 ( 8, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						break;
				}
				
				// set result
				//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


long R5900::Recompiler::Generate_VMR32_Store ( R5900::Instruction::Format i, u32 Address, u32 FtComponent )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.Fs )
			{
				if ( FtComponent != 2 )
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
				}
				else
				{
					e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0x3f800000 );
				}
			}
			else
			{
				switch ( FtComponent )
				{
					case 0:
						//e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
						break;
					case 1:
						//e->MovRegMem32 ( RCX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RCX );
						break;
					case 2:
						//e->MovRegMem32 ( RDX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RDX );
						break;
					case 3:
						//e->MovRegMem32 ( 8, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + ( ( FsComponent + 1 ) & 3 ) );
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 8 );
						break;
				}
				
				// set result
				//ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


long R5900::Recompiler::Generate_VMFIR ( R5900::Instruction::Format i, u32 Address, u32 FtComponent )
{
	long ret;
	
	ret = 1;

	if ( i.Value & ( 1 << ( ( FtComponent ^ 3 ) + 21 ) ) )
	{
		if ( i.Ft )
		{
			// flush ps2 float to zero
			if ( !i.is )
			{
				e->MovMemImm32 ( ( & VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, 0 );
			}
			else
			{
				// flush ps2 float to zero
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ i.is ].s ) );
				
				// sign-extend from 16-bit to 32-bit
				e->Cwde();
				
				// set result
				ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent, RAX );
			}
			
		}
	}

	return ret;
}


long R5900::Recompiler::Generate_VADD ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	long ret;
	
	ret = 1;


	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}


	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		// clear bits 14 and 15 in the flag register first
		//e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		if ( ( !i.Fs ) && ( FsComponent < 3 ) )
		{
			// Fs is zero register
			
			if ( ( !i.Ft ) && ( !pFt ) )
			{
				if ( FtComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (long*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) && ( FtComponent < 3 ) )
		{
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			
			// flush ps2 float to zero
			
			// pshufl+pshufh
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			//e->CmovNERegReg32 ( RAX, 10 );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();

			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			
			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// set MAC flag for underflow and zero in R10
			
			// zero MAC flag
			e->MovReg32ImmX ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			
			// if zero, then put in zero flag
			e->CmovERegReg32 ( 8, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			
			
			// if zero or underflow, then clear result
			
			// underflow status flag is 0x4 and sticky flag is 0x100 = 0x104
			//e->MovReg32ImmX ( RCX, 0x104 );
			
			// zero status flag is 0x1 and sticky flag is 0x40 = 0x41
			//e->MovReg32ImmX ( 8, 0x41 );
			
			// check for zero
			//e->OrRegReg32 ( RAX, RAX );
			
			// if zero, then not underflow
			//e->CmovERegReg32 ( RCX, RAX );
			//e->CmovERegReg32 ( 9, RAX );
			
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			//e->CmovAERegReg32 ( RCX, 11 );
			
			// if underflow, then set result to zero
			e->CmovBRegReg32 ( RAX, 11 );
			
			// if above or equal, then not underflow or zero
			//e->CmovAERegReg32 ( 8, 11 );
			e->CmovAERegReg32 ( 9, 11 );
			//e->CmovAERegReg32 ( 10, 11 );
			
			// combine underflow and zero MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			
			// check for overflow
			
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			
			// if unsigned above, then overflow
			e->CmovARegReg32 ( RAX, RCX );
			//e->CmovARegReg32 ( RCX, 9 );
			
			// set MAC flag for overflow (if overflow, then definitely not zero or underflow)
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// set MAC flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set sign
			//e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (long*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
		}
		
	}


	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}


	
	return ret;
}



long R5900::Recompiler::Generate_VSUB ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	long ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}


	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		// clear bits 14 and 15 in the flag register first
		//e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		if ( ( !i.Fs ) && ( FsComponent < 3 ) )
		{
			// Fs is zero register
			
			if ( ( !i.Ft ) && ( !pFt ) )
			{
				if ( FtComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					// set sign flag
					ret = e->OrReg32ImmX ( 10, 0x0010 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0xbf800000 );
					}
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (long*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->XorReg32ImmX ( RAX, 0x80000000 );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) && ( FtComponent < 3 ) )
		{
			if ( !i.Fs )
			{
				if ( FsComponent < 3 )
				{
					// set zero flag
					ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
					
					if ( i.Fd )
					{
						// set 0x00000000 as result
						ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 11 );
					}
				}
				else
				{
					if ( i.Fd )
					{
						// set 0x3f800000 as result
						ret = e->MovMemImm32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, 0x3f800000 );
					}
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );
			

			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			//e->CmovNERegReg32 ( RAX, 10 );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->subsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();

			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			
			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// set MAC flag for underflow and zero in R10
			
			// zero MAC flag
			e->MovReg32ImmX ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			
			// if zero, then put in zero flag
			e->CmovERegReg32 ( 8, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			
			
			// if zero or underflow, then clear result
			
			// underflow status flag is 0x4 and sticky flag is 0x100 = 0x104
			//e->MovReg32ImmX ( RCX, 0x104 );
			
			// zero status flag is 0x1 and sticky flag is 0x40 = 0x41
			//e->MovReg32ImmX ( 8, 0x41 );
			
			// check for zero
			//e->OrRegReg32 ( RAX, RAX );
			
			// if zero, then not underflow
			//e->CmovERegReg32 ( RCX, RAX );
			//e->CmovERegReg32 ( 9, RAX );
			
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			//e->CmovAERegReg32 ( RCX, 11 );
			
			// if underflow, then set result to zero
			e->CmovBRegReg32 ( RAX, 11 );
			
			// if above or equal, then not underflow or zero
			//e->CmovAERegReg32 ( 8, 11 );
			e->CmovAERegReg32 ( 9, 11 );
			//e->CmovAERegReg32 ( 10, 11 );
			
			// combine underflow and zero MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			
			// check for overflow
			
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			
			// if unsigned above, then overflow
			e->CmovARegReg32 ( RAX, RCX );
			//e->CmovARegReg32 ( RCX, 9 );
			
			// set MAC flag for overflow (if overflow, then definitely not zero or underflow)
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// set MAC flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set sign
			//e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );
			
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (long*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
		}
	}


	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}




long R5900::Recompiler::Generate_VMUL ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	long ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
		if ( !i.Fs )
		{
			// Fs is zero register
			
			if ( FsComponent < 3 )
			{
				// get Ft
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (long*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				// set zero flag
				ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
				
				// get sign of result
				e->AndReg32ImmX ( RAX, 0x80000000 );
					
				if ( i.Fd )
				{
					// set 0x00000000 as result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			else
			{
				if ( pFt )
				{
					e->MovRegMem32 ( RAX, (long*) pFt );
				}
				else
				{
					e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
				}
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->MovRegReg32 ( RDX, RAX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// preserve sign of zero ??
				e->AndReg32ImmX ( RDX, 0x80000000 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else if ( ( !i.Ft ) && ( !pFt ) )
		{
			// Ft is zero register
			
			if ( FtComponent < 3 )
			{
				// get Fs
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				// set zero flag
				ret = e->OrReg32ImmX ( 10, 0x0001 << ( FdComponent ^ 3 ) );
				
				// get sign of result
				e->AndReg32ImmX ( RAX, 0x80000000 );
					
				if ( i.Fd )
				{
					// set 0x00000000 as result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
				
				e->MovReg32ImmX ( RCX, 0x0010 << ( FdComponent ^ 3 ) );
				e->MovReg32ImmX ( RDX, 0x0001 << ( FdComponent ^ 3 ) );
				e->OrRegReg32 ( RAX, RAX );
				e->CmovNSRegReg32 ( RCX, 11 );
				
				e->TestReg32ImmX ( RAX, 0x7f800000 );
				e->CmovERegReg32 ( RCX, RDX );
				e->MovRegReg32 ( RDX, RAX );
				e->CmovERegReg32 ( RAX, 11 );
				
				// preserve sign of zero ??
				e->AndReg32ImmX ( RDX, 0x80000000 );
				e->OrRegReg32 ( RAX, RDX );
				
				// set MAC flag
				e->OrRegReg32 ( 10, RCX );
				
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
		else
		{
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			//e->XorRegReg32 ( 11, 11 );
			e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->AddRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->XorRegReg32 ( RDX, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->MovRegReg64 ( RCX, RAX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->LeaRegRegReg64 ( RAX, RAX, RCX );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll1, RAX );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// debug
			//e->MovMemReg64 ( &ll2, RAX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );

			// set sign MAC flag
			
			// put MAC flag in R8
			
			// sign flag
			e->MovReg32ImmX ( 8, 0x0010 << ( FdComponent ^ 3 ) );
			
			// clear sign flags if not sign
			e->CmovNSRegReg32 ( 8, 11 );
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );
			
			
			// also set zero flag if zero (which here, would also clear the sign flag ??)
			e->MovRegReg32 ( 9, 0x0001 << ( FdComponent ^ 3 ) );
			e->CmovERegReg32 ( 8, 9 );

			// save mantissa
			e->MovRegReg64 ( 9, RAX );
			e->AndReg32ImmX ( 9, 0x007fffff );
			
			
			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, 9 );
			
			// underflow+zero MAC flag
			e->MovReg32ImmX ( 9, 0x0101 << ( FdComponent ^ 3 ) );
			e->CmovGRegReg32 ( 9, 11 );
			
			// set result to zero on underflow
			e->CmovLERegReg32 ( RAX, 11 );
			//e->CmovGRegReg32 ( 9, 11 );
			//e->CmovLERegReg32 ( 10, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );
			
			
			// combine sign/zero/underflow MAC flags
			e->OrRegReg32 ( 8, 9 );
			
			// check for overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmpRegReg32 ( RAX, RCX );
			e->CmovARegReg32 ( RAX, RCX );
			e->LeaRegRegReg32 ( RAX, RAX, RDX );
			//e->MovReg32ImmX ( RDX, 0x208 );		//0x8010 );
			//e->CmovBERegReg32 ( RDX, 8 );


			// set overflow MAC flag
			e->MovReg32ImmX ( 9, 0x1000 << ( FdComponent ^ 3 ) );
			e->CmovBERegReg32 ( 9, 11 );
			
			// combine all MAC flags
			e->OrRegReg32 ( 8, 9 );


			// set MAC flags
			//ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 8 );
			e->OrRegReg32 ( 10, 8 );
			
			// set status flags
			//e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RDX );
			
			// set result
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (long*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
		}
	}
	
	
	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}




long R5900::Recompiler::Generate_VMADD ( R5900::Instruction::Format i, u32 Address, u32 FdComponent, u32 FsComponent, u32 FtComponent, u32 *pFd, u32 *pFt )
{
	long ret;
	
	ret = 1;
	
	// only clear non-sticky bits in status flag the first go around
	// also clear MAC flag (set to zero for components that are not calculated)
	if ( !FdComponent )
	{
		// clear bits 14 and 15 in the flag register first
		e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
		
		// clear MAC flags
		//ret = e->MovMemImm32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 0 );
		
		// R10 will be MAC flag
		e->XorRegReg32 ( 10, 10 );
		
		// R11 will be zero register
		e->XorRegReg32 ( 11, 11 );
	}
	
	// check if that component is set to output
	if ( i.Value & ( 1 << ( ( FdComponent ^ 3 ) + 21 ) ) )
	{
			// flush ps2 float to zero
			if ( pFt )
			{
				e->MovRegMem32 ( RAX, (long*) pFt );
			}
			else
			{
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Ft ].sw0 ) + FtComponent );
			}
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &r->CPR1 [ i.Ft ].s );
			//e->XorRegReg32 ( 11, 11 );
			e->MovRegReg32 ( 9, RAX );
			//e->Cdq ();
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RCX, RAX );

			
			e->MovRegMem32 ( RAX, ( &VU0::_VU0->vf [ i.Fs ].sw0 ) + FsComponent );
			e->XorRegReg32 ( 9, RAX );
			//e->Cdq ();
			//e->MovRegImm64 ( RAX, 896 << 23 );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->MovRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg64 ( RAX, RDX );
			//e->ShrRegImm32 ( 8, 31 );
			//e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, RDX );
			e->movq_to_sse ( RAX, RAX );
			
			
			// get sign
			e->AndReg32ImmX ( 9, 0x80000000 );
			
			// multiply
			e->mulsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			//e->ShlRegImm64 ( RAX, 1 );
			e->ShrRegImm64 ( RAX, 29 );
			e->CmovERegReg64 ( RCX, RAX );

			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RDX, 0x0008 );

			// save mantissa
			e->MovRegReg64 ( 10, RAX );
			e->AndReg32ImmX ( 10, 0x007fffff );

			
			e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->SubRegReg64 ( RAX, RCX );
			e->CmovLERegReg32 ( RAX, 11 );
			e->CmovLERegReg32 ( 10, 11 );
			e->CmovGERegReg32 ( RDX, 11 );
			//e->CmovBRegReg32 ( RAX, 11 );

			
			// get ACC
			e->MovRegMem32 ( 8, ( &VU0::_VU0->dACC[ 0 ].l ) + FdComponent );
			
			
			// running out of registers.. combine sign and mantissa
			e->OrRegReg32 ( 9, 10 );

			
			
			
			// if multiply underflow, then go ahead and set result to ACC here
			e->OrRegReg32 ( RDX, RDX );
			e->CmovNERegReg32 ( 9, 8 );
			e->CmovNERegReg32 ( RAX, 11 );
			
			
			
			
			// get multi-use constant for later
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			
			// test for ACC overflow
			e->MovRegReg32 ( 10, 8 );
			e->AndRegReg32 ( 10, RCX );
			e->CmpRegReg32 ( 10, RCX );
			
			
			// if ACC overflow, then set result to acc and set overflow
			//e->CmovERegReg32 ( RAX, RCX );
			e->CmovERegReg32 ( RAX, 8 );
			e->MovReg32ImmX ( 10, 0x8010 );
			e->CmovNERegReg32 ( 10, 11 );
			e->OrRegReg32 ( RDX, 10 );
			
			
			// test for multiply overflow
			//e->CmpRegReg32 ( RAX, RCX );
			e->OrRegReg32 ( RAX, RAX );
			
			// if multiply overflow, then set result to +/-max and set flags
			e->CmovSRegReg32 ( RAX, RCX );
			e->MovReg32ImmX ( RCX, 0x8010 );
			e->CmovNSRegReg32 ( RCX, 11 );
			
			
			// set sign/mantissa
			e->OrRegReg32 ( RAX, 9 );
			
			// or in the flag from the last overflow check
			e->OrRegReg32 ( RCX, RDX );
			
			
			// done
			e->Jmp_NE ( 0, 1 );
			//e->Jmp8_NE ( 0, 1 );
			
			
			
			
			// *** perform the ADD operation *** //
			
			
			// flush ps2 float to zero
			//e->MovRegMem32 ( RAX, &b );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovRegReg32 ( 9, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RCX, 29 );
			e->OrRegReg64 ( RCX, RDX );

			
			//e->MovRegMem32 ( RAX, &a );
			e->MovRegReg32 ( RAX, 8 );
			e->Cdq();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->MovRegReg32 ( 8, RAX );
			e->AndReg32ImmX ( 8, 0x7f800000 );
			//e->MovRegReg32 ( 8, RAX );
			e->CmovERegReg32 ( RAX, 8 );
			e->ShlRegImm64 ( RDX, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			e->OrRegReg64 ( RAX, RDX );
			
			// check if shift is more than 24, then zero
			//e->XorRegReg32 ( 11, 11 );
			e->SubRegReg32 ( 8, 9 );
			e->CmpRegImm32 ( 8, 24 << 23 );
			
			// if greater than +24, then R9 has higher magnitude, so zero RAX
			e->CmovGERegReg64 ( RCX, 11 );
			
			// if less than -24, then R11 has higher magnitude, so zero R8
			e->CmpReg32ImmX ( 8, -24 << 23 );
			e->CmovLERegReg64 ( RAX, 11 );
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			e->movq_to_sse ( RCX, RCX );
			
			
			// add
			e->addsd ( RAX, RCX );
			e->movq_from_sse ( RAX, RAX );
			
			// save sign
			e->Cqo();
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// if zero or underflow, then clear result
			e->MovReg32ImmX ( RCX, 0x4008 );
			e->OrRegReg32 ( RAX, RAX );
			e->CmovERegReg32 ( RCX, RAX );
			e->CmpReg32ImmX ( RAX, 0x00800000 );
			e->CmovAERegReg32 ( RCX, 11 );
			e->CmovBRegReg32 ( RAX, 11 );
			
			// check for overflow
			e->MovReg32ImmX ( 8, 0x7fffffff );
			e->MovReg32ImmX ( 9, 0x8010 );
			e->CmpRegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RAX, 8 );
			e->CmovARegReg32 ( RCX, 9 );
			
			// set sign
			e->ShlRegImm32 ( RDX, 31 );
			e->OrRegReg32 ( RAX, RDX );

			
			// finish here
			e->SetJmpTarget ( 1 );
			//e->SetJmpTarget8 ( 1 );

			
			// set flags
			e->OrMemReg32 ( &r->CPC1 [ 31 ], RCX );
			
			
			// set result
			//ret = e->MovMemReg32 ( &r->CPR1 [ i.Fd ].s, RAX );
			
			// set result
			if ( pFd )
			{
				ret = e->MovMemReg32 ( (long*) pFd, RAX );
			}
			else
			{
				// don't write to the zero register
				if ( i.Fd )
				{
					// set result
					ret = e->MovMemReg32 ( ( &VU0::_VU0->vf [ i.Fd ].sw0 ) + FdComponent, RAX );
				}
			}
			
	}
	
	
	if ( FdComponent == 3 )
	{
		// set MAC flags
		e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_MACFLAG ].s, 10 );
		
		// MAC flag is in R10
		
		// zero flag
		e->MovReg32ImmX ( RAX, 0x41 );
		e->TestReg32ImmX ( 10, 0x000f );
		e->CmovERegReg32 ( RAX, 11 );
		
		// sign flag
		e->MovReg32ImmX ( RCX, 0x82 );
		e->TestReg32ImmX ( 10, 0x00f0 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );

		// underflow flag
		e->MovReg32ImmX ( RCX, 0x104 );
		e->TestReg32ImmX ( 10, 0x0f00 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// overflow flag
		e->MovReg32ImmX ( RCX, 0x208 );
		e->TestReg32ImmX ( 10, 0xf000 );
		e->CmovERegReg32 ( RCX, 11 );
		e->OrRegReg32 ( RAX, RCX );
		
		// set status flag
		ret = e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RAX );
	}
	
	return ret;
}






// VABS //

long R5900::Recompiler::VABS ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VABS";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VABS;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
			
#ifdef USE_NEW_VABS_CODE
		case 1:
			//ret = Generate_VABS ( i, Address, 0 );
			//ret &= Generate_VABS ( i, Address, 1 );
			//ret &= Generate_VABS ( i, Address, 2 );
			//ret &= Generate_VABS ( i, Address, 3 );
			
			Generate_VPrefix ( Address );
			ret = Generate_VABSp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VADD //

long R5900::Recompiler::VADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADD_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 1 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 2 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 3 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VADDA //

long R5900::Recompiler::VADDA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, -1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 2, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VADDABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VADDABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VADDABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VADDAW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 0, i, 3, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// VSUB //

long R5900::Recompiler::VSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUB_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 1 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 2 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 3 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMADD //

long R5900::Recompiler::VMADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMADD_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x00 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMADDY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x55 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0xaa );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0xff );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMSUB //

long R5900::Recompiler::VMSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUB_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x00 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x55 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0xaa );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0xff );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMAX //

long R5900::Recompiler::VMAX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMAXi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAXi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMAXBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAXBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw0 );
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMAXBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAXBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw1 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMAXBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAXBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw2 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMAXBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMAXBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMAXBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMAXp ( i, &VU0::_VU0->vf [ i.Ft ].uw3 );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMINI //

long R5900::Recompiler::VMINI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMINIi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINIi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMINIBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINIBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMINIBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINIBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw1 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMINIBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINIBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw2 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMINIBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMINIBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMINIBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VMIN_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMINp ( i, &VU0::_VU0->vf [ i.Ft ].uw3 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMUL //

long R5900::Recompiler::VMUL ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMUL";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMUL;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMUL_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, NULL, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, NULL, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULBCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULBCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x00 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULBCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULBCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x55 );	//1 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULBCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULBCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0xaa );	//2 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULBCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULBCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULBCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0xff );	//3 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






long R5900::Recompiler::VOPMSUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VOPMSUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VOPMSUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VOPMSUB_CODE
		case 1:
			//long R5900::Recompiler::Generate_VMADDp ( u32 bSub, R5900::Instruction::Format i, u32 FtComponentp, void *pFd, u32 *pFt, u32 FsComponentp, u32 FdComponentp )
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x84, NULL, NULL, 0x60 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VIADD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VIADD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIADD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VIADD_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ ( i.is & 0xf ) + ( i.it & 0xf ) ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->AddMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegReg16 ( RAX, RAX );
					
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VISUB ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VISUB";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VISUB;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VISUB_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( !( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( !( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->NegReg16 ( RAX );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->SubMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->SubRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VIADDI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VIADDI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIADDI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
	
#ifdef USE_NEW_VIADDI_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.it & 0xf )
			{
				if ( !( i.is & 0xf ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, ( (s16) i.Imm5 ) );
				}
				else if ( i.it == i.is )
				{
					e->AddMemImm16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, ( (s16) i.Imm5 ) );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AddRegImm16 ( RAX, ( (s16) i.Imm5 ) );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
				}
			}
			break;
#endif
	
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VIAND ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VIAND";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIAND;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VIAND_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->AndMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AndMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->AndRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VIOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VIOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VIOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VIOR_CODE
		case 1:
			Generate_VPrefix ( Address );
			if ( i.id & 0xf )
			{
				if ( ( !( i.is & 0xf ) ) && ( !( i.it & 0xf ) ) )
				{
					e->MovMemImm16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, 0 );
				}
				else if ( ( !( i.is & 0xf ) ) || ( !( i.it & 0xf ) ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ ( i.is & 0xf ) + ( i.it & 0xf ) ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.is & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.is & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->OrMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else if ( ( i.id & 0xf ) == ( i.it & 0xf ) )
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->OrMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
				else
				{
					e->MovRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.is & 0xf ].s );
					e->OrRegMem16 ( RAX, (s16*) &VU0::_VU0->vi [ i.it & 0xf ].s );
					e->MovMemReg16 ( (s16*) &VU0::_VU0->vi [ i.id & 0xf ].s, RAX );
				}
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// VCALLMS //

long R5900::Recompiler::VCALLMS ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VCALLMS";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCALLMS;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VCALLMSR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VCALLMSR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCALLMSR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// should assume NextPC might get modified
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VFTOI //

long R5900::Recompiler::VFTOI0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VFTOI0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI0_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VFTOI4 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VFTOI4";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI4;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI4_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 4 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VFTOI12 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VFTOI12";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI12;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI12_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 12 );
			break;
#endif

		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VFTOI15 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VFTOI15";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VFTOI15;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VFTOI15_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VFTOIXp ( i, 15 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}


// VITOF //

long R5900::Recompiler::VITOF0 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VITOF0";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF0;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF0_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 0 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VITOF4 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VITOF4";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF4;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF4_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 4 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VITOF12 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VITOF12";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF12;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF12_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 12 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VITOF15 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VITOF15";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VITOF15;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VITOF15_CODE
		case 1:
			Generate_VPrefix ( Address );
			Generate_VITOFXp ( i, 15 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





long R5900::Recompiler::VMOVE ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMOVE";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMOVE;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMOVE_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMOVEp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VLQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VLQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VLQI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VLQI_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.Ft )
			{
				// add destination register to bitmap at end
				//Add_FDstReg ( i.Value, i.Ft );
				
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
				}

				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
				
				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
				//}

				
				// post-inc
				e->LeaRegRegImm32 ( RDX, RAX, 1 );
				e->MovMemReg16 ( & VU0::_VU0->vi [ i.is & 0xf ].sLo, RDX );
				
				//if ( !v->Number )
				//{
					e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				
				e->movdqa_from_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RAX );
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VDIV ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VDIV";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VDIV;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VDIV_CODE
		case 1:
		
			Generate_VPrefix ( Address );
			
			// clear bits 16 and 17 in the flag register first
			e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );		// r->CPC1 [ 31 ], ~0x00030000 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Ft ].vsw [ i.ftf ] );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg32ImmX ( 8, 0x00000c30 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			//e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovNERegReg32 ( 8, 11 );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RCX, RAX );
			
			
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			//e->MovReg64ImmX ( RCX, 896ULL << 23 );
			//e->XorRegReg32 ( 8, RAX );
			e->XorRegReg32 ( RDX, RAX );
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			//e->AddRegReg64 ( RCX, RAX );
			//e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 9, 0x00000820 );
			e->MovReg32ImmX ( 10, 0x00000410 );
			e->CmovERegReg32 ( 9, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			e->ShlRegImm64 ( RAX, 29 );
			e->movq_to_sse ( RAX, RAX );

			
			// get sign in R8
			e->AndReg32ImmX ( RDX, 0x80000000 );
			
			// set flags
			e->AndRegReg32 ( 8, 9 );
			e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, 8 );
			
			// perform div
			e->divsd ( RAX, RCX );


			// get result
			e->movq_from_sse ( RAX, RAX );

			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			
			// clear on underflow or zero
			e->TestReg32ImmX ( RAX, 0xff800000 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			e->CmovSRegReg32 ( RAX, RCX );
			
			// or if any flags are set
			e->OrRegReg32 ( 8, 8 );
			e->CmovNERegReg32 ( RAX, RCX );
			
			// set sign
			e->OrRegReg32 ( RAX, RDX );
			

			// store result
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_Q ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );
			
			break;
#endif
			

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMTIR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMTIR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMTIR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMTIR_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMTIRp ( i );
			break;
#endif
			
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VRNEXT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VRNEXT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRNEXT;
	
	static const unsigned long c_ulRandMask = 0x7ffb18;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRNEXT_CODE
		case 1:
			if ( i.Ft && i.xyzw )
			{
				//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
				
				// get new P register value if needed
				//e->movd_regmem ( RCX, & VU0::_VU0->vi [ VU::REG_R ].s );
				e->MovRegMem32 ( RAX, ( &VU0::_VU0->vi [ VU::REG_R ].s ) );
				
				e->MovRegReg32 ( RCX, RAX );
				e->AndReg32ImmX( RAX, c_ulRandMask );
				//e->Set_PO ( RCX );
				e->PopCnt32 ( RAX, RAX );
				e->AndReg32ImmX ( RAX, 1 );
				e->AddRegReg32 ( RCX, RCX );
				e->OrRegReg32 ( RAX, RCX );
				
				e->AndReg32ImmX ( RAX, 0x7fffff );
				e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
				e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
				
				e->movd_to_sse ( RCX, RAX );
				e->pshufdregregimm ( RCX, RCX, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
					e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMR32 ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMR32";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMR32;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMR32_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMR32p ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSQI ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSQI";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQI;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQI_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );

			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
			
			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			
			// post-inc
			e->LeaRegRegImm32 ( RDX, RAX, 1 );
			e->MovMemReg16 ( & VU0::_VU0->vi [ i.it & 0xf ].sLo, RDX );
			
			//if ( !v->Number )
			//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );
			
			
			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSQRT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSQRT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQRT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQRT_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Ft ].vsw [ i.ftf ] );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x00410 );
			
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg32 ( RDX, RAX );
			e->CmovNERegReg64 ( RAX, 8 );
			e->ShlRegImm64 ( RAX, 29 );
			
			
			// set flags
			e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, RDX );
			
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			
			// sqrt
			e->sqrtsd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			// ??
			e->AddReg64ImmX ( RAX, 0x10000000 );
			
			
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// if zero, then clear RCX
			e->CmovERegReg64 ( RCX, RAX );
			
			// subtract exponent
			e->SubRegReg64 ( RAX, RCX );
			
			
			// set result
			ret = e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_Q ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMFIR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMFIR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMFIR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMFIR_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMFIRp ( i );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VRGET ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VRGET";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRGET;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRGET_CODE
		case 1:
			if ( i.Ft && i.xyzw )
			{
				//e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Fs ].sw0 );
				
				// get new P register value if needed
				e->movd_regmem ( RCX, & VU0::_VU0->vi [ VU::REG_R ].s );
				
				//e->movd_to_sse ( RCX, RAX );
				e->pshufdregregimm ( RCX, RCX, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Ft ].sw0 );
					e->pblendwregregimm ( RCX, RAX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RCX );
			}
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VSUBA //

long R5900::Recompiler::VSUBA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, -1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 1, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 2, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSUBABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSUBABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSUBABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSUBAW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VADDp ( 1, i, 3, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}



// VMADDA //

long R5900::Recompiler::VMADDA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x00, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0x55, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0xaa, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMADDABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMADDABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMADDABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMADDAW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 0, i, 0xff, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}




// VMSUBA //

long R5900::Recompiler::VMSUBA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x00, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0x55, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0xaa, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMSUBABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMSUBABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMSUBABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMSUBAW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMADDp ( 1, i, 0xff, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





// VMULA //

long R5900::Recompiler::VMULA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x1b, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULAi ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULAi";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULAi;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAi_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_I ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULAq ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULAq";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULAq;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAq_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0, &VU0::_VU0->dACC[ 0 ].l, &VU0::_VU0->vi [ VU::REG_Q ].u );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULABCX ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULABCX";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCX;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAX_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x00, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULABCY ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULABCY";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCY;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAY_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x55, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULABCZ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULABCZ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCZ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAZ_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0xaa, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VMULABCW ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VMULABCW";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VMULABCW;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VMULAW_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0xff, &VU0::_VU0->dACC[ 0 ].l );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}





long R5900::Recompiler::VOPMULA ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VOPMULA";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VOPMULA;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VOPMULA_CODE
		case 1:
			Generate_VPrefix ( Address );
			ret = Generate_VMULp ( i, 0x84, &VU0::_VU0->dACC[ 0 ].l, NULL, 0x60 );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VLQD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VLQD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VLQD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VLQD_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.Ft )
			{
				// add destination register to bitmap at end
				//Add_FDstReg ( i.Value, i.Ft );
				
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				if ( i.xyzw != 0xf )
				{
					e->movdqa_regmem ( RCX, & VU0::_VU0->vf [ i.Ft ].sw0 );
				}
				
				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );
				
				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
				//}
				
				
				// post-inc
				e->DecReg16 ( RAX );
				e->MovMemReg16 ( & VU0::_VU0->vi [ i.is & 0xf ].sLo, RAX );
				
				//if ( !v->Number )
				//{
					e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				
				e->movdqa_from_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
				
				if ( i.xyzw != 0xf )
				{
					e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				}
				
				ret = e->movdqa_memreg ( & VU0::_VU0->vf [ i.Ft ].sw0, RAX );
			}
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VRSQRT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VRSQRT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRSQRT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VRSQRT_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			// clear bits 14 and 15 in the flag register first
			e->AndMem32ImmX ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, ~0x00000030 );
			
			// flush ps2 float to zero
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Ft ].vsw [ i.ftf ] );
			e->XorRegReg32 ( 11, 11 );
			e->MovReg64ImmX ( RCX, 896ULL << 23 );
			
			// get flags
			e->Cdq();
			e->AndReg32ImmX ( RDX, 0x00410 );
			
			
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( 8, RAX, RCX );
			e->AddRegReg64 ( RCX, RAX );
			e->AndReg32ImmX ( RAX, 0x7f800000 );
			e->MovReg32ImmX ( 8, 0x00820 );
			e->CmovNERegReg32 ( 8, RDX );
			e->CmovNERegReg64 ( RAX, RCX );
			e->ShlRegImm64 ( RAX, 29 );
			
			
			// set flags
			e->OrMemReg32 ( &VU0::_VU0->vi [ VU::REG_STATUSFLAG ].s, 8 );
			
			
			// move the registers now to floating point unit
			e->movq_to_sse ( RAX, RAX );
			//e->movq_to_sse ( RCX, RDX );
			
			
			// sqrt
			e->sqrtsd ( RAX, RAX );
			e->movq_from_sse ( RAX, RAX );
			
			// ??
			e->AddReg64ImmX ( RAX, 0x10000000 );
			e->AndReg64ImmX ( RAX, ~0x1fffffff );
			

			e->movq_to_sse ( RCX, RAX );


			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			//e->MovRegReg32 ( RCX, RAX );
			e->Cdq ();
			e->AndReg32ImmX ( RAX, 0x7fffffff );
			//e->LeaRegRegReg64 ( RDX, RAX, RCX );
			e->TestReg32ImmX ( RAX, 0x7f800000 );
			e->CmovERegReg64 ( RAX, 11 );
			//e->ShrRegImm32 ( 10, 31 );
			//e->ShlRegImm64 ( 10, 63 );
			e->ShlRegImm64 ( RAX, 29 );
			//e->OrRegReg64 ( RAX, 10 );
			e->movq_to_sse ( RAX, RAX );

			
			// divide
			e->divsd ( RAX, RCX );
			
			
			// get result
			e->movq_from_sse ( RAX, RAX );
			
			
			// shift back down without sign
			e->ShrRegImm64 ( RAX, 29 );
			
			// subtract exponent
			//e->XorRegReg32 ( 10, 10 );
			//e->MovRegReg32 ( RDX, RAX );
			//e->AndReg64ImmX ( RAX, ~0x007fffff );
			//e->SubRegReg64 ( RAX, RCX );
			e->TestReg32ImmX ( RAX, 0xff800000 );
			
			// clear on underflow or zero
			//e->CmovLERegReg32 ( RAX, 10 );
			//e->CmovLERegReg32 ( RDX, 10 );
			e->CmovERegReg32 ( RAX, 11 );
			
			
			// set to max on overflow
			e->MovReg32ImmX ( RCX, 0x7fffffff );
			//e->OrRegReg32 ( RDX, RDX );
			e->CmovSRegReg32 ( RAX, RCX );
			
			
			// or if any flags are set indicating denominator is zero
			e->AndReg32ImmX ( 8, 0x00020 );
			e->CmovNERegReg32 ( RAX, RCX );

			
			// set sign
			e->AndReg32ImmX ( RDX, 0x80000000 );
			e->OrRegReg32 ( RAX, RDX );
			

			// store result
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_Q ].s, RAX );		// &r->CPR1 [ i.Fd ].s, RAX );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VILWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VILWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VILWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VILWR_CODE
		case 1:
			Generate_VPrefix ( Address );

			if ( i.it )
			{
				//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
				e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
				
				
				//pVuMem32 = v->GetMemPtr ( LoadAddress );
				//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
				//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
				e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

				// special code for VU#0
				//if ( !v->Number )
				//{
					// check if Address & 0xf000 == 0x4000
					e->MovRegReg32 ( RDX, RAX );
					e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
					e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
					
					// here it will be loading/storing from/to the registers for VU#1
					e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
					e->CmovERegReg64 ( RCX, RDX );
					
					// ***TODO*** check if storing to TPC
				//}
				
				//if ( !v->Number )
				//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
				//}
				//else
				//{
				//e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
				//}
				e->AddRegReg32 ( RAX, RAX );
				
				switch( i.xyzw )
				{
					case 8:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
						break;
						
					case 4:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 4 );
						break;
						
					case 2:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 8 );
						break;
						
					case 1:
						e->MovRegFromMem32 ( RAX, RCX, RAX, SCALE_EIGHT, 12 );
						break;
						
					default:
						cout << "\nVU: Recompiler: ALERT: ILWR with illegal xyzw=" << hex << i.xyzw << "\n";
						break;
				}
				
				//if ( i.xyzw != 0xf )
				//{
				//	e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
				//}
				//ret = e->movdqa_memreg ( & v->vf [ i.Ft ].sw0, RAX );
				
				ret = e->MovMemReg32 ( & VU0::_VU0->vi [ i.it & 0xf ].s, RAX );
			}
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VRINIT ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VRINIT";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRINIT;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRINIT_CODE
		case 1:
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			//e->XorRegMem32 ( RAX, &v->vi [ VU::REG_R ].s );
			e->AndReg32ImmX ( RAX, 0x7fffff );
			e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VCLIP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VCLIP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VCLIP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;


#ifdef USE_NEW_VCLIP_CODE
		case 1:
			Generate_VPrefix ( Address );
			
			// load clip flag
			e->MovRegMem32 ( RAX, &VU0::_VU0->vi [ VU::REG_CLIPFLAG ].s );
			
			// flush ps2 float to zero
			e->movdqa_regmem ( RBX, &VU0::_VU0->vf [ i.Ft ].sw0 );
			
			if ( !i.Fs )
			{
				e->pxorregreg ( RAX, RAX );
			}
			else if ( i.Fs == i.Ft )
			{
				e->movdqa_regreg ( RAX, RBX );
			}
			else
			{
				e->movdqa_regmem ( RAX, &VU0::_VU0->vf [ i.Fs ].sw0 );
			}
			
			// get w from ft
			e->pshufdregregimm ( RBX, RBX, 0xff );
			
			
			// get +w into RBX
			e->pslldregimm ( RBX, 1 );
			e->psrldregimm ( RBX, 1 );
			
			// get -w into RCX
			e->pcmpeqbregreg ( RCX, RCX );
			e->movdqa_regreg ( RDX, RCX );
			e->pxorregreg ( RCX, RBX );
			//e->psubdregreg ( RCX, RDX );
			
			// get x,y from fs into RDX
			e->pshufdregregimm ( RDX, RAX, ( 1 << 6 ) | ( 1 << 4 ) | ( 0 << 2 ) | ( 0 << 0 ) );
			e->movdqa_regreg ( 4, RDX );
			e->psradregimm ( 4, 31 );
			//e->pslldregimm ( RDX, 1 );
			//e->psrldregimm ( RDX, 1 );
			e->psrldregimm ( 4, 1 );
			e->pxorregreg ( RDX, 4 );
			//e->psubdregreg ( RDX, 4 );
			
			// get greater than +w into R4 and less than -w into R5
			e->movdqa_regreg ( 4, RDX );
			e->pcmpgtdregreg ( 4, RBX );
			e->movdqa_regreg ( 5, RCX );
			e->pcmpgtdregreg ( 5, RDX );
			
			// get x and y flags into R4
			e->pblendwregregimm ( 4, 5, 0xcc );
			
			
			// get z from fs into RAX
			e->pshufdregregimm ( RAX, RAX, ( 2 << 6 ) | ( 2 << 4 ) | ( 2 << 2 ) | ( 2 << 0 ) );
			e->movdqa_regreg ( 5, RAX );
			e->psradregimm ( 5, 31 );
			//e->pslldregimm ( RAX, 1 );
			//e->psrldregimm ( RAX, 1 );
			e->psrldregimm ( 5, 1 );
			e->pxorregreg ( RAX, 5 );
			//e->psubdregreg ( RAX, 5 );
			
			// get greater than into RAX and less than into RCX
			e->pcmpgtdregreg ( RCX, RAX );
			e->pcmpgtdregreg ( RAX, RBX );
			
			// get z flags into RAX
			e->pblendwregregimm ( RAX, RCX, 0xcc );
			
			// pull flags
			e->movmskpsregreg ( RCX, 4 );
			e->movmskpsregreg ( RDX, RAX );
			
			// combine flags
			e->ShlRegImm32 ( RDX, 4 );
			e->OrRegReg32 ( RCX, RDX );
			e->AndReg32ImmX ( RCX, 0x3f );
			
			// combine into rest of the clipping flags
			e->ShlRegImm32 ( RAX, 6 );
			e->OrRegReg32 ( RAX, RCX );
			e->AndReg32ImmX ( RAX, 0x00ffffff );
			
			// write back to clipping flag
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_CLIPFLAG ].s, RAX );
			
			break;
#endif

			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VNOP ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VNOP";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VNOP;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VNOP_CODE
		case 1:
			Generate_VPrefix ( Address );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VSQD ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VSQD";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VSQD;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VSQD_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			
			e->movdqa_regmem ( RAX, & VU0::_VU0->vf [ i.Fs ].sw0 );
			
			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			// post-inc
			e->DecReg32 ( RAX );
			e->MovMemReg16 ( & VU0::_VU0->vi [ i.it & 0xf ].sLo, RAX );
			
			//if ( !v->Number )
			//{
				e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//	e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );
			
			
			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VWAITQ ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VWAITQ";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VWAITQ;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VISWR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VISWR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VISWR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;

#ifdef USE_NEW_VISWR_CODE
		case 1:
			Generate_VPrefix ( Address );

			//LoadAddress = ( v->vi [ i.is & 0xf ].sLo + i.Imm11 ) << 2;
			e->MovRegMem32 ( RAX, & VU0::_VU0->vi [ i.is & 0xf ].s );
			e->movd_regmem ( RAX, & VU0::_VU0->vi [ i.it & 0xf ].s );
			
			//e->movdqa_regmem ( RAX, & v->vf [ i.Fs ].sw0 );
			
			//pVuMem32 = v->GetMemPtr ( LoadAddress );
			//return & ( VuMem32 [ Address32 & ( c_ulVuMem1_Mask >> 2 ) ] );
			//e->MovRegImm64 ( RCX, (u64) & v->VuMem32 [ 0 ] );
			e->LeaRegMem64 ( RCX, & VU0::_VU0->VuMem32 [ 0 ] );

			// special code for VU#0
			//if ( !v->Number )
			//{
				// check if Address & 0xf000 == 0x4000
				e->MovRegReg32 ( RDX, RAX );
				e->AndReg32ImmX ( RDX, 0xf000 >> 4 );
				e->CmpReg32ImmX ( RDX, 0x4000 >> 4 );
				
				// here it will be loading/storing from/to the registers for VU#1
				e->LeaRegMem64 ( RDX, & VU1::_VU1->vf [ 0 ].sw0 );
				e->CmovERegReg64 ( RCX, RDX );
				
				// ***TODO*** check if storing to TPC
			//}
			
			//if ( !v->Number )
			//{
			e->AndReg32ImmX ( RAX, VU::c_ulVuMem0_Mask >> 4 );
			//}
			//else
			//{
			//e->AndReg32ImmX ( RAX, VU::c_ulVuMem1_Mask >> 4 );
			//}
			e->AddRegReg32 ( RAX, RAX );

			if ( i.xyzw != 0xf )
			{
				e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
			}
			
			e->pmovzxwdregreg ( RAX, RAX );
			e->pshufdregregimm ( RAX, RAX, 0 );
			//e->pslldregimm ( RAX, 16 );
			//e->psrldregimm ( RAX, 16 );
			
			if ( i.xyzw != 0xf )
			{
				//e->movdqa_from_mem128 ( RCX, RCX, RAX, SCALE_EIGHT, 0 );
				e->pblendwregregimm ( RAX, RCX, ~( ( i.destx * 0x03 ) | ( i.desty * 0x0c ) | ( i.destz * 0x30 ) | ( i.destw * 0xc0 ) ) );
			}
			
			//ret = e->movdqa_memreg ( & v->vf [ i.Ft ].sw0, RAX );
			ret = e->movdqa_to_mem128 ( RAX, RCX, RAX, SCALE_EIGHT, 0 );
			
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}

long R5900::Recompiler::VRXOR ( R5900::Instruction::Format i, u32 Address )
{
	static constexpr char *c_sName = "VRXOR";
	static const void *c_vFunction = (const void*) R5900::Instruction::Execute::VRXOR;
	
	int ret = 1;
	
	// for now, stop encoding after this instruction
	//bStopEncodingAfter = true;
	//bStopEncodingBefore = true;
	
	switch ( OpLevel )
	{
		case 0:
			// for now, stop encoding after this instruction
			bStopEncodingAfter = true;
			bStopEncodingBefore = true;
			
			// if the vu0 unit is not ready, then instruction stalls until it becomes available (for now)
			Local_NextPCModified = true;
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			e->SubReg64ImmX ( RSP, c_lSEH_StackSize );
#endif

			e->LoadImm32 ( RCX, i.Value );
			ret = e->Call ( c_vFunction );
			
#ifdef RESERVE_STACK_FRAME_FOR_CALL
			ret = e->AddReg64ImmX ( RSP, c_lSEH_StackSize );
#endif
			break;
			
#ifdef USE_NEW_VRXOR_CODE
		case 1:
			e->MovRegMem32 ( RAX, &VU0::_VU0->vf [ i.Fs ].vsw [ i.fsf ] );
			e->XorRegMem32 ( RAX, &VU0::_VU0->vi [ VU::REG_R ].s );
			e->AndReg32ImmX ( RAX, 0x7fffff );
			e->OrReg32ImmX ( RAX, ( 0x7f << 23 ) );
			e->MovMemReg32 ( &VU0::_VU0->vi [ VU::REG_R ].s, RAX );
			break;
#endif
			
		default:
			return -1;
			break;
	}
	
	if ( !ret )
	{
		cout << "\nx64 Recompiler: Error encoding " << c_sName << " instruction.\n";
		return -1;
	}
	return 1;
}






const R5900::Recompiler::Function R5900::Recompiler::FunctionList []
{
	// instructions on both R3000A and R5900
	// 1 + 56 + 6 = 63 instructions //
	R5900::Recompiler::Invalid,
	R5900::Recompiler::J, R5900::Recompiler::JAL, R5900::Recompiler::JR, R5900::Recompiler::JALR, R5900::Recompiler::BEQ, R5900::Recompiler::BNE, R5900::Recompiler::BGTZ, R5900::Recompiler::BGEZ,
	R5900::Recompiler::BLTZ, R5900::Recompiler::BLEZ, R5900::Recompiler::BGEZAL, R5900::Recompiler::BLTZAL, R5900::Recompiler::ADD, R5900::Recompiler::ADDI, R5900::Recompiler::ADDU, R5900::Recompiler::ADDIU,
	R5900::Recompiler::SUB, R5900::Recompiler::SUBU, R5900::Recompiler::MULT, R5900::Recompiler::MULTU, R5900::Recompiler::DIV, R5900::Recompiler::DIVU, R5900::Recompiler::AND, R5900::Recompiler::ANDI,
	R5900::Recompiler::OR, R5900::Recompiler::ORI, R5900::Recompiler::XOR, R5900::Recompiler::XORI, R5900::Recompiler::NOR, R5900::Recompiler::LUI, R5900::Recompiler::SLL, R5900::Recompiler::SRL,
	R5900::Recompiler::SRA, R5900::Recompiler::SLLV, R5900::Recompiler::SRLV, R5900::Recompiler::SRAV, R5900::Recompiler::SLT, R5900::Recompiler::SLTI, R5900::Recompiler::SLTU, R5900::Recompiler::SLTIU,
	R5900::Recompiler::LB, R5900::Recompiler::LBU, R5900::Recompiler::LH, R5900::Recompiler::LHU, R5900::Recompiler::LW, R5900::Recompiler::LWL, R5900::Recompiler::LWR, R5900::Recompiler::SB,
	R5900::Recompiler::SH, R5900::Recompiler::SW, R5900::Recompiler::SWL, R5900::Recompiler::SWR, R5900::Recompiler::MFHI, R5900::Recompiler::MTHI, R5900::Recompiler::MFLO, R5900::Recompiler::MTLO,
	R5900::Recompiler::MFC0, R5900::Recompiler::MTC0,
	R5900::Recompiler::CFC2_I, R5900::Recompiler::CTC2_I, R5900::Recompiler::CFC2_NI, R5900::Recompiler::CTC2_NI,
	R5900::Recompiler::SYSCALL, R5900::Recompiler::BREAK,
	
	// instructions on R3000A ONLY
	//R5900::Recompiler::MFC2, R5900::Recompiler::MTC2, R5900::Recompiler::LWC2, R5900::Recompiler::SWC2, R5900::Recompiler::RFE,
	//R5900::Recompiler::RTPS, R5900::Recompiler::RTPT, R5900::Recompiler::CC, R5900::Recompiler::CDP, R5900::Recompiler::DCPL, R5900::Recompiler::DPCS, R5900::Recompiler::DPCT, R5900::Recompiler::NCS,
	//R5900::Recompiler::NCT, R5900::Recompiler::NCDS, R5900::Recompiler::NCDT, R5900::Recompiler::NCCS, R5900::Recompiler::NCCT, R5900::Recompiler::GPF, R5900::Recompiler::GPL, R5900::Recompiler::AVSZ3,
	//R5900::Recompiler::AVSZ4, R5900::Recompiler::SQR, R5900::Recompiler::OP, R5900::Recompiler::NCLIP, R5900::Recompiler::INTPL, R5900::Recompiler::MVMVA
	
	// instructions on R5900 ONLY
	// (24*8) + 4 + 6 = 192 + 10 = 202 instructions //
	R5900::Recompiler::BEQL, R5900::Recompiler::BNEL, R5900::Recompiler::BGEZL, R5900::Recompiler::BGTZL, R5900::Recompiler::BLEZL, R5900::Recompiler::BLTZL, R5900::Recompiler::BGEZALL, R5900::Recompiler::BLTZALL,
	R5900::Recompiler::DADD, R5900::Recompiler::DADDI, R5900::Recompiler::DADDU, R5900::Recompiler::DADDIU, R5900::Recompiler::DSUB, R5900::Recompiler::DSUBU, R5900::Recompiler::DSLL, R5900::Recompiler::DSLL32,
	R5900::Recompiler::DSLLV, R5900::Recompiler::DSRA, R5900::Recompiler::DSRA32, R5900::Recompiler::DSRAV, R5900::Recompiler::DSRL, R5900::Recompiler::DSRL32, R5900::Recompiler::DSRLV, R5900::Recompiler::LD,
	R5900::Recompiler::LDL, R5900::Recompiler::LDR, R5900::Recompiler::LWU, R5900::Recompiler::LQ, R5900::Recompiler::PREF, R5900::Recompiler::SD, R5900::Recompiler::SDL, R5900::Recompiler::SDR,
	R5900::Recompiler::SQ, R5900::Recompiler::TEQ, R5900::Recompiler::TEQI, R5900::Recompiler::TNE, R5900::Recompiler::TNEI, R5900::Recompiler::TGE, R5900::Recompiler::TGEI, R5900::Recompiler::TGEU,
	R5900::Recompiler::TGEIU, R5900::Recompiler::TLT, R5900::Recompiler::TLTI, R5900::Recompiler::TLTU, R5900::Recompiler::TLTIU, R5900::Recompiler::MOVN, R5900::Recompiler::MOVZ, R5900::Recompiler::MULT1,
	R5900::Recompiler::MULTU1, R5900::Recompiler::DIV1, R5900::Recompiler::DIVU1, R5900::Recompiler::MADD, R5900::Recompiler::MADD1, R5900::Recompiler::MADDU, R5900::Recompiler::MADDU1, R5900::Recompiler::MFHI1,
	R5900::Recompiler::MTHI1, R5900::Recompiler::MFLO1, R5900::Recompiler::MTLO1, R5900::Recompiler::MFSA, R5900::Recompiler::MTSA, R5900::Recompiler::MTSAB, R5900::Recompiler::MTSAH,
	R5900::Recompiler::PABSH, R5900::Recompiler::PABSW, R5900::Recompiler::PADDB, R5900::Recompiler::PADDH, R5900::Recompiler::PADDW, R5900::Recompiler::PADDSB, R5900::Recompiler::PADDSH, R5900::Recompiler::PADDSW,
	R5900::Recompiler::PADDUB, R5900::Recompiler::PADDUH, R5900::Recompiler::PADDUW, R5900::Recompiler::PADSBH, R5900::Recompiler::PAND, R5900::Recompiler::POR, R5900::Recompiler::PXOR, R5900::Recompiler::PNOR,
	R5900::Recompiler::PCEQB, R5900::Recompiler::PCEQH, R5900::Recompiler::PCEQW, R5900::Recompiler::PCGTB, R5900::Recompiler::PCGTH, R5900::Recompiler::PCGTW, R5900::Recompiler::PCPYH, R5900::Recompiler::PCPYLD,
	R5900::Recompiler::PCPYUD, R5900::Recompiler::PDIVBW, R5900::Recompiler::PDIVUW, R5900::Recompiler::PDIVW, R5900::Recompiler::PEXCH, R5900::Recompiler::PEXCW, R5900::Recompiler::PEXEH, R5900::Recompiler::PEXEW,
	R5900::Recompiler::PEXT5, R5900::Recompiler::PEXTLB, R5900::Recompiler::PEXTLH, R5900::Recompiler::PEXTLW, R5900::Recompiler::PEXTUB, R5900::Recompiler::PEXTUH, R5900::Recompiler::PEXTUW, R5900::Recompiler::PHMADH,
	R5900::Recompiler::PHMSBH, R5900::Recompiler::PINTEH, R5900::Recompiler::PINTH, R5900::Recompiler::PLZCW, R5900::Recompiler::PMADDH, R5900::Recompiler::PMADDW, R5900::Recompiler::PMADDUW, R5900::Recompiler::PMAXH,
	R5900::Recompiler::PMAXW, R5900::Recompiler::PMINH, R5900::Recompiler::PMINW, R5900::Recompiler::PMFHI, R5900::Recompiler::PMFLO, R5900::Recompiler::PMTHI, R5900::Recompiler::PMTLO, R5900::Recompiler::PMFHL_LH,
	R5900::Recompiler::PMFHL_SH, R5900::Recompiler::PMFHL_LW, R5900::Recompiler::PMFHL_UW, R5900::Recompiler::PMFHL_SLW, R5900::Recompiler::PMTHL_LW, R5900::Recompiler::PMSUBH, R5900::Recompiler::PMSUBW, R5900::Recompiler::PMULTH,
	R5900::Recompiler::PMULTW, R5900::Recompiler::PMULTUW, R5900::Recompiler::PPAC5, R5900::Recompiler::PPACB, R5900::Recompiler::PPACH, R5900::Recompiler::PPACW, R5900::Recompiler::PREVH, R5900::Recompiler::PROT3W,
	R5900::Recompiler::PSLLH, R5900::Recompiler::PSLLVW, R5900::Recompiler::PSLLW, R5900::Recompiler::PSRAH, R5900::Recompiler::PSRAW, R5900::Recompiler::PSRAVW, R5900::Recompiler::PSRLH, R5900::Recompiler::PSRLW,
	R5900::Recompiler::PSRLVW, R5900::Recompiler::PSUBB, R5900::Recompiler::PSUBH, R5900::Recompiler::PSUBW, R5900::Recompiler::PSUBSB, R5900::Recompiler::PSUBSH, R5900::Recompiler::PSUBSW, R5900::Recompiler::PSUBUB,
	R5900::Recompiler::PSUBUH, R5900::Recompiler::PSUBUW,
	R5900::Recompiler::QFSRV, R5900::Recompiler::SYNC,
	
	R5900::Recompiler::DI, R5900::Recompiler::EI, R5900::Recompiler::ERET, R5900::Recompiler::CACHE, R5900::Recompiler::TLBP, R5900::Recompiler::TLBR, R5900::Recompiler::TLBWI, R5900::Recompiler::TLBWR,
	R5900::Recompiler::CFC0, R5900::Recompiler::CTC0,
	
	R5900::Recompiler::BC0T, R5900::Recompiler::BC0TL, R5900::Recompiler::BC0F, R5900::Recompiler::BC0FL, R5900::Recompiler::BC1T, R5900::Recompiler::BC1TL, R5900::Recompiler::BC1F, R5900::Recompiler::BC1FL,
	R5900::Recompiler::BC2T, R5900::Recompiler::BC2TL, R5900::Recompiler::BC2F, R5900::Recompiler::BC2FL,
	
	// COP1 floating point instructions
	R5900::Recompiler::LWC1, R5900::Recompiler::SWC1, R5900::Recompiler::MFC1, R5900::Recompiler::MTC1, R5900::Recompiler::CFC1, R5900::Recompiler::CTC1,
	R5900::Recompiler::ABS_S, R5900::Recompiler::ADD_S, R5900::Recompiler::ADDA_S, R5900::Recompiler::C_EQ_S, R5900::Recompiler::C_F_S, R5900::Recompiler::C_LE_S, R5900::Recompiler::C_LT_S, R5900::Recompiler::CVT_S_W,
	R5900::Recompiler::CVT_W_S, R5900::Recompiler::DIV_S, R5900::Recompiler::MADD_S, R5900::Recompiler::MADDA_S, R5900::Recompiler::MAX_S, R5900::Recompiler::MIN_S, R5900::Recompiler::MOV_S, R5900::Recompiler::MSUB_S,
	R5900::Recompiler::MSUBA_S, R5900::Recompiler::MUL_S, R5900::Recompiler::MULA_S, R5900::Recompiler::NEG_S, R5900::Recompiler::RSQRT_S, R5900::Recompiler::SQRT_S, R5900::Recompiler::SUB_S, R5900::Recompiler::SUBA_S,
	
	// VU macro mode instructions
	R5900::Recompiler::QMFC2_NI, R5900::Recompiler::QMFC2_I, R5900::Recompiler::QMTC2_NI, R5900::Recompiler::QMTC2_I, R5900::Recompiler::LQC2, R5900::Recompiler::SQC2,
	
	R5900::Recompiler::VABS,
	R5900::Recompiler::VADD, R5900::Recompiler::VADDi, R5900::Recompiler::VADDq, R5900::Recompiler::VADDBCX, R5900::Recompiler::VADDBCY, R5900::Recompiler::VADDBCZ, R5900::Recompiler::VADDBCW,
	R5900::Recompiler::VADDA, R5900::Recompiler::VADDAi, R5900::Recompiler::VADDAq, R5900::Recompiler::VADDABCX, R5900::Recompiler::VADDABCY, R5900::Recompiler::VADDABCZ, R5900::Recompiler::VADDABCW,
	R5900::Recompiler::VCALLMS, R5900::Recompiler::VCALLMSR, R5900::Recompiler::VCLIP, R5900::Recompiler::VDIV,
	R5900::Recompiler::VFTOI0, R5900::Recompiler::VFTOI4, R5900::Recompiler::VFTOI12, R5900::Recompiler::VFTOI15,
	R5900::Recompiler::VIADD, R5900::Recompiler::VIADDI, R5900::Recompiler::VIAND, R5900::Recompiler::VILWR, R5900::Recompiler::VIOR, R5900::Recompiler::VISUB, R5900::Recompiler::VISWR,
	R5900::Recompiler::VITOF0, R5900::Recompiler::VITOF4, R5900::Recompiler::VITOF12, R5900::Recompiler::VITOF15,
	R5900::Recompiler::VLQD, R5900::Recompiler::VLQI,
	
	R5900::Recompiler::VMADD, R5900::Recompiler::VMADDi, R5900::Recompiler::VMADDq, R5900::Recompiler::VMADDBCX, R5900::Recompiler::VMADDBCY, R5900::Recompiler::VMADDBCZ, R5900::Recompiler::VMADDBCW,
	R5900::Recompiler::VMADDA, R5900::Recompiler::VMADDAi, R5900::Recompiler::VMADDAq, R5900::Recompiler::VMADDABCX, R5900::Recompiler::VMADDABCY, R5900::Recompiler::VMADDABCZ, R5900::Recompiler::VMADDABCW,
	R5900::Recompiler::VMAX, R5900::Recompiler::VMAXi, R5900::Recompiler::VMAXBCX, R5900::Recompiler::VMAXBCY, R5900::Recompiler::VMAXBCZ, R5900::Recompiler::VMAXBCW,
	R5900::Recompiler::VMFIR,
	R5900::Recompiler::VMINI, R5900::Recompiler::VMINIi, R5900::Recompiler::VMINIBCX, R5900::Recompiler::VMINIBCY, R5900::Recompiler::VMINIBCZ, R5900::Recompiler::VMINIBCW,
	R5900::Recompiler::VMOVE, R5900::Recompiler::VMR32,
	
	R5900::Recompiler::VMSUB, R5900::Recompiler::VMSUBi, R5900::Recompiler::VMSUBq, R5900::Recompiler::VMSUBBCX, R5900::Recompiler::VMSUBBCY, R5900::Recompiler::VMSUBBCZ, R5900::Recompiler::VMSUBBCW,
	R5900::Recompiler::VMSUBA, R5900::Recompiler::VMSUBAi, R5900::Recompiler::VMSUBAq, R5900::Recompiler::VMSUBABCX, R5900::Recompiler::VMSUBABCY, R5900::Recompiler::VMSUBABCZ, R5900::Recompiler::VMSUBABCW,
	R5900::Recompiler::VMTIR,
	R5900::Recompiler::VMUL, R5900::Recompiler::VMULi, R5900::Recompiler::VMULq, R5900::Recompiler::VMULBCX, R5900::Recompiler::VMULBCY, R5900::Recompiler::VMULBCZ, R5900::Recompiler::VMULBCW,
	R5900::Recompiler::VMULA, R5900::Recompiler::VMULAi, R5900::Recompiler::VMULAq, R5900::Recompiler::VMULABCX, R5900::Recompiler::VMULABCY, R5900::Recompiler::VMULABCZ, R5900::Recompiler::VMULABCW,
	R5900::Recompiler::VNOP, R5900::Recompiler::VOPMSUB, R5900::Recompiler::VOPMULA, R5900::Recompiler::VRGET, R5900::Recompiler::VRINIT, R5900::Recompiler::VRNEXT, R5900::Recompiler::VRSQRT, R5900::Recompiler::VRXOR,
	R5900::Recompiler::VSQD, R5900::Recompiler::VSQI, R5900::Recompiler::VSQRT,
	R5900::Recompiler::VSUB, R5900::Recompiler::VSUBi, R5900::Recompiler::VSUBq, R5900::Recompiler::VSUBBCX, R5900::Recompiler::VSUBBCY, R5900::Recompiler::VSUBBCZ, R5900::Recompiler::VSUBBCW,
	R5900::Recompiler::VSUBA, R5900::Recompiler::VSUBAi, R5900::Recompiler::VSUBAq, R5900::Recompiler::VSUBABCX, R5900::Recompiler::VSUBABCY, R5900::Recompiler::VSUBABCZ, R5900::Recompiler::VSUBABCW,
	R5900::Recompiler::VWAITQ,
	R5900::Recompiler::COP2
};
