#version 450


//***TODO***
// 1. copying into local memory should operate in parallel with each subgroup on different line unless destination buffer changes location/size
// 2. 


#extension GL_KHR_shader_subgroup_basic: enable
#extension GL_KHR_shader_subgroup_vote: enable
#extension GL_KHR_shader_subgroup_ballot: enable
//#extension GL_KHR_shader_subgroup_arithmetic: enable
//#extension GL_KHR_shader_subgroup_shuffle: enable
//#extension GL_KHR_shader_subgroup_shuffle_relative: enable
//#extension GL_KHR_shader_subgroup_clustered: enable

// adds: int8_t  i8vec2  i8vec3  i8vec4  uint8_t  u8vec2  u8vec3  u8vec4
#extension GL_EXT_shader_8bit_storage: enable

// adds: float16_t  f16vec2  f16vec3  f16vec4  int16_t  i16vec2  i16vec3  i16vec4  uint16_t  u16vec2  u16vec3  u16vec4
#extension GL_EXT_shader_16bit_storage: enable

// adds: int64_t  i64vec2  i64vec3  i64vec4  uint64_t  u64vec2  u64vec3  u64vec4
#extension GL_ARB_gpu_shader_int64: enable

// adds: pack8, unpack8, pack16, unpack16, pack32, unpack32, etc
#extension GL_EXT_shader_explicit_arithmetic_types : enable


// when reading the CLUT from cpu, read it as if it is split on the CPU (512 16-bit elements) but combined on the GPU (256 32-bit elements)
#define READ_BACK_CLUT_SPLIT

// when writing back the clut from GPU to CPU, write it as if it is split on the CPU (512 16-bit elements) but combined on the GPU (256 32-bit elements)
#define WRITE_BACK_CLUT_SPLIT


// this looks to be the way to go, contiguous ranges for each shader to maximize shader usage
#define ENABLE_RANGE_DRAW

// synchronize at particular points
#define USE_NEW_SYNC_BEFORE_RUN
#define REQUEST_SYNC_ON_ANYTHING
//#define ENABLE_SUBGROUP_SYNC_ALL
//#define ENABLE_LOCAL_SYNC_ALL
//#define ENABLE_GLOBAL_SYNC_ALL


// enable multi-threading on gpu
//#define ENABLE_MULTIPLE_WORKGROUPS
#define USE_MEMORY_BARRIER_BUFFER


// write back workgroup and subgroup data at end
#define ENABLE_WRITE_BACK_DEVICE_DATA


// uses atomics for 4-bit writes
//#define ENABLE_4BIT_ATOMICS


// enable precalc
#define ENABLE_PRECOMPUTE_DATA
#define PRECALC_SPRITE_VARS
#define PRECALC_TRIANGLE_VARS
#define PRECALC_LINE_VARS
#define PRECALC_PIXEL_VARS


// this uses less code space by re-using transfer-in function for the latter part of a transfer-move
// ***todo*** not ready yet because of a problem with how pixels are counted
//#define USE_TRANSFER_IN_WITH_MOVE


// enable/disable drawing of object types
#define ENABLE_DRAW_PIXEL_INPUT
#define ENABLE_DRAW_PIXEL_MOVE
//#define ENABLE_DRAW_TRIANGLE_COLOR
#define ENABLE_DRAW_TRIANGLE_TEXTURE
//#define ENABLE_DRAW_RECTANGLE
#define ENABLE_DRAW_SPRITE
#define ENABLE_DRAW_SCREEN
#define ENABLE_DRAW_VARIABLE
#define ENABLE_DRAW_LINE_COLOR
#define ENABLE_DRAW_PIXEL_COLOR

// note: the most that this should probably do is just copy VRAM from internal buffer to external buffer at the end
//#define ENABLE_DRAW_PIXEL_OUTPUT



#define ENABLE_ALPHA_BLEND_RECTANGLE
#define ENABLE_SRCALPHA_TEST_RECTANGLE
#define ENABLE_DSTALPHA_TEST_RECTANGLE
#define ENABLE_DEPTH_TEST_RECTANGLE
#define ENABLE_WRITE_ZBUFFER_RECTANGLE

#define ENABLE_TEXTURE_MAPPING_SPRITE
#define ENABLE_TEXTURE_FUNC_SPRITE
#define ENABLE_FOGGING_SPRITE
#define ENABLE_ALPHA_BLEND_SPRITE
#define ENABLE_SRCALPHA_TEST_SPRITE
#define ENABLE_DSTALPHA_TEST_SPRITE
#define ENABLE_DEPTH_TEST_SPRITE
#define ENABLE_WRITE_ZBUFFER_SPRITE

#define ENABLE_ALPHA_BLEND_TRIANGLE_COLOR
#define ENABLE_SRCALPHA_TEST_TRIANGLE_COLOR
#define ENABLE_DSTALPHA_TEST_TRIANGLE_COLOR
#define ENABLE_DEPTH_TEST_TRIANGLE_COLOR
#define ENABLE_WRITE_ZBUFFER_TRIANGLE_COLOR

#define ENABLE_TEXTURE_MAPPING_TRIANGLE_TEXTURE
#define ENABLE_TEXTURE_FUNC_TRIANGLE_TEXTURE
#define ENABLE_FOGGING_TRIANGLE_TEXTURE
#define ENABLE_ALPHA_BLEND_TRIANGLE_TEXTURE
#define ENABLE_SRCALPHA_TEST_TRIANGLE_TEXTURE
#define ENABLE_DSTALPHA_TEST_TRIANGLE_TEXTURE
#define ENABLE_DEPTH_TEST_TRIANGLE_TEXTURE
#define ENABLE_WRITE_ZBUFFER_TRIANGLE_TEXTURE

#define ENABLE_ALPHA_BLEND_LINE_COLOR
#define ENABLE_SRCALPHA_TEST_LINE_COLOR
#define ENABLE_DSTALPHA_TEST_LINE_COLOR
#define ENABLE_DEPTH_TEST_LINE_COLOR
#define ENABLE_WRITE_ZBUFFER_LINE_COLOR

#define ENABLE_ALPHA_BLEND_PIXEL_COLOR
#define ENABLE_SRCALPHA_TEST_PIXEL_COLOR
#define ENABLE_DSTALPHA_TEST_PIXEL_COLOR
#define ENABLE_DEPTH_TEST_PIXEL_COLOR
#define ENABLE_WRITE_ZBUFFER_PIXEL_COLOR


// these need to be enabled incase sh is negative (which means object is not draw by that shader subgroup)
#define ENABLE_RECTANGLE_SUBGROUP_SKIP
#define ENABLE_TRIANGLE_SUBGROUP_SKIP


// sync on transfer or move
//#define SYNC_BEFORE_TRANSFER
//#define SYNC_AFTER_TRANSFER
//#define SYNC_BEFORE_MOVE
//#define SYNC_AFTER_MOVE



//#define DRAW_RECTANGLE_MULTI
//#define DRAW_SPRITE_MULTI
//#define DRAW_TRIANGLE_TEXTURE_MULTI
//#define DRAW_TRIANGLE_COLOR_MULTI




#define COMMAND_LIST_SIZE		( 1 << 16 )
#define COMMAND_LIST_MASK		( COMMAND_LIST_SIZE - 1 )

#define PIXEL_LIST_SIZE			( 1 << 21 )
#define PIXEL_LIST_MASK			( PIXEL_LIST_SIZE - 1 )

// this needs to be set here and in PS2_GPU.cpp
#define PRECOMPUTE_LIST_SIZE	( 1 << 16 )
#define PRECOMPUTE_LIST_MASK	( PRECOMPUTE_LIST_SIZE - 1 )


#define COMMAND_LIST_ITEM_COUNT		(32)
#define PRECOMPUTE_LIST_ITEM_COUNT	(64)





// shader arrangement for drawing triangles for now
#define SHADER_Y_SHIFT	5
#define SHADER_X_MASK	( ( 1 << SHADER_Y_SHIFT ) - 1 )

// size of screen
#define SCREEN_X_SIZE 640
#define SCREEN_Y_SIZE 480

// set the sizes for the global memory areas here
#define GLOBAL_MEM_SCRATCH_SIZE_BYTES			(1024*4)
//#define GLOBAL_MEM_GPUVARS_SIZE_BYTES			(128*8)
//#define GLOBAL_MEM_GPUCLUT_SIZE_BYTES			(512*4)
//#define GLOBAL_MEM_SCRATCH2_SIZE_BYTES			(16*4)
#define GLOBAL_MEM_VRAM_SIZE_BYTES				(1 << 22)
#define GLOBAL_MEM_SVRAM_SIZE_BYTES				(1 << 22)
#define GLOBAL_MEM_PIXELBUF_SIZE_BYTES			(1024*1024*4)
#define GLOBAL_MEM_INPUT_COMM_SIZE_BYTES		(COMMAND_LIST_ITEM_COUNT * COMMAND_LIST_SIZE * 4)
#define GLOBAL_MEM_INPUT_PIX_SIZE_BYTES			(PIXEL_LIST_SIZE * 4)
#define GLOBAL_MEM_XY_LUT_SIZE_BYTES			(16384 * 32 * 4)
//#define GLOBAL_MEM_XOFF_LUT_SIZE_BYTES			(4096 * 32 * 4)
//#define GLOBAL_MEM_YOFF_LUT_SIZE_BYTES			(128 * 32 * 4)

#define GLOBAL_MEM_WORK_AREA_SIZE_BYTES			(PRECOMPUTE_LIST_ITEM_COUNT * PRECOMPUTE_LIST_SIZE * 4)
#define GLOBAL_MEM_STAGING_SIZE_BYTES			(SCREEN_X_SIZE * SCREEN_Y_SIZE * 4)



//layout (local_size_x = 8, local_size_y = 32) in;
layout (local_size_x = 256) in;


// *** EXTERNAL VARS *** //


// SCRATCH SPACE //


layout (std430, binding = 0) buffer TheSpace {

// 16384 but in bytes
uint uScatchSpace [];

};


// *** edge of host accessible buffer ?? *** //
// *TODO* this needs to be a separate block accessible from CPU side
layout (std430, binding = 0) buffer TheCounter {

// the start index of data in input command buffer
// offset#0
uint guStartIndex;

// the end index of data in input command buffer
// offset#1
uint guEndIndex;

// workgroup synchronization counter (important note: MUST initialize to ZERO from CPU side!)
// offset#2
uint auCounter;

// 0- do nothing, 1- update frame buffer from input, 2- update frame buffer from output, 3- update frame buffer both at input and output
// probably not needed since this would be part of the command buffer
// offset#3
uint guUpdateFrameBuffer;


// offset#4
uint guSubgroupSize;
// offset#5
uint guNumSubgroups;
// offset#6
uint guWorkgroupSize;
// offset#7
uint guNumWorkgroups;


// offset#8
//ivec2 cCBPX2;
uint cCBPX2_0;
// offset#9
uint cCBPX2_1;

// offset #10 = byte 6*4 = byte 24
uint global_gpu_vars [ 128 * 2 ];

// offset#10+256=266
// offset #262 = byte 262 * 4 = 1048
uint cLOCAL_CLUT [ 512 ];

};




// VRAM //

layout (std430, binding = 1) buffer FrameBuf {
// the shader representation of vram
// on the ps2 this should be 4MB
uint VRAM [];
};

layout (std430, binding = 1) buffer FrameBuf16 {
// the shader representation of vram
// on the ps2 this should be 4MB
uint16_t VRAM16 [];
};

layout (std430, binding = 1) buffer FrameBuf8 {
// the shader representation of vram
// on the ps2 this should be 4MB
uint8_t VRAM8 [];
};


layout (std430, binding = 1) buffer FrameBuf2 {
uvec2 VRAM2 [];
};
layout (std430, binding = 1) buffer FrameBuf4 {
uvec4 VRAM4 [];
};



// SVRAM //

layout (std430, binding = 2) buffer ShadowFrameBuf {
// the shader representation of vram
uint sVRAM [];
};
layout (std430, binding = 2) buffer ShadowFrameBuf2 {
uvec2 sVRAM2 [];
};
layout (std430, binding = 2) buffer ShadowFrameBuf4 {
uvec4 sVRAM4 [];
};

layout (std430, binding = 2) buffer ShadowFrameBuf16 {
// the shader representation of vram
uint16_t sVRAM16 [];
};

layout (std430, binding = 2) buffer ShadowFrameBuf16_4 {
// the shader representation of vram
u16vec4 sVRAM16_4 [];
};

layout (std430, binding = 2) buffer ShadowFrameBuf8 {
// the shader representation of vram
uint8_t sVRAM8 [];
};

layout (std430, binding = 2) buffer ShadowFrameBuf8_4 {
// the shader representation of vram
u8vec4 sVRAM8_4 [];
};





// input command buffer //

layout (std430, binding = 3) buffer Cmd {
	// the input commands to draw
	uint inputdata [];
};
layout (std430, binding = 3) buffer Cmd2 {
	uvec2 inputdata2 [];
};
layout (std430, binding = 3) buffer Cmd4 {
	uvec4 inputdata4 [];
};


// input pixel buffer //

layout (std430, binding = 4) restrict buffer InputPixels {
uint PixelInput32 [];
};



// LUTs //


layout (std430, binding = 5) restrict readonly buffer LUTBUFXY {
int LUT_XYOFFSET [];
};




// pixel buffer //

layout (std430, binding = 6) buffer ScreenBuf {
uint pixelbuffer32 [];
};
layout (std430, binding = 6) buffer ScreenBuf2 {
uvec2 pixel2buffer32 [];
};
layout (std430, binding = 6) buffer ScreenBuf4 {
uvec4 pixel4buffer32 [];
};



// *** INTERNAL VARS *** //


// shader work area //

layout (std430, binding = 7) buffer sCmd {
	// the pre-compute buffer
	int data [];
};
layout (std430, binding = 7) buffer sCmd2 {
	// the pre-compute buffer
	ivec2 data2 [];
};
layout (std430, binding = 7) buffer sCmd4 {
	// the pre-compute buffer
	ivec4 data4 [];
};


// *** final screen image *** //


layout (std430, binding = 7) restrict writeonly buffer sstaging_buffer {
	// the shader work area
	uvec4 staging_buffer32_4 [];
};















#define ENABLE_PIXELBUF_INTERLACING	


const int c_iFrameBuffer_DisplayWidth = 640;
const int c_iFrameBuffer_DisplayHeight = 960;

const int c_iScreen_MaxWidth = 1024;
const int c_iScreen_MaxHeight = 1024;


//shared int LUT_YNAND [ 32 ];

const int VBlank_Y_LUT [] = { 480, 576 };


const int LUT_YNAND[] = { ~0x1f, ~0x3f, 0, 0, 0, ~0x3f, 0, 0,
							0, ~0x3f, ~0x7f, 0, 0, ~0x1f, 0, 0,
							0, 0, ~0x1f, 0, 0, 0, ~0x1f, 0,
							~0x1f, ~0x3f, 0, 0, 0, ~0x3f, 0, 0 };

int LUT_XNAND[] = { ~0x3f, ~0x3f, 0, 0, 0, ~0x3f, 0, 0, 
							0, ~0x7f, ~0x7f, 0, 0, ~0x3f, 0, 0,
							0, 0, ~0x3f, 0, 0, 0, ~0x3f, 0,
							~0x3f, ~0x3f, 0, 0, 0, ~0x3f, 0, 0 };


int LUT_XSHIFT[] = { 5, 6, 0, 0, 0, 6, 0, 0,
							0, 6, 7, 0, 0, 5, 0, 0,
							0, 0, 5, 0, 0, 0, 5, 0,
							5, 6, 0, 0, 0, 6, 0, 0 };

// ZTE,ZTST
const int c_iLUT_TEST_ZMASK [ 2 ] [ 4 ] = { { 7, 7, 7, 7 },
											{ 0, 7, 5, 4 } };

// equal | greater | less
// ATE,ATST
const int c_iLUT_TEST_AMASK [ 2 ] [ 8 ] = { { 7, 7, 7, 7, 7, 7, 7, 7 },
											{ 0, 7, 4, 5, 1, 3, 2, 6 } };


// ATE/AFAIL
// AFAIL_FBMASK/AFAIL_ZBMASK/AFAIL_FBMASK(!FPSM)/AFAIL_ZBMASK(!FPSM)
const uvec4 c_uvLUT_TEST_AFAIL [ 2 ] [ 4 ] = { { uvec4( -1, -1, -1, -1 ), uvec4( -1, -1, -1, -1 ), uvec4( -1, -1, -1, -1 ), uvec4( -1, -1, -1, -1 ) },
												{ uvec4( 0, 0, 0, 0 ), uvec4( -1, 0, -1, 0 ), uvec4( 0, -1, 0, -1 ), uvec4( -1, -1, 0x00ffffff, 0 ) }
												};

// ZTE/ZTST
// LESS,EQUAL,GREATER,OFFSET
const uvec4 c_uvLUT_TEST_ZTST [ 2 ] [ 4 ] = { { uvec4( -1, -1, -1, 2 ), uvec4( -1, -1, -1, 2 ), uvec4( -1, -1, -1, 2 ), uvec4( -1, -1, -1, 2 ) },
												{ uvec4( 0, 0, 0, -2 ), uvec4( -1, -1, -1, 2 ), uvec4( 0, -1, -1, -1 ), uvec4( 0, 0, -1, 0 ) }
												};



// ATE/ATST
// ATST_LESS,ATST_EQUAL,ATST_GREATER
// iATOffset, iATMask
const uvec4 c_uvLUT_TEST_ATST [ 2 ] [ 8 ] = { { uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ),
												uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ) },
												{ uvec4( 0x00000000, 2, -1, 0 ), uvec4( 0x00ffffff, -2, -1, 0 ), uvec4( 0x000000ff, 0, -1, 0 ), uvec4( 0x0000ffff, -1, -1, 0 ),
												uvec4( 0x0000ff00, -1, 1, 0 ), uvec4( 0x00ffff00, -0x80000000, -1, 0 ), uvec4( 0x00ff0000, 0x7fffffff, -1, 0 ), uvec4( 0x00ff00ff, 0x7fffffff, 1, 0 ) }
												};


// iAnd1/iShift1,iShift2,iAnd3,iShift3
// TPSM
const uvec4 c_uvLUT_TEX02_TPSM [ 64 ] = { uvec4( 0, 0, -1, 0 ), uvec4( 0, 0, -1, 0 ), uvec4( 0, 1, 0xffff, 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ),			// 0-7
											uvec4( 0 ), uvec4( 0 ), uvec4( 0, 1, 0xffff, 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ),							// 8-15
												uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0x0303, 2, 0xff, 0 ), uvec4( 0x0207, 3, 0xf, 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ),	// 16-23
												uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0, 0, 0xff, 24 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ), uvec4( 0 ),						// 24-31
												uvec4( 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),uvec4( 0, 0, 0xf, 24 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),							// 32-39
												uvec4( 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),uvec4( 0, 0, 0xf, 28 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),							// 40-47
												uvec4( 0, 0, -1, 0 ), uvec4( 0, 0, -1, 0 ),uvec4( 0, 1, 0xffff, 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),		// 48-55
												uvec4( 0 ), uvec4( 0 ),uvec4( 0, 1, 0xffff, 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 ),uvec4( 0 ), uvec4( 0 )							// 56-63
												};


const int c_MaxPolygonWidth = 1023;
const int c_MaxPolygonHeight = 511;


const ivec4 vZero = ivec4( 0 );



#define intdivf(op1, op2, fp1, fp2, fpout) (int(( ( float( (op1) ) / float( 1 << (fp1) ) ) / ( float( (op2) ) / float( 1 << (fp2) ) ) ) * float(1 << (fpout))))
#define intdivd(op1, op2, fp1, fp2, fpout) (int(( ( double( (op1) ) / double( 1 << (fp1) ) ) / ( double( (op2) ) / double( 1 << (fp2) ) ) ) * double(1 << (fpout))))

#define intdivf2(op1, op2, fp1, fp2, fpout) (int( ( float( (op1) ) / float( (op2) ) ) * float( 1 << ( (fpout)-((fp1)-(fp2)) ) ) ))


#define intdivfv2(op1, op2, fp1, fp2, fpout) (ivec2( ( vec2( (op1) ) / vec2( (op2) ) ) * float( 1 << ( (fpout)-((fp1)-(fp2)) ) ) ))
#define intdivfv3(op1, op2, fp1, fp2, fpout) (ivec3( ( vec3( (op1) ) / float( (op2) ) ) * float( 1 << ( (fpout)-((fp1)-(fp2)) ) ) ))
#define intdivfv4(op1, op2, fp1, fp2, fpout) (ivec4( ( vec4( (op1) ) / float( (op2) ) ) * float( 1 << ( (fpout)-((fp1)-(fp2)) ) ) ))

// 64-bit integer divides (on a gpu probably not really 64-bit, maybe 52-bit ??)
#define uint64div(op1, op2, fp1, fp2, fpout) uint( ( uint64_t(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / uint64_t(op2) )
#define int64div(op1, op2, fp1, fp2, fpout) int( ( int64_t(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / int64_t(op2) )

#define uint64sdiv(op1, op2, fp1, fp2, fpout) uint( int64_t( uint64_t(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / int64_t(op2) )

#define uint64div2(op1, op2, fp1, fp2, fpout) uvec2( ( u64vec2(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / u64vec2(op2) )
#define int64div2(op1, op2, fp1, fp2, fpout) ivec2( ( i64vec2(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / i64vec2(op2) )
#define uint64div3(op1, op2, fp1, fp2, fpout) uvec3( ( u64vec3(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / u64vec3(op2) )
#define int64div3(op1, op2, fp1, fp2, fpout) ivec3( ( i64vec3(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / i64vec3(op2) )
#define uint64div4(op1, op2, fp1, fp2, fpout) uvec4( ( u64vec4(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / u64vec4(op2) )
#define int64div4(op1, op2, fp1, fp2, fpout) ivec4( ( i64vec4(op1) << ( (fpout)-((fp1)-(fp2)) ) ) / i64vec4(op2) )






shared int group_xinc_shift;
shared int group_yinc_shift;
shared int group_vxinc_shift;


// shared global variables //

shared int xinc;
shared int yinc;

// local count of shader invocations
shared int xxinc;

// global count of shader invocations
shared int gxxinc;

// workgroup synchronization
shared uint NextBarrierSync;


shared int xxmask;

shared int group_x, group_y;
shared int group_xcount, group_ycount;
shared int group_xinc, group_yinc;
shared int group_xshift, group_yshift;
shared int group_xmask, group_ymask;

shared int group_vxinc;
shared int group_vxmask;

shared int group_vyinc;

shared int group_yoffset;


// shared subgroup vars //
shared uint subgroup_local_count;
shared uint subgroup_global_count;
shared uint subgroup_count;
shared uint subgroup_shift;
shared uint subgroup_mask;
shared uint subgroup_size;

// shared workgroup vars //
shared uint workgroup_count;

#define MAX_LOCAL_SUBGROUPS		(8)


// FINAL format for prim data in draw command
// 0: command/prim
// 1: FRAME (lower)
// 2: SCISSOR(lower)
// 3: SCISSOR(upper)
// 4: xy0
// 5: xy1
// 6. xy2
// 7: XYOFFSET (lower)
// 8: z0
// 9: z1
// 10: z2
// 11: XYOFFSET (upper)
// 12: rgba0
// 13: rgba1
// 14: rgba2
// 15: COLCLAMP
// 16: s0/uv0
// 17: s1/uv1
// 18: s2/uv2
// 19: TEX0/2 (lower)
// 20: t0
// 21: t1
// 22: t2
// 23: TEX0/2 (upper)
// 24: q0
// 25: q1
// 26: q2
// 27: PABE (optional)
// 28: f0
// 29: f1
// 30: f2
// 31: FOGCOL (optional)



// format for var set command
// 0: command
// 1: previous0
// 2: previous1
// 3: previous2
// 4: count
// 5: index0
// 6: var0_0
// 7: var0_1
// 8: not used
// 9: index1
// 10: var1_0
// 11: var1_1
// 12: etc

// format for precalc data


// 0
// dz across
// dz across
// draw
// sync

// 4
// dr across
// dg across
// db across
// da across

// 8
// ds/u across
// dt/v across
// dq across
// df across

// 12
// starty0
// endy0
// starty1
// endy1

// 16
// x0 left
// x0 right
// dx0 left
// dx0 right

// 20
// z0 left
// z0 left
// dz0 left
// dz0 left

// 24
// r0 left
// g0 left
// b0 left
// a0 left

// 28
// dr0 left
// dg0 left
// db0 left
// da0 left

// 32
// s/u0 left
// t/v0 left
// q0 left
// f0 left

// 36
// ds/u0 left
// dt/v0 left
// dq0 left
// df0 left

// 40
// x1 left
// x1 right
// dx1 left
// dx1 right

// 44
// z1 left
// z1 left
// dz1 left
// dz1 left

// 48
// r1 left
// g1 left
// b1 left
// a1 left

// 52
// dr1 left
// dg1 left
// db1 left
// da1 left

// 56
// s/u1 left
// t/v1 left
// q1 left
// f1 left

// 60
// ds/u1 left
// dt/v1 left
// dq1 left
// df1 left


// vars to set: ALPHAX(fit into 32-bits), CLAMPX(64), COLCLAMP(1), DIMX(64), DTHE(1), FBAX(1), FOGCOL(24), FRAMEX(64), MIPTBP1X(64), MIPTBP2X(64),PABE(1),SCANMSK(2)
// vars to set: SCISSORX(64),TESTX(19),TEX0X(64),TEX1X(64),TEX2X(64),TEXA(fit into 32),TEXCLUT(22),ZBUFX(33)

// bits to set: COLCLAMP(1),DTHE(1),FBAX(2),PABE(1),SCANMSK(2),ZMSK(2)
// slots to set: ALPHAX(2),CLAMPX(4),DIMX(1),FOGCOL(1),(FRAMEX(2)),FBMSKX(2),(MIPTBP1X(4)),(MIPTBP2X(4)),TESTX(2),TEX0/2X(4),(TEX1X(4)),TEXA(1),TEXCLUT(1),ZBUF(2)

// small vars: COLCLAMP,DTHE,PABE,FBA,(ZMSK),SCANMSK
// simple vars: DIMX,FOGCOL,SCISSOR,ALPHA,(FBMSK),TEXA

// vars with dependencies: TEST,FRAME,TEX0,TEX1,TEX2,CLAMP,TEXCLUT,MIPTBP1,MIPTBP2,ZBUF
// other complex vars: 



// slots: 2+4+1+1+2+2+4+2+4+1+1+2

// vars: FBMSK, ZMSK, PABE, FBA, ALPHA(A,B,C,D,FIX),COLCLAMP,FPSM,ZPSM,DRAWPSM,ZBUFPSM
// vars: FrameBufferStartOffset32, FrameBufferWidth_Pixels, ZBufferStartOffset32

// vars: TEST, FGE, DATE, DATM, ABE, ZTE, ATE, iATMask, iATOffset
// vars: AREF, ATST(LESS,GREATER,EQUAL), ZTST(LESS,GREATER,EQUAL)


// format for var set command
// 0: command
// 1: count
// 2: not used
// 3: not used
// 4: index0
// 5: var0_0
// 6: var0_1
// 7: not used
// 8: index1
// 9: var1_0
// 10: var1_1
// 11: not used
// 12: etc


#define MAX_GLOBAL_SUBGROUPS	(32)

#define MAX_LOCAL_SUBGROUPS		(8)
#define MAX_NUM_CONTEXTS		(2)



// 8 bytes * 8 * 128 = 8 * 1k = 8k bytes
shared uvec2 uvps2gpu_vars [ MAX_LOCAL_SUBGROUPS ] [ 128 ];

// 4 bytes * 8 * 256 = 8 * 1k = 8k bytes
//shared uint LOCAL_CLUT [ MAX_LOCAL_SUBGROUPS ] [ 256 * 2 ];
shared uint LOCAL_CLUT [ MAX_LOCAL_SUBGROUPS ] [ 256 ];


// 8 bytes * 8 = 64 bytes
shared ivec2 CBPX2 [ MAX_LOCAL_SUBGROUPS ];

// 8 * 8 = 64 bytes
shared uvec2 uvDIMX_DIMX0_DIMX1_LUT [ MAX_LOCAL_SUBGROUPS ];


// localsubgroup/context/wms or wmt
// Tex_And/Tex_Or/Tex_Min/Tex_Max

// 16 bytes * 8 * 4 = 512 bytes
shared uvec4 uvCLAMP_LUT_WMS4 [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ] [ 4 ];

// 16 bytes * 8 * 4 = 512 bytes
shared uvec4 uvCLAMP_LUT_WMT4 [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ] [ 4 ];




// 16 bytes * 8 * 2 = 256 bytes
shared uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 bytes * 8 * 2 = 256 bytes
shared uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 bytes * 8 * 2 = 256 bytes
shared uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 bytes * 8 * 2 = 256 bytes
shared uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 bytes * 8 * 2 = 256 bytes
// 256 bytes * 2 = 512 total bytes
shared uvec4 uvTEST_ATE_AREF_ATST_AFAIL_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];
shared uvec4 uvTEST_ZTE_ZTST_DATE_DATM_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 bytes * 8 * 2 = 256 bytes
shared uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];
shared uvec4 uvTEX02_TW_TH_TWMASK_THMASK_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];
shared uvec4 uvTEX02_TCC_TFX_CPSM_CSA_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];


// 8 * 8 * 2 = 64 * 2 = 128 bytes
shared uvec2 uvALPHA_ABCD_FIX_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];

// 16 * 8 = 128 bytes
shared uvec4 uvTEXA_TA0_TA1_AEM_LUT [ MAX_LOCAL_SUBGROUPS ];


// 4 * 8 * 2 = 32 * 2 = 64 bytes
//shared uint uFBA_FBA_LUT [ MAX_LOCAL_SUBGROUPS ] [ MAX_NUM_CONTEXTS ];


// draw ranges for local subgroups
// draw start line (inclusive), draw end line (not inclusive)
// 8 * 8 bytes = 64 bytes
shared ivec2 ivDrawRange [ MAX_LOCAL_SUBGROUPS ];


// 4k of shared memory used, leaves another 4k for drawing bitmap
// 4k / 8 max subgroups = 512 bytes

// 512 bytes * 8 bits per byte = 4k bits per subgroup -> should be enough, can do multiple loops or at least just testing
// sync vars = 4 * 8 max subgroups = 32 bytes


// update clut for just one subgroup
// uIndex - the index for TEX0/2
void update_clut ( uint uIndex )
{
	const uint c_utex02_start_idx = 0x06;
	const uint c_utexclut_start_idx = 0x1c;

	uint subgroup_local_id = gl_SubgroupID;

	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	int xxid = int( gl_LocalInvocationIndex );

	uvec2 tex02;
	uint varidx2;

	int lCLD, CLUTBufBase32, PixelFormat, CLUTPixelFormat, CLUTOffset, CLUTStoreMode;
	int clut_width, clut_x, clut_y;
	int lPixelCount, lPixelSize;
	
	int x, y;
	
	int lIndex;
	uint bgr;

	int offset32, xoffset32, yoffset32, yoffset32_xor;
	int TEX0_0, TEX0_1, TEXCLUT, TPSM, CBP, CPSM, CSM, CSA, CLD, CBW, COU, COV;
	int CBPX0, CBPX1;
	int CLUTPSM;

	ivec2 CBP2;

	uvec4 vPixel32, vDestPixel32;
	ivec4 idx4, x4, y4, ivPtr, vIdx, vOffset;
	
	//u16 *ptr_clut16;
	//u32 *ptr_clut32;
	
	// get context
	uint context = uIndex & 1;

	// load clamp for context
	varidx2 = c_utex02_start_idx + context;

	tex02 = uvps2gpu_vars [ subgroup_local_id ] [ varidx2 ];

	//uIndex <<= 6;

	//TEX0_0 = int( inputdata[ uIndex + 0 ] );
	//TEX0_1 = int( inputdata[ uIndex + 1 ] );
	TEX0_0 = int( tex02.x );
	TEX0_1 = int( tex02.y );

	CLD = ( TEX0_1 >> 29 ) & 0x7;

	// check if should not load CLUT
	if ( subgroupAll( CLD == 0 ) )
	{
		return;
	}


	TPSM = ( TEX0_0 >> 20 ) & 0x3f;

	// check if psm is an indexed color format that requires CLUT
	//if ( ( ( TEX02.PSM >> 4 ) == 0 ) || ( ( TEX02.PSM >> 4 ) == 0x3 ) )
	if ( subgroupAll( ( ( TPSM >> 4 ) == 0 ) || ( ( TPSM >> 4 ) == 0x3 ) ) )
	{
		// this is not an indexed pixel format so has nothing to do with CLUT
		return;
	}

	TEXCLUT = int( uvps2gpu_vars [ subgroup_local_id ] [ c_utexclut_start_idx ][0] );
	
	CBP = ( TEX0_1 >> 5 ) & 0x3fff;

	CBP2 = CBPX2 [ subgroup_local_id ];
	//CBPX0 = CBPX2[0];
	//CBPX1 = CBPX2[1];
	CBPX0 = CBP2.x;
	CBPX1 = CBP2.y;

	if ( subgroupAll( ( CLD == 4 ) && ( CBP == CBPX0 ) ) )
	{
		return;
	}

	if ( subgroupAll( ( CLD == 5 ) && ( CBP == CBPX1 ) ) )
	{
		return;
	}


	CPSM = ( TEX0_1 >> 19 ) & 0xf;
	CSM = ( TEX0_1 >> 23 ) & 0x1;
	CSA = ( TEX0_1 >> 24 ) & 0x1f;

	CBW = ( TEXCLUT >> 0 ) & 0x3f;
	COU = ( TEXCLUT >> 6 ) & 0x3f;
	COV = ( TEXCLUT >> 12 ) & 0x3ff;
	


	// check cld
	switch ( CLD )
	{
		case 0:
			// do not load into temp CLUT //
			//return;
			break;
			
		case 1:
			// always load //
			break;
			
		case 2:
			// load and copy CBP to CBP0 //
			//CBP0 = CBP;
			CBPX0 = CBP;
			break;
			
		case 3:
			// load and copy CBP to CBP1 //
			//CBP1 = CBP;
			CBPX1 = CBP;
			break;
			
		case 4:
			// load and copy CBP to CBP0 only if CBP<>CBP0 //
			//if ( CBP == CBPX0 ) 
			//{
			//	return;
			//}
			//else
			{
				CBPX0 = CBP;
			}
			break;
			
		case 5:
			// load and copy CBP to CBP1 only if CBP<>CBP1 //
			//if ( CBP == CBPX1 )
			//{
			//	return;
			//}
			//else
			{
				CBPX1 = CBP;
			}
			break;

	}	// end switch ( CLD )

	

	// clut offset ??
	CLUTOffset = CSA;

	// the clut offset is actually CSA times 16 pixels
	CLUTOffset <<= 4;
	CSA <<= 4;
	
	// get base pointer to color lookup table (32-bit word address divided by 64)
	CLUTBufBase32 = CBP << 6;
	CBP <<= 6;

	// adjust for shader (32-bit vs 16-bit)
	//CLUTBufBase32 <<= 1;

	// get pointer into CLUT in local memory
	//ptr_clut32 = & ( RAM32 [ CLUTBufBase32 ] );
	//ptr_clut16 = (u16*)ptr_clut32;
	
	
	

	//if ( xxid == 0 )
	//{
	//	CBPX2[0] = CBPX0;
	//	CBPX2[1] = CBPX1;
	//}

	CBP2 = ivec2( CBPX0, CBPX1 );
	CBPX2 [ subgroup_local_id ] = CBP2;
	
	// transfer pixels

	// the lookup tables use this shifted right one
	CLUTPSM = CPSM >> 1;

	// need to know if pixels are 4/8-bit
	if ( subgroupAll( ( TPSM & 7 ) > 2 ) )
	{
		// will need to write into the internal CLUT
		
		// get the number of pixels to transfer
		if ( ( TPSM & 0x4 ) != 0 )
		{
			// 4-bit pixels - 16 colors
			lPixelCount = 16;
			
		}
		else
		{
			// 8-bit pixels - 256 colors
			lPixelCount = 256;
			
		}

		
	
		if ( subgroupAll( CSM == 0 ) )
		{
			// CSM1 //
			//CLUT_LUT = ucCLUT_Lookup_CSM01_4bpp;
			//CLUT_LUT = (u16*) ucCLUT_Lookup_CSM01;
			
			// need to determine size of pixels to transfer into clut
			// need to know if pixels are 16 or 32 bit
			if ( subgroupAll( ( CPSM & 0x2 ) != 0 ) )
			{
				// 16-bit pixels //
				
				//for ( lIndex = int( lxid ); lIndex < lPixelCount; lIndex += int( lxinc ) )
				for ( lIndex = int( lxid ) << 2; lIndex < lPixelCount; lIndex += int( lxinc ) << 2 )
				{

					idx4 = lIndex + ivec4( 0, 1, 2, 3 );
					x4 = ( idx4 & 0x7 ) | ( ( idx4 & 0x10 ) >> 1 );
					y4 = ( ( idx4 >> 4 ) & 0xe ) | ( ( idx4 >> 3 ) & 1 );

					ivPtr = ( x4 & 0x3f ) | ( ( y4 & 0x3f ) << 7 );

					// need x/y/format
					vIdx = ivPtr | ( CLUTPSM << 14 );
					vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
					vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
					vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
					vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

					// put in the remainder of the x-bits that don't get swizzled
					//vOffset |= ( x4 & ~0x3f ) << 6;	//( 5 + ( CLUTPSM & 1 ) );


					// add in the bits for the y
					//vOffset += ( y4 & DYNAND ) * int( FBW );
					//vOffset += ( y4 & ~0x3f );

					// shift left dst offset by one for 16-bit pixels
					vOffset += int( CBP ) << 1;	// << ( CLUTPSM & 1 );

					// x-bit pixels //

					// load pixels from framebuffer as 32-bit for simplicity //

					// shift offset right 1 if 16-bit pixels (if loading from 32-bit pointer)
					//vIdx = vOffset >> ( CLUTPSM & 1 );
					vIdx = vOffset;

					// load pixels
					vDestPixel32[0] = uint( VRAM16 [ vIdx[0] ] );
					vDestPixel32[1] = uint( VRAM16 [ vIdx[1] ] );
					vDestPixel32[2] = uint( VRAM16 [ vIdx[2] ] );
					vDestPixel32[3] = uint( VRAM16 [ vIdx[3] ] );


					// shift pixel right if 16-bit pixel and was in upper part of 32-bits
					//vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

					// save raw destination pixel
					//vDPixelX = vDestPixel32;

					// mask pixel if 24-bit or 16-bit
					vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (CPSM & 3) << 3 ) ) );

					//bgr = VRAM [ offset32 ];

					// pull pixels from clut
					vIdx = ( CSA + idx4 ) & 0xff;
					vPixel32[0] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[0] ];
					vPixel32[1] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[1] ];
					vPixel32[2] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[2] ];
					vPixel32[3] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[3] ];

					// put 16-bit pixel into 32-bit pixel
					vPixel32 = bitfieldInsert( vPixel32, vDestPixel32, ( CSA >> 4 ) & 0x10, 16 );
					
					// 512-entry 16-bit pixels
					//LOCAL_CLUT [ subgroup_local_id ] [ ( CSA + lIndex ) & 511 ] = bgr & 0xffff;
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[0] ] = vPixel32[0];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[1] ] = vPixel32[1];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[2] ] = vPixel32[2];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[3] ] = vPixel32[3];
				}

			}
			else
			{
				// 32-bit pixels //
				
				// only 4-bits of Offset are valid
				CLUTOffset &= 255;
				CSA &= 0xff;
				
				// transfer pixels
				//for ( lIndex = int( lxid ); lIndex < lPixelCount; lIndex += int( lxinc ) )
				for ( lIndex = int( lxid ) << 2; lIndex < lPixelCount; lIndex += int( lxinc ) << 2 )
				{

					idx4 = lIndex + ivec4( 0, 1, 2, 3 );
					x4 = ( idx4 & 0x7 ) | ( ( idx4 & 0x10 ) >> 1 );
					y4 = ( ( idx4 >> 4 ) & 0xe ) | ( ( idx4 >> 3 ) & 1 );

					ivPtr = ( x4 & 0x3f ) | ( ( y4 & 0x3f ) << 7 );

					// need x/y/format
					vIdx = ivPtr | ( CLUTPSM << 14 );
					vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
					vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
					vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
					vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

					// put in the remainder of the x-bits that don't get swizzled
					//vOffset |= ( x4 & ~0x3f ) << 5;	//( 5 + ( CLUTPSM & 1 ) );


					// add in the bits for the y
					//vOffset += ( y4 & DYNAND ) * int( FBW );
					//vOffset += ( y4 & ~0x1f );

					// shift left dst offset by one for 16-bit pixels, 0 for 32-bit pixels
					vOffset += int( CBP ) << 0;	// << ( CLUTPSM & 1 );


					// x-bit pixels //

					// load pixels from framebuffer as 32-bit for simplicity //

					// shift offset right 1 if 16-bit pixels (if loading from 32-bit pointer)
					//vIdx = vOffset >> ( CLUTPSM & 1 );
					vIdx = vOffset;

					// load pixels
					vDestPixel32[0] = VRAM [ vIdx[0] ];
					vDestPixel32[1] = VRAM [ vIdx[1] ];
					vDestPixel32[2] = VRAM [ vIdx[2] ];
					vDestPixel32[3] = VRAM [ vIdx[3] ];


					// shift pixel right if 16-bit pixel and was in upper part of 32-bits
					//vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

					// save raw destination pixel
					//vDPixelX = vDestPixel32;

					// mask pixel if 24-bit or 16-bit
					vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (CPSM & 3) << 3 ) ) );

					//bgr = VRAM [ offset32 ];

					// pull pixels from clut
					//vPixel32[0] = LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[0] ) & 0xff ];
					//vPixel32[1] = LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[1] ) & 0xff ];
					//vPixel32[2] = LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[2] ) & 0xff ];
					//vPixel32[3] = LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[3] ) & 0xff ];

					// put 16-bit pixel into 32-bit pixel
					//bitfieldInsert( vPixel32, vDestPixel32, ( CSA >> 4 ) & 0x10, 16 );
					
					// 512-entry 16-bit pixels
					//LOCAL_CLUT [ subgroup_local_id ] [ ( CSA + lIndex ) & 511 ] = bgr & 0xffff;
					LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[0] ) & 0xff ] = vDestPixel32[0];
					LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[1] ) & 0xff ] = vDestPixel32[1];
					LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[2] ) & 0xff ] = vDestPixel32[2];
					LOCAL_CLUT[ subgroup_local_id ][ ( CSA + idx4[3] ) & 0xff ] = vDestPixel32[3];
				}
			}
		}
		else
		{
			// CSM2 //
			//CLUT_LUT = (u16*) ucCLUT_Lookup_CSM02;
			
			// CBW is in units of pixels/64
			clut_width = CBW << 6;
			CBW <<= 6;
			
			// COU is in units of pixels/16
			clut_x = COU << 4;
			COU <<= 4;
			
			// get clut y in units of pixels
			clut_y = COV;
			
			// in CSM2 mode, the size of the pixels is always 16-bit and can only specify PSMCT16 //
			
			
			// 16-bit pixels //


			//yoffset32_xor = LUT_YOFFSET [ ( clut_y & 0x7f ) | ( CLUTPSM << 7 ) ];
			//yoffset32 = ( clut_y & LUT_YNAND[ CLUTPSM ] ) * ( clut_width );

			//for ( lIndex = xxid; lIndex < lPixelCount; lIndex++ )
			//for ( lIndex = xxid; lIndex < lPixelCount; lIndex += xxinc )
			for ( lIndex = int( lxid ); lIndex < lPixelCount; lIndex += int( lxinc ) )
			{

					idx4 = lIndex + ivec4( 0, 1, 2, 3 );
					//x4 = ( idx4 & 0x7 ) | ( ( idx4 & 0x10 ) >> 1 );
					//y4 = ( ( idx4 >> 4 ) & 0xe ) | ( ( idx4 >> 3 ) & 1 );

					// add the clut x
					x4 = idx4 + COU;
					y4 = ivec4( COV );

					ivPtr = ( x4 & 0x3f ) | ( ( y4 & 0x3f ) << 7 );

					// need x/y/format
					vIdx = ivPtr | ( CLUTPSM << 14 );
					vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
					vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
					vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
					vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

					// put in the remainder of the x-bits that don't get swizzled
					vOffset |= ( x4 & ~0x3f ) << 6;	//( 5 + ( CLUTPSM & 1 ) );

					// add in the bits for the y
					//vOffset += ( y4 & DYNAND ) * int( FBW );
					vOffset += ( y4 & ~0x3f );

					// shift left dst offset by one for 16-bit pixels
					vOffset += int( CBP ) << 1;	// << ( CLUTPSM & 1 );

					// x-bit pixels //

					// load pixels from framebuffer as 32-bit for simplicity //

					// shift offset right 1 if 16-bit pixels (if loading from 32-bit pointer)
					//vIdx = vOffset >> ( CLUTPSM & 1 );
					vIdx = vOffset;

					// load pixels
					vDestPixel32[0] = uint( VRAM16 [ vIdx[0] ] );
					vDestPixel32[1] = uint( VRAM16 [ vIdx[1] ] );
					vDestPixel32[2] = uint( VRAM16 [ vIdx[2] ] );
					vDestPixel32[3] = uint( VRAM16 [ vIdx[3] ] );


					// shift pixel right if 16-bit pixel and was in upper part of 32-bits
					//vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

					// save raw destination pixel
					//vDPixelX = vDestPixel32;

					// mask pixel if 24-bit or 16-bit
					vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (CPSM & 3) << 3 ) ) );

					//bgr = VRAM [ offset32 ];

					// pull pixels from clut
					vIdx = ( CSA + idx4 ) & 0xff;
					vPixel32[0] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[0] ];
					vPixel32[1] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[1] ];
					vPixel32[2] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[2] ];
					vPixel32[3] = LOCAL_CLUT[ subgroup_local_id ][ vIdx[3] ];

					// put 16-bit pixel into 32-bit pixel
					vPixel32 = bitfieldInsert( vPixel32, vDestPixel32, ( CSA >> 4 ) & 0x10, 16 );
					
					// 512-entry 16-bit pixels
					//LOCAL_CLUT [ subgroup_local_id ] [ ( CSA + lIndex ) & 511 ] = bgr & 0xffff;
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[0] ] = vPixel32[0];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[1] ] = vPixel32[1];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[2] ] = vPixel32[2];
					LOCAL_CLUT[ subgroup_local_id ][ vIdx[3] ] = vPixel32[3];
			}
		}
		
	}	// end if ( subgroupAll( ( TPSM & 7 ) > 2 ) )
	
}


// update just clamp for one subgroup and context
// to update all just have all subgroups make the call with both indexes for CLAMP0 AND CLAMP1
// note: update TEX0 first if initializing
// dependencies: TEX0
void update_CLAMP ( uint uIndex )
{
	const uint c_uclamp_start_idx = 0x08;
	const uint c_utex02_start_idx = 0x06;

	uint subgroup_local_id = gl_SubgroupID;

	uvec2 clamp2;
	uvec2 tex02;

	uvec4 value0, value1, value2, value3;

	uint varidx1, varidx2;

	uint TW, TH, TexWidth, TexHeight, TexWidth_Mask, TexHeight_Mask;
	uint WMS, WMT, MINU, MAXU, MINV, MAXV;

	// get context
	uint context = uIndex & 1;

	// load clamp for context
	varidx1 = c_uclamp_start_idx + context;

	// get value of clamp for context
	clamp2 = uvps2gpu_vars [ subgroup_local_id ] [ varidx1 ];

	WMS = ( clamp2.x >> 0 ) & 0x3;
	WMT = ( clamp2.x >> 2 ) & 0x3;

	MINU = ( clamp2.x >> 4 ) & 0x3ff;
	MAXU = ( clamp2.x >> 14 ) & 0x3ff;

	MINV = ( ( clamp2.x >> 24 ) & 0xff ) | ( ( clamp2.y & 0x3 ) << 8 );
	MAXV = ( clamp2.y >> 2 ) & 0x3ff;

	// load clamp for context
	varidx2 = c_utex02_start_idx + context;

	tex02 = uvps2gpu_vars [ subgroup_local_id ] [ varidx2 ];

	TW = ( tex02.x >> 26 ) & 0xf;
	TH = ( ( tex02.x >> 30 ) & 0x3 ) | ( ( tex02.y & 0x3 ) << 2 );

	TexWidth = 1 << TW;
	TexHeight = 1 << TH;
	TexWidth_Mask = TexWidth - 1;
	TexHeight_Mask = TexHeight - 1;

	// Tex_And/Tex_Or for first 3 have these values
	// then -2047/2047, 0/Tex_Mask, MIN/MAX
	value0 = uvec4( TexHeight_Mask, 0, -2047, 2047 );
	value1 = uvec4( TexHeight_Mask, 0, 0, TexHeight_Mask );
	value2 = uvec4( TexHeight_Mask, 0, MINV, MAXV );
	value3 = uvec4( MINV & TexHeight_Mask, MAXV & TexHeight_Mask, -2047, 2047 );

	uvCLAMP_LUT_WMT4 [ subgroup_local_id ] [ context ] [ 0 ] = value0;
	uvCLAMP_LUT_WMT4 [ subgroup_local_id ] [ context ] [ 1 ] = value1;
	uvCLAMP_LUT_WMT4 [ subgroup_local_id ] [ context ] [ 2 ] = value2;
	uvCLAMP_LUT_WMT4 [ subgroup_local_id ] [ context ] [ 3 ] = value3;

	value0 = uvec4( TexWidth_Mask, 0, -2047, 2047 );
	value1 = uvec4( TexWidth_Mask, 0, 0, TexWidth_Mask );
	value2 = uvec4( TexWidth_Mask, 0, MINU, MAXU );
	value3 = uvec4( MINU & TexWidth_Mask, MAXU & TexWidth_Mask, -2047, 2047 );

	uvCLAMP_LUT_WMS4 [ subgroup_local_id ] [ context ] [ 0 ] = value0;
	uvCLAMP_LUT_WMS4 [ subgroup_local_id ] [ context ] [ 1 ] = value1;
	uvCLAMP_LUT_WMS4 [ subgroup_local_id ] [ context ] [ 2 ] = value2;
	uvCLAMP_LUT_WMS4 [ subgroup_local_id ] [ context ] [ 3 ] = value3;

	// set precalculated vars
	uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ context ] = uvCLAMP_LUT_WMS4 [ subgroup_local_id ] [ context ] [ WMS ];
	uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ context ] = uvCLAMP_LUT_WMT4 [ subgroup_local_id ] [ context ] [ WMT ];
}




void update_FRAME( uint uIndex )
{
	const uint c_uFRAME_start_idx = 0x4c;

	uint subgroup_local_id = gl_SubgroupID;

	uint context = uIndex & 1;

	uvec2 FRAME2;

	uint varidx;

	uint FRAME, FBMSK, FBP, FBW, FPSM;

	varidx = c_uFRAME_start_idx + context;

	FRAME2 = uvps2gpu_vars [ subgroup_local_id ] [ varidx ];

	FRAME = FRAME2 [ 0 ];
	FBMSK = FRAME2 [ 1 ];

	FBP = FRAME & 0x1ff;
	FBW = ( FRAME >> 16 ) & 0x3f;
	FPSM = ( FRAME >> 24 ) & 0x3f;

	// the offset is two times further because of the data arrangement in shader
	//FrameBufferStartOffset32 = FBP << 11;
	//FrameBufferStartOffset32 <<= 1;
	FBP <<= 11;

	//FrameBufferWidth_Pixels = FBW << 6;
	FBW <<= 6;

	//DRAWPSM = FPSM >> 1;

	// store precalculated variables
	uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ context ] = uvec4( FBP, FBW, FPSM, FBMSK );
}

void update_ZBUF( uint uIndex )
{
	const uint c_uZBUF_start_idx = 0x4e;

	uint subgroup_local_id = gl_SubgroupID;

	uint context = uIndex & 1;

	uvec2 ZBUF2;

	uint varidx;

	uint ZBUF, ZMSK, ZBP, ZPSM, ZBUFPSM;

	varidx = c_uZBUF_start_idx + context;

	ZBUF2 = uvps2gpu_vars [ subgroup_local_id ] [ varidx ];

	ZBUF = ZBUF2 [ 0 ];
	ZBP = ZBUF & 0x1ff;
	ZPSM = ( ZBUF >> 24 ) & 0xf;
	ZMSK = ZBUF2 [ 1 ] & 1;
	//ZMSK = framezbuf.w;

	//ZBufferStartOffset32 = ZBP << 11;
	//ZBufferStartOffset32 <<= 1;
	ZBP <<= 11;

	// add on the missing bits for the zpsm
	ZPSM |= 0x30;

	ZBUFPSM = ZPSM >> 1;

	uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ context ] = uvec4( ZBP, ZPSM, ZBUFPSM, ZMSK );
}


void update_TEX0( uint uIndex )
{
	const uint c_uTEX0_start_idx = 0x06;

	uint subgroup_local_id = gl_SubgroupID;

	uint context = uIndex & 1;

	uvec2 TEX02;

	uint varidx;

	uint TEX0_0, TEX0_1, TBP0, TBW, TPSM, TEXPSM, TW, TH, TWMASK, THMASK, TCC, TFX;
	uint CBP, CPSM, CSM, CSA, CLD;

	varidx = c_uTEX0_start_idx + context;

	TEX02 = uvps2gpu_vars [ subgroup_local_id ] [ varidx ];

	// TEX0 //

	// get the texture variabls
	TEX0_0 = TEX02 [ 0 ];
	TEX0_1 = TEX02 [ 1 ];

	TBP0 = ( TEX0_0 >> 0 ) & 0x3fff;

	//TextureBufferStartOffset32 = ( TBP0 << 6 );
	//TextureBufferStartOffset32 <<= 1;
	TBP0 <<= 6;

	TBW = ( TEX0_0 >> 14 ) & 0x3f;

	//TextureBufferWidth_Pixels = TBW << 6;
	TBW <<= 6;

	TPSM = ( TEX0_0 >> 20 ) & 0x3f;

	TEXPSM = TPSM >> 1;

	TW = ( TEX0_0 >> 26 ) & 0xf;
	TH = ( ( TEX0_0 >> 30 ) & 0x3 ) | ( ( TEX0_1 & 0x3 ) << 2 );

	TW = 1 << TW;
	TH = 1 << TH;
	TWMASK = TW - 1;
	THMASK = TH - 1;

	TCC = ( TEX0_1 >> 2 ) & 0x1;
	TFX = ( TEX0_1 >> 3 ) & 0x3;


	// color lookup table pixel format variables //

	//CBP = ( TEX0_1 >> 5 ) & 0x3fff;

	//CLUTStartOffset32 = ( CBP << 6 );
	//CLUTStartOffset32 <<= 1;

	CPSM = ( TEX0_1 >> 19 ) & 0xf;
	CSM = ( TEX0_1 >> 23 ) & 0x1;
	CSA = ( TEX0_1 >> 24 ) & 0x1f;
	CLD = ( TEX0_1 >> 29 ) & 0x7;

	
	// CLUT setup //
	/*
	if ( CSM == 0 )
	{
		// CSM1 //
		
		if ( ( CPSM & 0x2 ) != 0 )
		{
			// 4-bit pixels - 16 colors
			// 16-bit pixels in CLUT //
			CSA &= 0x1f;
		}
		else
		{
			// 32-bit pixels in CLUT //
			CSA &= 0xf;
		}
		
	}
	else
	{
		// CSM2 //
		
		// when these pixels load into temporary clut, they should be at index 0
		CSA = 0;
	}
	*/

	CSA &= ( ( CPSM & 0x2 ) << 3 ) | 0xf;
	CSA &= ( CSM - 1 );
	
	CSA <<= 4;
	//ptr_clut16 = & ( InternalCLUT [ CLUTOffset ] );

	// note: mind as well load CPSM with TPSM if it isn't a lookup pixel type format
	if ( ( TPSM & 7 ) < 3 )
	{
		CPSM = TPSM;
	}

	uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ context ] = uvec4( TBP0, TBW, TPSM, TEXPSM );
	uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ context ] = uvec4( TW, TH, TWMASK, THMASK );
	uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ context ] = uvec4( TCC, TFX, CPSM, CSA );

}


void update_TEST( uint uIndex )
{
	const uint c_uTEST_start_idx = 0x47;

	uint subgroup_local_id = gl_SubgroupID;

	uint context = ( uIndex & 1 ) ^ 1;

	uvec2 TEST2;

	uint varidx;

	uint TEST, DATE, DATM, ZTE, ZTST, ATE, ATST, AREF, AFAIL;

	varidx = c_uTEST_start_idx + context;

	TEST2 = uvps2gpu_vars [ subgroup_local_id ] [ varidx ];

	// pixel test (TEST) //

	// pixel test
	TEST = TEST2 [ 0 ];


	// destination alpha test
	//DATE = ( ( TEST >> 14 ) & 1 ) << 31;
	//DATM = ( ( TEST >> 15 ) & 1 ) << 31;
	DATE = ( TEST >> 14 ) << 31;
	DATM = ( TEST >> 15 ) << 31;
	
	// depth test
	ZTE = ( TEST >> 16 ) & 1;
	ZTST = ( TEST >> 17 ) & 0x3;

	// alpha test
	ATE = TEST & 1;
	ATST = ( TEST >> 1 ) & 0x7;
	AREF = ( TEST >> 4 ) & 0xff;
	AFAIL = ( TEST >> 12 ) & 0x3;

	uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ context ] = uvec4( ATE, AREF, ATST, AFAIL );
	uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ context ] = uvec4( ZTE, ZTST, DATE, DATM );
}


void update_ALPHA( uint uIndex )
{
	const uint c_uALPHA_start_idx = 0x42;

	uint subgroup_local_id = gl_SubgroupID;

	uint context = uIndex & 1;

	uvec2 ALPHA2;

	uint varidx;

	uint ALPHA, ALPHA_FIX;
	uvec4 ALPHA_X;

	varidx = c_uALPHA_start_idx + context;

	ALPHA2 = uvps2gpu_vars [ subgroup_local_id ] [ varidx ];

	ALPHA = ALPHA2 [ 0 ];

	// no alpha blending if disabled
	//ALPHA &= -ABE;

	ALPHA_X [ 0 ] = ( ALPHA >> 0 ) & 0x3;
	ALPHA_X [ 1 ] = ( ALPHA >> 2 ) & 0x3;
	ALPHA_X [ 2 ] = ( ALPHA >> 4 ) & 0x3;
	ALPHA_X [ 3 ] = ( ALPHA >> 6 ) & 0x3;
	ALPHA_FIX = ALPHA2[ 1 ] << 24;

	uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ context ] = uvec2( pack32( u8vec4( ALPHA_X ) ), ALPHA_FIX );
}

// variables required to send here for updating:
// ALPHA(0x42,0x43),CLAMP(0x08,0x09),DIMX(0x44),DTHE(0x45),FBA(0x4a,0x4b),FRAME(0x4c,0x4d),MIPTBP1,MIPTBP2,SCANMSK,TEST(0x47,0x48),TEX0(0x06,0x07),TEX1(0x14,0x15),TEX2(0x16,0x17),TEXA(0x3b),TEXCLUT(0x1c),ZBUF(0x4e,0x4f)
// variables that can optionally be sent here (but must be sent with draw command currently, so not needed):
// COLCLAMP,FOGCOL,PABE,SCISSOR,XYOFFSET
void update_vars( uint uIndex )
{
	uint subgroup_local_id = gl_SubgroupID;

	const ivec2 TEX2MASK = ivec2( 0x03f00000, 0xffffffe0 );
	uint MASK;

	uint count;
	uint idx;

	uint varidx;
	uint value0;
	uint value1;

	uvec2 value2;
	uvec2 DIMX2, DTHE2, TEXA2, FBA2;

	uvec4 var4;

	uvec2 value21;

	// 32 elements in the input command data
	uIndex <<= 5;


	// test all the inputs
	//sVRAM[0] = uIndex;
	//for ( int i = 0; i < 16; i++ )
	//{
	//	sVRAM[i+1] = inputdata [ uIndex + i ];
	//}


	
	count = inputdata [ uIndex + 4 ];

	uIndex >>= 2;

	// vars that need updating:
	// TEX0(2)(64),TEX1(2)(64),CLAMP(2)(64),TEXCLUT(32),TEXA(64),FOGCOL(32),SCISSOR(2)(64),ALPHA(2),DIMX,DTHE,COLCLAMP,TEST(2),PABE,FBA(2),FRAME(2),ZBUF(2),MIPTBP1(2),MIPTBP2(2),SCANMSK
	// 30
	// include in command: TEXCLUT,TEXA,FOGCOL,DTHE,PABE/FBA
	// vars with dependencies: TEST,FRAME,TEX0,TEX1,TEX2,CLAMP,TEXCLUT,MIPTBP1,MIPTBP2,ZBUF

	for ( idx = 1; idx <= count; idx++ )
	{
		var4 = inputdata4 [ uIndex + idx ];

		varidx = var4.y;

		value2 = var4.zw;

		// testing
		//sVRAM[20] = varidx;
		//sVRAM[21] = value2.x;
		//sVRAM[22] = value2.y;

		// handle actions before update //
		// todo

		// store value //
		
		uvps2gpu_vars [ subgroup_local_id ] [ varidx & 0x7f ] = value2;


		// testing
		//sVRAM[20] = uvps2gpu_vars [ subgroup_local_id ] [ varidx & 0x7f ].x;
		//sVRAM[21] = uvps2gpu_vars [ subgroup_local_id ] [ varidx & 0x7f ].y;


		// handle actions after update //

		// TEX0 (0x06,0x07)/TEX2(0x16,0x17)
		if( ( varidx & ~0x11 ) == 0x06 )
		{
			//if ( ( varidx & 0x10 ) != 0 )
			{
				MASK = -sign( int( varidx ) & 0x10 );
				value21 = uvps2gpu_vars [ subgroup_local_id ] [ varidx & 0xf ];
				value21 = ( value2 & TEX2MASK & MASK ) | ( value21 & ~( TEX2MASK & MASK ) );
				uvps2gpu_vars [ subgroup_local_id ] [ varidx & 0xf ] = value21;
			}

			update_TEX0 ( varidx );

			// also if TEX0/2 then update LUTs for CLAMP
			// note: do this before starting run as well as here
			update_CLAMP ( varidx );

			// if variable is TEX0/2 then check/update CLUT
			update_clut ( varidx );
			
		}

		// CLAMP (0x08,0x09)
		if ( ( varidx & ~1 ) == 0x08 )
		{
			update_CLAMP ( varidx );
		}

		// FRAME (0x4c,0x4d)
		// frame buffer //
		if ( ( varidx & ~1 ) == 0x4c )
		{
			update_FRAME ( varidx );
		}

		// ZBUF (0x4e,0x4f)
		// z-buffer //
		if ( ( varidx & ~1 ) == 0x4e )
		{
			update_ZBUF ( varidx );
		}

		// ALPHA (0x42,0x43)
		if ( ( varidx & ~1 ) == 0x42 )
		{
			update_ALPHA( varidx );
		}

		// TEST (0x47,0x48)
		if ( ( ( varidx + 1 ) & ~1 ) == 0x48 )
		{
			update_TEST( varidx );
		}


		// TEXA (0x3b)
		if ( varidx == 0x3b )
		{
			//TEXA_0 = int( inputdata [ uIndex + ( 6 << 1 ) + 0 ] );
			//TEXA_1 = int( inputdata [ uIndex + ( 6 << 1 ) + 1 ] );
			//AEM = ( TEXA_0 >> 15 ) & 1;
			//AEM -= 1;
			//TEXA_0 <<= 24;
			//TEXA_1 <<= 24;
			uvTEXA_TA0_TA1_AEM_LUT [ subgroup_local_id ] = ivec4( value2[0] << 24, value2[1] << 24, ( ( value2[0] >> 15 ) & 1 ) - 1, 0 );
		}


		// DIMX (0x44)
		// DTHE (0x45)
		//if ( ( varidx & ~1 ) == 0x44 )
		//{
		//	DTHE2 = uvps2gpu_vars [ subgroup_local_id ] [ 0x45 ];
		//	value2 &= -( DTHE2 [ 0 ] & 1 );
		//	uvDIMX_DIMX0_DIMX1_LUT [ subgroup_local_id ] = value2;
		//}

		// FBA (0x4a,0x4b)
		//if ( ( varidx & ~1 ) == 0x4a )
		//{
		//	uFBA_FBA_LUT [ subgroup_local_id ] [ varidx & 1 ] = value2 [ 0 ] << 31;
		//}


		// COLCLAMP (0x46)
		//if ( varidx == 0x46 )
		//{
		//}

		// PABE (0x49)
		//if ( varidx == 0x49 )
		//{
		//}

	}	// end for ( idx = 0; idx < count; idx++ )

}




// need to know visible range of screen for NTSC and for PAL (each should be different)
// NTSC visible y range is usually from 16-256 (0x10-0x100) (height=240)
// PAL visible y range is usually from 35-291 (0x23-0x123) (height=256)
// NTSC visible x range is.. I don't know. start with from about gpu cycle#544 to about gpu cycle#3232 (must use gpu cycles since res changes)
//shared int VisibleArea_StartX, VisibleArea_EndX, VisibleArea_StartY, VisibleArea_EndY, VisibleArea_Width, VisibleArea_Height;
// this allows you to calculate horizontal pixels
//shared int GPU_CyclesPerPixel;
// need to know where to draw the actual image at



void draw_texture ( int xsize, int ysize )
{
	//int xid = int( gl_GlobalInvocationID.x );
	//int yid = int( gl_GlobalInvocationID.y );

	int xxid = int( gl_LocalInvocationIndex );

	// global invocation index
	int gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );

	uint CurBarrierSync;

	ivec2 pos;
	uvec4 rgba;
	int pixel;
	vec4 frgba;

	int idx;
	vec4 vfr, vfg, vfb, vfa;

	ivec4 ivPtr32;
	ivec4 idx4, dx4, dy4, sx4, sy4;
	int count;
	float fscalex, fscaley;
	uvec4 uvpixel32;

	mat4 fcolor4x4;

	count = SCREEN_X_SIZE * SCREEN_Y_SIZE;

	fscalex = float(xsize) / float(SCREEN_X_SIZE);
	fscaley = float(ysize) / float(SCREEN_Y_SIZE);

#ifdef USE_MEMORY_BARRIER_BUFFER

	memoryBarrierBuffer ();
	memoryBarrierShared ();
	groupMemoryBarrier ();
	memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS

	// need to do subgroupElect because all subgroups need to synchronize globally before they synchronize locally
	if ( subgroupElect() )
	{

		// count global subgroups that have completed the work
		CurBarrierSync = atomicAdd( auCounter, 1 );
		//atomicAdd( auCounter, 1 );


		// only need the first shader of the entire workgroup to spin wait though
		if ( xxid == 0 )
		{
			CurBarrierSync++;

			// would probably need to be a less than comparison due to possible race conditions
			//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
			while ( CurBarrierSync < NextBarrierSync )
			{
				//CurBarrierSync = atomicAdd( auCounter, 0 );
				CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
			}
		
			// at the next sync point, need all subgroups
			NextBarrierSync += subgroup_global_count;

		}	// end if ( xxid == 0 )

	}	// end if ( subgroupElect() )


#endif	// end ENABLE_MULTIPLE_WORKGROUPS

	// don't know if all the threads have completed all the other tasks yet
	barrier ();

	
	//for ( idx = xxid << 2; idx < count; idx += xxinc << 2 )
	for ( idx = gxxid << 2; idx < count; idx += gxxinc << 2 )
	{
		idx4 = idx + ivec4( 0, 1, 2, 3 );
		dx4 = idx4 % SCREEN_X_SIZE;
		dy4 = idx4 / SCREEN_X_SIZE;

		sx4 = ivec4( vec4( dx4 ) * fscalex );
		sy4 = ivec4( vec4( dy4 ) * fscaley );

		// rotate screen 
		sy4 = ysize - sy4;

		ivPtr32 =  sx4 + ( sy4 * xsize );
		uvpixel32.x = pixelbuffer32 [ ivPtr32.x ];
		uvpixel32.y = pixelbuffer32 [ ivPtr32.y ];
		uvpixel32.z = pixelbuffer32 [ ivPtr32.z ];
		uvpixel32.w = pixelbuffer32 [ ivPtr32.w ];

		// write to buffer instead of image
		staging_buffer32_4 [ idx >> 2 ] = uvpixel32;
		//staging_buffer32_4 [ idx >> 2 ] = uvec4( 0xff00ff );
		
		// pixel needs alpha ??
		//uvpixel32 |= 0xff000000;

		//ivPtr32 =  dx4 + ( dy4 * SCREEN_X_SIZE );
		//data [ ivPtr32.x ] = int( uvpixel32.x );
		//data [ ivPtr32.y ] = int( uvpixel32.y );
		//data [ ivPtr32.z ] = int( uvpixel32.z );
		//data [ ivPtr32.w ] = int( uvpixel32.w );


	}
}

void draw_screen( uint uIndex )
{

	int xxid = int( gl_LocalInvocationIndex );
	
	// global invocation index
	int gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );

	//const int c_iVisibleArea_StartX_Cycle = 584;
	//const int c_iVisibleArea_EndX_Cycle = 3192;
	//const int c_iVisibleArea_StartY_Pixel_NTSC = 15;
	//const int c_iVisibleArea_EndY_Pixel_NTSC = 257;
	//const int c_iVisibleArea_StartY_Pixel_PAL = 34;
	//const int c_iVisibleArea_EndY_Pixel_PAL = 292;

	//const int c_iVisibleArea_StartY [] = { c_iVisibleArea_StartY_Pixel_NTSC, c_iVisibleArea_StartY_Pixel_PAL };
	//const int c_iVisibleArea_EndY [] = { c_iVisibleArea_EndY_Pixel_NTSC, c_iVisibleArea_EndY_Pixel_PAL };	
	

	int x, y;
	int count;
	
	//u32* buf_ptr;
	//u32 *buf_ptr32;
	//u16 *buf_ptr16;
	
	//u32* buf_ptr_2;
	//u32 *buf_ptr32_2;
	//u16 *buf_ptr16_2;
	
	int draw_buffer_offset32;
	int draw_width, draw_height;
	int start_x, start_y;
	int Index = 0;

	int draw_buffer_offset_2;
	int draw_width_2, draw_height_2;
	int start_x_2, start_y_2;
	
	uint Pixel16, Pixel32;
	uint Pixel32_0, Pixel32_1;
	//u32 PixelFormat;
	
	//u64 DISPFBX, DISPLAYX;
	//u64 DISPFB1, DISPLAY1;
	//u64 DISPFB2, DISPLAY2;
	uint DISPFBX_0, DISPLAYX_0;
	uint DISPFB1_0, DISPLAY1_0;
	uint DISPFB2_0, DISPLAY2_0;
	uint DISPFBX_1, DISPLAYX_1;
	uint DISPFB1_1, DISPLAY1_1;
	uint DISPFB2_1, DISPLAY2_1;
	
	uint DISPFBX_FBP, DISPFBX_FBW, DISPLAYX_DH, DISPFBX_DBX, DISPFBX_DBY;
	uint DISPFB1_FBP, DISPFB1_FBW, DISPLAY1_DH, DISPLAY1_DW, DISPLAY1_DX, DISPLAY1_DY, DISPLAY1_MAGH, DISPFB1_DBX, DISPFB1_DBY;
	uint DISPFB2_FBP, DISPFB2_FBW, DISPLAY2_DH, DISPLAY2_DW, DISPLAY2_DX, DISPLAY2_DY, DISPLAY2_MAGH, DISPFB2_DBX, DISPFB2_DBY;
	uint DISPFB1_PSM, DISPFB2_PSM;
	uint lScanline;
	
	uint PMODE;
	uint PMODE_MMOD, PMODE_AMOD, PMODE_SLBG, PMODE_ALP;
	

	uint DISPFBX_PSM, SMODE2_FFMD, SMODE2_INTER;
	uint SMODE2;


	//bool bEnableBlend;

	int ipixelbuffer32;
	int xoffset32, yoffset32, offset32;
	int PixelFormat;

	ivec4 vxoffset32, vyoffset32, voffset32;
	ivec4 vIdx, ivIndex;
	ivec4 vx, vy, vy2;
	ivec4 vMask;
	uvec4 vPixel0, vPixel1;

	int iCount;
	int iStride;

	int iMaxLines;
	int FBP, FBW, FPSM, DRAWPSM;
	int draw_buffer_offset;
	int display_magh, display_dw;
	int iFrameBufStartX, iFrameBufStartY, iFrameBufWidth;
	int iBlackTopLines, iBlackBottomLines;
	int iYUpdate;
	int iOffset;
	ivec4 sx4, sy4, dx4, dy4;
	int idx;
	ivec4 idx4;
	ivec4 ivPtr;
	uvec4 uvEnable;
	ivec4 vOffset;
	uvec4 vDestPixel32, vDestPixel32_0;

	bool bFRAME32;
	int DYNAND;

	int iGraphicsMode;

	uint CurBarrierSync;

	// don't know yet if blending is needed
	//bEnableBlend = false;
	
	//uIndex <<= 6;
	uIndex <<= 5;

// validate input
//for ( int i = 0; i < 32; i++ )
//{
//	sVRAM[i] = inputdata[ uIndex + i ];
//}

//return;

	lScanline = inputdata [ uIndex + 1 ];

	iGraphicsMode = int( inputdata [ uIndex + 18 ] );

	PMODE = inputdata [ uIndex + 2 ];

	PMODE_MMOD = ( PMODE >> 5 ) & 1;
	PMODE_AMOD = ( PMODE >> 6 ) & 1;
	PMODE_SLBG = ( PMODE >> 7 ) & 1;
	PMODE_ALP = ( PMODE >> 8 ) & 0xff;
	
	
	DISPFB1_0 = inputdata [ uIndex + 4 ];
	DISPFB1_1 = inputdata [ uIndex + 5 ];

	DISPFB2_0 = inputdata [ uIndex + 6 ];
	DISPFB2_1 = inputdata [ uIndex + 7 ];

	DISPLAY1_0 = inputdata [ uIndex + 8 ];
	DISPLAY1_1 = inputdata [ uIndex + 9 ];

	DISPLAY2_0 = inputdata [ uIndex + 10 ];
	DISPLAY2_1 = inputdata [ uIndex + 11 ];

	SMODE2 = inputdata [ uIndex + 12 ];

	DISPFBX_0 = inputdata [ uIndex + 14 ];
	DISPFBX_1 = inputdata [ uIndex + 15 ];

	DISPLAYX_0 = inputdata [ uIndex + 16 ];
	DISPLAYX_1 = inputdata [ uIndex + 17 ];


	SMODE2_FFMD = SMODE2 & 2;
	SMODE2_INTER = SMODE2 & 1;
	
	//DISPFBX_FBP = ( DISPFBX_0 >> 0 ) & 0x1ff;
	//DISPFBX_FBW = ( DISPFBX_0 >> 9 ) & 0x3f;

	//DISPFBX_PSM = ( DISPFBX_0 >> 15 ) & 0x1f;

	//DISPFBX_DBX = ( DISPFBX >> 32 ) & 0x7ff;
	//DISPFBX_DBY = ( DISPFBX >> 43 ) & 0x7ff;
	//DISPLAYX_DH = ( DISPLAYX >> 44 ) & 0x7ff;
	//DISPFBX_DBX = ( DISPFBX_1 >> 0 ) & 0x7ff;
	//DISPFBX_DBY = ( DISPFBX_1 >> 11 ) & 0x7ff;
	//DISPLAYX_DH = ( DISPLAYX_1 >> 12 ) & 0x7ff;

	
	//draw_buffer_offset32 = int( DISPFBX_FBP << 11 );
	
	//draw_width = int( DISPFBX_FBW << 6 );
	//draw_height = int( DISPLAYX_DH + 1 );
	//start_x = int( DISPFBX_DBX );
	//start_y = int( DISPFBX_DBY );
	


	DISPFB1_FBP = ( DISPFB1_0 >> 0 ) & 0x1ff;
	DISPFB1_FBW = ( DISPFB1_0 >> 9 ) & 0x3f;
	DISPFB1_PSM = ( DISPFB1_0 >> 15 ) & 0x1f;

	//DISPFB1_DBX = ( DISPFB1 >> 32 ) & 0x7ff;
	//DISPFB1_DBY = ( DISPFB1 >> 43 ) & 0x7ff;
	//DISPLAY1_DH = ( DISPLAY1 >> 44 ) & 0x7ff;
	DISPFB1_DBX = ( DISPFB1_1 >> 0 ) & 0x7ff;
	DISPFB1_DBY = ( DISPFB1_1 >> 11 ) & 0x7ff;
	DISPLAY1_DX = ( DISPLAY1_0 >> 0 ) & 0xfff;
	DISPLAY1_DY = ( DISPLAY1_0 >> 12 ) & 0x7ff;
	DISPLAY1_MAGH = ( DISPLAY1_0 >> 23 ) & 0xf;
	DISPLAY1_DW = ( DISPLAY1_1 >> 0 ) & 0xfff;
	DISPLAY1_DH = ( DISPLAY1_1 >> 12 ) & 0x7ff;


	DISPFB2_FBP = ( DISPFB2_0 >> 0 ) & 0x1ff;
	DISPFB2_FBW = ( DISPFB2_0 >> 9 ) & 0x3f;
	DISPFB2_PSM = ( DISPFB2_0 >> 15 ) & 0x1f;

	//DISPFB2_DBX = ( DISPFB2 >> 32 ) & 0x7ff;
	//DISPFB2_DBY = ( DISPFB2 >> 43 ) & 0x7ff;
	//DISPLAY2_DH = ( DISPLAY2 >> 44 ) & 0x7ff;
	DISPFB2_DBX = ( DISPFB2_1 >> 0 ) & 0x7ff;
	DISPFB2_DBY = ( DISPFB2_1 >> 11 ) & 0x7ff;
	DISPLAY2_DX = ( DISPLAY2_0 >> 0 ) & 0xfff;
	DISPLAY2_DY = ( DISPLAY2_0 >> 12 ) & 0x7ff;
	DISPLAY2_MAGH = ( DISPLAY2_0 >> 23 ) & 0xf;
	DISPLAY2_DW = ( DISPLAY2_1 >> 0 ) & 0xfff;
	DISPLAY2_DH = ( DISPLAY2_1 >> 12 ) & 0x7ff;



	// set max lines for screen in screen mode
	iMaxLines = VBlank_Y_LUT[ ( ( ( iGraphicsMode & 3 ) + 1) >> 2) & 1 ];

	// make sure that framebuffer has some width and height to it before drawing it
	if ( subgroupAll( ( ( PMODE & 1 ) != 0 ) && ( DISPFB1_FBW != 0 ) && ( DISPLAY1_DH != 0 ) ) )
	{

		// display 1 //
		
		draw_buffer_offset = int( DISPFB1_FBP ) << 11;
		
		//buf_ptr = & ( RAM32 [ GPURegs0.DISPFB1.FBP >> 4 ] );
		//buf_ptr = & ( RAM32 [ draw_buffer_offset ] );

		display_magh = int( DISPLAY1_MAGH );
		display_dw = int( DISPLAY1_DW );
		display_magh++;
		display_dw++;
		draw_width = display_dw / display_magh;

		iFrameBufWidth = int( DISPFB1_FBW ) << 6;
		draw_height = int( DISPLAY1_DH ) + 1;
		start_x = int( DISPFB1_DBX );
		start_y = int( DISPFB1_DBY );
		
		//buf_ptr32 = buf_ptr;
		//buf_ptr16 = (u16*) buf_ptr;
		
		PixelFormat = int( DISPFB1_PSM );

		// get x location to start drawing in frame buffer
		iFrameBufStartX = int( DISPLAY1_DX );

		// get y location to start drawing in frame buffer
		iFrameBufStartY = int( DISPLAY1_DY );

		// maybe half this value ??
		iFrameBufStartY >>= 1;

	}
	else if ( subgroupAll( ( PMODE & 2 ) != 0 ) )
	{

		// display 2 //
		
		draw_buffer_offset = int( DISPFB2_FBP ) << 11;
		
		//buf_ptr = & ( RAM32 [ DISPFB2_FBP >> 4 ] );
		//buf_ptr = & ( RAM32 [ draw_buffer_offset ] );

		display_magh = int( DISPLAY2_MAGH );
		display_dw = int( DISPLAY2_DW );
		display_magh++;
		display_dw++;
		draw_width = display_dw / display_magh;

		iFrameBufWidth = int( DISPFB2_FBW ) << 6;
		draw_height = int( DISPLAY2_DH ) + 1;
		start_x = int( DISPFB2_DBX );
		start_y = int( DISPFB2_DBY );
		
		//buf_ptr32 = buf_ptr;
		//buf_ptr16 = (u16*) buf_ptr;
		
		PixelFormat = int( DISPFB2_PSM );
		
		// get x location to start drawing in frame buffer
		iFrameBufStartX = int( DISPLAY2_DX );

		// get y location to start drawing in frame buffer
		iFrameBufStartY = int( DISPLAY2_DY );

		// maybe half this value ??
		iFrameBufStartY >>= 1;
	}
	else
	{
		// ???
		// todo: probably should black out screen in this case ??
		return;
	}



	// draw height can only be a maximum of 1024
	draw_height = ( ( draw_height > c_iScreen_MaxHeight ) ? c_iFrameBuffer_DisplayHeight : draw_height );
	
	// draw width can only be a maximum of 1024
	draw_width = ( ( draw_width > c_iScreen_MaxWidth ) ? c_iFrameBuffer_DisplayWidth : draw_width );


	// can't draw more lines than are on the screen
	draw_height = (draw_height > iMaxLines) ? iMaxLines : draw_height;

	// but if not interlaced, use half that
	if ( SMODE2_INTER == 0 )
	{
		draw_height = (draw_height > (iMaxLines >> 1)) ? (iMaxLines >> 1) : draw_height;

		// and then double that
		draw_height <<= 1;
	}

	// if the draw height in the frame buffer is less than max on screen, then fill the rest with black lines on bottom
	iBlackTopLines = 0;
	iBlackBottomLines = 0;
	if (draw_height < iMaxLines)
	{
		iBlackBottomLines = iMaxLines - draw_height;
	}

	// update the number of black lines at the top if drawing further down on the screen
	iBlackTopLines += iFrameBufStartY;

	// either subtract from lines on bottom or the draw height (total draw height does not change)
	if (iBlackBottomLines >= iFrameBufStartY)
	{
		// push the image down on the screen by removing any black bars on the bottom
		iBlackBottomLines -= iFrameBufStartY;
	}
	else
	{
		// this is going to cut the image off the screen vertically ?
		//int iTemp;
		//iTemp = iFrameBufStartY - iBlackBottomLines;
		draw_height -= (iFrameBufStartY - iBlackBottomLines);
		draw_height -= iBlackBottomLines;
		iBlackBottomLines = 0;
	}

	// if the draw_height is less than or equal to zero, then just draw all black bars because no image
	if ((draw_height <= 0) || (draw_height > iMaxLines))
	{
		iBlackBottomLines = iMaxLines;
		iBlackTopLines = 0;
		draw_height = 0;
	}


	// by default read every line of source image
	iYUpdate = 1;

	iOffset = 0;

#ifdef ENABLE_PIXELBUF_INTERLACING
	// if set to read every line, then half draw height for now
	// *todo* need to take into account whether interlaced or not
	// comment this out to show correct screen at top for now
	//if ( GPURegs0.SMODE2.FFMD ) draw_height >>= 1;
	// check if this is set to read every line
	//if ( GPURegs0.SMODE2.FFMD && GPURegs0.SMODE2.INTER )
	if ( SMODE2_INTER != 0 )
	{
		// set to read every line, so need to skip lines when writing to pixel buffer for interlacing
		if ( (lScanline & 1) != 0 )
		{
			//Index += draw_width;
			iOffset = 1;
		}

		// check if should draw every line in source image or every other line
		if ( SMODE2_FFMD != 0 )
		{
			// drawing every line, so source image is half the height
			draw_height >>= 1;
			iOffset = 0;
		}
		else
		{
			// read every other line of source image
			iYUpdate = 2;
		}

	}
	// if not interlaced, then half the height ??
	else
	{
		// and then half that again for the source image
		draw_height >>= 1;
	}
#endif





	// init Index
	Index = 0;

/*
sVRAM[33] = iBlackBottomLines;
sVRAM[34] = draw_width;
sVRAM[35] = count;
sVRAM[36] = idx;
sVRAM[37] = draw_height;
return;
*/

	// check if there is extra space on the bottom that needs filling in
	if ( subgroupAll( iBlackBottomLines != 0 ) )
	{
		// pad on the bottom with zeros if needed for now

		// start at the end of the image
		//y = 0;

		count = draw_width * iBlackBottomLines;

		// update Index
		Index += count;

		// do 4 pixels at a time
		//count >>= 2;

		for ( idx = gxxid; idx < ( count >> 2 ); idx += gxxinc )
		{
			pixel4buffer32 [ idx ] = uvec4( 0 );
		}


	} // end if (iBlackBottomLines)



	// always interlacing for now
	// alternate the scanlines
	//if ( (lScanline & 1) != 0 )
	//{
	//	Index += draw_width;
	//}


	// get count
	//count = draw_width * ( ( draw_height - start_y - iOffset - 1 ) / iYUpdate );
	count = draw_width * ( ( draw_height - iOffset - 1 ) / iYUpdate );

/*
sVRAM[32] = iBlackBottomLines;
sVRAM[33] = iBlackTopLines;
sVRAM[34] = draw_width;
sVRAM[35] = draw_height;
sVRAM[36] = start_x;
sVRAM[37] = start_y;
sVRAM[38] = draw_buffer_offset;
sVRAM[39] = PixelFormat;
sVRAM[40] = iFrameBufWidth;
sVRAM[41] = count;
sVRAM[42] = iOffset;
sVRAM[43] = iYUpdate;
*/
	
	//if ( PixelFormat < 2 )
	if ( subgroupAll( count > 0 ) )
	{

		// 24/32-bit pixels in frame buffer //
		

		FBP = draw_buffer_offset;
		FPSM = PixelFormat;
		FBW = iFrameBufWidth;

		// shift pixel format right 1
		DRAWPSM = FPSM >> 1;

		bFRAME32 = ( DRAWPSM & 1 ) == 0;

		DYNAND = LUT_YNAND[ DRAWPSM ];

		for ( idx = gxxid << 2; idx < count; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			dx4 = idx4 % draw_width;
			dy4 = idx4 / draw_width;

			// space source y by iYUpdate
			sy4 = dy4 << ( iYUpdate - 1 );

			// draw upside down ??
			sy4 = ( draw_height - iOffset - 1 ) - sy4;

			// offset source y by start_y
			sy4 += start_y;

			// offset source x by start_x
			sx4 = dx4 + start_x;


			// get the offset to the source pixel
			ivPtr = ( sx4 & 0x3f ) | ( ( sy4 & 0x3f ) << 7 );

			// get the pixels to be drawn
			usubBorrow( uvec4( sx4 ), uvec4( draw_width ), uvEnable );



			// calculate xy offset //

			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( sx4 & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			vOffset += ( sy4 & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );



			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// mask pixel if 24-bit or 16-bit
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			//vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;

			// if interlaced, then space the destination y by 1
			//if ( SMODE2_INTER != 0 )
			{
				dy4 <<= 1;
			}

			// for now, always offset destination y by scanline
			dy4 += int( lScanline ) & 1;

			// set the pixels not to be drawn to black
			//vDestPixel32 &= -uvEnable;

			// store pixel to screen buffer
			pixel4buffer32 [ ( Index + dx4.x + ( dy4.x * draw_width ) ) >> 2 ] = vDestPixel32;
		}

		// update index
		Index += count << 1;
		

	}	// end 
	

	// check if there is extra space on the top that needs filling in
	if ( subgroupAll( iBlackTopLines != 0 ) )
	{
		// pad on the top with zeros if needed for now


		count = draw_width * iBlackTopLines;

		// update Index
		//Index += count;

		// do 4 pixels at a time
		count >>= 2;

		for ( idx = gxxid; idx < count; idx += gxxinc )
		{
			pixel4buffer32 [ ( Index >> 2 ) + idx ] = uvec4( 0 );
		}


	} // end if (iBlackTopLines)

	
	// the height of image is for now going to be 480 for ntsc, 5xx for pal
	draw_height = iMaxLines;
	
	
		
	// *** output of pixel buffer to screen *** //


	// needs to synchronize gpu core before proceeding
	//barrier ();

	//draw_texture ( VisibleArea_Width, VisibleArea_Height );
	draw_texture ( draw_width, draw_height );

	// that's going to be the end of the run, so no need to synchronize after that
	return;
}





void precompute_data ()
{
	//const int iDataCount = ( 1 << 16 );
	//const int iDataElementSize = 128;
	//const int iDataShift = 7;

	int xxid = int( gl_LocalInvocationIndex );

	// global invocation index
	int gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );

	uint uIdx;
	uint uIndex;

	uint uIdx4;
	uint uIndex4;

	uvec4 uvPrev4, uvCur4;

	uint Comm;

	// common object vars //

	int DrawArea_TopLeftX;
	int DrawArea_TopLeftY;
	int DrawArea_BottomRightX;
	int DrawArea_BottomRightY;
	int DrawArea_OffsetX;
	int DrawArea_OffsetY;

	uint PRIM;
	int FRAME;
	uint FBMSK;

	uint FST, ABE, FGE, PABE;
	uint FOGCOL;
	int FCR, FCG, FCB;

	int FBP;
	int FBW;
	int FPSM;

	int FrameBufferStartOffset32;
	int FrameBufferWidth_Pixels;

	uint TEST, AFAIL;
	int AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	//uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	//uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	//uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	//uvec4 vAREF;

	int ZBUF;
	int ZBP;
	int ZPSM;
	int ZMSK;

	int ZBufferStartOffset32;

	int DRAWPSM, ZBUFPSM;

	uint FBA;

	int CLAMP_0, CLAMP_1;
	int WMS, WMT;
	int MINU, MAXU, MINV, MAXV;
	int TexY_And, TexY_Or, TexY_Min, TexY_Max;
	int TexX_And, TexX_Or, TexX_Min, TexX_Max;

	int AEM;
	int TEXA_0, TEXA_1;

	int TEX0_0, TEX0_1;
	int TBP0, TBW, TPSM, TW, TH;
	int TEXPSM;
	int TexWidth, TexHeight;
	int TexWidth_Mask, TexHeight_Mask;
	int TCC, TFX;
	int CBP, CPSM, CSM, CSA, CLD;
	int CLUTStartOffset32;

	int TextureBufferStartOffset32;
	int TextureBufferWidth_Pixels;

	int iAnd1, iShift1, iShift2, iAnd3, iShift3;


	int COLCLAMP;

	int StartX;
	int EndX;
	int StartY;
	int EndY;

	uint bgr32;
	int bgra, bgrr, bgrg, bgrb;

	ivec4 vx, vy, vu, vv;

	uvec4 vz;

	int f0, rf0;
	vec4 vfs, vft;

	ivec4 dxdx;
	//int dudx;
	int dvdy;
	int Temp;
	int w;

	int LeftMostX, RightMostX, TopMostY, BottomMostY;
	int t0, t1, denominator;

	// triangle vars //

	ivec4 vdx;
	ivec4 vdxdy;

	ivec4 vr, vg, vb, va;
	int vdr, vdg, vdb, vda;

	int vdrdy, vdgdy, vdbdy, vdady;

	int drdx, dgdx, dbdx, dadx;
	//double dzdx;
	//double vdz;
	//double vdzdy;
	int64_t dzdx;
	int64_t vdz;
	int64_t vdzdy;

	int64_t dz, iz;
	int x_distance, y_distance, line_length;
	int iEndpointX, iEndpointY;
	int x0, x1, y0, y1;
	uint z0, z1;
	int ix, iy;
	int dx, dy;
	ivec4 c0, c1;
	ivec4 iC;
	ivec4 dc;

	uvec4 vdz2, vdzdy2, dzdx2;

	int dudx, dvdx, dfdx;
	float dsdx, dtdx, dqdx;

	int vdu, vdv, vdf;
	float vds, vdt, vdq;

	int vdudy, vdvdy, vdfdy;
	float vdsdy, vdtdy, vdqdy;

	ivec4 vf;
	vec4 vs, vt, vq;


	ivec4 vrgba0, vrgba1, vrgba2;
	ivec4 vuvf0, vuvf1, vuvf2;
	vec4 vstq0, vstq1, vstq2;

	ivec4 drgbadx;
	ivec4 duvfdx;
	vec4 dstqdx;

	ivec4 vdrgbady;
	ivec4 vduvfdy;
	vec4 vdstqdy;

	ivec4 vdrgba;
	ivec4 vduvf;
	vec4 vdstq;

	uvec4 Coord;

	int iATOffset, iATMask;
	int iZTOffset;

	int bDraw;

	uint uStartIdx, uEndIdx;
	uint uCount;

	int sync;

	uStartIdx = guStartIndex;
	uEndIdx = guEndIndex;


	// loop through data

	//for ( uCount = xxid; uCount < uEndIdx; uCount += xxinc )
	for ( uCount = gxxid; uCount < uEndIdx; uCount += gxxinc )
	{
		//uIndex = ( xxid & PRECOMPUTE_LIST_MASK ) << 6;
		//uIdx = ( xxid & PRECOMPUTE_LIST_MASK ) << 7;

		uIndex = ( uCount & PRECOMPUTE_LIST_MASK ) << 5;
		uIndex4 = ( uCount & PRECOMPUTE_LIST_MASK ) << 3;
		uIdx = ( uCount & PRECOMPUTE_LIST_MASK ) << 6;
		uIdx4 = ( uCount & PRECOMPUTE_LIST_MASK ) << 4;

		// init sync
		sync = 0;

		// determine if need to synchronize //

#ifdef REQUEST_SYNC_ON_ANYTHING
		// if index 1,2,3 don't match, then synchronize
		if ( uCount > 0 )
		{
			uvPrev4 = inputdata4 [ uIndex4 - 8 ];
			uvCur4 = inputdata4 [ uIndex4 ];

			uvPrev4.x = 0;
			uvCur4.x = 0;

			if ( any( notEqual( uvPrev4, uvCur4 ) ) )
			{
				sync = 1;
			}
		}
#endif

		// set sync
		data [ uIdx + 3 ] = sync;


		// handle rectange/sprite //

// FINAL format for prim data in draw command
// 0: command/prim
// 1: FRAME (lower)
// 2: SCISSOR(lower)
// 3: SCISSOR(upper)
// 4: xy0
// 5: xy1
// 6. xy2
// 7: XYOFFSET (lower)
// 8: z0
// 9: z1
// 10: z2
// 11: XYOFFSET (upper)
// 12: rgba0
// 13: rgba1
// 14: rgba2
// 15: ZBUF (lower)
// 16: s0/uv0
// 17: s1/uv1
// 18: s2/uv2
// 19: TEX0/2 (lower)
// 20: t0
// 21: t1
// 22: t2
// 23: TEX0/2 (upper)
// 24: q0
// 25: q1
// 26: q2
// 27: PABE (optional)
// 28: f0
// 29: f1
// 30: f2
// 31: FOGCOL (optional)


		// load vars from input //

		// load command
		vg = ivec4( inputdata4 [ uIndex4 + 0 ] );

		// load x,y,z
		vy = ivec4( inputdata4 [ uIndex4 + 1 ] );
		vz = ivec4( inputdata4 [ uIndex4 + 2 ] );

		// load rgba
		va = ivec4( inputdata4 [ uIndex4 + 3 ] );

		// load texcoords uv/st
		vu = ivec4( inputdata4 [ uIndex4 + 4 ] );
		vv = ivec4( inputdata4 [ uIndex4 + 5 ] );

		// load q
		vr = ivec4( inputdata4 [ uIndex4 + 6 ] );

		// load FOG
		vf = ivec4( inputdata4 [ uIndex4 + 7 ] );

		// NEED: FST, FGE, DRAWAREA, OFFSET, TEXWIDTH, TEXHEIGHT //

		PRIM = vg.x;
		FST = ( PRIM >> 8 ) & 1;
		//ABE = ( PRIM >> 6 ) & 1;
		FGE = ( PRIM >> 5 ) & 1;

		DrawArea_OffsetX = vy.w & 0xffff;
		DrawArea_OffsetY = int( vz.w ) & 0xffff;

		DrawArea_TopLeftX = int( vg.z );
		DrawArea_BottomRightX = ( DrawArea_TopLeftX >> 16 ) & 0x7ff;
		DrawArea_TopLeftX &= 0x7ff;

		DrawArea_TopLeftY = vg.w;
		DrawArea_BottomRightY = ( DrawArea_TopLeftY >> 16 ) & 0x7ff;
		DrawArea_TopLeftY &= 0x7ff;

		TEX0_0 = vu.w;
		TEX0_1 = vv.w;
		TW = ( TEX0_0 >> 26 ) & 0xf;
		TH = ( ( TEX0_0 >> 30 ) & 0x3 ) | ( ( TEX0_1 & 0x3 ) << 2 );

		TexWidth = 1 << TW;
		TexHeight = 1 << TH;
		TexWidth_Mask = TexWidth - 1;
		TexHeight_Mask = TexHeight - 1;

		// get ZPSM from frame buffer
		ZPSM = ( va.w >> 24 ) & 0xf;

		// use this to mask z
		//vz &= ( (-1u) >> ( (ZPSM & 3) << 3 ) );

		bDraw = 1;

		// check for some important conditions
		if ( DrawArea_BottomRightX < DrawArea_TopLeftX )
		{
			//return;
			bDraw = 0;
		}
	

		if ( DrawArea_BottomRightY < DrawArea_TopLeftY )
		{
			//return;
			bDraw = 0;
		}


		if ( ( ( PRIM & 7 ) == 0 ) )
		{
			// pixel //

#ifdef PRECALC_PIXEL_VARS

			vx = vy & 0xffff;
			vy = ( vy >> 16 ) & 0xffff;

			// get top left corner of sprite and bottom right corner of sprite
			vx -= DrawArea_OffsetX;
			vy -= DrawArea_OffsetY;

			// get integer part of nearest pixel
			StartX = ( vx.x + 0x8 ) >> 4;
			StartY = ( vy.x + 0x8 ) >> 4;

			// check if pixel is within draw area
			if ( ( StartX < DrawArea_TopLeftX ) || ( StartX > DrawArea_BottomRightX ) || ( StartY < DrawArea_TopLeftY ) || ( StartY > DrawArea_BottomRightY ) )
			{
				bDraw = 0;
			}

			// *** TODO *** fit more pixels into command

			//data [ uIdx + 0 ] = ;
			//data [ uIdx + 1 ] = pixelcount;
			data [ uIdx + 2 ] = bDraw;
			data [ uIdx + 3 ] = sync;

			// store x,y,z,color
			data [ uIdx + 4 ] = vx.x;
			data [ uIdx + 5 ] = vy.x;
			data [ uIdx + 6 ] = int( vz.x );
			data [ uIdx + 7 ] = va.x;
#endif
		}
		else if ( ( ( PRIM & 7 ) == 6 ) )
		{
			// 2d object //


#ifdef PRECALC_SPRITE_VARS


			// get rgba from coord1 (last color value entered)
			bgr32 = va.y;

			// split into rgba
			bgra = int( bgr32 >> 24 ) & 0xff;
			bgrr = int( bgr32 >> 16 ) & 0xff;
			bgrg = int( bgr32 >> 8 ) & 0xff;
			bgrb = int( bgr32 >> 0 ) & 0xff;

			// coords //
			
			// get x0,y0 from coord1 (first coord entered)
			// x0,y0 are unsigned

			// get x1,y1 from coord0

			//vx.y = int( inputdata [ uIndex + ( 20 << 1 ) + 0 ] );
			//vx.x = int( inputdata [ uIndex + ( 24 << 1 ) + 0 ] );
			vx = vy & 0xffff;
			vy = ( vy >> 16 ) & 0xffff;


			// get z from coord1
			//z0 = int( inputdata [ uIndex + ( 24 << 1 ) + 1 ] );
			//f0 = int( inputdata [ uIndex + ( 27 << 1 ) + 0 ] );
			z0 = int( vz.y );
			f0 = vf.y;
			
			// get top left corner of sprite and bottom right corner of sprite
			vx -= DrawArea_OffsetX;
			vy -= DrawArea_OffsetY;


			// prepare f0, rf0
			f0 = f0 & 0xff;
			rf0 = 0xff - f0;

			// if no fogging, then set f0,rf0 appropriately for the calculation to come out with no fogging
			if ( FGE == 0 )
			{
				f0 = 0x100;
				rf0 = 0;
			}

			// need to do swap/scissor after texwidth/texheight //

			if ( FST != 0 )
			{
				// get u,v
				// coord0

				// coord1

				//vu.y = int( inputdata [ uIndex + ( 22 << 1 ) + 0 ] );
				//vu.x = int( inputdata [ uIndex + ( 26 << 1 ) + 0 ] );
				vv = ( vu >> 16 ) & 0x3fff;
				vu &= 0x3fff;
				
			}
			else
			{

				// put s,t coords into 10.4 fixed point
				// note: tex width/height should probably be minus one

				//vu.y = int( inputdata [ uIndex + ( 22 << 1 ) + 0 ] );
				//vv.y = int( inputdata [ uIndex + ( 22 << 1 ) + 1 ] );
				//vu.x = int( inputdata [ uIndex + ( 26 << 1 ) + 0 ] );
				//vv.x = int( inputdata [ uIndex + ( 26 << 1 ) + 1 ] );

				vfs = intBitsToFloat( vu );
				vft = intBitsToFloat( vv );

				vu.xy = ivec2( vfs.xy * float( TexWidth ) * 16.0f );
				vv.xy = ivec2( vft.xy * float( TexHeight ) * 16.0f );
			}


			// order coords so they go top to bottom and left to right
			if ( vx.y < vx.x )
			{
				// swap x,u coords
				vx.xy = vx.yx;
				vu.xy = vu.yx;
			}
			
			if ( vy.y < vy.x )
			{
				// swap y,v coords
				vy.xy = vy.yx;
				vv.xy = vv.yx;
			}


			// scissor test //
			
			StartX = ( vx.x + 0xf ) >> 4;
			EndX = ( vx.y - 1 ) >> 4;
			StartY = ( vy.x + 0xf ) >> 4;
			EndY = ( vy.y - 1 ) >> 4;


			// draw test //


			// check if sprite is within draw area
			if ( ( EndX < DrawArea_TopLeftX ) || ( StartX > DrawArea_BottomRightX ) || ( EndY < DrawArea_TopLeftY ) || ( StartY > DrawArea_BottomRightY ) )
			{
				bDraw = 0;
			}

			if ( ( vy.y < vy.x ) || ( vx.y < vx.x ) )
			{
				bDraw = 0;
			}


			// dx/dy values //

			

			//dxdx.xy = intdivfv2( ivec2( vu.y - vu.x, vv.y - vv.x), ivec2( vx.y - vx.x, vy.y - vy.x ), 4, 4, 16 );
			dxdx.xy = int64div2( ivec2( vu.y - vu.x, vv.y - vv.x), ivec2( vx.y - vx.x, vy.y - vy.x ), 4, 4, 16 );
			dudx = dxdx.x;
			dvdy = dxdx.y;


			vu <<= 12;
			vv <<= 12;

			// y clip/start //

			Temp = ( StartY << 4 ) - vy.x;

			//if ( StartY < DrawArea_TopLeftY )
			//{
			//	Temp += ( DrawArea_TopLeftY - StartY ) << 4;
			//	StartY = DrawArea_TopLeftY;
			//}
			Temp += ( DrawArea_TopLeftY - min( StartY, DrawArea_TopLeftY ) ) << 4;
			StartY = max( StartY, DrawArea_TopLeftY );
			
			vv.x += ( dvdy >> 4 ) * Temp;
			//vv.x += ( dxdx.y >> 4 ) * Temp;
			
			
			//if ( EndY > DrawArea_BottomRightY )
			//{
			//	EndY = DrawArea_BottomRightY;
			//}
			EndY = min ( EndY, DrawArea_BottomRightY );


			// x clip/start //
			
			Temp = ( StartX << 4 ) - vx.x;
			
			//if ( StartX < DrawArea_TopLeftX )
			//{
			//	Temp += ( DrawArea_TopLeftX - StartX ) << 4;
			//	StartX = DrawArea_TopLeftX;
			//}
			Temp += ( DrawArea_TopLeftX - min( StartX, DrawArea_TopLeftX ) ) << 4;
			StartX = max( StartX, DrawArea_TopLeftX );
			
			vu.x += ( dudx >> 4 ) * Temp;
			//vu.x += ( dxdx.x >> 4 ) * Temp;
			
			
			//if ( EndX > DrawArea_BottomRightX )
			//{
			//	EndX = DrawArea_BottomRightX;
			//}
			EndX = min( EndX, DrawArea_BottomRightX );


			// sprite:
			// StartX, EndX, z0, w, u0, v0, f0, rf0, dudx, dvdy

			w = EndX - StartX + 1;

// debugging
//sVRAM[0] = StartX;
//sVRAM[1] = StartY;
//sVRAM[2] = EndX;
//sVRAM[3] = EndY;
//sVRAM[4] = vu.x;
//sVRAM[5] = vv.x;
//sVRAM[6] = dudx;
//sVRAM[7] = dvdy;

			// sprite vars //

			// dz across/rgba/sync,etc //

			data [ uIdx + 0 ] = int( z0 );
			data [ uIdx + 1 ] = f0;
			data [ uIdx + 2 ] = bDraw;
			data [ uIdx + 3 ] = sync;

			data [ uIdx + 4 ] = bgra;
			data [ uIdx + 5 ] = bgrr;
			data [ uIdx + 6 ] = bgrg;
			data [ uIdx + 7 ] = bgrb;

			// initial u/v //

			data [ uIdx + 8 ] = StartX;
			data [ uIdx + 9 ] = StartY;
			data [ uIdx + 10 ] = EndX;
			data [ uIdx + 11 ] = EndY;


			// dstqf or duvqf across //

			data [ uIdx + 12 ] = vu.x;
			data [ uIdx + 13 ] = vv.x;
			data [ uIdx + 14 ] = dudx;	// q = 1.0 for sprites
			data [ uIdx + 15 ] = dvdy;

			// rest of the sprite vars //

			data [ uIdx + 16 ] = w;
			data [ uIdx + 17 ] = rf0;
			data [ uIdx + 18 ] = int( bgr32 );
			//data [ uIdx + 19 ] = ;

#endif	// end #ifdef PRECALC_SPRITE_VARS

		}
		else if ( ( PRIM & 7 ) <= 2 )
		{
			// line //

#ifdef PRECALC_LINE_VARS

			// if mono line, then all the colors are the same
			if ( ( PRIM & 0x8 ) == 0 )
			{
				va = ivec4( va.y );
			}

			// unpack x,y coords
			vx = vy & 0xffff;
			vy = ( vy >> 16 ) & 0xffff;

			//////////////////////////////////////////
			// get coordinates on screen
			vx -= DrawArea_OffsetX;
			vy -= DrawArea_OffsetY;

			// initial start point, need to do again after sort
			//StartX = ( vx.x + 0x8 ) >> 4;
			//EndX = ( vx.y + 0x8 ) >> 4;
			//StartY = ( vy.x + 0x8 ) >> 4;
			//EndY = ( vy.y + 0x8 ) >> 4;
			StartX = vx.x >> 4;
			EndX = vx.y >> 4;
			StartY = vy.x >> 4;
			EndY = vy.y >> 4;
		
			// get line distance x,y
			x_distance = abs( EndX - StartX );
			y_distance = abs( EndY - StartY );

			// get the endpoint, since it shouldn't be drawn
			iEndpointX = EndX;
			iEndpointY = EndY;

		
			if ( x_distance > y_distance )
			{
				// sort coords from left to right if line is horizontal
				if ( vx.y < vx.x )
				{
					vx.xy = vx.yx;
					vy.xy = vy.yx;
					va.xy = va.yx;
					vz.xy = vz.yx;
				}

			}
			else
			{
				// sort coords from top to bottom if line is vertical
				if ( vy.y < vy.x )
				{
					vx.xy = vx.yx;
					vy.xy = vy.yx;
					va.xy = va.yx;
					vz.xy = vz.yx;
				}

			}
		
			// final start/end points for drawing
			//StartX = ( vx.x + 0x8 ) >> 4;
			//EndX = ( vx.y + 0x8 ) >> 4;
			//StartY = ( vy.x + 0x8 ) >> 4;
			//EndY = ( vy.y + 0x8 ) >> 4;
			StartX = vx.x >> 4;
			EndX = vx.y >> 4;
			StartY = vy.x >> 4;
			EndY = vy.y >> 4;
		
		
			// get the left/right most x
			LeftMostX = min( StartX, EndX );
			RightMostX = max( StartX, EndX );
			TopMostY = min( StartY, EndY );
			BottomMostY = max( StartY, EndY );


			// check for some important conditions
			if ( DrawArea_BottomRightX < DrawArea_TopLeftX )
			{
				bDraw = 0;
			}
		
			if ( DrawArea_BottomRightY < DrawArea_TopLeftY )
			{
				bDraw = 0;
			}

			// check if sprite is within draw area
			if ( ( RightMostX < DrawArea_TopLeftX ) || ( LeftMostX > DrawArea_BottomRightX ) || ( BottomMostY < DrawArea_TopLeftY ) || ( TopMostY > DrawArea_BottomRightY ) )
			{
				bDraw = 0;
			}
		
			// skip drawing if distance between vertices is greater than max allowed by GPU
			if ( ( x_distance > c_MaxPolygonWidth ) || ( y_distance > c_MaxPolygonHeight ) )
			{
				bDraw = 0;
			}


			// get rgb-values

			c0 = ivec4( uvec4( unpack8( uint( va.x ) ) ) );
			c1 = ivec4( uvec4( unpack8( uint( va.y ) ) ) );
	
			z0 = uint( vz.x );
			z1 = uint( vz.y );
	
			//iC = ( c0 << 16 ) + 0x8000;
			iC = c0 << 16;

			//iz = int64_t( uint64_t( z0 ) << 16 ) + 0x8000;
			iz = int64_t( uint64_t( z0 ) << 16 );

			// check if line is horizontal
			if ( x_distance > y_distance )
			{
				// get the largest length
				line_length = x_distance;
		
				y0 = vy.x;
				y1 = vy.y;

				iy = ( y0 << 12 ) + 0x8000;

				if ( line_length != 0 )
				{
					/////////////////////////////////////////////
					// init x on the left and right

					dy = int( ( int64_t( y1 - y0 ) << 12 ) / int64_t( line_length ) );
					dc = ( ( c1 - c0 ) << 16 ) / ( line_length );

					dz = ( int64_t( uint64_t( z1 ) - uint64_t( z0 ) ) << 16 ) / int64_t( line_length );

					//dy <<= 8;
					//dc <<= 8;
					//dz <<= 8;
				}

		
				// check if line is going left or right
				// clip against edge of screen
				Temp = max( StartX, DrawArea_TopLeftX ) - StartX;
				StartX = max( StartX, DrawArea_TopLeftX );

				iy += dy * Temp;
				iC += dc * Temp;

				iz += dz * int64_t( Temp );
			
				EndX = min( EndX, DrawArea_BottomRightX );
		
				if ( dy < 0 )
				{
					if ( ( iy >> 16 ) < DrawArea_TopLeftY )
					{
						bDraw = 0;
					}
				}
		
				if ( dy > 0 )
				{
					if ( ( iy >> 16 ) > DrawArea_BottomRightY )
					{
						// line is veering off screen
						bDraw = 0;
					}
				}
			}
			else
			{
				// line is vertical //

				// get the largest length
				line_length = y_distance;
		
				x0 = vx.x;
				x1 = vx.y;
			
				ix = ( x0 << 12 ) + 0x8000;

				if ( line_length != 0 )
				{
					/////////////////////////////////////////////
					// init x on the left and right
			
					dx = int( ( int64_t( x1 - x0 ) << 12 ) / int64_t( line_length ) );
					dc = ( ( c1 - c0 ) << 16 ) / ( line_length );

					dz = ( int64_t( uint64_t( z1 ) - uint64_t( z0 ) ) << 16 ) / int64_t( line_length );

					//dx <<= 8;
					//dc <<= 8;
					//dz <<= 8;
				}
		
		
				// clip against edge of screen
				Temp = max( StartY, DrawArea_TopLeftY ) - StartY;
				StartY = max( StartY, DrawArea_TopLeftY );

				ix += dx * Temp;
				iC += dc * Temp;

				iz += dz * int64_t( Temp );
			
				EndY = min( EndY, DrawArea_BottomRightY );
	
				if ( dx < 0 )
				{
					if ( ( ix >> 16 ) < DrawArea_TopLeftX )
					{
						// line is veering off screen
						bDraw = 0;
					}
			
				}
		
				if ( dx > 0 )
				{
					if ( ( ix >> 16 ) > DrawArea_BottomRightX )
					{
						// line is veering off screen
						bDraw = 0;
					}
			
				}

			}	// end if else if ( x_distance > y_distance )


			// dz across/rgba/sync,etc //
			// split double and store
			dzdx2.xy = unpackInt2x32( dz );

			// also rgba
			dzdx2.z = bDraw;
			dzdx2.w = sync;

			data4 [ uIdx4 + 0 ] = ivec4( dzdx2 );


			// drgba across //

			data4 [ uIdx4 + 1 ] = dc;

			// draw area
			data [ uIdx + 8 ] = DrawArea_TopLeftX;
			data [ uIdx + 9 ] = DrawArea_TopLeftY;
			data [ uIdx + 10 ] = DrawArea_BottomRightX;
			data [ uIdx + 11 ] = DrawArea_BottomRightY;

			// store x/dx left/right
			vdx.x = ix;
			vdx.y = iy;
			vdx.z = dx;
			vdx.w = dy;
			data4 [ uIdx4 + 3 ] = vdx;


			// xdistance, ydistance, xendpoint,yendpoint //

			data [ uIdx + 16 ] = x_distance;
			data [ uIdx + 17 ] = y_distance;
			data [ uIdx + 18 ] = iEndpointX;
			data [ uIdx + 19 ] = iEndpointY;


			// first section //

			// starty0/endy0
			data [ uIdx + 20 ] = StartX;
			data [ uIdx + 21 ] = StartY;
			data [ uIdx + 22 ] = EndX;
			data [ uIdx + 23 ] = EndY;




			// store z left and dz left
			vdz2.xy = unpackInt2x32( iz );
			//vdz2.zw = unpackInt2x32( dz );
			data4 [ uIdx4 + 6 ] = ivec4( vdz2 );

			// drgba left //
			data4 [ uIdx4 + 7 ] = iC;



#endif	// end #ifdef PRECALC_LINE_VARS

		}
		else if ( ( PRIM & 7 ) <= 5 )
		{
			// triangle //

#ifdef PRECALC_TRIANGLE_VARS

			// triangle coords //


			// if mono triangle, then copy coord2 to all the colors
			if ( ( PRIM & 0x8 ) == 0 )
			{
				bgr32 = va.z;
			}

			if ( uint( vy.y ) < uint( vy.x ) )
			{
				//Coord.xyz = Coord.yxz;
				vy.xyz = vy.yxz;
				vz.xyz = vz.yxz;
				va.xyz = va.yxz;
				vu.xyz = vu.yxz;
				vv.xyz = vv.yxz;
				vr.xyz = vr.yxz;
				vf.xyz = vf.yxz;
			}

			if ( uint( vy.z ) < uint( vy.x ) )
			{
				//Coord.xyz = Coord.zyx;
				vy.xyz = vy.zyx;
				vz.xyz = vz.zyx;
				va.xyz = va.zyx;
				vu.xyz = vu.zyx;
				vv.xyz = vv.zyx;
				vr.xyz = vr.zyx;
				vf.xyz = vf.zyx;
			}
			
			if ( uint( vy.z ) < uint( vy.y ) )
			{
				//Coord.xyz = Coord.xzy;
				vy.xyz = vy.xzy;
				vz.xyz = vz.xzy;
				va.xyz = va.xzy;
				vu.xyz = vu.xzy;
				vv.xyz = vv.xzy;
				vr.xyz = vr.xzy;
				vf.xyz = vf.xzy;
			}
			
			// get x,y

			vx = vy & 0xffff;
			vy = ( vy >> 16 ) & 0xffff;
			
			// get z

			//***todo*** unsure of F is in upper or lower value ??

			// shift fog value down
			vf = vf & 0xff;

			// get r,g,b,a

			// if mono triangle, then all the colors are the same
			if ( ( PRIM & 0x8 ) == 0 )
			{
				va = ivec4( bgr32 );
			}


			//////////////////////////////////////////
			// get coordinates on screen
			// *note* this is different from PS1, where you would add the offsets..
			
			vx -= DrawArea_OffsetX;
			vy -= DrawArea_OffsetY;


			// get the left/right most x
			LeftMostX = ( ( vx.x < vx.y ) ? vx.x : vx.y );
			LeftMostX = ( ( vx.z < LeftMostX ) ? vx.z : LeftMostX );
			RightMostX = ( ( vx.x > vx.y ) ? vx.x : vx.y );
			RightMostX = ( ( vx.z > RightMostX ) ? vx.z : RightMostX );
			
			LeftMostX >>= 4;
			RightMostX >>= 4;
			TopMostY = vy.x >> 4;
			BottomMostY = vy.z >> 4;


			// draw test //


			// check if sprite is within draw area
			if ( ( RightMostX < DrawArea_TopLeftX ) || ( LeftMostX > DrawArea_BottomRightX ) || ( BottomMostY < DrawArea_TopLeftY ) || ( TopMostY > DrawArea_BottomRightY ) )
			{
				bDraw = 0;
			}


			if ( FST != 0 )
			{

				// get u,v

				vv = ( vu >> 16 ) & 0x3fff;
				vu &= 0x3fff;
				
			}
			else
			{
				// *** TODO *** //

				// put s,t coords into 10.4 fixed point
				// note: tex width/height should probably be minus one

				vs = intBitsToFloat ( vu );
				vt = intBitsToFloat ( vv );

				// multiply by tex width/height
				vs *= float( TexWidth );
				vt *= float( TexHeight );

				// had put q into vr for loading
				//vq = intBitsToFloat ( vu );
				vq = intBitsToFloat ( vr );

			}

			vb = ( va >> 0 ) & 0xff;
			vg = ( va >> 8 ) & 0xff;
			vr = ( va >> 16 ) & 0xff;
			va = ( va >> 24 ) & 0xff;

			// put the coords vertical

			vrgba0 = ivec4 ( vr.x, vg.x, vb.x, va.x );
			vrgba1 = ivec4 ( vr.y, vg.y, vb.y, va.y );
			vrgba2 = ivec4 ( vr.z, vg.z, vb.z, va.z );

			vstq0 = vec4 ( vs.x, vt.x, vq.x, vq.x );
			vstq1 = vec4 ( vs.y, vt.y, vq.y, vq.y );
			vstq2 = vec4 ( vs.z, vt.z, vq.z, vq.z );

			vf <<= 4;
			vuvf0 = ivec4 ( vu.x, vv.x, vf.x, vf.x );
			vuvf1 = ivec4 ( vu.y, vv.y, vf.y, vf.y );
			vuvf2 = ivec4 ( vu.z, vv.z, vf.z, vf.z );


			//t0 = vy[1] - vy[2];
			//t1 = vy[0] - vy[2];
			//denominator = ( ( vx[0] - vx[2] ) * t0 ) - ( ( vx[1] - vx[2] ) * t1 );
			t0 = vy.y - vy.z;
			t1 = vy.x - vy.z;
			denominator = ( ( vx.x - vx.z ) * t0 ) - ( ( vx.y - vx.z ) * t1 );
			
			// check if x1 is on left or right //
			
			// calculate across
			if ( denominator != 0 )
			{
				
				// result here should be in x.24 fixed point for now

				// colors //


				//drgbadx = intdivfv4( ( ( ( vrgba0 - vrgba2 ) * t0 ) - ( ( vrgba1 - vrgba2 ) * t1 ) ), denominator, 4, 8, 16 );
				drgbadx = int64div4( ( ( ( vrgba0 - vrgba2 ) * t0 ) - ( ( vrgba1 - vrgba2 ) * t1 ) ), denominator, 4, 8, 16 );

				// u/v texture coords //


				// fog //

				//duvfdx = intdivfv4( ( ( ( vuvf0 - vuvf2 ) * t0 ) - ( ( vuvf1 - vuvf2 ) * t1 ) ), denominator, 8, 8, 16 );
				duvfdx = int64div4( ( ( ( vuvf0 - vuvf2 ) * t0 ) - ( ( vuvf1 - vuvf2 ) * t1 ) ), denominator, 8, 8, 16 );


				// s/t/q texture coords //

				dstqdx = ( ( ( ( vstq0 - vstq2 ) * ( float( t0 ) ) ) - ( ( vstq1 - vstq2 ) * ( float( t1 ) ) ) ) / ( float( denominator ) ) ) * 16.0f;


				// z-value //

				// ***todo*** need to use a double here
				//dzdx = ( ( ( ( (s64) ( z0 - z2 ) ) * t0 ) - ( ( (s64) ( z1 - z2 ) ) * t1 ) ) << 27 ) / denominator;
				//dzdx = ( ( ( double(vz[0]) - double(vz[2]) ) * ( double( t0 )/16.0 ) ) - ( ( double(vz[1]) - double(vz[2]) ) * ( double( t1 )/16.0 ) ) ) / ( double( denominator )/256.0 );
				//dzdx = ( ( ( ( double(vz[0]) - double(vz[2]) ) * ( double( t0 ) ) ) - ( ( double(vz[1]) - double(vz[2]) ) * ( double( t1 ) ) ) ) / ( double( denominator ) ) ) * 16.0;
				dzdx = ( ( ( int64_t( uint64_t( vz[0] ) - uint64_t( vz[2] ) ) * int64_t( t0 ) ) - ( int64_t( uint64_t( vz[1] ) - uint64_t( vz[2] ) ) * int64_t( t1 ) ) ) << 16 ) / int64_t( denominator );
				dzdx <<= 4;


				//drdx = drgbadx.r;
				//dgdx = drgbadx.g;
				//dbdx = drgbadx.b;
				//dadx = drgbadx.a;
				//dudx = duvfdx.x;
				//dvdx = duvfdx.y;
				//dfdx = duvfdx.z;
				//dsdx = dstqdx.x;
				//dtdx = dstqdx.y;
				//dqdx = dstqdx.z;
			}
			
			
			/////////////////////////////////////////////////
			// draw top part of triangle
			
			
			

			if ( ( vy.y - vy.x ) != 0 )
			{
				// triangle is pointed on top //

				// need to set the x0 index unconditionally
				//vdx [ X0Index ] = ( vx[0] << 12 );
				vdx.xy = vx.xx << 12;
				
				
				//vdr = vr.x << 16;
				//vdg = vg.x << 16;
				//vdb = vb.x << 16;
				//vda = va.x << 16;

				//vdu = vu.x << 12;
				//vdv = vv.x << 12;
				//vdf = vf.x << 16;

				//vds = vs.x;
				//vdt = vt.x;
				//vdq = vq.x;
				

				vdrgba = vrgba0 << 16;
				vduvf = vuvf0 << 12;
				vdstq = vstq0;

				//vdz = double( vz[0] );
				vdz = int64_t( uint64_t( vz[0] ) << 16 );


				if ( denominator < 0 )
				{
					//vdxdy [ 0 ] = intdivf2(( vx[1] - vx[0] ), ( vy[1] - vy[0] ), 4, 4, 16 );
					//vdxdy [ 1 ] = intdivf2(( vx[2] - vx[0] ), ( vy[2] - vy[0] ), 4, 4, 16 );
					//vdxdy.xy = intdivfv2( vx.yz - vx.xx, vy.yz - vy.xx, 4, 4, 16 );
					vdxdy.xy = int64div2( vx.yz - vx.xx, vy.yz - vy.xx, 4, 4, 16 );

					
					//vdrdy = intdivf2(( vr.y - vr.x ), ( vy.y - vy.x ), 0, 4, 16 );
					//vdgdy = intdivf2(( vg.y - vg.x ), ( vy.y - vy.x ), 0, 4, 16 );
					//vdbdy = intdivf2(( vb.y - vb.x ), ( vy.y - vy.x ), 0, 4, 16 );
					//vdady = intdivf2(( va.y - va.x ), ( vy.y - vy.x ), 0, 4, 16 );

					//vdudy = intdivf2(( vu.y - vu.x ), ( vy.y - vy.x ), 4, 4, 16 );
					//vdvdy = intdivf2(( vv.y - vv.x ), ( vy.y - vy.x ), 4, 4, 16 );
					//vdfdy = intdivf2(( vf.y - vf.x ), ( vy.y - vy.x ), 0, 4, 16 );

					//vdsdy = ( ( vs.y - vs.x ) / ( float( vy.y - vy.x ) ) ) * 16.0f;
					//vdtdy = ( ( vt.y - vt.x ) / ( float( vy.y - vy.x ) ) ) * 16.0f;
					//vdqdy = ( ( vq.y - vq.x ) / ( float( vy.y - vy.x ) ) ) * 16.0f;
					

					//vdrgbady = intdivfv4( vrgba1 - vrgba0, vy.y - vy.x, 0, 4, 16 );
					//vduvfdy = intdivfv4( vuvf1 - vuvf0, vy.y - vy.x, 4, 4, 16 );
					vdrgbady = int64div4( vrgba1 - vrgba0, vy.y - vy.x, 0, 4, 16 );
					vduvfdy = int64div4( vuvf1 - vuvf0, vy.y - vy.x, 4, 4, 16 );
					vdstqdy = ( ( vstq1 - vstq0 ) / ( float( vy.y - vy.x ) ) ) * 16.0f;

					//vdzdy = ( ( double(vz[1]) - double(vz[0]) ) / ( double( vy[1] - vy[0] ) ) ) * 16.0;
					vdzdy = ( int64_t( uint64_t( vz[1] ) - uint64_t( vz[0] ) ) << 20 ) / int64_t( vy[1] - vy[0] );
				}
				else
				{
					//vdxdy [ 0 ] = intdivf2(( vx[2] - vx[0] ), ( vy[2] - vy[0] ), 4, 4, 16 );
					//vdxdy [ 1 ] = intdivf2(( vx[1] - vx[0] ), ( vy[1] - vy[0] ), 4, 4, 16 );
					//vdxdy.xy = intdivfv2( vx.zy - vx.xx, vy.zy - vy.xx, 4, 4, 16 );
					vdxdy.xy = int64div2( vx.zy - vx.xx, vy.zy - vy.xx, 4, 4, 16 );

					
					//vdrdy = intdivf2(( vr.z - vr.x ), ( vy.z - vy.x ), 0, 4, 16 );
					//vdgdy = intdivf2(( vg.z - vg.x ), ( vy.z - vy.x ), 0, 4, 16 );
					//vdbdy = intdivf2(( vb.z - vb.x ), ( vy.z - vy.x ), 0, 4, 16 );
					//vdady = intdivf2(( va.z - va.x ), ( vy.z - vy.x ), 0, 4, 16 );

					//vdudy = intdivf2(( vu.z - vu.x ), ( vy.z - vy.x ), 4, 4, 16 );
					//vdvdy = intdivf2(( vv.z - vv.x ), ( vy.z - vy.x ), 4, 4, 16 );
					//vdfdy = intdivf2(( vf.z - vf.x ), ( vy.z - vy.x ), 0, 4, 16 );

					//vdsdy = ( ( vs.z - vs.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
					//vdtdy = ( ( vt.z - vt.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
					//vdqdy = ( ( vq.z - vq.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
					

					//vdrgbady = intdivfv4( vrgba2 - vrgba0, vy.z - vy.x, 0, 4, 16 );
					//vduvfdy = intdivfv4( vuvf2 - vuvf0, vy.z - vy.x, 4, 4, 16 );
					vdrgbady = int64div4( vrgba2 - vrgba0, vy.z - vy.x, 0, 4, 16 );
					vduvfdy = int64div4( vuvf2 - vuvf0, vy.z - vy.x, 4, 4, 16 );
					vdstqdy = ( ( vstq2 - vstq0 ) / ( float( vy.z - vy.x ) ) ) * 16.0f;

					//vdzdy = ( ( double(vz[2]) - double(vz[0]) ) / ( double( vy[2] - vy[0] ) ) ) * 16.0;
					vdzdy = ( int64_t( uint64_t( vz[2] ) - uint64_t( vz[0] ) ) << 20 ) / int64_t( vy[2] - vy[0] );
				}
				

			}
			else
			{
				// Triangle is flat on top //


				if ( denominator < 0 )
				{
					// x1 is on left //
					vdx.xy = vx.yx << 12;
					
					
					//vdr = vr.y << 16;
					//vdg = vg.y << 16;
					//vdb = vb.y << 16;
					//vda = va.y << 16;

					//vdu = vu.y << 12;
					//vdv = vv.y << 12;
					//vdf = vf.y << 16;

					//vds = vs.y;
					//vdt = vt.y;
					//vdq = vq.y;
					

					vdrgba = vrgba1 << 16;
					vduvf = vuvf1 << 12;
					vdstq = vstq1;

					//vdz = double( vz[1] );
					vdz = int64_t( uint64_t( vz[1] ) << 16 );

					if ( ( vy.z - vy.y ) != 0 )
					{
						//vdxdy [ 0 ] = intdivf2(( vx[2] - vx[1] ), ( vy[2] - vy[1] ), 4, 4, 16 );
						//vdxdy [ 1 ] = intdivf2(( vx[2] - vx[0] ), ( vy[2] - vy[0] ), 4, 4, 16 );
						//vdxdy.xy = intdivfv2( vx.zz - vx.yx, vy.zz - vy.yx, 4, 4, 16 );
						vdxdy.xy = int64div2( vx.zz - vx.yx, vy.zz - vy.yx, 4, 4, 16 );
						
						
						//vdrdy = intdivf2(( vr.z - vr.y ), ( vy.z - vy.y ), 0, 4, 16 );
						//vdgdy = intdivf2(( vg.z - vg.y ), ( vy.z - vy.y ), 0, 4, 16 );
						//vdbdy = intdivf2(( vb.z - vb.y ), ( vy.z - vy.y ), 0, 4, 16 );
						//vdady = intdivf2(( va.z - va.y ), ( vy.z - vy.y ), 0, 4, 16 );

						//vdudy = intdivf2(( vu.z - vu.y ), ( vy.z - vy.y ), 4, 4, 16 );
						//vdvdy = intdivf2(( vv.z - vv.y ), ( vy.z - vy.y ), 4, 4, 16 );
						//vdfdy = intdivf2(( vf.z - vf.y ), ( vy.z - vy.y ), 0, 4, 16 );

						//vdsdy = ( ( vs.z - vs.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;
						//vdtdy = ( ( vt.z - vt.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;
						//vdqdy = ( ( vq.z - vq.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;
						

						//vdrgbady = intdivfv4( vrgba2 - vrgba1, vy.z - vy.y, 0, 4, 16 );
						//vduvfdy = intdivfv4( vuvf2 - vuvf1, vy.z - vy.y, 4, 4, 16 );
						vdrgbady = int64div4( vrgba2 - vrgba1, vy.z - vy.y, 0, 4, 16 );
						vduvfdy = int64div4( vuvf2 - vuvf1, vy.z - vy.y, 4, 4, 16 );
						vdstqdy = ( ( vstq2 - vstq1 ) / ( float( vy.z - vy.y ) ) ) * 16.0f;

						//vdzdy = ( ( double(vz[2]) - double(vz[1]) ) / ( double( vy[2] - vy[1] ) ) ) * 16.0;
						vdzdy = ( int64_t( uint64_t( vz[2] ) - uint64_t( vz[1] ) ) << 20 ) / int64_t( vy[2] - vy[1] );
					}
				}
				else
				{
					// x1 is on right //
					vdx.xy = vx.xy << 12;
					
					
					//vdr = vr.x << 16;
					//vdg = vg.x << 16;
					//vdb = vb.x << 16;
					//vda = va.x << 16;

					//vdu = vu.x << 12;
					//vdv = vv.x << 12;
					//vdf = vf.x << 16;

					//vds = vs.x;
					//vdt = vt.x;
					//vdq = vq.x;
					

					vdrgba = vrgba0 << 16;
					vduvf = vuvf0 << 12;
					vdstq = vstq0;

					//vdz = double( vz[0] );
					vdz = int64_t( uint64_t( vz[0] ) << 16 );

					if ( ( vy.z - vy.y ) != 0 )
					{
						//vdxdy [ 0 ] = intdivf2(( vx[2] - vx[0] ), ( vy[2] - vy[0] ), 4, 4, 16 );
						//vdxdy [ 1 ] = intdivf2(( vx[2] - vx[1] ), ( vy[2] - vy[1] ), 4, 4, 16 );
						//vdxdy.xy = intdivfv2( vx.zz - vx.xy, vy.zz - vy.xy, 4, 4, 16 );
						vdxdy.xy = int64div2( vx.zz - vx.xy, vy.zz - vy.xy, 4, 4, 16 );
						
						
						//vdrdy = intdivf2(( vr.z - vr.x ), ( vy.z - vy.x ), 0, 4, 16 );
						//vdgdy = intdivf2(( vg.z - vg.x ), ( vy.z - vy.x ), 0, 4, 16 );
						//vdbdy = intdivf2(( vb.z - vb.x ), ( vy.z - vy.x ), 0, 4, 16 );
						//vdady = intdivf2(( va.z - va.x ), ( vy.z - vy.x ), 0, 4, 16 );

						//vdudy = intdivf2(( vu.z - vu.x ), ( vy.z - vy.x ), 4, 4, 16 );
						//vdvdy = intdivf2(( vv.z - vv.x ), ( vy.z - vy.x ), 4, 4, 16 );
						//vdfdy = intdivf2(( vf.z - vf.x ), ( vy.z - vy.x ), 0, 4, 16 );

						//vdsdy = ( ( vs.z - vs.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
						//vdtdy = ( ( vt.z - vt.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
						//vdqdy = ( ( vq.z - vq.x ) / ( float( vy.z - vy.x ) ) ) * 16.0f;
						

						//vdrgbady = intdivfv4( vrgba2 - vrgba0, vy.z - vy.x, 0, 4, 16 );
						//vduvfdy = intdivfv4( vuvf2 - vuvf0, vy.z - vy.x, 4, 4, 16 );
						vdrgbady = int64div4( vrgba2 - vrgba0, vy.z - vy.x, 0, 4, 16 );
						vduvfdy = int64div4( vuvf2 - vuvf0, vy.z - vy.x, 4, 4, 16 );
						vdstqdy = ( ( vstq2 - vstq0 ) / ( float( vy.z - vy.x ) ) ) * 16.0f;

						//vdzdy = ( ( double(vz[2]) - double(vz[0]) ) / ( double( vy[2] - vy[0] ) ) ) * 16.0;
						vdzdy = ( int64_t( uint64_t( vz[2] ) - uint64_t( vz[0] ) ) << 20 ) / int64_t( vy[2] - vy[0] );
					}
				}
				
			}



			// left point is included if points are equal
			StartY = ( vy.x + 0xf ) >> 4;
			EndY = ( vy.y - 1 ) >> 4;


			Temp = ( StartY << 4 ) - vy.x;

			if ( StartY < DrawArea_TopLeftY )
			{
				if ( EndY < DrawArea_TopLeftY )
				{
					Temp += ( EndY - StartY + 1 ) << 4;
					StartY = EndY + 1;
				}
				else
				{
					Temp += ( DrawArea_TopLeftY - StartY ) << 4;
					StartY = DrawArea_TopLeftY;
				}
			}
			
			
			if ( EndY > DrawArea_BottomRightY )
			{
				EndY = DrawArea_BottomRightY;
			}

			
			// dxdy is in .16, Temp is in .4, and x is in .16
			//vdx [ 0 ] += ( vdxdy [ 0 ] >> 4 ) * Temp;
			//vdx [ 1 ] += ( vdxdy [ 1 ] >> 4 ) * Temp;
			vdx += ( vdxdy >> 4 ) * Temp;
			
			
			//vdr += ( vdrdy >> 4 ) * Temp;
			//vdg += ( vdgdy >> 4 ) * Temp;
			//vdb += ( vdbdy >> 4 ) * Temp;
			//vda += ( vdady >> 4 ) * Temp;

			//vdu += ( vdudy >> 4 ) * Temp;
			//vdv += ( vdvdy >> 4 ) * Temp;
			//vdf += ( vdfdy >> 4 ) * Temp;

			//vds += ( vdsdy ) * ( float( Temp )/16.0f );
			//vdt += ( vdtdy ) * ( float( Temp )/16.0f );
			//vdq += ( vdqdy ) * ( float( Temp )/16.0f );

			vdrgba += ( vdrgbady >> 4 ) * Temp;
			vduvf += ( vduvfdy >> 4 ) * Temp;
			vdstq += ( vdstqdy ) * ( float( Temp )/16.0f );

			// *** todo *** should be a double
			//vdz += ( vdzdy ) * ( double( Temp )/16.0 );
			vdz += ( vdzdy >> 4 ) * int64_t( Temp );

// 0
// dz across
// dz across
// draw
// sync

// 4
// dr across
// dg across
// db across
// da across

// 8
// ds/u across
// dt/v across
// dq across
// df across

// 12
// starty0
// endy0
// starty1
// endy1

// 16
// x0 left
// x0 right
// dx0 left
// dx0 right

// 20
// z0 left
// z0 left
// dz0 left
// dz0 left

// 24
// r0 left
// g0 left
// b0 left
// a0 left

// 28
// dr0 left
// dg0 left
// db0 left
// da0 left

// 32
// s/u0 left
// t/v0 left
// q0 left
// f0 left

// 36
// ds/u0 left
// dt/v0 left
// dq0 left
// df0 left

// 40
// x1 left
// x1 right
// dx1 left
// dx1 right

// 44
// z1 left
// z1 left
// dz1 left
// dz1 left

// 48
// r1 left
// g1 left
// b1 left
// a1 left

// 52
// dr1 left
// dg1 left
// db1 left
// da1 left

// 56
// s/u1 left
// t/v1 left
// q1 left
// f1 left

// 60
// ds/u1 left
// dt/v1 left
// dq1 left
// df1 left

			// triangle vars //

			// dz across/rgba/sync,etc //
			// split double and store
			dzdx2.xy = unpackInt2x32( dzdx );

			// also rgba
			dzdx2.z = bDraw;
			dzdx2.w = sync;

			data4 [ uIdx4 + 0 ] = ivec4( dzdx2 );


			// drgba across //

			data4 [ uIdx4 + 1 ] = drgbadx;

			// dstqf or duvqf across //

			// handle stq/uvf
			duvfdx.w = duvfdx.z;
			if ( FST == 0 )
			{
				duvfdx.xyz = floatBitsToInt( dstqdx.xyz );
			}
			data4 [ uIdx4 + 2 ] = duvfdx;


			// first section //

			// starty0/endy0
			data [ uIdx + 12 ] = StartY;
			data [ uIdx + 13 ] = EndY;


			// store x/dx left/right
			vdx.zw = vdxdy.xy;
			data4 [ uIdx4 + 4 ] = vdx;


			// store z left and dz left
			vdz2.xy = unpackInt2x32( vdz );
			vdz2.zw = unpackInt2x32( vdzdy );
			data4 [ uIdx4 + 5 ] = ivec4( vdz2 );


			// drgba left //
			data4 [ uIdx4 + 6 ] = vdrgba;

			// drgbady left //
			data4 [ uIdx4 + 7 ] = vdrgbady;
			

			// handle stq/uvf left //
			//duvf.w = duvf.z;
			//vduvfdy.w = vduvfdy.z;
			if ( FST == 0 )
			{
				vduvf.xyz = floatBitsToInt( vdstq.xyz );
				vduvfdy.xyz = floatBitsToInt( vdstqdy.xyz );
			}
			data4 [ uIdx4 + 8 ] = vduvf;
			data4 [ uIdx4 + 9 ] = vduvfdy;

	

			if ( denominator < 0 )
			{
				vdx.x = vx.y << 12;
				vdx.y = ( vx.x << 12 ) + ( ( vy.y - vy.x ) * ( vdxdy.y >> 4 ) );
				
				//vdr = vr.y << 16;
				//vdg = vg.y << 16;
				//vdb = vb.y << 16;
				//vda = va.y << 16;

				//vdu = vu.y << 12;
				//vdv = vv.y << 12;
				//vdf = vf.y << 16;

				//vds = vs.y;
				//vdt = vt.y;
				//vdq = vq.y;

				vdrgba = vrgba1 << 16;
				vduvf = vuvf1 << 12;
				vdstq = vstq1;

				//vdz = double( vz[1] );
				vdz = int64_t( uint64_t( vz[1] ) << 16 );

				
				if ( ( vy.z - vy.y ) != 0 )
				{
					// triangle is pointed on the bottom //
					//vdxdy.x = intdivf2(( vx.z - vx.y ), ( vy.z - vy.y ), 4, 4, 16 );
					vdxdy.x = int64div(( vx.z - vx.y ), ( vy.z - vy.y ), 4, 4, 16 );
					
					//vdrdy = intdivf2(( vr.z - vr.y ), ( vy.z - vy.y ), 0, 4, 16 );
					//vdgdy = intdivf2(( vg.z - vg.y ), ( vy.z - vy.y ), 0, 4, 16 );
					//vdbdy = intdivf2(( vb.z - vb.y ), ( vy.z - vy.y ), 0, 4, 16 );
					//vdady = intdivf2(( va.z - va.y ), ( vy.z - vy.y ), 0, 4, 16 );

					//vdudy = intdivf2(( vu.z - vu.y ), ( vy.z - vy.y ), 4, 4, 16 );
					//vdvdy = intdivf2(( vv.z - vv.y ), ( vy.z - vy.y ), 4, 4, 16 );
					//vdfdy = intdivf2(( vf.z - vf.y ), ( vy.z - vy.y ), 0, 4, 16 );

					//vdsdy = ( ( vs.z - vs.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;
					//vdtdy = ( ( vt.z - vt.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;
					//vdqdy = ( ( vq.z - vq.y ) / ( float( vy.z - vy.y ) ) ) * 16.0f;

					//vdrgbady = intdivfv4( vrgba2 - vrgba1, vy.z - vy.y, 0, 4, 16 );
					//vduvfdy = intdivfv4( vuvf2 - vuvf1, vy.z - vy.y, 4, 4, 16 );
					vdrgbady = int64div4( vrgba2 - vrgba1, vy.z - vy.y, 0, 4, 16 );
					vduvfdy = int64div4( vuvf2 - vuvf1, vy.z - vy.y, 4, 4, 16 );
					vdstqdy = ( ( vstq2 - vstq1 ) / ( float( vy.z - vy.y ) ) ) * 16.0f;

					//vdzdy = ( ( double(vz[2]) - double(vz[1]) ) / ( double( vy[2] - vy[1] ) ) ) * 16.0;
					vdzdy = ( int64_t( uint64_t(vz[2]) - uint64_t(vz[1]) ) << 20 ) / int64_t( vy[2] - vy[1] );

				}
				
			}
			else
			{
				vdx.y = vx.y << 12;
				vdx.x = ( vx.x << 12 ) + ( ( vy.y - vy.x ) * ( vdxdy.x >> 4 ) );
				
				//vdr = ( vr.x << 16 ) + ( ( vy.y - vy.x ) * ( vdrdy >> 4 ) );
				//vdg = ( vg.x << 16 ) + ( ( vy.y - vy.x ) * ( vdgdy >> 4 ) );
				//vdb = ( vb.x << 16 ) + ( ( vy.y - vy.x ) * ( vdbdy >> 4 ) );
				//vda = ( va.x << 16 ) + ( ( vy.y - vy.x ) * ( vdady >> 4 ) );

				//vdu = ( vu.x << 12 ) + ( ( vy.y - vy.x ) * ( vdudy >> 4 ) );
				//vdv = ( vv.x << 12 ) + ( ( vy.y - vy.x ) * ( vdvdy >> 4 ) );
				//vdf = ( vf.x << 16 ) + ( ( vy.y - vy.x ) * ( vdfdy >> 4 ) );

				//vds = vs.x + ( (float( vy.y - vy.x )/16.0f) * vdsdy );
				//vdt = vt.x + ( (float( vy.y - vy.x )/16.0f) * vdtdy );
				//vdq = vq.x + ( (float( vy.y - vy.x )/16.0f) * vdqdy );

				vdrgba = ( vrgba0 << 16 ) + ( ( vy.y - vy.x ) * ( vdrgbady >> 4 ) );
				vduvf = ( vuvf0 << 12 ) + ( ( vy.y - vy.x ) * ( vduvfdy >> 4 ) );
				vdstq = vstq0 + ( ( float( vy.y - vy.x )/16.0f ) * vdstqdy );

				//vdz = double(vz[0]) + ( (double( vy.y - vy.x )/16.0) * vdzdy );
				vdz = int64_t( uint64_t( vz[0] ) << 16 ) + ( int64_t( vy.y - vy.x ) * ( vdzdy >> 4 ) );

				if ( ( vy.z - vy.y ) != 0 )
				{
					// triangle is pointed on the bottom //
					//vdxdy.y = intdivf2(( vx.z - vx.y ), ( vy.z - vy.y ), 4, 4, 16 );
					vdxdy.y = int64div(( vx.z - vx.y ), ( vy.z - vy.y ), 4, 4, 16 );
				}
			}


			// left point is included if points are equal
			StartY = ( vy.y + 0xf ) >> 4;
			EndY = ( vy.z - 1 ) >> 4;


			Temp = ( StartY << 4 ) - vy.y;


			if ( StartY < DrawArea_TopLeftY )
			{
				if ( EndY < DrawArea_TopLeftY )
				{
					Temp += ( EndY - StartY + 1 ) << 4;
					StartY = EndY + 1;
				}
				else
				{
					Temp += ( DrawArea_TopLeftY - StartY ) << 4;
					StartY = DrawArea_TopLeftY;
				}
			}
			
			
			if ( EndY > DrawArea_BottomRightY )
			{
				EndY = DrawArea_BottomRightY;
			}

			
			// dxdy is in .16, Temp is in .4, and x is in .16
			//vdx [ 0 ] += ( vdxdy [ 0 ] >> 4 ) * Temp;
			//vdx [ 1 ] += ( vdxdy [ 1 ] >> 4 ) * Temp;
			vdx += ( vdxdy >> 4 ) * Temp;
			
			//vdr += ( vdrdy >> 4 ) * Temp;
			//vdg += ( vdgdy >> 4 ) * Temp;
			//vdb += ( vdbdy >> 4 ) * Temp;
			//vda += ( vdady >> 4 ) * Temp;

			//vdu += ( vdudy >> 4 ) * Temp;
			//vdv += ( vdvdy >> 4 ) * Temp;
			//vdf += ( vdfdy >> 4 ) * Temp;

			//vds += ( vdsdy ) * ( float( Temp )/16.0f );
			//vdt += ( vdtdy ) * ( float( Temp )/16.0f );
			//vdq += ( vdqdy ) * ( float( Temp )/16.0f );

			vdrgba += ( vdrgbady >> 4 ) * Temp;
			vduvf += ( vduvfdy >> 4 ) * Temp;
			vdstq += ( vdstqdy ) * ( float( Temp )/16.0f );

			// *** todo *** should be a double
			//vdz += ( vdzdy ) * ( double( Temp )/16.0 );
			vdz += ( vdzdy >> 4 ) * int64_t( Temp );


			// second set //

			// starty1/endy1
			data [ uIdx + 14 ] = StartY;
			data [ uIdx + 15 ] = EndY;


			// store x/dx left/right
			vdx.zw = vdxdy.xy;
			data4 [ uIdx4 + 10 ] = vdx;


			// store z left and dz left
			vdz2.xy = unpackInt2x32( vdz );
			vdz2.zw = unpackInt2x32( vdzdy );
			data4 [ uIdx4 + 11 ] = ivec4( vdz2 );

			// drgba left //
			data4 [ uIdx4 + 12 ] = vdrgba;

			// drgbady left //
			data4 [ uIdx4 + 13 ] = vdrgbady;
			

			// handle stq/uvf left //
			//duvf.w = duvf.z;
			//vduvfdy.w = vduvfdy.z;
			if ( FST == 0 )
			{
				vduvf.xyz = floatBitsToInt( vdstq.xyz );
				vduvfdy.xyz = floatBitsToInt( vdstqdy.xyz );
			}
			data4 [ uIdx4 + 14 ] = vduvf;
			data4 [ uIdx4 + 15 ] = vduvfdy;




#endif	// end #ifdef PRECALC_TRIANGLE_VARS

		}



	// -----------------------------------------------




	// -------------------------------------------




	// ---------------------------------------------

		


// -------------------------------------------------------
		

	}	// end for ( uCount = gxxid; uCount < uEndIdx; uCount += gxxinc )
	//} while ( ( ( inputdata [ uIndex + ( 15 << 1 ) + 0 ] >> 24 ) != 0xff ) && ( xxid < PRECOMPUTE_LIST_SIZE ) );

	//barrier ();
}






#ifdef ENABLE_DRAW_PIXEL_COLOR

void Draw_Pixel_Color ( uint uIndex )
{
	// constants //


	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	// variables //

	//int xid;
	int yid;

	int x0, y0;
	uint z0;

	uint Comm;
	int bDraw;

	uint uIdx;


	int iPtr;
	ivec4 ivPtr;
	
	int Temp;
	
	uint DestPixel;
	uint bgr_temp;
	int x_across;
	int Line;

	uint bgr16;
	uint bgr32;
	int x, y, w, h;
	int DrawArea_TopLeftX;
	int DrawArea_TopLeftY;
	int DrawArea_BottomRightX;
	int DrawArea_BottomRightY;
	int DrawArea_OffsetX;
	int DrawArea_OffsetY;

	int ix, iy;

	int sw, sh;
	int count;
	int idx;
	ivec4 idx4;
	ivec4 ivLine;

	//int StartX;
	//int EndX;
	//int StartY;
	//int EndY;


	uint PRIM;
	//int FRAME;
	//uint FBMSK;

	uint FST, ABE, FGE, PABE;
	uint AA1;

	//int FBP;
	//int FBW;
	//int FPSM;

	//int FrameBufferStartOffset32;
	//int FrameBufferWidth_Pixels;

	//int yoffset32, zyoffset32;
	//int yoffset32_xor, zyoffset32_xor;
	//ivec4 vXOffset32, vZXOffset32;

	uint TEST, ATE, ATST, AFAIL;
	//uint DATE, DATM;
	uint DATE;
	uint ZTE, ZTST;
	uint AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;

	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	//uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	uvec4 vAREF;

	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;

	//int ZBUF;
	//int ZBP;
	//int ZPSM;
	//int ZMSK;

	int ZBufferStartOffset32;

	uint FBA;

	ivec4 vIdx0;
	ivec4 vIdx;
	ivec4 vIdx32;
	ivec4 vxid;
	ivec4 vx_across;
	ivec4 vOffset;
	ivec4 vZOffset;

	uvec4 vDestPixel16, vDestPixel32, vDestPixel32_0, vDestPixel32_1;
	uvec4 vZDestPixel16, vZDestPixel32, vZDestPixel32_0, vZDestPixel32_1;
	uvec4 vZDestPixel24_1;
	uvec4 vPixel32, vZPixel32;
	uvec4 vPixel24, vZPixel24;
	uvec4 vPixel32_0, vPixel32_1, vZPixel32_0, vZPixel32_1;
	uvec4 vPixel32_2;
	uvec4 vPixel16;
	uvec4 vMask, vMask32;
	ivec4 vPixelShift;

	uvec4 vDPixelX, vZPixelX;

	bvec4 bvALPHA_A_SELECT, bvALPHA_B_SELECT, bvALPHA_C_SELECT, bvALPHA_D_SELECT;
	ivec4 ivAlphaA, ivAlphaB, ivAlphaC, ivAlphaD;
	ivec4 ivRedA, ivRedB, ivRedC, ivRedD;
	ivec4 ivGreenA, ivGreenB, ivGreenC, ivGreenD;
	ivec4 ivBlueA, ivBlueB, ivBlueC, ivBlueD;

	//ivec4 ivATSelect, ivDASelect, ivZSelect;
	uvec4 uvATSelect, uvDASelect, uvZSelect;

	bvec4 bvZTST_LESS, bvZTST_GREATER, bvZTST_EQUAL;
	bvec4 bvTestMask;
	bvec4 bvEnable;
	uvec4 uvEnable;
	uvec4 uvZTST_EQUAL, uvZTST_GREATER;

	uvec4 vTestPixel32;

	int DRAWPSM;
	//int ZBUFPSM;

	ivec4 vav, vrv, vgv, vbv;
	ivec4 vaf, vrf, vgf, vbf;
	ivec4 vat, vrt, vgt, vbt;
	ivec4 va, vm;

	uvec4 uvbgr32;

	ivec2 vx, vy;

	int COLCLAMP;

	int DYNAND, ZYNAND;
	uvec4 uvALPHA_FIX;

	int iATOffset, iATMask;

	uint ctx;

	//uvec4 uvAlphaSelect [ 4 ];

	// note: these are for textured objects only
	//uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX;
	//uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX;
	//uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM;
	//uvec4 uvTEX02_TW_TH_TWMASK_THMASK;
	//uvec4 uvTEX02_TCC_TFX_CPSM_CSA;


	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	uvec4 uvZTST_LESS_EQUAL_GREATER;
	uvec4 uvATST_LEG_OFFSET_MASK;

	uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	uvec4 uv_z0_f0_bDraw_sync;
	ivec4 iv_StartX_StartY_EndX_EndY;
	ivec4 iv_vu_vv_dudx_dvdy;
	uvec4 uv_w_rf0_bgr32;

	int iZMASK, iAMASK;

	bool bFRAME32;
	bool bZBUF32;

	// *** setup *** //

	// 64 elements each
	uIdx = uIndex << 6;

	// 32 elements each
	uIndex <<= 5;

	


	//bDraw = data [ uIdx + 0 ];
	bDraw = data [ uIdx + 2 ];

	//if ( subgroupAll( bDraw != 0 ) )
	{

		// load common vars //

		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );

		// for now treating AA1 as alpha
		ABE |= AA1;

		// note: CLAMP and TEXA are for textured objects
		// note: DIMX is for gradient objects
		//uvCLAMP_WMS_AND_OR_MIN_MAX = uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];
		//uvCLAMP_WMT_AND_OR_MIN_MAX = uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];

		// note: TEX0/2 data is only needed for textured objects
		//uvTEX02_TBP_TBW_TPSM_TEXPSM = uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TW_TH_TWMASK_THMASK = uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TCC_TFX_CPSM_CSA = uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ ctx ];

		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;


		//uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		//uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];
		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		//uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );

		
		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );


		// load rectangle vars //

		// loading 4 at a time from pre-calc values
		//uIdx >>= 2;
		//uv_z0_f0_bDraw_sync = data4 [ uIdx + 0 ];
		//iv_StartX_StartY_EndX_EndY = data4 [ uIdx + 2 ];
		//iv_vu_vv_dudx_dvdy = data4 [ uIdx + 3 ];
		//uv_w_rf0_bgr32 = data4 [ uIdx + 4 ];
		x0 = data [ uIdx + 0 ];
		y0 = data [ uIdx + 1 ];
		z0 = data [ uIdx + 2 ];
		bgr32 = data [ uIdx + 3 ];


		// COLCLAMP(+15)(0x46),PABE(+27)(0x49)
		//COLCLAMP = int( inputdata [ uIndex + 15 ] );
		//PABE = inputdata [ uIndex + 27 ];
		COLCLAMP = int( uvps2gpu_vars[subgroup_local_id][0x46].x );
		PABE = int( uvps2gpu_vars[subgroup_local_id][0x49].x );

		// FBA (0x4a,0x4b)
		FBA = int( uvps2gpu_vars[subgroup_local_id][0x4a+ctx].x );

		// FOGCOL(+31)(0x3d),DTHE/DIMX(0x45/0x44)
		//FOGCOL = uvps2gpu_vars[subgroup_local_id][0x3d].x;
		//DTHE = uvps2gpu_vars[subgroup_local_id][0x45].x;
		//DIMX2 = uvps2gpu_vars[subgroup_local_id][0x44];

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		int(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		int(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])


	//uvbgr32 = uvec4( BGR32 );

	// 24-bit pixels do not have destination alpha test
	DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

	// this will come last
	COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

	//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
	PABE <<= 31;

	// FBA
	FBA <<= 31;

	// FOGCOL
	// DTHE/DIMX
	//DIMX &= -( DTHE & 1 );

	// if alpha is disabled then no alpha blending
	uvALPHA_ABCD &= -ABE;

	// drawpsm is fpsm shifted right one
	DRAWPSM = int( FPSM >> 1 );

	bFRAME32 = ( DRAWPSM & 1 ) == 0;
	bZBUF32 = ( ZBUFPSM & 1 ) == 0;


	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];


	//vAREF = uvec4( AREF );
	//uvALPHA_FIX = uvec4( ALPHA_FIX );
	vAREF = uvec4( uvTEST_ATE_AREF_ATST_AFAIL[1] );
	uvALPHA_FIX = uvec4( uvALPHA_ABCD_FIX[1] );

	iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
	iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];


	// get nearest pixel
	ix = ( x0 + 0x8 ) >> 4;
	iy = ( y0 + 0x8 ) >> 4;

	if ( ( iy >= ivDrawRange [ subgroup_local_id ].x ) && ( iy < ivDrawRange [ subgroup_local_id ].y ) )
	{
		uvEnable = uvec4( 1, 0, 0, 0 );

			ivPtr = ivec4( ( ix & 0x3f ) | ( ( iy & 0x3f ) << 7 ) );


			// get the pixels to be drawn
			//usubBorrow( uvec4( idx4 ), uvec4( count ), uvEnable );

			// z value is z0
			vZPixel32 = uvec4( z0 );


			// calculate xy offset //

			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ix & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			vOffset += ( iy & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );



			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			//vIdx = vOffset;
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;


			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ix & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			vZOffset += ( iy & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

		vPixel32 = uvec4( bgr32 );


#ifdef ENABLE_ALPHA_BLEND_PIXEL_COLOR

		//if ( ABE == 1 )
		{
			// alpha blend //


			// A pixel //

			// select
			//vPixelA = ( ( vPixel32 & (ALPHA_A-1) ) | ( vDestPixel32 & -ALPHA_A ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			//vPixelB = ( ( vPixel32 & (ALPHA_B-1) ) | ( vDestPixel32 & -ALPHA_B ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			//vPixelD = ( ( vPixel32 & (ALPHA_D-1) ) | ( vDestPixel32 & -ALPHA_D ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			//vPixelC = ( ( ( vPixel32 & (ALPHA_C-1) ) | ( vDestPixel32 & -ALPHA_C ) ) & ( ( ALPHA_C >> 1 ) - 1 ) ) | ( uvec4( ALPHA_FIX ) & -(ALPHA_C >> 1) );
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );


			//uvAlphaSelect [ 0 ] = vPixel32;
			//uvAlphaSelect [ 1 ] = vDestPixel32;

			//vPixelA = uvAlphaSelect [ ALPHA_A ];
			//vPixelB = uvAlphaSelect [ ALPHA_B ];
			//vPixelC = uvAlphaSelect [ ALPHA_C ];
			//vPixelD = uvAlphaSelect [ ALPHA_D ];


			// perform alpha blend calculation //

			// get alpha
			//ivc = ivec4( vPixelC >> 24 ) & 0xff;
			ivc = ivec4( bitfieldExtract( vPixelC, 24, 8 ) );

			// do r
			//iva = ivec4( vPixelA >> 16 ) & 0xff;
			//ivb = ivec4( vPixelB >> 16 ) & 0xff;
			//ivd = ivec4( vPixelD >> 16 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			//iva = ivec4( vPixelA >> 8 ) & 0xff;
			//ivb = ivec4( vPixelB >> 8 ) & 0xff;
			//ivd = ivec4( vPixelD >> 8 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			//iva = ivec4( vPixelA >> 0 ) & 0xff;
			//ivb = ivec4( vPixelB >> 0 ) & 0xff;
			//ivd = ivec4( vPixelD >> 0 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );

		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_PIXEL_COLOR

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle


		// alpha test //

#ifdef ENABLE_SRCALPHA_TEST_PIXEL_COLOR

		vTestPixel32 = vPixel32 >> 24;

		//if ( ATE != 0 )
		{

			//uvATSelect = uvec4( ( ( sign( ivec4( vTestPixel32 - vAREF ) ) & iATMask ) + iATOffset ) >> 31 );
			//uvATSelect = uvec4( ivec4( ( sign( ivec4( vTestPixel32 - vAREF ) ) & AMASK ) + AOFFSET ) >> 31 );
			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );


		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_PIXEL_COLOR


#ifdef ENABLE_DSTALPHA_TEST_PIXEL_COLOR

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			//uvDASelect = ( uvDASelect >> 31 ) ^ 1;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_PIXEL_COLOR


#ifdef ENABLE_DEPTH_TEST_PIXEL_COLOR

		// depth test //

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			//uvZSelect = ( sign( ivec4( uvZTST_EQUAL ) ) ^ ZTST_EQUAL ) | uvZTST_GREATER | ZTST_LESS;
			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_PIXEL_COLOR

			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );

			// if storing to 24-bit buffer, combine pixel with destination
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );


			// write frame buffer //


			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //


				// store the pixels //

				VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				VRAM [ vOffset[3] ] = vPixel32 [ 3 ];
			}
			else
			{
				// 16-bit pixels


				// store the pixels //

				VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}


#ifdef ENABLE_WRITE_ZBUFFER_PIXEL_COLOR

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, (ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					VRAM [ vZOffset[0] ] = vZPixel32[0];
					VRAM [ vZOffset[1] ] = vZPixel32[1];
					VRAM [ vZOffset[2] ] = vZPixel32[2];
					VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}
			}
			
#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_PIXEL_COLOR

	}


	}	// end if ( subgroupAll( bDraw != 0 ) )

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX


}

#endif	// end #ifdef ENABLE_DRAW_PIXEL_COLOR




#ifdef ENABLE_DRAW_RECTANGLE


#ifdef DRAW_RECTANGLE_MULTI
uint Draw_Rectangle ( uint uIndex )
#else
void Draw_Rectangle ( uint uIndex )
#endif
{
	// constants //


	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	// variables //

	//int xid;
	int yid;


	uint Comm;
	int bDraw;

	uint uIdx;


	int iPtr;
	ivec4 ivPtr;
	
	int Temp;
	
	uint DestPixel;
	uint bgr_temp;
	int x_across;
	int Line;

	uint bgr16;
	uint bgr32;
	int x, y, w, h;
	int DrawArea_TopLeftX;
	int DrawArea_TopLeftY;
	int DrawArea_BottomRightX;
	int DrawArea_BottomRightY;
	int DrawArea_OffsetX;
	int DrawArea_OffsetY;
	//int x0, y0, x1, y1;
	//uint z0, z1;

	int sw, sh;
	int count;
	int idx;
	ivec4 idx4;
	ivec4 ivLine;

	//int StartX;
	//int EndX;
	//int StartY;
	//int EndY;


	uint PRIM;
	//int FRAME;
	//uint FBMSK;

	uint FST, ABE, FGE, PABE;
	uint AA1;

	//int FBP;
	//int FBW;
	//int FPSM;

	//int FrameBufferStartOffset32;
	//int FrameBufferWidth_Pixels;

	//int yoffset32, zyoffset32;
	//int yoffset32_xor, zyoffset32_xor;
	//ivec4 vXOffset32, vZXOffset32;

	uint TEST, ATE, ATST, AFAIL;
	//uint DATE, DATM;
	uint DATE;
	uint ZTE, ZTST;
	uint AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;

	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	//uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	uvec4 vAREF;

	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;

	//int ZBUF;
	//int ZBP;
	//int ZPSM;
	//int ZMSK;

	int ZBufferStartOffset32;

	uint FBA;

	ivec4 vIdx0;
	ivec4 vIdx;
	ivec4 vIdx32;
	ivec4 vxid;
	ivec4 vx_across;
	ivec4 vOffset;
	ivec4 vZOffset;

	uvec4 vDestPixel16, vDestPixel32, vDestPixel32_0, vDestPixel32_1;
	uvec4 vZDestPixel16, vZDestPixel32, vZDestPixel32_0, vZDestPixel32_1;
	uvec4 vZDestPixel24_1;
	uvec4 vPixel32, vZPixel32;
	uvec4 vPixel24, vZPixel24;
	uvec4 vPixel32_0, vPixel32_1, vZPixel32_0, vZPixel32_1;
	uvec4 vPixel32_2;
	uvec4 vPixel16;
	uvec4 vMask, vMask32;
	ivec4 vPixelShift;

	uvec4 vDPixelX, vZPixelX;

	bvec4 bvALPHA_A_SELECT, bvALPHA_B_SELECT, bvALPHA_C_SELECT, bvALPHA_D_SELECT;
	ivec4 ivAlphaA, ivAlphaB, ivAlphaC, ivAlphaD;
	ivec4 ivRedA, ivRedB, ivRedC, ivRedD;
	ivec4 ivGreenA, ivGreenB, ivGreenC, ivGreenD;
	ivec4 ivBlueA, ivBlueB, ivBlueC, ivBlueD;

	//ivec4 ivATSelect, ivDASelect, ivZSelect;
	uvec4 uvATSelect, uvDASelect, uvZSelect;

	bvec4 bvZTST_LESS, bvZTST_GREATER, bvZTST_EQUAL;
	bvec4 bvTestMask;
	bvec4 bvEnable;
	uvec4 uvEnable;
	uvec4 uvZTST_EQUAL, uvZTST_GREATER;

	uvec4 vTestPixel32;

	int DRAWPSM;
	//int ZBUFPSM;

	ivec4 vav, vrv, vgv, vbv;
	ivec4 vaf, vrf, vgf, vbf;
	ivec4 vat, vrt, vgt, vbt;
	ivec4 va, vm;

	uvec4 uvbgr32;

	ivec2 vx, vy;

	int COLCLAMP;

	int DYNAND, ZYNAND;
	uvec4 uvALPHA_FIX;

	int iATOffset, iATMask;

	uint ctx;

	//uvec4 uvAlphaSelect [ 4 ];

	// note: these are for textured objects only
	//uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX;
	//uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX;
	//uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM;
	//uvec4 uvTEX02_TW_TH_TWMASK_THMASK;
	//uvec4 uvTEX02_TCC_TFX_CPSM_CSA;


	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	uvec4 uvZTST_LESS_EQUAL_GREATER;
	uvec4 uvATST_LEG_OFFSET_MASK;

	uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	uvec4 uv_z0_f0_bDraw_sync;
	ivec4 iv_StartX_StartY_EndX_EndY;
	ivec4 iv_vu_vv_dudx_dvdy;
	uvec4 uv_w_rf0_bgr32;

	int iZMASK, iAMASK;

	bool bFRAME32;
	bool bZBUF32;

	// *** setup *** //

	// 64 elements each
	//uIdx = uIndex << 7;
	uIdx = uIndex << 6;

	// 32 elements each
	//uIndex <<= 6;
	uIndex <<= 5;

	
#ifdef DRAW_RECTANGLE_MULTI
	do
	{
#endif


	//bDraw = data [ uIdx + 0 ];
	bDraw = data [ uIdx + 2 ];

	if ( subgroupAll( bDraw != 0 ) )
	{

		// load common vars //

		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );

		// for now treating AA1 as alpha
		ABE |= AA1;

		// note: CLAMP and TEXA are for textured objects
		// note: DIMX is for gradient objects
		//uvCLAMP_WMS_AND_OR_MIN_MAX = uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];
		//uvCLAMP_WMT_AND_OR_MIN_MAX = uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];

		// note: TEX0/2 data is only needed for textured objects
		//uvTEX02_TBP_TBW_TPSM_TEXPSM = uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TW_TH_TWMASK_THMASK = uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TCC_TFX_CPSM_CSA = uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ ctx ];

		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];
		uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;

		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );

		
		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );


		// load rectangle vars //

		// loading 4 at a time from pre-calc values
		uIdx >>= 2;
		uv_z0_f0_bDraw_sync = data4 [ uIdx + 0 ];
		iv_StartX_StartY_EndX_EndY = data4 [ uIdx + 2 ];
		iv_vu_vv_dudx_dvdy = data4 [ uIdx + 3 ];
		uv_w_rf0_bgr32 = data4 [ uIdx + 4 ];


		// COLCLAMP(+15)(0x46),PABE(+27)(0x49)
		//COLCLAMP = int( inputdata [ uIndex + 15 ] );
		//PABE = inputdata [ uIndex + 27 ];
		COLCLAMP = int( uvps2gpu_vars[subgroup_local_id][0x46].x );
		PABE = int( uvps2gpu_vars[subgroup_local_id][0x49].x );

		// FBA (0x4a,0x4b)
		//FBA = uFBA_FBA_LUT [ subgroup_local_id ] [ ctx ];
		FBA = int( uvps2gpu_vars[subgroup_local_id][0x4a+ctx].x );

		// FOGCOL(+31)(0x3d),DTHE/DIMX(0x45/0x44)
		//FOGCOL = uvps2gpu_vars[subgroup_local_id][0x3d].x;
		//DTHE = uvps2gpu_vars[subgroup_local_id][0x45].x;
		//DIMX2 = uvps2gpu_vars[subgroup_local_id][0x44];


#define StartY		(iv_StartX_StartY_EndX_EndY[1])
#define EndY		(iv_StartX_StartY_EndX_EndY[3])
#define StartX		(iv_StartX_StartY_EndX_EndY[0])
#define EndX		(iv_StartX_StartY_EndX_EndY[2])

#define Z0			(uv_z0_f0_bDraw_sync[0])

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		int(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		int(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

#define WIDTH		(uv_w_rf0_bgr32 [ 0 ])
#define BGR32		(uv_w_rf0_bgr32 [ 2 ])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ZTST_LESS	(uvZTST_LESS_EQUAL_GREATER[0])
#define ZTST_EQUAL	(uvZTST_LESS_EQUAL_GREATER[1])

#define AOFFSET		(uvATST_LEG_OFFSET_MASK[1])
#define AMASK		(uvATST_LEG_OFFSET_MASK[2])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])

	// 24-bit pixels do not have destination alpha test
	DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

	uvbgr32 = uvec4( BGR32 );


	// this will come last
	COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

	//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
	PABE <<= 31;

	// FBA
	FBA <<= 31;

	// FOGCOL
	// DTHE/DIMX
	//DIMX &= -( DTHE & 1 );

	// if alpha is disabled then no alpha blending
	uvALPHA_ABCD &= -ABE;

	// drawpsm is fpsm shifted right one
	DRAWPSM = int( FPSM >> 1 );

	bFRAME32 = ( DRAWPSM & 1 ) == 0;
	bZBUF32 = ( ZBUFPSM & 1 ) == 0;


	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];


	//vAREF = uvec4( AREF );
	//uvALPHA_FIX = uvec4( ALPHA_FIX );
	vAREF = uvec4( uvTEST_ATE_AREF_ATST_AFAIL[1] );
	uvALPHA_FIX = uvec4( uvALPHA_ABCD_FIX[1] );

	iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
	iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];

	// h - total height
	h = EndY - StartY + 1;

	// adjust starty (here it is doing inclusive of window start)
	yid = max( StartY, ivDrawRange [ subgroup_local_id ].x ) - StartY;
	//StartY = max( StartY, ivDrawRange [ subgroup_local_id ].x );

	// adjust endy (here it is doing exclusive of window end)
	// note: sprite is inclusive of EndY, so need the line before here as end line for draw range
	EndY = min( EndY, ivDrawRange [ subgroup_local_id ].y - 1 );
	//EndY = min( EndY, ivDrawRange [ subgroup_local_id ].y );

	// get height for subgroup (adding one for inclusive of EndY)
	//sh = EndY - StartY + 1 - yid;
	sh = EndY - StartY + 1 - yid;


#ifdef ENABLE_RECTANGLE_SUBGROUP_SKIP

	// if nothing to draw, then done
	//if ( subgroupAll( sh <= 0 ) )
	if ( subgroupAll( sh < 0 ) )
	{
		return;
	}

#endif

	//sw = w - 1;
	//sw = int( WIDTH ) - 1;
	sw = int( WIDTH );


	// count - count of pixels to draw for the subgroup
	count = sw * sh;


	// test all the inputs
	//for ( int i = 0; i < 16; i++ )
	//{
	//	sVRAM[i+16] = inputdata [ (uIndex<<5) + i ];
	//}


	for ( idx = int( lxid ) << 2; idx < count; idx += int( lxinc ) << 2 )
	//for ( Line = StartY + yid; Line <= EndY; Line += group_yinc )
	{

		
		// draw horizontal line
		//for ( vx_across = vxid; any( lessThan( uvec4( vx_across ), uvec4( w ) ) ); vx_across += group_vxinc )
		//for ( vx_across = vxid; vx_across.x <= w; vx_across += group_vxinc )
		{
			// get pointer to pixel based on frame buffer pixel format (4-bit aligned offset) //

			idx4 = idx + ivec4( 0, 1, 2, 3 );
			vx_across = idx4 % sw;

			ivLine = ( idx4 / sw ) + yid;

			ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( StartY + ivLine ) & 0x3f ) << 7 );


			// get the pixels to be drawn
			//bvEnable = lessThan( uvec4( vx_across ), uvec4( w ) );
			//usubBorrow( uvec4( vx_across ), uvec4( w ), uvEnable );
			usubBorrow( uvec4( idx4 ), uvec4( count ), uvEnable );

			// z value is z0
			vZPixel32 = uvec4( Z0 );


			// calculate xy offset //

			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			//vOffset += ( ivLine & DYNAND ) * int( FBW );
			vOffset += ( ( StartY + ivLine ) & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );
			//vOffset += int( FBP );



			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			//vIdx = vOffset;
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vDestPixel32 >>= ( ( vOffset & 1 ) << 4 );
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( (FPSM & 1) << 31 );
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;


			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			//vZOffset += ( ivLine & ZYNAND ) * int( FBW );
			vZOffset += ( ( StartY + ivLine ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );
			//vZOffset += int( ZBP );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			//vIdx = vZOffset;
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vZDestPixel32 >>= ( ( vZOffset & 1 ) << 4 );
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) );
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

			vPixel32 = uvbgr32;


#ifdef ENABLE_ALPHA_BLEND_RECTANGLE

		//if ( ABE == 1 )
		{
			// alpha blend //


			// A pixel //

			// select
			//vPixelA = ( ( vPixel32 & (ALPHA_A-1) ) | ( vDestPixel32 & -ALPHA_A ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			//vPixelB = ( ( vPixel32 & (ALPHA_B-1) ) | ( vDestPixel32 & -ALPHA_B ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			//vPixelD = ( ( vPixel32 & (ALPHA_D-1) ) | ( vDestPixel32 & -ALPHA_D ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			//vPixelC = ( ( ( vPixel32 & (ALPHA_C-1) ) | ( vDestPixel32 & -ALPHA_C ) ) & ( ( ALPHA_C >> 1 ) - 1 ) ) | ( uvec4( ALPHA_FIX ) & -(ALPHA_C >> 1) );
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );


			//uvAlphaSelect [ 0 ] = vPixel32;
			//uvAlphaSelect [ 1 ] = vDestPixel32;

			//vPixelA = uvAlphaSelect [ ALPHA_A ];
			//vPixelB = uvAlphaSelect [ ALPHA_B ];
			//vPixelC = uvAlphaSelect [ ALPHA_C ];
			//vPixelD = uvAlphaSelect [ ALPHA_D ];


			// perform alpha blend calculation //

			// get alpha
			//ivc = ivec4( vPixelC >> 24 ) & 0xff;
			ivc = ivec4( bitfieldExtract( vPixelC, 24, 8 ) );

			// do r
			//iva = ivec4( vPixelA >> 16 ) & 0xff;
			//ivb = ivec4( vPixelB >> 16 ) & 0xff;
			//ivd = ivec4( vPixelD >> 16 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			//iva = ivec4( vPixelA >> 8 ) & 0xff;
			//ivb = ivec4( vPixelB >> 8 ) & 0xff;
			//ivd = ivec4( vPixelD >> 8 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			//iva = ivec4( vPixelA >> 0 ) & 0xff;
			//ivb = ivec4( vPixelB >> 0 ) & 0xff;
			//ivd = ivec4( vPixelD >> 0 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );

		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_RECTANGLE

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle


			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );


		// alpha test //

#ifdef ENABLE_SRCALPHA_TEST_RECTANGLE

		//vTestPixel32 = vPixel32 >> 24;
		vTestPixel32 = uvbgr32 >> 24;

		//if ( ATE != 0 )
		{

			//uvATSelect = uvec4( ( ( sign( ivec4( vTestPixel32 - vAREF ) ) & iATMask ) + iATOffset ) >> 31 );
			//uvATSelect = uvec4( ivec4( ( sign( ivec4( vTestPixel32 - vAREF ) ) & AMASK ) + AOFFSET ) >> 31 );
			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );


		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_RECTANGLE


#ifdef ENABLE_DSTALPHA_TEST_RECTANGLE

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			//uvDASelect = ( uvDASelect >> 31 ) ^ 1;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_RECTANGLE


#ifdef ENABLE_DEPTH_TEST_RECTANGLE

		// depth test //

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			//uvZSelect = ( sign( ivec4( uvZTST_EQUAL ) ) ^ ZTST_EQUAL ) | uvZTST_GREATER | ZTST_LESS;
			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_RECTANGLE


			// if storing to 24-bit buffer, combine pixel with destination
			//vPixel32 = ( vPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( vDPixelX & ( (-(FPSM & 1)) << 24 ) );
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			//vPixel32_0 = ( ( vPixel32 >> 3 ) & 0x001f ) | ( ( vPixel32 >> 6 ) & 0x03e0 ) | ( ( vPixel32 >> 9 ) & 0x7c00 ) | ( ( vPixel32 >> 16 ) & 0x8000 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );


			// write frame buffer //


			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //


				// store the pixels //

				VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				VRAM [ vOffset[3] ] = vPixel32 [ 3 ];
			}
			else
			{
				// 16-bit pixels


				// store the pixels //

				VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}



#ifdef ENABLE_WRITE_ZBUFFER_RECTANGLE

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, (ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					VRAM [ vZOffset[0] ] = vZPixel32[0];
					VRAM [ vZOffset[1] ] = vZPixel32[1];
					VRAM [ vZOffset[2] ] = vZPixel32[2];
					VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}
			}
			
#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_RECTANGLE

		}	// end for ( vx_across = vxid; any( lessThan( uvec4( vx_across ), uvec4( w ) ) ); vx_across += group_vxinc )
		
	}	// end for ( Line = StartY + yid; Line <= EndY; Line += yinc )

	}	// end if ( bDraw == 1 )


#undef StartY
#undef EndY
#undef StartX
#undef EndX

#undef Z0

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

#undef WIDTH
#undef BGR32

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ZTST_LESS
#undef ZTST_EQUAL

#undef AMASK
#undef AOFFSET

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX


#ifdef DRAW_RECTANGLE_MULTI

		uIndex += 64;

		uIdx += 128;

		Comm = inputdata [ uIndex + ( 15 << 1 ) + 0 ];


		Comm &= 0xff000017;

	} while ( ( ( Comm == 0x06 ) || ( Comm == 0x00 ) ) && ( uIndex < ( COMMAND_LIST_SIZE << 6 ) ) );

	return ( uIndex >> 6 ) - 1;

#else

	return;

#endif
	
}


#endif	// end #ifdef ENABLE_DRAW_RECTANGLE



#ifdef ENABLE_DRAW_SPRITE


#ifdef DRAW_SPRITE_MULTI
uint Draw_Sprite ( uint uIndex )
#else
void Draw_Sprite ( uint uIndex )
#endif
{
	// constants //

	//int xxid = int( gl_LocalInvocationIndex );

	//int cxid = int( gl_GlobalInvocationID.x );
	//int cyid = int( gl_GlobalInvocationID.y );

	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	// variables //

	int xid, yid;


	uint Comm;
	int bDraw;

	uint uIdx;


	int iPtr;
	ivec4 vPtr;
	
	int Temp;
	
	uint DestPixel;
	uint bgr_temp;
	int x_across;
	int Line;

	uint bgr16;
	uint bgr32;
	int x, y, w, h;
	//int DrawArea_TopLeftX;
	//int DrawArea_TopLeftY;
	//int DrawArea_BottomRightX;
	//int DrawArea_BottomRightY;
	//int DrawArea_OffsetX;
	//int DrawArea_OffsetY;
	//int x0, y0, x1, y1;
	//uint z0, z1;

	int sh, sw;
	int idx, count;
	ivec4 idx4;
	ivec4 ivLine;
	ivec4 ivPtr;

	//ivec4 viStartU;

	//int StartX;
	//int EndX;
	//int StartY;
	//int EndY;


	uint PRIM;
	//int FRAME;
	//uint FBMSK;
	uint DATE;

	uint FST, ABE, FGE, PABE, TME;

	uint AA1;

	uint FOGCOL;
	//int FCR, FCG, FCB;

	//int FBP;
	//int FBW;
	//int FPSM;

	//int FrameBufferStartOffset32;
	//int FrameBufferWidth_Pixels;

	//int yoffset32, zyoffset32;
	//int yoffset32_xor, zyoffset32_xor;
	//ivec4 vXOffset32, vZXOffset32;

	//uint TEST, AFAIL;
	uint AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;

	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	//uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	uvec4 vAREF;

	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;

	//int ZBUF;
	//int ZBP;
	//int ZPSM;
	//int ZMSK;

	//int ZBufferStartOffset32;

	uint FBA;


	ivec4 vIdx;
	ivec4 vIdx32;
	ivec4 vxid;
	ivec4 vx_across;
	ivec4 vOffset;
	ivec4 vZOffset;

	uvec4 vDestPixel16, vDestPixel32, vDestPixel32_0, vDestPixel32_1;
	uvec4 vZDestPixel16, vZDestPixel32, vZDestPixel32_0, vZDestPixel32_1;
	uvec4 vZDestPixel24_1;
	uvec4 vPixel32, vZPixel32;
	uvec4 vPixel24, vZPixel24;
	uvec4 vPixel32_0, vPixel32_1, vZPixel32_0, vZPixel32_1;
	uvec4 vPixel32_2;
	uvec4 vPixel16;
	uvec4 vMask, vMask32;
	ivec4 vPixelShift;

	uvec4 vDPixelX, vZPixelX;

	bvec4 bvALPHA_A_SELECT, bvALPHA_B_SELECT, bvALPHA_C_SELECT, bvALPHA_D_SELECT;
	ivec4 ivAlphaA, ivAlphaB, ivAlphaC, ivAlphaD;
	ivec4 ivRedA, ivRedB, ivRedC, ivRedD;
	ivec4 ivGreenA, ivGreenB, ivGreenC, ivGreenD;
	ivec4 ivBlueA, ivBlueB, ivBlueC, ivBlueD;

	ivec4 ivATSelect, ivDASelect, ivZSelect;
	uvec4 uvATSelect, uvDASelect, uvZSelect;

	bvec4 bvZTST_LESS, bvZTST_GREATER, bvZTST_EQUAL;
	uvec4 uvZTST_GREATER, uvZTST_EQUAL;
	bvec4 bvTestMask;
	bvec4 bvEnable;
	uvec4 uvEnable;

	uvec4 vTestPixel32;

	int DRAWPSM;
	//int ZBUFPSM;

	ivec4 vav, vrv, vgv, vbv;
	ivec4 vaf, vrf, vgf, vbf;
	ivec4 vat, vrt, vgt, vbt;
	ivec4 vadd, vmul;

	uvec4 uvbgr32;


	// texture vars //

	uvec4 vTPixel32;
	ivec4 viU;
	ivec4 viV;
	int iV;
	//int iAnd1, iShift1, iShift2, iAnd3, iShift3;
	int iAnd1;
	int iShift1;

	//int dudx, dvdy;
	//int CLAMP_0, CLAMP_1;
	//int WMS, WMT;
	//int MINU, MAXU, MINV, MAXV;
	//int TexY_And, TexY_Or, TexY_Min, TexY_Max;
	//int TexX_And, TexX_Or, TexX_Min, TexX_Max;

	ivec4 vTexCoordX, vTXOffset, vTOffset;
	ivec4 vTexCoordY;
	//int TexCoordY;
	//int iTYOffset, xTYOffset;

	//int AEM;
	//int TEXA_0, TEXA_1;

	uvec4 uvTEXA_0, uvTEXA_1;
	uvec4 uvZ0;

	//float fs0, ft0, fs1, ft1;

	//int u0, v0, u1, v1;
	//int f0, f1;
	//int rf0;
	//int TEX0_0, TEX0_1;
	//int TBP0, TBW, TPSM, TW, TH;
	//int TEXPSM;
	int TexWidth, TexHeight;
	int TexWidth_Mask, TexHeight_Mask;
	//int TCC, TFX;
	//int CBP, CPSM, CSM, CSA, CLD;
	//int CLUTStartOffset32;

	//int TextureBufferStartOffset32;
	//int TextureBufferWidth_Pixels;

	//ivec2 vx, vy;
	//ivec2 vu, vv;
	//vec2 vfs, vft;

	//ivec4 clampprimfogcol, xyoffsetscissor, framezbuf, alphatest, texatex0, pabefbacolclampdthe;
	//ivec4 xyzrgbaq0, xyzrgbaq1, xyzrgbaq2;
	//ivec4 uvstfog0, uvstfog1, uvstfog2;

	//ivec2 dxdx;

	int COLCLAMP;

	uvec4 uvALPHA_FIX;

	//uvec4 uvAlphaSelect [ 4 ];
	//mat4 mAlphaSelect;

	int DYNAND, ZYNAND, TYNAND;
	int TXNAND, TXSHIFT;

	//int iZTOffset;
	//int iATOffset, iATMask;

	// note: these are for textured objects only
	uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX;
	uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX;
	uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM;
	uvec4 uvTEX02_TW_TH_TWMASK_THMASK;
	uvec4 uvTEX02_TCC_TFX_CPSM_CSA;

	uvec4 uvTEXA_TA0_TA1_AEM;

	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	uvec4 uvZTST_LESS_EQUAL_GREATER;
	uvec4 uvATST_LEG_OFFSET_MASK;

	uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	uvec4 uvFOGCOL_FCR_FCG_FCB;

	uvec4 uv_z0_f0_bDraw_sync;
	ivec4 iv_StartX_StartY_EndX_EndY;
	ivec4 iv_vu_vv_dudx_dvdy;
	uvec4 uv_w_rf0_bgr32;

	uvec4 uv_And1_Shift1_Shift2_And3_Shift3;

	ivec4 iv_vaf_vrf_vgf_vbf;

	int iZMASK, iAMASK;

	bool bFRAME32, bZBUF32;
	bool bTEXTURE;

	uint ctx;

	// *** setup *** //

	// 64 elements each
	//uIdx = uIndex << 7;
	uIdx = uIndex << 6;

	// 32 elements each
	//uIndex <<= 6;
	uIndex <<= 5;


		//uIndex <<= 2;


#ifdef DRAW_SPRITE_MULTI
	do
	{
#endif




	//bDraw = data [ uIdx + 0 ];
	bDraw = data [ uIdx + 2 ];

	if ( subgroupAll( bDraw == 1 ) )
	{

		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		//FGE = bitfieldExtract( PRIM, 5, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );
		TME = bitfieldExtract( PRIM, 4, 1 );

		bTEXTURE = TME != 0;

		// for now treating AA1 as alpha
		ABE |= AA1;

		// note: CLAMP and TEXA are for textured objects
		// note: DIMX is for gradient objects
		uvCLAMP_WMS_AND_OR_MIN_MAX = uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];
		uvCLAMP_WMT_AND_OR_MIN_MAX = uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];

		// note: TEX0/2 data is only needed for textured objects
		uvTEX02_TBP_TBW_TPSM_TEXPSM = uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ ctx ];
		uvTEX02_TW_TH_TWMASK_THMASK = uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEX02_TCC_TFX_CPSM_CSA = uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ ctx ];

		uvTEXA_TA0_TA1_AEM = uvTEXA_TA0_TA1_AEM_LUT [ subgroup_local_id ];


		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];
		uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];
		uv_And1_Shift1_Shift2_And3_Shift3 = c_uvLUT_TEX02_TPSM [ uvTEX02_TBP_TBW_TPSM_TEXPSM[2] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;

		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );

		
		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );

		// load rectangle vars //


		// loading 4 at a time from pre-calc values
		uIdx >>= 2;
		uv_z0_f0_bDraw_sync = data4 [ uIdx + 0 ];
		iv_StartX_StartY_EndX_EndY = data4 [ uIdx + 2 ];
		iv_vu_vv_dudx_dvdy = data4 [ uIdx + 3 ];
		uv_w_rf0_bgr32 = data4 [ uIdx + 4 ];

		iv_vaf_vrf_vgf_vbf = data4 [ uIdx + 1 ];


		// COLCLAMP(+15)(0x46),PABE(+27)(0x49)
		//COLCLAMP = int( inputdata [ uIndex + 15 ] );
		//PABE = inputdata [ uIndex + 27 ];
		COLCLAMP = int( uvps2gpu_vars[subgroup_local_id][0x46].x );
		PABE = int( uvps2gpu_vars[subgroup_local_id][0x49].x );

		// FBA (0x4a,0x4b)
		//FBA = uFBA_FBA_LUT [ subgroup_local_id ] [ ctx ];
		FBA = int( uvps2gpu_vars[subgroup_local_id][0x4a+ctx].x );

		// FOGCOL(+31)(0x3d),DTHE/DIMX(0x45/0x44)
		FOGCOL = uvps2gpu_vars[subgroup_local_id][0x3d].x;
		//DTHE = uvps2gpu_vars[subgroup_local_id][0x45].x;
		//DIMX2 = uvps2gpu_vars[subgroup_local_id][0x44];

		uvFOGCOL_FCR_FCG_FCB = uvec4( unpack8( FOGCOL ) );


#define StartY		(iv_StartX_StartY_EndX_EndY[1])
#define EndY		(iv_StartX_StartY_EndX_EndY[3])
#define StartX		(iv_StartX_StartY_EndX_EndY[0])
#define EndX		(iv_StartX_StartY_EndX_EndY[2])

#define Z0			(uv_z0_f0_bDraw_sync[0])

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		int(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		int(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

#define WIDTH		(uv_w_rf0_bgr32 [ 0 ])
#define BGR32		(uv_w_rf0_bgr32 [ 2 ])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ZTST_LESS	(uvZTST_LESS_EQUAL_GREATER[0])
#define ZTST_EQUAL	(uvZTST_LESS_EQUAL_GREATER[1])

#define AOFFSET		(uvATST_LEG_OFFSET_MASK[1])
#define AMASK		(uvATST_LEG_OFFSET_MASK[2])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])

#define TEXA_0		(uvTEXA_TA0_TA1_AEM[0])
#define TEXA_1		(uvTEXA_TA0_TA1_AEM[1])
#define AEM			(uvTEXA_TA0_TA1_AEM[2])

#define TexX_And	int(uvCLAMP_WMS_AND_OR_MIN_MAX[0])
#define TexX_Or		int(uvCLAMP_WMS_AND_OR_MIN_MAX[1])
#define TexX_Min	int(uvCLAMP_WMS_AND_OR_MIN_MAX[2])
#define TexX_Max	int(uvCLAMP_WMS_AND_OR_MIN_MAX[3])

#define TexY_And	int(uvCLAMP_WMT_AND_OR_MIN_MAX[0])
#define TexY_Or		int(uvCLAMP_WMT_AND_OR_MIN_MAX[1])
#define TexY_Min	int(uvCLAMP_WMT_AND_OR_MIN_MAX[2])
#define TexY_Max	int(uvCLAMP_WMT_AND_OR_MIN_MAX[3])

#define TBP			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[0])
#define TBW			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[1])
#define TPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[2])
#define TEXPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[3])

#define FCR			int(uvFOGCOL_FCR_FCG_FCB[0])
#define FCG			int(uvFOGCOL_FCR_FCG_FCB[1])
#define FCB			int(uvFOGCOL_FCR_FCG_FCB[2])

#define F0			int(uv_z0_f0_bDraw_sync[1])
#define RF0			int(uv_w_rf0_bgr32[1])

#define VU			(iv_vu_vv_dudx_dvdy[0])
#define VV			(iv_vu_vv_dudx_dvdy[1])
#define DUDX		(iv_vu_vv_dudx_dvdy[2])
#define DVDY		(iv_vu_vv_dudx_dvdy[3])

#define And1		int(uv_And1_Shift1_Shift2_And3_Shift3[0])
#define iShift2		int(uv_And1_Shift1_Shift2_And3_Shift3[1])
#define iAnd3		int(uv_And1_Shift1_Shift2_And3_Shift3[2])
#define iShift3		int(uv_And1_Shift1_Shift2_And3_Shift3[3])

#define TCC			int(uvTEX02_TCC_TFX_CPSM_CSA[0])
#define TFX			int(uvTEX02_TCC_TFX_CPSM_CSA[1])
#define CPSM		int(uvTEX02_TCC_TFX_CPSM_CSA[2])
#define CSA			int(uvTEX02_TCC_TFX_CPSM_CSA[3])

		// 24-bit pixels do not have destination alpha test
		DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

		iShift1 = ( And1 >> 8 ) & 0xff;
		iAnd1 = And1 & 0xff;

		uvbgr32 = uvec4( BGR32 );

		vaf = ivec4( iv_vaf_vrf_vgf_vbf[0] );
		vrf = ivec4( iv_vaf_vrf_vgf_vbf[1] );
		vgf = ivec4( iv_vaf_vrf_vgf_vbf[2] );
		vbf = ivec4( iv_vaf_vrf_vgf_vbf[3] );

		// this will come last
		COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

		//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
		PABE <<= 31;

		// FBA
		FBA <<= 31;

		// FOGCOL
		// DTHE/DIMX
		//DIMX &= -( DTHE & 1 );

		// if alpha is disabled then no alpha blending
		uvALPHA_ABCD &= -ABE;

		// drawpsm is fpsm shifted right one
		DRAWPSM = int( FPSM >> 1 );


		bFRAME32 = ( DRAWPSM & 1 ) == 0;
		bZBUF32 = ( ZBUFPSM & 1 ) == 0;


		uvTEXA_0 = uvec4( TEXA_0 );
		uvTEXA_1 = uvec4( TEXA_1 );
		uvALPHA_FIX = uvec4( ALPHA_FIX );
		uvZ0 = uvec4( Z0 );


		vAREF = uvec4( AREF );

		iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
		iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];


//sVRAM[0+(subgroup_local_id<<3)] = subgroup_local_id;
//sVRAM[1+(subgroup_local_id<<3)] = StartY;
//sVRAM[2+(subgroup_local_id<<3)] = EndY;
//sVRAM[3+(subgroup_local_id<<3)] = ivDrawRange [ subgroup_local_id ].x;
//sVRAM[4+(subgroup_local_id<<3)] = ivDrawRange [ subgroup_local_id ].y;


	// h - total height
	h = EndY - StartY + 1;

	// adjust starty (here it is doing inclusive of window start)
	yid = max( StartY, ivDrawRange [ subgroup_local_id ].x ) - StartY;
	//StartY = max( StartY, ivDrawRange [ subgroup_local_id ].x );

	// adjust endy (here it is doing exclusive of window end)
	// note: sprite is inclusive of EndY, so need the line before here as end line for draw range
	EndY = min( EndY, ivDrawRange [ subgroup_local_id ].y - 1 );
	//EndY = min( EndY, ivDrawRange [ subgroup_local_id ].y );

	// get height for subgroup (adding one for inclusive of EndY)
	//sh = EndY - StartY + 1 - yid;
	sh = EndY - StartY + 1 - yid;


//sVRAM[5+(subgroup_local_id<<3)] = h;
//sVRAM[6+(subgroup_local_id<<3)] = sh;
//sVRAM[7+(subgroup_local_id<<3)] = yid;
	


#ifdef ENABLE_RECTANGLE_SUBGROUP_SKIP

	// if nothing to draw, then done
	//if ( subgroupAll( sh <= 0 ) )
	if ( subgroupAll( sh < 0 ) )
	{
		return;
	}

#endif

	//sw = w - 1;
	//sw = int( WIDTH ) - 1;
	sw = int( WIDTH );


	// count - count of pixels to draw for the subgroup
	count = sw * sh;




	// test all the inputs
	//for ( int i = 0; i < 16; i++ )
	//{
	//	sVRAM[i+16] = inputdata [ (uIndex<<5) + i ];
	//}

	// test the clut
	//for ( uint i = lxid; i < 256; i += lxinc )
	//{
	//	sVRAM[i+64] = LOCAL_CLUT [subgroup_local_id][ i ];
	//}


	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];
	TYNAND = LUT_YNAND[ TEXPSM ];

	TXNAND = LUT_XNAND[ TEXPSM ];
	TXSHIFT = LUT_XSHIFT[ TEXPSM ];





	//for ( Line = StartY + yid; Line <= EndY; Line += group_yinc )
	for ( idx = int( lxid ) << 2; idx < count; idx += int( lxinc ) << 2 )
	{


		// draw horizontal line
		//for ( vx_across = vxid; any( lessThan( uvec4( vx_across ), uvec4( w ) ) ); vx_across += group_vxinc )
		//for ( vx_across = vxid; vx_across.x <= w; vx_across += group_vxinc )
		{
			// get pointer to pixel based on frame buffer pixel format (4-bit aligned offset) //

			idx4 = idx + ivec4( 0, 1, 2, 3 );
			vx_across = idx4 % sw;

			ivLine = ( idx4 / sw ) + yid;

			ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( StartY + ivLine ) & 0x3f ) << 7 );


			// get the pixels to be drawn
			//bvEnable = lessThan( uvec4( vx_across ), uvec4( w ) );
			//usubBorrow( uvec4( vx_across ), uvec4( w ), uvEnable );
			usubBorrow( uvec4( idx4 ), uvec4( count ), uvEnable );

			// z value is z0
			vZPixel32 = uvec4( Z0 );


			// calculate xy offset //

			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];


			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			vOffset += ( ( StartY + ivLine ) & DYNAND ) * int( FBW );


			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );

			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			//vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;


			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			vZOffset += ( ( StartY + ivLine ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vZDestPixel32 >>= ( ( vZOffset & 1 ) << 4 );
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) );
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

#ifndef ENABLE_DRAW_RECTANGLE

		// set pixel to color in-case it is not textured
		vPixel32 = uvbgr32;

		if( subgroupAll( bTEXTURE ) )
#endif
		{

#ifdef ENABLE_TEXTURE_MAPPING_SPRITE

			viU = VU + ( DUDX * vx_across );
			viV = VV + ( DVDY * ivLine );
			
			vTexCoordX = ( viU >> 16 );
			vTexCoordY = ( viV >> 16 );

			//vTexCoordX = mix( vTexCoordX, ivec4( TexX_Min ), lessThan( vTexCoordX, ivec4( TexX_Min ) ) );
			//vTexCoordX = mix( vTexCoordX, ivec4( TexX_Max ), greaterThan( vTexCoordX, ivec4( TexX_Max ) ) );
			vTexCoordX = clamp( vTexCoordX, TexX_Min, TexX_Max );
			vTexCoordX &= TexX_And;
			vTexCoordX |= TexX_Or;

			//TexCoordY = ( ( TexCoordY < TexY_Min ) ? TexY_Min : TexCoordY );
			//TexCoordY = ( ( TexCoordY > TexY_Max ) ? TexY_Max : TexCoordY );
			vTexCoordY = clamp( vTexCoordY, TexY_Min, TexY_Max );
			vTexCoordY &= TexY_And;
			vTexCoordY |= TexY_Or;


			vIdx = ( vTexCoordX & 0x7f ) | ( ( vTexCoordY & 0x7f ) << 7 ) | ( TEXPSM << 14 );
			//vIdx = ( vTexCoordX & ~TXNAND ) | ( ( vTexCoordY & ~TYNAND ) << 7 ) | ( TEXPSM << 14 );
			vTOffset[0] = LUT_XYOFFSET [ vIdx[0] ];
			vTOffset[1] = LUT_XYOFFSET [ vIdx[1] ];
			vTOffset[2] = LUT_XYOFFSET [ vIdx[2] ];
			vTOffset[3] = LUT_XYOFFSET [ vIdx[3] ];


			// iAnd1= 32-bit: 0, 16-bit: 0, 8-bit: 0x3, 4-bit: 0x7
			// iShift1= 32-bit: 0, 16-bit: 0, 8-bit: 3, 4-bit: 2
			// get the amount to shift pixel
			vPixelShift = ( vTOffset & iAnd1 ) << iShift1;

			// if looking up 32-bit pixels, then need to multiply by 2 in x-direction
			// pixels stored normally now
			//vTOffset <<= 1;

			// put in the remainder of the x-bits that don't get swizzled
			vTOffset |= ( ( vTexCoordX ) & TXNAND ) << TXSHIFT;

			// add in the bits for the y
			vTOffset += ( ( vTexCoordY ) & TYNAND ) * int( TBW );

			//vTOffset += TextureBufferStartOffset32;
			//vTOffset += TBP;
			vTOffset += ( TBP << iShift2 );

			// iShift2= 32-bit: 0, 16-bit: 1, 8-bit: 2, 4-bit: 3
			// get the remainder of the offset (for 32-bit lookup after already shifting left 1)
			//vTOffset >>= iShift2;
			vIdx = vTOffset >> iShift2;

			// load 32-bit pixel data

			//vTPixel32 = uvec4(0);

			// pixels stored normally now
			vPixel32[0] = VRAM [ vIdx[0] ];
			vPixel32[1] = VRAM [ vIdx[1] ];
			vPixel32[2] = VRAM [ vIdx[2] ];
			vPixel32[3] = VRAM [ vIdx[3] ];

			if ( ( TPSM & 7 ) > 2 )
			{
				// lookup pixel //

				// iAnd3= 32-bit: -1, 16-bit: 0xffff, 8-bit: 0xff, 4-bit: 0xf
				// iShift3= 32-bit: 0, 16-bit: 0, 8-bit: 0, 4-bit: 0, 8h-bit: 24, 4hh-bit: 28, 4hl-bit: 24
				// shift/mask pixel (need mask value and right shift value for offset)
				vPixel32 = ( ( vPixel32 >> vPixelShift ) >> iShift3 ) & iAnd3;

				vIdx = ivec4( vPixel32 ) + CSA;
				//vIdx = ivec4( vPixel32 ) + ( CSA & 0xf );

				// lookup pixel in CLUT (and load 16-bit chunks)

				vPixel32[0] = LOCAL_CLUT[subgroup_local_id][ vIdx[0] ];
				vPixel32[1] = LOCAL_CLUT[subgroup_local_id][ vIdx[1] ];
				vPixel32[2] = LOCAL_CLUT[subgroup_local_id][ vIdx[2] ];
				vPixel32[3] = LOCAL_CLUT[subgroup_local_id][ vIdx[3] ];

				// shift pixel if 16-bit pixel in upper part
				vPixel32 >>= ( CSA >> 4 ) & 0x10;
			}
			else
			{
				// shift pixel right if in upper part of pixel
				vPixel32 >>= ( ( vTOffset & TEXPSM & 1 ) << 4 );
			}


			// check if 32-bit pixel format or not for texture
			if ( ( CPSM & 7 ) != 0 )
			{
				// 24 or 16 bit pixel //

				// mask pixel if 24-bit or 16-bit
				vPixel32 = ( vPixel32 & ( (-1u) >> ( (CPSM & 3) << 3 ) ) );

				// if a=0, then a=texa0 if either rgb!=0 or aem=0, otherwise a=0
				//vPixel24 = TEXA_0 & ( ( AEM ) | ~( vPixel32 - 1 ) );
				vPixel24 = uvec4( TEXA_0 );

				if ( ( CPSM & 7 ) == 2 )
				{
					// 16 bit pixel //

					// select alpha
					vPixel16 = -( vPixel32 >> 15 );
					vPixel24 = ( TEXA_1 & vPixel16 ) | ( vPixel24 & ~vPixel16 );

					// convert 16-bit pixels to 32-bit pixels
					//vPixel32 = ( ( vPixel32 << 3 ) & ( 0xf8 << 0 ) ) | ( ( vPixel32 << 6 ) & ( 0xf8 << 8 ) ) | ( ( vPixel32 << 9 ) & ( 0xf8 << 16 ) );
					//vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vPixel32, 10, 5 ), 19, 5 );
					vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vPixel32, 10, 5 ), 19, 5 );

				}

				// if rgb==0 and aem==1, then a=0, otherwise a=1
				//vPixel24 = vPixel24 & ( ( AEM ) | ~( vPixel32 - 1 ) );
				//vPixel32 |= vPixel24;
				vPixel32 |= vPixel24 & ( ( AEM ) | ~( vPixel32 - 1 ) );

				//vTPixel32 |= AEM;
			}

#endif	// end #ifdef ENABLE_TEXTURE_MAPPING_SPRITE



#ifdef ENABLE_TEXTURE_FUNC_SPRITE

			// fragment color should already be in vaf, vrf, vgf, vbf
			// split into rgba
			//vat = ivec4( vPixel32 >> 24 ) & 0xff;
			//vrt = ivec4( vPixel32 >> 16 ) & 0xff;
			//vgt = ivec4( vPixel32 >> 8 ) & 0xff;
			//vbt = ivec4( vPixel32 >> 0 ) & 0xff;

			// tfx, tcc

			if ( TFX == 1 )
			{
				//if ( TCC == 0 )
				//{
					//vav = vaf;
					//vPixel32 = ( vPixel32 & 0x00ffffff ) | ( vaf << 24 );
					vPixel32 = bitfieldInsert( vPixel32, vaf, 24, ( TCC ^ 1 ) << 3 );
				//}
			}
			else
			{
				//vat = ivec4( vPixel32 >> 24 ) & 0xff;
				//vrt = ivec4( vPixel32 >> 16 ) & 0xff;
				//vgt = ivec4( vPixel32 >> 8 ) & 0xff;
				//vbt = ivec4( vPixel32 >> 0 ) & 0xff;
				vat = ivec4( bitfieldExtract( vPixel32, 24, 8 ) );
				vrt = ivec4( bitfieldExtract( vPixel32, 16, 8 ) );
				vgt = ivec4( bitfieldExtract( vPixel32, 8, 8 ) );
				vbt = ivec4( bitfieldExtract( vPixel32, 0, 8 ) );

				// handle alpha first

				// do the multiply and add
				vmul = ( vat * vaf ) >> 7;
				vadd = vat + vaf;


				// select multiply/add
				//vat = ( TFX == 0 ) ? vmul : vat;
				//vat = ( TFX == 2 ) ? vadd : vat;
				vmul = bitfieldInsert( vmul, vadd, 0, ( TFX << 3 ) );
				vat = bitfieldInsert( vat, vmul, 0, ( TFX - 3 ) & 0x1f );

				// select af,at
				//vav = ( TCC == 0 ) ? vaf : vat;
				vav = bitfieldInsert( vaf, vat, 0, TCC << 5 );

				// COLCLAMP ??
				//vav &= COLCLAMP;

				vav = clamp( vav, 0, 255 );


				// handle the colors next


				//vadd = ( ( TFX & 0x2 ) == 0 ) ? vZero : vaf;
				//vadd = vaf & -( ( TFX >> 1 ) & 1 );
				vadd = vaf & -( TFX >> 1 );

				// red
				vmul = ( ( vrt * vrf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vrv = ( TFX == 1 ) ? vrt : vmul;
				vrv = clamp( vmul, 0, 255 );

				// green
				vmul = ( ( vgt * vgf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vgv = ( TFX == 1 ) ? vgt : vmul;
				vgv = clamp( vmul, 0, 255 );

				// blue
				vmul = ( ( vbt * vbf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vbv = ( TFX == 1 ) ? vbt : vmul;
				vbv = clamp( vmul, 0, 255 );

				//vPixel32 = ( vav << 24 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
				vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbv, vav, 24, 8 ), vrv, 16, 8 ), vgv, 8, 8 );
			}

#endif	// end #ifdef ENABLE_TEXTURE_FUNC_SPRITE


#ifdef ENABLE_FOGGING_SPRITE

	//if ( FGE == 1 )
	{
		//vav = ivec4( vPixel32 >> 24 ) & 0xff;
		//vrv = ivec4( vPixel32 >> 16 ) & 0xff;
		//vgv = ivec4( vPixel32 >> 8 ) & 0xff;
		//vbv = ivec4( vPixel32 >> 0 ) & 0xff;
		vav = ivec4( bitfieldExtract( vPixel32, 24, 8 ) );
		vrv = ivec4( bitfieldExtract( vPixel32, 16, 8 ) );
		vgv = ivec4( bitfieldExtract( vPixel32, 8, 8 ) );
		vbv = ivec4( bitfieldExtract( vPixel32, 0, 8 ) );

		// should do fogging here
		vrv = ( ( vrv * F0 ) >> 8 ) + ( ( RF0 * FCR ) >> 8 );
		vgv = ( ( vgv * F0 ) >> 8 ) + ( ( RF0 * FCG ) >> 8 );
		vbv = ( ( vbv * F0 ) >> 8 ) + ( ( RF0 * FCB ) >> 8 );

		// COLCLAMP ??
		vrv &= COLCLAMP;
		vgv &= COLCLAMP;
		vbv &= COLCLAMP;

		// fogging clamp
		vrv = clamp ( vrv, 0, 255 );
		vgv = clamp ( vgv, 0, 255 );
		vbv = clamp ( vbv, 0, 255 );

		//vPixel32 = ( vav << 24 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
		vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbv, vav, 24, 8 ), vrv, 16, 8 ), vgv, 8, 8 );

	}	// end if ( FGE == 1 )

#endif	// end #ifdef ENABLE_FOGGING_SPRITE

	}	// end if( bTEXTURE )

	// this is what I'll use for the source alpha test
	vTestPixel32 = vPixel32 >> 24;


#ifdef ENABLE_ALPHA_BLEND_SPRITE

	if ( subgroupAll( ABE == 1 ) )
	{
			// alpha blend //


			// A pixel //

			// select
			//mAlphaSelect [ 0 ] = uintBitsToFloat( vPixel32 );
			//mAlphaSelect [ 1 ] = uintBitsToFloat( vDestPixel32 );
			//vPixelA = floatBitsToInt( mAlphaSelect [ ALPHA_A ] );
			//vPixelB = floatBitsToInt( mAlphaSelect [ ALPHA_B ] );
			//vPixelC = floatBitsToInt( mAlphaSelect [ ALPHA_C ] );
			//vPixelD = floatBitsToInt( mAlphaSelect [ ALPHA_D ] );
			//vPixelA = ( ( vPixel32 & (ALPHA_A-1) ) | ( vDestPixel32 & -ALPHA_A ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			//vPixelB = ( ( vPixel32 & (ALPHA_B-1) ) | ( vDestPixel32 & -ALPHA_B ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			//vPixelD = ( ( vPixel32 & (ALPHA_D-1) ) | ( vDestPixel32 & -ALPHA_D ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			//vPixelC = ( ( ( vPixel32 & (ALPHA_C-1) ) | ( vDestPixel32 & -ALPHA_C ) ) & ( ( ALPHA_C >> 1 ) - 1 ) ) | ( ALPHA_FIX & -(ALPHA_C >> 1) );

			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );

			// perform alpha blend calculation //

			// get alpha
			//ivc = ivec4( vPixelC >> 24 ) & 0xff;
			ivc = ivec4( bitfieldExtract( vPixelC, 24, 8 ) );

			// do r
			//iva = ivec4( vPixelA >> 16 ) & 0xff;
			//ivb = ivec4( vPixelB >> 16 ) & 0xff;
			//ivd = ivec4( vPixelD >> 16 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			//iva = ivec4( vPixelA >> 8 ) & 0xff;
			//ivb = ivec4( vPixelB >> 8 ) & 0xff;
			//ivd = ivec4( vPixelD >> 8 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			//iva = ivec4( vPixelA >> 0 ) & 0xff;
			//ivb = ivec4( vPixelB >> 0 ) & 0xff;
			//ivd = ivec4( vPixelD >> 0 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //



			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );

			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then alpha blend pixel
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );

	}

#endif

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle

#ifdef ENABLE_SRCALPHA_TEST_SPRITE
			// alpha test //

		//if ( ATE != 0 )
		{
			
			//uvATSelect = uvec4( ( ( sign( ivec4( vTestPixel32 - vAREF ) ) & iATMask ) + iATOffset ) >> 31 );
			//uvATSelect = uvec4( ivec4( ( sign( ivec4( vTestPixel32 - vAREF ) ) & AMASK ) + AOFFSET ) >> 31 );
			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );

		}

#endif



#ifdef ENABLE_DSTALPHA_TEST_SPRITE

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			//uvDASelect = ( uvDASelect >> 31 ) ^ 1;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif



#ifdef ENABLE_DEPTH_TEST_SPRITE

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			//uvZSelect = ( sign( ivec4( uvZTST_EQUAL ) ) ^ ZTST_EQUAL ) | uvZTST_GREATER | ZTST_LESS;
			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;
			
		}

#endif

			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );

			// if storing to 24-bit buffer, combine pixel with destination
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			//vPixel32_0 = ( ( vPixel32 >> 3 ) & 0x001f ) | ( ( vPixel32 >> 6 ) & 0x03e0 ) | ( ( vPixel32 >> 9 ) & 0x7c00 ) | ( ( vPixel32 >> 16 ) & 0x8000 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			// select whether to draw 32-bit or 16-bit pixels
			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			// transparent pixel test ??
			//uvEnable &= sign( ivec4( vTPixel32 ) );

			// testing //
			//uvEnable &= 1;

			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );
			

			// write frame buffer //


			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //

				// store the pixels //
				VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				VRAM [ vOffset[3] ] = vPixel32 [ 3 ];

			}
			else
			{
				// 16-bit pixels

				// store the pixels //

				VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}


#ifdef ENABLE_WRITE_ZBUFFER_SPRITE

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				//vZPixel32 = ( vZPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) ) | ( vZPixelX & ( (-(ZPSM & 1)) << 24 ) );
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, (ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //

					// store the pixels //

					VRAM [ vZOffset[0] ] = vZPixel32[0];
					VRAM [ vZOffset[1] ] = vZPixel32[1];
					VRAM [ vZOffset[2] ] = vZPixel32[2];
					VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					VRAM16 [ vZOffset.x ] = uint16_t( vZPixel32 [ 0 ] );
					VRAM16 [ vZOffset.y ] = uint16_t( vZPixel32 [ 1 ] );
					VRAM16 [ vZOffset.z ] = uint16_t( vZPixel32 [ 2 ] );
					VRAM16 [ vZOffset.w ] = uint16_t( vZPixel32 [ 3 ] );
				}

			}	// end if ( ZMSK == 0 )

#endif


			//viU += dudx;

		}	// end for ( vx_across = vxid; any( lessThan( uvec4( vx_across ), uvec4( w ) ) ); vx_across += group_vxinc )


		//iV += dvdy;
		
	}	// end for ( Line = StartY + yid; Line <= EndY; Line += yinc )

	}	// end if ( bDraw == 1 )



#undef StartY
#undef EndY
#undef StartX
#undef EndX

#undef Z0

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

#undef WIDTH
#undef BGR32

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ZTST_LESS
#undef ZTST_EQUAL

#undef AMASK
#undef AOFFSET

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX

#undef TEXA_0
#undef TEXA_1
#undef AEM

#undef TexX_And
#undef TexX_Or
#undef TexX_Min
#undef TexX_Max

#undef TexY_And
#undef TexY_Or
#undef TexY_Min
#undef TexY_Max

#undef TBP
#undef TBW
#undef TPSM
#undef TEXPSM

#undef FCR	
#undef FCG
#undef FCB

#undef F0
#undef RF0

#undef VU
#undef VV
#undef DUDX
#undef DVDY

#undef And1
#undef iShift2
#undef iAnd3
#undef iShift3

#undef TCC
#undef TFX
#undef CPSM
#undef CSA




#ifdef DRAW_SPRITE_MULTI

		uIndex += 64;

		uIdx += 128;

		Comm = inputdata [ uIndex + ( 15 << 1 ) + 0 ];

		//PRIM = Comm & 0xff000017;
		//Comm >>= 24;

		Comm &= 0xff000017;

	} while ( ( ( Comm == 0x16 ) || ( Comm == 0x10 ) ) && ( uIndex < ( COMMAND_LIST_SIZE << 6 ) ) );

	return ( uIndex >> 6 ) - 1;

#else

	return;

#endif

}


#endif	// end #ifdef ENABLE_DRAW_SPRITE




#ifdef ENABLE_DRAW_TRIANGLE_COLOR


#ifdef DRAW_TRIANGLE_COLOR_MULTI
uint Draw_Triangle_Color ( uint uIndex )
#else
void Draw_Triangle_Color ( uint uIndex )
#endif
{
	int xid;
	int yid;

	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	int iPtr;
	ivec4 ivPtr;

	ivec4 ivLine;

	int idx;
	ivec4 idx4;
	
	int Temp;

	// common object vars //

	int DrawArea_TopLeftX;
	int DrawArea_BottomRightX;

	//int DrawArea_TopLeftY;
	//int DrawArea_BottomRightY;
	//int DrawArea_OffsetX;
	//int DrawArea_OffsetY;

	uint PRIM;
	//int FRAME;
	//uint FBMSK;

	uint DATE;

	uint FST, ABE, FGE, PABE;
	uint AA1;
	uint FOGCOL;
	//int FCR, FCG, FCB;

	//int FBP;
	//int FBW;
	//int FPSM;

	//int FrameBufferStartOffset32;
	//int FrameBufferWidth_Pixels;

	uint TEST, AFAIL;
	uint AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	uvec4 vAREF;

	//int ZBUF;
	//int ZBP;
	//int ZPSM;
	//int ZMSK;

	//int ZBufferStartOffset32;

	int DRAWPSM;
	//int ZBUFPSM;

	uint FBA;

	//int CLAMP_0, CLAMP_1;
	int WMS, WMT;
	int MINU, MAXU, MINV, MAXV;
	int TexY_And, TexY_Or, TexY_Min, TexY_Max;
	int TexX_And, TexX_Or, TexX_Min, TexX_Max;

	//int AEM;
	//int TEXA_0, TEXA_1;

	//int TEX0_0, TEX0_1;
	//int TBP0, TBW, TPSM, TW, TH;
	//int TEXPSM;
	//int TexWidth, TexHeight;
	//int TexWidth_Mask, TexHeight_Mask;
	//int TCC, TFX;
	//int CBP, CPSM, CSM, CSA, CLD;
	//int CLUTStartOffset32;

	//int TextureBufferStartOffset32;
	//int TextureBufferWidth_Pixels;

	int COLCLAMP;

	int StartX;
	int EndX;

	//int StartY;
	//int EndY;
	//int StartY1;
	//int EndY1;


	// common triangle vars //

	//uvec4 Coord;

	//int LeftMostX, RightMostX, TopMostY, BottomMostY;
	//int t0, t1, denominator;
	//int X0Index, X1Index;
	int w;
	int h, sh;

	uint DestPixel;
	uint bgr_temp;
	int x_across;
	int Line;

	//uint bgr16;
	//uint bgr32;
	//ivec3 vx, vy;
	//uvec3 vz;

	ivec4 vdx, vdx1;
	//ivec2 vdxdy;

	ivec4 xoff;

	//ivec4 vr, vg, vb, va;
	//int vdr, vdg, vdb, vda;

	//int vdrdy, vdgdy, vdbdy, vdady;

	//int drdx, dgdx, dbdx, dadx;
	//double dzdx;
	//double vdz, vdz1;
	//double vdzdy, vdzdy1;
	int64_t dzdx;
	int64_t vdz, vdz1;
	int64_t vdzdy, vdzdy1;

	uvec2 vdzdy2, dzdx2;
	uvec4 vdz2;

	int iR, iG, iB, iA;
	ivec4 viR, viG, viB, viA;
	ivec4 vRed, vGreen, vBlue, vAlpha;
	//double iZ;
	//dvec4 viZ;
	int64_t iZ;
	i64vec4 viZ;



	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;



	ivec4 vIdx;
	ivec4 vIdx32;
	ivec4 vxid;
	ivec4 vx_across;
	ivec4 vOffset;
	ivec4 vZOffset;

	uvec4 vDestPixel16, vDestPixel32, vDestPixel32_0, vDestPixel32_1;
	uvec4 vZDestPixel16, vZDestPixel32, vZDestPixel32_0, vZDestPixel32_1;
	uvec4 vZDestPixel24_1;
	uvec4 vPixel32, vZPixel32;
	uvec4 vPixel24, vZPixel24;
	uvec4 vPixel32_0, vPixel32_1, vZPixel32_0, vZPixel32_1;
	uvec4 vPixel32_2;
	uvec4 vPixel16;
	uvec4 vMask, vMask32;
	ivec4 vPixelShift;

	uvec4 vDPixelX, vZPixelX;

	bvec4 bvALPHA_A_SELECT, bvALPHA_B_SELECT, bvALPHA_C_SELECT, bvALPHA_D_SELECT;
	ivec4 ivAlphaA, ivAlphaB, ivAlphaC, ivAlphaD;
	ivec4 ivRedA, ivRedB, ivRedC, ivRedD;
	ivec4 ivGreenA, ivGreenB, ivGreenC, ivGreenD;
	ivec4 ivBlueA, ivBlueB, ivBlueC, ivBlueD;

	ivec4 ivATSelect, ivDASelect, ivZSelect;
	uvec4 uvATSelect, uvDASelect, uvZSelect;

	//bvec4 bvZTST_LESS, bvZTST_GREATER, bvZTST_EQUAL;
	uvec4 uvZTST_GREATER, uvZTST_EQUAL;
	bvec4 bvTestMask;
	//bvec4 bvEnable;
	uvec4 uvEnable;

	uvec4 vTestPixel32;


	ivec4 vav, vrv, vgv, vbv;
	ivec4 vaf, vrf, vgf, vbf;
	ivec4 vat, vrt, vgt, vbt;
	ivec4 vadd, vmul;

	uvec4 uvbgr32;


	uint Comm;
	uint bDraw;

	uint uIdx;
	uint uLoop;


	// texture vars //

	uvec4 vTPixel32;
	int iAnd1, iShift1, iShift2, iAnd3, iShift3;

	//int dudx, dvdx, dfdx;
	//float dsdx, dtdx, dqdx;

	//int vdu, vdv, vdf;
	//float vds, vdt, vdq;

	//int vdudy, vdvdy, vdfdy;
	//float vdsdy, vdtdy, vdqdy;

	int iU, iV, iF;
	float fS, fT, fQ;

	ivec4 viU, viV, viF;
	vec4 vfS, vfT, vfQ;

	ivec4 vf0, vrf0;


	ivec4 vTexCoordX, vTXOffset, vTOffset;
	ivec4 vTexCoordY;
	//ivec2 vTexCoordUV, vTexCoordST;
	//ivec4 viTYOffset, vxTYOffset;


	//int f0, f1;
	//int rf0;

	//ivec3 vu, vv;
	//ivec3 vf;
	//vec3 vs, vt, vq;


	//ivec4 vrgba0, vrgba1, vrgba2;
	//ivec3 vuvf0, vuvf1, vuvf2;
	//vec3 vstq0, vstq1, vstq2;

	ivec4 drgbadx;
	ivec4 duvfdx;
	vec4 dstqdx;

	ivec4 vdrgbady, vdrgbady1;
	ivec4 vduvfdy, vduvfdy1;
	vec4 vdstqdy, vdstqdy1;

	vec4 vyvdstqdy;
	double vyvdzdy;

	ivec4 vdrgba, vdrgba1;
	ivec4 vduvf, vduvf1;
	vec4 vdstq, vdstq1;

	float vxdsdx;
	float vxdtdx;
	float vxdqdx;
	double vxdzdx;

	ivec4 irgba, iuvf;
	vec4 ifstq;

	ivec4 vTemp;

	uvec4 uvAlphaSelect [ 4 ];

	uvec4 uvTEXA_0;
	uvec4 uvTEXA_1;
	uvec4 uvALPHA_FIX;

	int iATOffset, iATMask;

	int DYNAND, ZYNAND, TYNAND;

	int iXInc, iYInc;
	int yoffset;

	// note: these are for textured objects only
	//uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX;
	//uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX;
	//uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM;
	//uvec4 uvTEX02_TW_TH_TWMASK_THMASK;
	//uvec4 uvTEX02_TCC_TFX_CPSM_CSA;

	uvec4 uvTEXA_TA0_TA1_AEM;

	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	uvec4 uvZTST_LESS_EQUAL_GREATER;
	uvec4 uvATST_LEG_OFFSET_MASK;

	uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	//uvec4 uvFOGCOL_FCR_FCG_FCB;


	uvec4 uv_dzdx0_dzdx1_bDraw_sync;

	//uvec4 uv_And1_Shift1_Shift2_And3_Shift3;

	ivec4 iv_StartY0_EndY0_StartY1_EndY1;

	//ivec4 iv_vaf_vrf_vgf_vbf;

	int iZMASK, iAMASK;

	bool bFRAME32, bZBUF32;

	uint ctx;



	uIdx = uIndex << 6;
	uIndex <<= 5;


#ifdef DRAW_TRIANGLE_COLOR_MULTI
	do
	{
#endif


	bDraw = data [ uIdx + 2 ];

	if ( subgroupAll( bDraw == 1 ) )
	{
		// load common settings //

		
		//DrawArea_TopLeftX = int( inputdata [ uIndex + ( 1 << 1 ) + 0 ] );
		DrawArea_TopLeftX = int( inputdata [ uIndex + 2 ] );
		DrawArea_BottomRightX = ( DrawArea_TopLeftX >> 16 ) & 0x7ff;
		DrawArea_TopLeftX &= 0x7ff;

		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );
		FGE = bitfieldExtract( PRIM, 5, 1 );
		//FST = bitfieldExtract( PRIM, 8, 1 );

		// for now treating AA1 as alpha
		ABE |= AA1;

		// note: CLAMP and TEXA are for textured objects
		// note: DIMX is for gradient objects
		//uvCLAMP_WMS_AND_OR_MIN_MAX = uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];
		//uvCLAMP_WMT_AND_OR_MIN_MAX = uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];

		// note: TEX0/2 data is only needed for textured objects
		//uvTEX02_TBP_TBW_TPSM_TEXPSM = uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TW_TH_TWMASK_THMASK = uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ ctx ];
		//uvTEX02_TCC_TFX_CPSM_CSA = uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ ctx ];

		//uvTEXA_TA0_TA1_AEM = uvTEXA_TA0_TA1_AEM_LUT [ subgroup_local_id ];


		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];
		uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];

		//uv_And1_Shift1_Shift2_And3_Shift3 = c_uvLUT_TEX02_TPSM [ uvTEX02_TBP_TBW_TPSM_TEXPSM[2] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;

		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );

		
		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );

		// load triangle vars //


		// loading 4 at a time from pre-calc values
		uIdx >>= 2;

		uv_dzdx0_dzdx1_bDraw_sync = data4 [ uIdx + 0 ];
		drgbadx = data4 [ uIdx + 1 ];

		//duvfdx = data4 [ uIdx + 2 ];
		// but it might be storing stq dx and not uv dx
		//dstqdx = intBitsToFloat( duvfdx );
		// move f over into z component for now
		//duvfdx.z = duvfdx.w;

		// combine z value into a double for now (might use 64-bit int later)
		//dzdx = packDouble2x32( uv_dzdx0_dzdx1_bDraw_sync.xy );
		dzdx = packInt2x32( ivec2( uv_dzdx0_dzdx1_bDraw_sync.xy ) );

		iv_StartY0_EndY0_StartY1_EndY1 = data4 [ uIdx + 3 ];



		vdx = data4 [ uIdx + 4 ];

		vdz2 = data4 [ uIdx + 5 ];

		// make these double for now, but later want to use 64-bit integers
		//vdz = packDouble2x32( vdz2.xy );
		//vdzdy = packDouble2x32( vdz2.zw );
		vdz = packInt2x32( ivec2( vdz2.xy ) );
		vdzdy = packInt2x32( ivec2( vdz2.zw ) );

		vdrgba = data4 [ uIdx + 6 ];

		vdrgbady = data4 [ uIdx + 7 ];

		//vduvf = data4 [ uIdx + 8 ];
		//vdstq = intBitsToFloat( vduvf );
		//vduvf.z = vduvf.w;

		//vduvfdy = data4 [ uIdx + 9 ];
		//vdstqdy = intBitsToFloat( vduvfdy );
		//vduvfdy.z = vduvfdy.w;

		vdx1 = data4 [ uIdx + 10 ];

		vdz2 = data4 [ uIdx + 11 ];

		// make these double for now, but later want to use 64-bit integers
		//vdz1 = packDouble2x32( vdz2.xy );
		//vdzdy1 = packDouble2x32( vdz2.zw );
		vdz1 = packInt2x32( ivec2( vdz2.xy ) );
		vdzdy1 = packInt2x32( ivec2( vdz2.zw ) );

		vdrgba1 = data4 [ uIdx + 12 ];

		vdrgbady1 = data4 [ uIdx + 13 ];

		//vduvf1 = data4 [ uIdx + 14 ];
		//vdstq1 = intBitsToFloat( vduvf1 );
		//vduvf1.z = vduvf1.w;

		//vduvfdy1 = data4 [ uIdx + 15 ];
		//vdstqdy1 = intBitsToFloat( vduvfdy1 );
		//vduvfdy1.z = vduvfdy1.w;







		// COLCLAMP(+15)(0x46),PABE(+27)(0x49)
		//COLCLAMP = int( inputdata [ uIndex + 15 ] );
		//PABE = inputdata [ uIndex + 27 ];
		COLCLAMP = int( uvps2gpu_vars[subgroup_local_id][0x46].x );
		PABE = int( uvps2gpu_vars[subgroup_local_id][0x49].x );

		// FBA (0x4a,0x4b)
		//FBA = uFBA_FBA_LUT [ subgroup_local_id ] [ ctx ];
		FBA = int( uvps2gpu_vars[subgroup_local_id][0x4a+ctx].x );

		// FOGCOL(+31)(0x3d),DTHE/DIMX(0x45/0x44)
		//FOGCOL = uvps2gpu_vars[subgroup_local_id][0x3d].x;

		//DTHE = uvps2gpu_vars[subgroup_local_id][0x45].x;
		//DIMX2 = uvps2gpu_vars[subgroup_local_id][0x44];

		//uvFOGCOL_FCR_FCG_FCB = uvec4( unpack8( FOGCOL ) );



//#define StartY		(iv_StartX_StartY_EndX_EndY[1])
//#define EndY		(iv_StartX_StartY_EndX_EndY[3])
//#define StartX		(iv_StartX_StartY_EndX_EndY[0])
//#define EndX		(iv_StartX_StartY_EndX_EndY[2])

#define StartY		(iv_StartY0_EndY0_StartY1_EndY1[0])
#define EndY		(iv_StartY0_EndY0_StartY1_EndY1[1])
#define StartY1		(iv_StartY0_EndY0_StartY1_EndY1[2])
#define EndY1		(iv_StartY0_EndY0_StartY1_EndY1[3])

//#define Z0			(uv_z0_f0_bDraw_sync[0])

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		int(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		int(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

//#define WIDTH		(uv_w_rf0_bgr32 [ 0 ])
//#define BGR32		(uv_w_rf0_bgr32 [ 2 ])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ZTST_LESS	(uvZTST_LESS_EQUAL_GREATER[0])
#define ZTST_EQUAL	(uvZTST_LESS_EQUAL_GREATER[1])

#define AOFFSET		(uvATST_LEG_OFFSET_MASK[1])
#define AMASK		(uvATST_LEG_OFFSET_MASK[2])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])

//#define TEXA_0		(uvTEXA_TA0_TA1_AEM[0])
//#define TEXA_1		(uvTEXA_TA0_TA1_AEM[1])
//#define AEM			(uvTEXA_TA0_TA1_AEM[2])

//#define TexX_And	int(uvCLAMP_WMS_AND_OR_MIN_MAX[0])
//#define TexX_Or		int(uvCLAMP_WMS_AND_OR_MIN_MAX[1])
//#define TexX_Min	int(uvCLAMP_WMS_AND_OR_MIN_MAX[2])
//#define TexX_Max	int(uvCLAMP_WMS_AND_OR_MIN_MAX[3])

//#define TexY_And	int(uvCLAMP_WMT_AND_OR_MIN_MAX[0])
//#define TexY_Or		int(uvCLAMP_WMT_AND_OR_MIN_MAX[1])
//#define TexY_Min	int(uvCLAMP_WMT_AND_OR_MIN_MAX[2])
//#define TexY_Max	int(uvCLAMP_WMT_AND_OR_MIN_MAX[3])

//#define TBP			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[0])
//#define TBW			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[1])
//#define TPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[2])
//#define TEXPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[3])

//#define FCR			int(uvFOGCOL_FCR_FCG_FCB[0])
//#define FCG			int(uvFOGCOL_FCR_FCG_FCB[1])
//#define FCB			int(uvFOGCOL_FCR_FCG_FCB[2])

//#define F0			int(uv_z0_f0_bDraw_sync[1])
//#define RF0			int(uv_w_rf0_bgr32[1])

//#define VU			(iv_vu_vv_dudx_dvdy[0])
//#define VV			(iv_vu_vv_dudx_dvdy[1])
//#define DUDX		(iv_vu_vv_dudx_dvdy[2])
//#define DVDY		(iv_vu_vv_dudx_dvdy[3])

//#define And1		int(uv_And1_Shift1_Shift2_And3_Shift3[0])
//#define iShift2		int(uv_And1_Shift1_Shift2_And3_Shift3[1])
//#define iAnd3		int(uv_And1_Shift1_Shift2_And3_Shift3[2])
//#define iShift3		int(uv_And1_Shift1_Shift2_And3_Shift3[3])

//#define TCC			int(uvTEX02_TCC_TFX_CPSM_CSA[0])
//#define TFX			int(uvTEX02_TCC_TFX_CPSM_CSA[1])
//#define CPSM		int(uvTEX02_TCC_TFX_CPSM_CSA[2])
//#define CSA			int(uvTEX02_TCC_TFX_CPSM_CSA[3])


	// 24-bit pixels do not have destination alpha test
	DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

		//iShift1 = ( And1 >> 8 ) & 0xff;
		//iAnd1 = And1 & 0xff;

		//uvbgr32 = uvec4( BGR32 );

		//vaf = ivec4( iv_vaf_vrf_vgf_vbf[0] );
		//vrf = ivec4( iv_vaf_vrf_vgf_vbf[1] );
		//vgf = ivec4( iv_vaf_vrf_vgf_vbf[2] );
		//vbf = ivec4( iv_vaf_vrf_vgf_vbf[3] );

		// this will come last
		COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

		//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
		PABE <<= 31;

		// FBA
		FBA <<= 31;

		// FOGCOL
		// DTHE/DIMX
		//DIMX &= -( DTHE & 1 );

		// if alpha is disabled then no alpha blending
		uvALPHA_ABCD &= -ABE;

		// drawpsm is fpsm shifted right one
		DRAWPSM = int( FPSM >> 1 );


		bFRAME32 = ( DRAWPSM & 1 ) == 0;
		bZBUF32 = ( ZBUFPSM & 1 ) == 0;


		//uvTEXA_0 = uvec4( TEXA_0 );
		//uvTEXA_1 = uvec4( TEXA_1 );
		
		uvALPHA_FIX = uvec4( ALPHA_FIX );

		//uvZ0 = uvec4( Z0 );


		vAREF = uvec4( AREF );

		iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
		iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];


	// adjust starty (here it is doing inclusive of window start)
	yid = max( StartY, ivDrawRange [ subgroup_local_id ].x ) - StartY;
	//StartY = max( StartY, ivDrawRange [ subgroup_local_id ].x );

	// adjust endy (here it is doing exclusive of window end since it is already exclusive of EndY1)
	//EndY1 = min( EndY1, ivDrawRange [ subgroup_local_id ].y );
	EndY1 = min( EndY1, ivDrawRange [ subgroup_local_id ].y - 1 );

	// get height for subgroup (exclusive of EndY1)
	sh = EndY1 - StartY - yid;


	


#ifdef ENABLE_TRIANGLE_SUBGROUP_SKIP

	// if nothing to draw, then done
	//if ( subgroupAll( sh <= 0 ) )
	if ( subgroupAll( sh < 0 ) )
	{
		return;
	}

#endif

		idx = int( lxid ) << 2;
		idx4 = idx + ivec4( 0, 1, 2, 3 );
		xid = idx & SHADER_X_MASK;
		vxid = idx4 & SHADER_X_MASK;

		// number of pixels to go across is number of pixels being drawn across
		iXInc = SHADER_X_MASK + 1;


		yoffset = ( idx >> SHADER_Y_SHIFT ) + yid;

		// the amount to loop down is the number of shader lines being drawn times global shader groups
		iYInc = ( int( lxinc << 2 ) >> SHADER_Y_SHIFT );


		//dCx_across.rgb = dC_across.rgb * iXInc;
		//dTx_across.st = dT_across.st * iXInc;

		
		// triangle vars //


	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];

	//TYNAND = LUT_YNAND[ TEXPSM ];



	//for ( uLoop = 0; uLoop < 60; uLoop += 32 )
	{

		// first set //
		


	//uvTEXA_0 = uvec4( TEXA_0 );
	//uvTEXA_1 = uvec4( TEXA_1 );

	uvALPHA_FIX = uvec4( ALPHA_FIX );

	vAREF = uvec4( AREF );

	//vxdsdx = dsdx * float( group_vxinc );
	//vxdtdx = dtdx * float( group_vxinc );
	//vxdqdx = dqdx * float( group_vxinc );
	//vxdzdx = dzdx * double( group_vxinc );

	//vyvdstqdy = vdstqdy * float( group_yinc );
	//vyvdzdy = vdzdy * double( group_yinc );



	//if ( EndY >= StartY )
	{

	// align the compute units with pixels
	//yid = ( ( ( cyid << group_yshift ) + group_y ) - StartY ) & group_ymask;



	//////////////////////////////////////////////
	// draw down to y1
	//for ( Line = StartY + yid; Line <= EndY; Line += group_yinc )
	for ( Line = StartY + yoffset; Line <= EndY1; Line += iYInc )
	{

		if ( Line >= StartY1 )
		{
			//StartY = StartY1;
			//EndY = EndY1;
			iv_StartY0_EndY0_StartY1_EndY1.xy = iv_StartY0_EndY0_StartY1_EndY1.zw;

			vdx = vdx1;
			vdrgba = vdrgba1;
			vdrgbady = vdrgbady1;

			//vduvf = vduvf1;
			//vduvfdy = vduvfdy1;
			//vdstq = vdstq1;
			//vdstqdy = vdstqdy1;

			vdz = vdz1;
			vdzdy = vdzdy1;

		}

		yoffset = Line - StartY;

		// dxdy is in .16, Temp is in .4, and x is in .16
		//vdx += vdxdy * yid;
		//vdx.xy += vdx.zw * yid;
		xoff.xy = vdx.xy + ( vdx.zw * yoffset );
	
		irgba = vdrgba + ( vdrgbady * yoffset );

		//vdrgba += vdrgbady * yid;
		//vduvf += vduvfdy * yid;
		//vdstq += ( vdstqdy ) * ( float( yid ) );
		//iuvf = vduvf + ( vduvfdy * yoffset );
		//ifstq = vdstq + ( ( vdstqdy ) * ( float( yoffset ) ) );

		// *** todo *** should be a double
		//vdz += ( vdzdy ) * ( double( Temp )/16.0 );
		//vdz += ( vdzdy ) * ( double( yid ) );
		//iZ = vdz + ( ( vdzdy ) * ( double( yoffset ) ) );
		iZ = vdz + ( ( vdzdy ) * int64_t( yoffset ) );


		// left point is included if points are equal
		//StartX = ( vdx.x + 0xffff ) >> 16;
		//EndX = ( vdx.y - 1 ) >> 16;
		StartX = ( xoff.x + 0xffff ) >> 16;
		EndX = ( xoff.y - 1 ) >> 16;


		//if ( StartX <= DrawArea_BottomRightX && EndX >= DrawArea_TopLeftX && EndX >= StartX )
		{

			//irgba = vdrgba;
			//iuvf = vduvf;
			//ifstq = vdstq;
			// *** todo ***
			//iZ = vdz;
			
			
			// get distance from point to pixel
			//Temp = ( StartX << 16 ) - vdx.x;
			Temp = ( StartX << 16 ) - xoff.x;
			
			//if ( StartX < DrawArea_TopLeftX )
			//{
			//	Temp += ( DrawArea_TopLeftX - StartX ) << 16;
			//	StartX = DrawArea_TopLeftX;
			//}
			Temp += ( DrawArea_TopLeftX - min( StartX, DrawArea_TopLeftX ) ) << 16;
			StartX = max( StartX, DrawArea_TopLeftX );

			
			irgba += ( drgbadx >> 8 ) * ( Temp >> 8 );


			//iuvf += ( duvfdx >> 8 ) * ( Temp >> 8 );
			//ifstq += ( dstqdx ) * ( float( Temp ) * (1.0f/65536.0f) );

			//iZ += dzdx * ( double( Temp )/65536.0 );
			//iZ += dzdx * ( double( Temp ) * (1.0/65536.0) );
			iZ += ( dzdx >> 8 ) * int64_t( Temp >> 8 );
			
			
			//if ( EndX > DrawArea_BottomRightX )
			//{
			//	//EndX = Window_XRight + 1;
			//	EndX = DrawArea_BottomRightX;
			//}
			EndX = min( EndX, DrawArea_BottomRightX );

			
			//viR = irgba.r + ( vxid * drdx );
			//viG = irgba.g + ( vxid * dgdx );
			//viB = irgba.b + ( vxid * dbdx );
			//viA = irgba.a + ( vxid * dadx );
			viR = irgba.r + ( vxid * drgbadx.r );
			viG = irgba.g + ( vxid * drgbadx.g );
			viB = irgba.b + ( vxid * drgbadx.b );
			viA = irgba.a + ( vxid * drgbadx.a );

			//viU = iuvf.x + ( vxid * dudx );
			//viV = iuvf.y + ( vxid * dvdx );
			//viF = iuvf.z + ( vxid * dfdx );
			//viU = iuvf.x + ( vxid * duvfdx.x );
			//viV = iuvf.y + ( vxid * duvfdx.y );
			//viF = iuvf.z + ( vxid * duvfdx.z );

			//vfS = ifstq.x + ( vec4( vxid ) * dsdx );
			//vfT = ifstq.y + ( vec4( vxid ) * dtdx );
			//vfQ = ifstq.z + ( vec4( vxid ) * dqdx );
			//vfS = ifstq.x + ( vec4( vxid ) * dstqdx.x );
			//vfT = ifstq.y + ( vec4( vxid ) * dstqdx.y );
			//vfQ = ifstq.z + ( vec4( vxid ) * dstqdx.z );

			//viZ = iZ + ( dvec4( vxid ) * dzdx );
			viZ = iZ + ( i64vec4( vxid ) * dzdx );
			


			w = EndX - StartX + 1;

			w &= -( int( StartX <= DrawArea_BottomRightX ) & int( EndX >= DrawArea_TopLeftX ) & int( EndX >= StartX ) );

			// draw horizontal line
			// x_left and x_right need to be rounded off
			//for ( vx_across = vxid; vx_across.x < w; vx_across += group_vxinc )
			for ( vx_across = vxid; vx_across.x < w; vx_across += iXInc )
			{

			// get the pixels to be drawn
			//bvEnable = lessThan( uvec4( vx_across ), uvec4( w ) );
			usubBorrow( uvec4( vx_across ), uvec4( w ), uvEnable );

			// z value is z0
			//vZPixel32 = ivec4( z0 );
			vZPixel32 = uvec4( viZ >> 16 );

			//ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( StartY + ivLine ) & 0x3f ) << 7 );
			ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( Line ) & 0x3f ) << 7 );

			
			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			//vOffset += ( ivLine & DYNAND ) * int( FBW );
			//vOffset += ( ( StartY + ivLine ) & DYNAND ) * int( FBW );
			vOffset += ( ( Line ) & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );
			//vOffset += int( FBP );



			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vDestPixel32 >>= ( ( vOffset & 1 ) << 4 );
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( (FPSM & 1) << 31 );
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;


			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			//vZOffset += ( ivLine & ZYNAND ) * int( FBW );
			//vZOffset += ( ( StartY + ivLine ) & ZYNAND ) * int( FBW );
			vZOffset += ( ( Line ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );
			//vZOffset += int( ZBP );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vZDestPixel32 >>= ( ( vZOffset & 1 ) << 4 );
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) );
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

			// ***TODO*** this is a PROBLEM, since iR, iG, iB, iA are signed 32-bit values, so below can easily get wrong colors!
			vrf = viR >> 16;
			vgf = viG >> 16;
			vbf = viB >> 16;
			vaf = viA >> 16;

			vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbf, vaf, 24, 8 ), vrf, 16, 8 ), vgf, 8, 8 );


	// transparency check
	vTPixel32 = vPixel32;



#ifdef ENABLE_FOGGING_TRIANGLE_COLOR

	if ( FGE == 1 )
	{
	// get f0, rf0 //
	vf0 = viF >> 16;
	vrf0 = 0xff - vf0;

	// should do fogging here
	// but pixel is bgr
	vrv = ( ( vrv * vf0 ) >> 8 ) + ( ( vrf0 * FCR ) >> 8 );
	vgv = ( ( vgv * vf0 ) >> 8 ) + ( ( vrf0 * FCG ) >> 8 );
	vbv = ( ( vbv * vf0 ) >> 8 ) + ( ( vrf0 * FCB ) >> 8 );

	//vrv = ivec4 ( ( ( ( ( vPixel32 & 0x00ff00ff ) * uint( vf0 ) ) & 0xff00ff00 ) + ( uint( FCR | ( FCB << 16 ) ) * uint( vrf0 ) ) & 0xff00ff00 ) >> 8 );
	//vgv = ivec4( ( ( ( vPixel32 >> 8 ) & 0x000000ff ) * uint( vf0 ) ) + ( ( uint( FCG ) * uint( vrf0 ) ) & 0x0000ff00 ) ) & 0x0000ff00;
	//vPixel32 = bitfieldInsert( vPixel32, uvec4( vrv | vgv ), 0, 24 );


	// COLCLAMP ??
	//vrv &= COLCLAMP;
	//vgv &= COLCLAMP;
	//vbv &= COLCLAMP;

	// fogging clamp (***todo*** COLCLAMP??)
	//vrv = clamp ( vrv, 0, 255 );
	//vgv = clamp ( vgv, 0, 255 );
	//vbv = clamp ( vbv, 0, 255 );

	// re-form pixel //
	//vPixel32 = ( vav << 24 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
	vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbv, vav, 24, 8 ), vrv, 16, 8 ), vgv, 8, 8 );
	}

#endif	// end #ifdef ENABLE_FOGGING_TRIANGLE_COLOR



	// if not fogging, then use orginal pixel
	//vPixel32 = ( FGE == 0 ) ? vPixel32 : vPixel32_0;




#ifdef ENABLE_ALPHA_BLEND_TRIANGLE_COLOR

		if ( ABE == 1 )
		{
			// alpha blend //


			// A pixel //

			// select
			//uvAlphaSelect [ 0 ] = vPixel32;
			//uvAlphaSelect [ 1 ] = vDestPixel32;

			//vPixelA = uvAlphaSelect [ ALPHA_A ];
			//vPixelB = uvAlphaSelect [ ALPHA_B ];
			//vPixelC = uvAlphaSelect [ ALPHA_C ];
			//vPixelD = uvAlphaSelect [ ALPHA_D ];

			//vPixelA = ( ( vPixel32 & (ALPHA_A-1) ) | ( vDestPixel32 & -ALPHA_A ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			//vPixelB = ( ( vPixel32 & (ALPHA_B-1) ) | ( vDestPixel32 & -ALPHA_B ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			//vPixelD = ( ( vPixel32 & (ALPHA_D-1) ) | ( vDestPixel32 & -ALPHA_D ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			//vPixelC = ( ( ( vPixel32 & (ALPHA_C-1) ) | ( vDestPixel32 & -ALPHA_C ) ) & ( ( ALPHA_C >> 1 ) - 1 ) ) | ( uvALPHA_FIX & -(ALPHA_C >> 1) );
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );



			// perform alpha blend calculation //

			// get alpha
			ivc = ivec4( vPixelC >> 24 ) & 0xff;

			// do r
			//iva = ivec4( vPixelA >> 16 ) & 0xff;
			//ivb = ivec4( vPixelB >> 16 ) & 0xff;
			//ivd = ivec4( vPixelD >> 16 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			//iva = ivec4( vPixelA >> 8 ) & 0xff;
			//ivb = ivec4( vPixelB >> 8 ) & 0xff;
			//ivd = ivec4( vPixelD >> 8 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			//iva = ivec4( vPixelA >> 0 ) & 0xff;
			//ivb = ivec4( vPixelB >> 0 ) & 0xff;
			//ivd = ivec4( vPixelD >> 0 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );
		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_TRIANGLE_COLOR

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle

			// alpha test //


			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );


#ifdef ENABLE_SRCALPHA_TEST_TRIANGLE_COLOR

		//if ( ATE != 0 )
		{
			vTestPixel32 = vTPixel32 >> 24;

			
			//uvATSelect = uvec4( ( ( sign( ivec4( vTestPixel32 - vAREF ) ) & iATMask ) + iATOffset ) >> 31 );
			//uvATSelect = uvec4( ivec4( ( sign( ivec4( vTestPixel32 - vAREF ) ) & AMASK ) + AOFFSET ) >> 31 );
			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );

		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_TRIANGLE_COLOR


#ifdef ENABLE_DSTALPHA_TEST_TRIANGLE_COLOR

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_TRIANGLE_COLOR


#ifdef ENABLE_DEPTH_TEST_TRIANGLE_COLOR

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			//uvZSelect = ( sign( ivec4( uvZTST_EQUAL ) ) ^ ZTST_EQUAL ) | uvZTST_GREATER | ZTST_LESS;
			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_TRIANGLE_COLOR


			// if storing to 24-bit buffer, combine pixel with destination
			//vPixel32 = ( vPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( vDPixelX & ( (-(FPSM & 1)) << 24 ) );
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			//vPixel32_0 = ( ( vPixel32 >> 3 ) & 0x001f ) | ( ( vPixel32 >> 6 ) & 0x03e0 ) | ( ( vPixel32 >> 9 ) & 0x7c00 ) | ( ( vPixel32 >> 16 ) & 0x8000 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			// select whether to draw 32-bit or 16-bit pixels
			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			//uvEnable &= sign( ivec4( vTPixel32 ) );
			uvEnable = -uvEnable;

			// and only the enabled pixels
			//vPixel32 = ( vPixel32 & uvEnable ) | ( vDestPixel32 & ~uvEnable );
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );
			

			// write frame buffer //


			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //


				// store the pixels //
				VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				VRAM [ vOffset[3] ] = vPixel32 [ 3 ];

			}
			else
			{
				// 16-bit pixels

				// store the pixels //

				VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}



#ifdef ENABLE_WRITE_ZBUFFER_TRIANGLE_COLOR

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				//vZPixel32 = ( vZPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) ) | ( vZPixelX & ( (-(ZPSM & 1)) << 24 ) );
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, (ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					VRAM [ vZOffset[0] ] = vZPixel32[0];
					VRAM [ vZOffset[1] ] = vZPixel32[1];
					VRAM [ vZOffset[2] ] = vZPixel32[2];
					VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}

			}	// end if ( ZMSK == 0 )

#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_TRIANGLE_COLOR


				//viR += drdx << group_vxinc_shift;
				//viG += dgdx << group_vxinc_shift;
				//viB += dbdx << group_vxinc_shift;
				//viA += dadx << group_vxinc_shift;
				viR += drgbadx.r * ( iXInc );
				viG += drgbadx.g * ( iXInc );
				viB += drgbadx.b * ( iXInc );
				viA += drgbadx.a * ( iXInc );

				//viU += dudx << group_vxinc_shift;
				//viV += dvdx << group_vxinc_shift;
				//viF += dfdx << group_vxinc_shift;
				//viU += duvfdx.x * ( iXInc );
				//viV += duvfdx.y * ( iXInc );
				//viF += duvfdx.z * ( iXInc );

				//vfS += dsdx * float( group_vxinc );
				//vfT += dtdx * float( group_vxinc );
				//vfQ += dqdx * float( group_vxinc );
				//vfS += vxdsdx;
				//vfT += vxdtdx;
				//vfQ += vxdqdx;
				//vfS += dstqdx.x * float( iXInc );
				//vfT += dstqdx.y * float( iXInc );
				//vfQ += dstqdx.z * float( iXInc );

				// *** todo ***
				//viZ += dzdx * double( group_vxinc );
				//viZ += vxdzdx;
				//viZ += dzdx * double( iXInc );
				viZ += dzdx * int64_t( iXInc );
			}
			
		}
		
		
	}
	
	} // end if ( EndY >= StartY )


	}	// end for ( uLoop = 0; uLoop < 60; uLoop += 32 )


	}	// end if ( bDraw == 1 )


//#undef StartY
//#undef EndY
//#undef StartX
//#undef EndX

#undef StartY
#undef EndY
#undef StartY1
#undef EndY1

//#undef Z0

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

//#undef WIDTH
//#undef BGR32

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ZTST_LESS
#undef ZTST_EQUAL

#undef AMASK
#undef AOFFSET

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX

#undef TEXA_0
#undef TEXA_1
#undef AEM

#undef TexX_And
#undef TexX_Or
#undef TexX_Min
#undef TexX_Max

#undef TexY_And
#undef TexY_Or
#undef TexY_Min
#undef TexY_Max

#undef TBP
#undef TBW
#undef TPSM
#undef TEXPSM

#undef FCR	
#undef FCG
#undef FCB

//#undef F0
//#undef RF0

//#undef VU
//#undef VV
//#undef DUDX
//#undef DVDY

#undef And1
#undef iShift2
#undef iAnd3
#undef iShift3

#undef TCC
#undef TFX
#undef CPSM
#undef CSA



#ifdef DRAW_TRIANGLE_COLOR_MULTI

		uIndex += 64;

		uIdx += 128;

		Comm = inputdata [ uIndex + ( 15 << 1 ) + 0 ];

		//PRIM = Comm & 0x17;
		//Comm >>= 24;

		Comm &= 0xff000017;

	} while ( ( Comm >= 0x13 ) && ( Comm <= 0x15 ) && ( uIndex < ( COMMAND_LIST_SIZE << 6 ) ) );

	return ( uIndex >> 6 ) - 1;

#else

	return;

#endif

}


#endif	// end #ifdef ENABLE_DRAW_TRIANGLE_COLOR






#ifdef ENABLE_DRAW_TRIANGLE_TEXTURE


#ifdef DRAW_TRIANGLE_TEXTURE_MULTI
uint Draw_Triangle_Texture ( uint uIndex )
#else
void Draw_Triangle_Texture ( uint uIndex )
#endif
{
	int xid;
	int yid;

	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	int iPtr;
	ivec4 ivPtr;

	ivec4 ivLine;

	int idx;
	ivec4 idx4;
	
	int Temp;

	// common object vars //

	int DrawArea_TopLeftX;
	int DrawArea_BottomRightX;

	//int DrawArea_TopLeftY;
	//int DrawArea_BottomRightY;
	//int DrawArea_OffsetX;
	//int DrawArea_OffsetY;

	uint PRIM;
	//int FRAME;
	//uint FBMSK;

	uint DATE;

	uint FST, ABE, FGE, PABE, TME;
	uint AA1;
	uint FOGCOL;
	//int FCR, FCG, FCB;

	//int FBP;
	//int FBW;
	//int FPSM;

	//int FrameBufferStartOffset32;
	//int FrameBufferWidth_Pixels;

	uint TEST, AFAIL;
	uint AFAIL_FBMASK, AFAIL_ZBMASK, ZTST_LESS, ZTST_GREATER, ZTST_EQUAL;
	int ATST_LESS, ATST_EQUAL, ATST_GREATER;
	bvec4 bvATST_LESS, bvATST_EQUAL, bvATST_GREATER;
	uvec4 uvAFAIL_PIXEL, uvAFAIL_ZPIXEL;

	uint ALPHA;
	uint ALPHA_A, ALPHA_B, ALPHA_C, ALPHA_D, ALPHA_FIX;
	uint ALPHA_A_SELECT, ALPHA_B_SELECT, ALPHA_C_SELECT, ALPHA_D_SELECT;
	uint ALPHA_A_AND, ALPHA_B_AND, ALPHA_C_AND, ALPHA_D_AND, ALPHA_C_OR;
	uvec4 vALPHA_A_PIXEL, vALPHA_B_PIXEL, vALPHA_C_PIXEL, vALPHA_D_PIXEL;
	uvec4 vAREF;

	//int ZBUF;
	//int ZBP;
	//int ZPSM;
	//int ZMSK;

	//int ZBufferStartOffset32;

	int DRAWPSM;
	//int ZBUFPSM;

	uint FBA;

	//int CLAMP_0, CLAMP_1;
	int WMS, WMT;
	int MINU, MAXU, MINV, MAXV;
	int TexY_And, TexY_Or, TexY_Min, TexY_Max;
	int TexX_And, TexX_Or, TexX_Min, TexX_Max;

	//int AEM;
	//int TEXA_0, TEXA_1;

	//int TEX0_0, TEX0_1;
	//int TBP0, TBW, TPSM, TW, TH;
	//int TEXPSM;
	//int TexWidth, TexHeight;
	//int TexWidth_Mask, TexHeight_Mask;
	//int TCC, TFX;
	//int CBP, CPSM, CSM, CSA, CLD;
	//int CLUTStartOffset32;

	//int TextureBufferStartOffset32;
	//int TextureBufferWidth_Pixels;

	int COLCLAMP;

	int StartX;
	int EndX;

	//int StartY;
	//int EndY;
	//int StartY1;
	//int EndY1;


	// common triangle vars //

	//uvec4 Coord;

	//int LeftMostX, RightMostX, TopMostY, BottomMostY;
	//int t0, t1, denominator;
	//int X0Index, X1Index;
	int w;
	int h, sh;

	uint DestPixel;
	uint bgr_temp;
	int x_across;
	int Line;

	//uint bgr16;
	//uint bgr32;
	//ivec3 vx, vy;
	//uvec3 vz;

	ivec4 vdx, vdx1;
	//ivec2 vdxdy;

	ivec4 xoff;

	//ivec4 vr, vg, vb, va;
	//int vdr, vdg, vdb, vda;

	//int vdrdy, vdgdy, vdbdy, vdady;

	//int drdx, dgdx, dbdx, dadx;
	//double dzdx;
	//double vdz, vdz1;
	//double vdzdy, vdzdy1;
	int64_t dzdx;
	int64_t vdz, vdz1;
	int64_t vdzdy, vdzdy1;

	uvec2 vdzdy2, dzdx2;
	uvec4 vdz2;

	int iR, iG, iB, iA;
	ivec4 viR, viG, viB, viA;
	ivec4 vRed, vGreen, vBlue, vAlpha;
	//double iZ;
	//dvec4 viZ;
	int64_t iZ;
	i64vec4 viZ;



	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;



	ivec4 vIdx;
	ivec4 vIdx32;
	ivec4 vxid;
	ivec4 vx_across;
	ivec4 vOffset;
	ivec4 vZOffset;

	uvec4 vDestPixel16, vDestPixel32, vDestPixel32_0, vDestPixel32_1;
	uvec4 vZDestPixel16, vZDestPixel32, vZDestPixel32_0, vZDestPixel32_1;
	uvec4 vZDestPixel24_1;
	uvec4 vPixel32, vZPixel32;
	uvec4 vPixel24, vZPixel24;
	uvec4 vPixel32_0, vPixel32_1, vZPixel32_0, vZPixel32_1;
	uvec4 vPixel32_2;
	uvec4 vPixel16;
	uvec4 vMask, vMask32;
	ivec4 vPixelShift;

	uvec4 vDPixelX, vZPixelX;

	bvec4 bvALPHA_A_SELECT, bvALPHA_B_SELECT, bvALPHA_C_SELECT, bvALPHA_D_SELECT;
	ivec4 ivAlphaA, ivAlphaB, ivAlphaC, ivAlphaD;
	ivec4 ivRedA, ivRedB, ivRedC, ivRedD;
	ivec4 ivGreenA, ivGreenB, ivGreenC, ivGreenD;
	ivec4 ivBlueA, ivBlueB, ivBlueC, ivBlueD;

	ivec4 ivATSelect, ivDASelect, ivZSelect;
	uvec4 uvATSelect, uvDASelect, uvZSelect;

	//bvec4 bvZTST_LESS, bvZTST_GREATER, bvZTST_EQUAL;
	uvec4 uvZTST_GREATER, uvZTST_EQUAL;
	bvec4 bvTestMask;
	//bvec4 bvEnable;
	uvec4 uvEnable;

	uvec4 vTestPixel32;


	ivec4 vav, vrv, vgv, vbv;
	ivec4 vaf, vrf, vgf, vbf;
	ivec4 vat, vrt, vgt, vbt;
	ivec4 vadd, vmul;

	uvec4 uvbgr32;


	uint Comm;
	uint bDraw;

	uint uIdx;
	uint uLoop;


	// texture vars //

	uvec4 vTPixel32;
	int iAnd1, iShift1, iShift2, iAnd3, iShift3;

	//int dudx, dvdx, dfdx;
	//float dsdx, dtdx, dqdx;

	//int vdu, vdv, vdf;
	//float vds, vdt, vdq;

	//int vdudy, vdvdy, vdfdy;
	//float vdsdy, vdtdy, vdqdy;

	int iU, iV, iF;
	float fS, fT, fQ;

	ivec4 viU, viV, viF;
	vec4 vfS, vfT, vfQ;

	ivec4 vf0, vrf0;


	ivec4 vTexCoordX, vTXOffset, vTOffset;
	ivec4 vTexCoordY;
	//ivec2 vTexCoordUV, vTexCoordST;
	//ivec4 viTYOffset, vxTYOffset;


	//int f0, f1;
	//int rf0;

	//ivec3 vu, vv;
	//ivec3 vf;
	//vec3 vs, vt, vq;


	//ivec4 vrgba0, vrgba1, vrgba2;
	//ivec3 vuvf0, vuvf1, vuvf2;
	//vec3 vstq0, vstq1, vstq2;

	ivec4 drgbadx;
	ivec4 duvfdx;
	vec4 dstqdx;

	ivec4 vdrgbady, vdrgbady1;
	ivec4 vduvfdy, vduvfdy1;
	vec4 vdstqdy, vdstqdy1;

	vec4 vyvdstqdy;
	double vyvdzdy;

	ivec4 vdrgba, vdrgba1;
	ivec4 vduvf, vduvf1;
	vec4 vdstq, vdstq1;

	float vxdsdx;
	float vxdtdx;
	float vxdqdx;
	double vxdzdx;

	ivec4 irgba, iuvf;
	vec4 ifstq;

	ivec4 vTemp;

	uvec4 uvAlphaSelect [ 4 ];

	uvec4 uvTEXA_0;
	uvec4 uvTEXA_1;
	uvec4 uvALPHA_FIX;

	int iATOffset, iATMask;

	int DYNAND, ZYNAND, TYNAND;
	int TXNAND, TXSHIFT;

	int iXInc, iYInc;
	int yoffset;

	// note: these are for textured objects only
	uvec4 uvCLAMP_WMS_AND_OR_MIN_MAX;
	uvec4 uvCLAMP_WMT_AND_OR_MIN_MAX;
	uvec4 uvTEX02_TBP_TBW_TPSM_TEXPSM;
	uvec4 uvTEX02_TW_TH_TWMASK_THMASK;
	uvec4 uvTEX02_TCC_TFX_CPSM_CSA;

	uvec4 uvTEXA_TA0_TA1_AEM;

	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	uvec4 uvZTST_LESS_EQUAL_GREATER;
	uvec4 uvATST_LEG_OFFSET_MASK;

	uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	uvec4 uvFOGCOL_FCR_FCG_FCB;

	//uvec4 uv_z0_f0_bDraw_sync;
	//ivec4 iv_StartX_StartY_EndX_EndY;
	//ivec4 iv_vu_vv_dudx_dvdy;
	//uvec4 uv_w_rf0_bgr32;

	uvec4 uv_dzdx0_dzdx1_bDraw_sync;

	uvec4 uv_And1_Shift1_Shift2_And3_Shift3;

	ivec4 iv_StartY0_EndY0_StartY1_EndY1;

	//ivec4 iv_vaf_vrf_vgf_vbf;

	int iZMASK, iAMASK;

	bool bFRAME32, bZBUF32;
	bool bTEXTURE;

	uint ctx;



	uIdx = uIndex << 6;
	uIndex <<= 5;


#ifdef DRAW_TRIANGLE_TEXTURE_MULTI
	do
	{
#endif





	bDraw = data [ uIdx + 2 ];

	if ( subgroupAll( bDraw == 1 ) )
	{
		// load common settings //

		
		//DrawArea_TopLeftX = int( inputdata [ uIndex + ( 1 << 1 ) + 0 ] );
		DrawArea_TopLeftX = int( inputdata [ uIndex + 2 ] );
		DrawArea_BottomRightX = ( DrawArea_TopLeftX >> 16 ) & 0x7ff;
		DrawArea_TopLeftX &= 0x7ff;

		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );
		FGE = bitfieldExtract( PRIM, 5, 1 );
		FST = bitfieldExtract( PRIM, 8, 1 );
		TME = bitfieldExtract( PRIM, 4, 1 );

		bTEXTURE = TME != 0;

		// for now treating AA1 as alpha
		ABE |= AA1;

		// note: CLAMP and TEXA are for textured objects
		// note: DIMX is for gradient objects
		uvCLAMP_WMS_AND_OR_MIN_MAX = uvCLAMP_WMS_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];
		uvCLAMP_WMT_AND_OR_MIN_MAX = uvCLAMP_WMT_AND_OR_MIN_MAX_LUT [ subgroup_local_id ] [ ctx ];

		// note: TEX0/2 data is only needed for textured objects
		uvTEX02_TBP_TBW_TPSM_TEXPSM = uvTEX02_TBP_TBW_TPSM_TEXPSM_LUT [ subgroup_local_id ] [ ctx ];
		uvTEX02_TW_TH_TWMASK_THMASK = uvTEX02_TW_TH_TWMASK_THMASK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEX02_TCC_TFX_CPSM_CSA = uvTEX02_TCC_TFX_CPSM_CSA_LUT [ subgroup_local_id ] [ ctx ];

		uvTEXA_TA0_TA1_AEM = uvTEXA_TA0_TA1_AEM_LUT [ subgroup_local_id ];


		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];
		uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];
		uv_And1_Shift1_Shift2_And3_Shift3 = c_uvLUT_TEX02_TPSM [ uvTEX02_TBP_TBW_TPSM_TEXPSM[2] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;

		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );

		
		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );

		// load triangle vars //


		// loading 4 at a time from pre-calc values
		uIdx >>= 2;

		uv_dzdx0_dzdx1_bDraw_sync = data4 [ uIdx + 0 ];
		drgbadx = data4 [ uIdx + 1 ];
		duvfdx = data4 [ uIdx + 2 ];

		// but it might be storing stq dx and not uv dx
		dstqdx = intBitsToFloat( duvfdx );

		// move f over into z component for now
		duvfdx.z = duvfdx.w;

		// combine z value into a double for now (might use 64-bit int later)
		//dzdx = packDouble2x32( uv_dzdx0_dzdx1_bDraw_sync.xy );
		dzdx = packInt2x32( ivec2( uv_dzdx0_dzdx1_bDraw_sync.xy ) );

		iv_StartY0_EndY0_StartY1_EndY1 = data4 [ uIdx + 3 ];



		vdx = data4 [ uIdx + 4 ];

		vdz2 = data4 [ uIdx + 5 ];

		// make these double for now, but later want to use 64-bit integers
		//vdz = packDouble2x32( vdz2.xy );
		//vdzdy = packDouble2x32( vdz2.zw );
		vdz = packInt2x32( ivec2( vdz2.xy ) );
		vdzdy = packInt2x32( ivec2( vdz2.zw ) );

		vdrgba = data4 [ uIdx + 6 ];

		vdrgbady = data4 [ uIdx + 7 ];

		vduvf = data4 [ uIdx + 8 ];
		vdstq = intBitsToFloat( vduvf );
		vduvf.z = vduvf.w;

		vduvfdy = data4 [ uIdx + 9 ];
		vdstqdy = intBitsToFloat( vduvfdy );
		vduvfdy.z = vduvfdy.w;

		vdx1 = data4 [ uIdx + 10 ];

		vdz2 = data4 [ uIdx + 11 ];

		// make these double for now, but later want to use 64-bit integers
		//vdz1 = packDouble2x32( vdz2.xy );
		//vdzdy1 = packDouble2x32( vdz2.zw );
		vdz1 = packInt2x32( ivec2( vdz2.xy ) );
		vdzdy1 = packInt2x32( ivec2( vdz2.zw ) );


		vdrgba1 = data4 [ uIdx + 12 ];

		vdrgbady1 = data4 [ uIdx + 13 ];

		vduvf1 = data4 [ uIdx + 14 ];
		vdstq1 = intBitsToFloat( vduvf1 );
		vduvf1.z = vduvf1.w;

		vduvfdy1 = data4 [ uIdx + 15 ];
		vdstqdy1 = intBitsToFloat( vduvfdy1 );
		vduvfdy1.z = vduvfdy1.w;





		// COLCLAMP(+15)(0x46),PABE(+27)(0x49)
		//COLCLAMP = int( inputdata [ uIndex + 15 ] );
		//PABE = inputdata [ uIndex + 27 ];
		COLCLAMP = int( uvps2gpu_vars[subgroup_local_id][0x46].x );
		PABE = int( uvps2gpu_vars[subgroup_local_id][0x49].x );

		// FBA (0x4a,0x4b)
		//FBA = uFBA_FBA_LUT [ subgroup_local_id ] [ ctx ];
		FBA = int( uvps2gpu_vars[subgroup_local_id][0x4a+ctx].x );

		// FOGCOL(+31)(0x3d),DTHE/DIMX(0x45/0x44)
		FOGCOL = uvps2gpu_vars[subgroup_local_id][0x3d].x;
		//DTHE = uvps2gpu_vars[subgroup_local_id][0x45].x;
		//DIMX2 = uvps2gpu_vars[subgroup_local_id][0x44];

		uvFOGCOL_FCR_FCG_FCB = uvec4( unpack8( FOGCOL ) );



//#define StartY		(iv_StartX_StartY_EndX_EndY[1])
//#define EndY		(iv_StartX_StartY_EndX_EndY[3])
//#define StartX		(iv_StartX_StartY_EndX_EndY[0])
//#define EndX		(iv_StartX_StartY_EndX_EndY[2])

#define StartY		(iv_StartY0_EndY0_StartY1_EndY1[0])
#define EndY		(iv_StartY0_EndY0_StartY1_EndY1[1])
#define StartY1		(iv_StartY0_EndY0_StartY1_EndY1[2])
#define EndY1		(iv_StartY0_EndY0_StartY1_EndY1[3])

//#define Z0			(uv_z0_f0_bDraw_sync[0])

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		int(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		int(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

//#define WIDTH		(uv_w_rf0_bgr32 [ 0 ])
//#define BGR32		(uv_w_rf0_bgr32 [ 2 ])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ZTST_LESS	(uvZTST_LESS_EQUAL_GREATER[0])
#define ZTST_EQUAL	(uvZTST_LESS_EQUAL_GREATER[1])

#define AOFFSET		(uvATST_LEG_OFFSET_MASK[1])
#define AMASK		(uvATST_LEG_OFFSET_MASK[2])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])

#define TEXA_0		(uvTEXA_TA0_TA1_AEM[0])
#define TEXA_1		(uvTEXA_TA0_TA1_AEM[1])
#define AEM			(uvTEXA_TA0_TA1_AEM[2])

#define TexX_And	int(uvCLAMP_WMS_AND_OR_MIN_MAX[0])
#define TexX_Or		int(uvCLAMP_WMS_AND_OR_MIN_MAX[1])
#define TexX_Min	int(uvCLAMP_WMS_AND_OR_MIN_MAX[2])
#define TexX_Max	int(uvCLAMP_WMS_AND_OR_MIN_MAX[3])

#define TexY_And	int(uvCLAMP_WMT_AND_OR_MIN_MAX[0])
#define TexY_Or		int(uvCLAMP_WMT_AND_OR_MIN_MAX[1])
#define TexY_Min	int(uvCLAMP_WMT_AND_OR_MIN_MAX[2])
#define TexY_Max	int(uvCLAMP_WMT_AND_OR_MIN_MAX[3])

#define TBP			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[0])
#define TBW			int(uvTEX02_TBP_TBW_TPSM_TEXPSM[1])
#define TPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[2])
#define TEXPSM		int(uvTEX02_TBP_TBW_TPSM_TEXPSM[3])

#define FCR			int(uvFOGCOL_FCR_FCG_FCB[0])
#define FCG			int(uvFOGCOL_FCR_FCG_FCB[1])
#define FCB			int(uvFOGCOL_FCR_FCG_FCB[2])

//#define F0			int(uv_z0_f0_bDraw_sync[1])
//#define RF0			int(uv_w_rf0_bgr32[1])

//#define VU			(iv_vu_vv_dudx_dvdy[0])
//#define VV			(iv_vu_vv_dudx_dvdy[1])
//#define DUDX		(iv_vu_vv_dudx_dvdy[2])
//#define DVDY		(iv_vu_vv_dudx_dvdy[3])

#define And1		int(uv_And1_Shift1_Shift2_And3_Shift3[0])
#define iShift2		int(uv_And1_Shift1_Shift2_And3_Shift3[1])
#define iAnd3		int(uv_And1_Shift1_Shift2_And3_Shift3[2])
#define iShift3		int(uv_And1_Shift1_Shift2_And3_Shift3[3])

#define TCC			int(uvTEX02_TCC_TFX_CPSM_CSA[0])
#define TFX			int(uvTEX02_TCC_TFX_CPSM_CSA[1])
#define CPSM		int(uvTEX02_TCC_TFX_CPSM_CSA[2])
#define CSA			int(uvTEX02_TCC_TFX_CPSM_CSA[3])

	// 24-bit pixels do not have destination alpha test
	DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

		iShift1 = ( And1 >> 8 ) & 0xff;
		iAnd1 = And1 & 0xff;

		//uvbgr32 = uvec4( BGR32 );

		//vaf = ivec4( iv_vaf_vrf_vgf_vbf[0] );
		//vrf = ivec4( iv_vaf_vrf_vgf_vbf[1] );
		//vgf = ivec4( iv_vaf_vrf_vgf_vbf[2] );
		//vbf = ivec4( iv_vaf_vrf_vgf_vbf[3] );

		// this will come last
		COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

		//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
		PABE <<= 31;

		// FBA
		FBA <<= 31;

		// FOGCOL
		// DTHE/DIMX
		//DIMX &= -( DTHE & 1 );

		// if alpha is disabled then no alpha blending
		uvALPHA_ABCD &= -ABE;

		// drawpsm is fpsm shifted right one
		DRAWPSM = int( FPSM >> 1 );


		bFRAME32 = ( DRAWPSM & 1 ) == 0;
		bZBUF32 = ( ZBUFPSM & 1 ) == 0;


		uvTEXA_0 = uvec4( TEXA_0 );
		uvTEXA_1 = uvec4( TEXA_1 );
		uvALPHA_FIX = uvec4( ALPHA_FIX );
		//uvZ0 = uvec4( Z0 );


		vAREF = uvec4( AREF );

		iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
		iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];


	// adjust starty (here it is doing inclusive of window start)
	yid = max( StartY, ivDrawRange [ subgroup_local_id ].x ) - StartY;
	//StartY = max( StartY, ivDrawRange [ subgroup_local_id ].x );

	// adjust endy (here it is doing exclusive of window end since it is already exclusive of EndY1)
	//EndY1 = min( EndY1, ivDrawRange [ subgroup_local_id ].y );
	EndY1 = min( EndY1, ivDrawRange [ subgroup_local_id ].y - 1 );

	// get height for subgroup (exclusive of EndY1)
	sh = EndY1 - StartY - yid;


	


#ifdef ENABLE_TRIANGLE_SUBGROUP_SKIP

	// if nothing to draw, then done
	//if ( subgroupAll( sh <= 0 ) )
	if ( subgroupAll( sh < 0 ) )
	{
		return;
	}

#endif

		idx = int( lxid ) << 2;
		idx4 = idx + ivec4( 0, 1, 2, 3 );
		xid = idx & SHADER_X_MASK;
		vxid = idx4 & SHADER_X_MASK;

		// number of pixels to go across is number of pixels being drawn across
		iXInc = SHADER_X_MASK + 1;


		yoffset = ( idx >> SHADER_Y_SHIFT ) + yid;

		// the amount to loop down is the number of shader lines being drawn times global shader groups
		iYInc = ( int( lxinc << 2 ) >> SHADER_Y_SHIFT );


		//dCx_across.rgb = dC_across.rgb * iXInc;
		//dTx_across.st = dT_across.st * iXInc;

		//dR_across = dC_across.r * vxid;
		//dG_across = dC_across.g * vxid;
		//dB_across = dC_across.b * vxid;

		//dU_across = dT_across.s * vxid;
		//dV_across = dT_across.t * vxid;


		
		// triangle vars //


	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];
	TYNAND = LUT_YNAND[ TEXPSM ];

	TXNAND = LUT_XNAND [ TEXPSM ];
	TXSHIFT = LUT_XSHIFT[ TEXPSM ];

	//for ( uLoop = 0; uLoop < 60; uLoop += 32 )
	{

		// first set //
		


	uvTEXA_0 = uvec4( TEXA_0 );
	uvTEXA_1 = uvec4( TEXA_1 );
	uvALPHA_FIX = uvec4( ALPHA_FIX );

	vAREF = uvec4( AREF );

	//vxdsdx = dsdx * float( group_vxinc );
	//vxdtdx = dtdx * float( group_vxinc );
	//vxdqdx = dqdx * float( group_vxinc );
	//vxdzdx = dzdx * double( group_vxinc );

	//vyvdstqdy = vdstqdy * float( group_yinc );
	//vyvdzdy = vdzdy * double( group_yinc );



	//if ( EndY >= StartY )
	{

	// align the compute units with pixels
	//yid = ( ( ( cyid << group_yshift ) + group_y ) - StartY ) & group_ymask;



	//////////////////////////////////////////////
	// draw down to y1
	//for ( Line = StartY + yid; Line <= EndY; Line += group_yinc )
	for ( Line = StartY + yoffset; Line <= EndY1; Line += iYInc )
	{

		if ( Line >= StartY1 )
		{
			//StartY = StartY1;
			//EndY = EndY1;
			iv_StartY0_EndY0_StartY1_EndY1.xy = iv_StartY0_EndY0_StartY1_EndY1.zw;

			vdx = vdx1;
			vdrgba = vdrgba1;
			vdrgbady = vdrgbady1;
			vduvf = vduvf1;
			vduvfdy = vduvfdy1;
			vdstq = vdstq1;
			vdstqdy = vdstqdy1;
			vdz = vdz1;
			vdzdy = vdzdy1;

			//x = x1;
			//dx = dx1;
			//C_left = C_left1;
			//dC_left = dC_left1;
			//T_left = T_left1;
			//dT_left = dT_left1;
			
		}

		yoffset = Line - StartY;

		// dxdy is in .16, Temp is in .4, and x is in .16
		//vdx += vdxdy * yid;
		//vdx.xy += vdx.zw * yid;
		xoff.xy = vdx.xy + ( vdx.zw * yoffset );
	
		//vdrgba += vdrgbady * yid;
		//vduvf += vduvfdy * yid;
		//vdstq += ( vdstqdy ) * ( float( yid ) );
		irgba = vdrgba + ( vdrgbady * yoffset );
		iuvf = vduvf + ( vduvfdy * yoffset );
		ifstq = vdstq + ( ( vdstqdy ) * ( float( yoffset ) ) );

		// *** todo *** should be a double
		//vdz += ( vdzdy ) * ( double( Temp )/16.0 );
		//vdz += ( vdzdy ) * ( double( yid ) );
		//iZ = vdz + ( ( vdzdy ) * ( double( yoffset ) ) );
		iZ = vdz + ( ( vdzdy ) * ( int64_t( yoffset ) ) );


		// left point is included if points are equal
		//StartX = ( vdx.x + 0xffff ) >> 16;
		//EndX = ( vdx.y - 1 ) >> 16;
		StartX = ( xoff.x + 0xffff ) >> 16;
		EndX = ( xoff.y - 1 ) >> 16;


		//if ( StartX <= DrawArea_BottomRightX && EndX >= DrawArea_TopLeftX && EndX >= StartX )
		{

			//irgba = vdrgba;
			//iuvf = vduvf;
			//ifstq = vdstq;
			// *** todo ***
			//iZ = vdz;
			
			
			// get distance from point to pixel
			//Temp = ( StartX << 16 ) - vdx.x;
			Temp = ( StartX << 16 ) - xoff.x;
			
			//if ( StartX < DrawArea_TopLeftX )
			//{
			//	Temp += ( DrawArea_TopLeftX - StartX ) << 16;
			//	StartX = DrawArea_TopLeftX;
			//}
			Temp += ( DrawArea_TopLeftX - min( StartX, DrawArea_TopLeftX ) ) << 16;
			StartX = max( StartX, DrawArea_TopLeftX );

			
			irgba += ( drgbadx >> 8 ) * ( Temp >> 8 );

			iuvf += ( duvfdx >> 8 ) * ( Temp >> 8 );

			ifstq += ( dstqdx ) * ( float( Temp ) * (1.0f/65536.0f) );

			//iZ += dzdx * ( double( Temp )/65536.0 );
			//iZ += dzdx * ( double( Temp ) * (1.0/65536.0) );
			iZ += ( dzdx >> 8 ) * int64_t( Temp >> 8 );
			
			
			//if ( EndX > DrawArea_BottomRightX )
			//{
			//	//EndX = Window_XRight + 1;
			//	EndX = DrawArea_BottomRightX;
			//}
			EndX = min( EndX, DrawArea_BottomRightX );

			
			//viR = irgba.r + ( vxid * drdx );
			//viG = irgba.g + ( vxid * dgdx );
			//viB = irgba.b + ( vxid * dbdx );
			//viA = irgba.a + ( vxid * dadx );
			viR = irgba.r + ( vxid * drgbadx.r );
			viG = irgba.g + ( vxid * drgbadx.g );
			viB = irgba.b + ( vxid * drgbadx.b );
			viA = irgba.a + ( vxid * drgbadx.a );

			//viU = iuvf.x + ( vxid * dudx );
			//viV = iuvf.y + ( vxid * dvdx );
			//viF = iuvf.z + ( vxid * dfdx );
			viU = iuvf.x + ( vxid * duvfdx.x );
			viV = iuvf.y + ( vxid * duvfdx.y );
			viF = iuvf.z + ( vxid * duvfdx.z );

			//vfS = ifstq.x + ( vec4( vxid ) * dsdx );
			//vfT = ifstq.y + ( vec4( vxid ) * dtdx );
			//vfQ = ifstq.z + ( vec4( vxid ) * dqdx );
			vfS = ifstq.x + ( vec4( vxid ) * dstqdx.x );
			vfT = ifstq.y + ( vec4( vxid ) * dstqdx.y );
			vfQ = ifstq.z + ( vec4( vxid ) * dstqdx.z );

			//viZ = iZ + ( dvec4( vxid ) * dzdx );
			viZ = iZ + ( i64vec4( vxid ) * dzdx );
			


			w = EndX - StartX + 1;

			w &= -( int( StartX <= DrawArea_BottomRightX ) & int( EndX >= DrawArea_TopLeftX ) & int( EndX >= StartX ) );

			// draw horizontal line
			// x_left and x_right need to be rounded off
			//for ( vx_across = vxid; vx_across.x < w; vx_across += group_vxinc )
			for ( vx_across = vxid; vx_across.x < w; vx_across += iXInc )
			{

			// get the pixels to be drawn
			//bvEnable = lessThan( uvec4( vx_across ), uvec4( w ) );
			usubBorrow( uvec4( vx_across ), uvec4( w ), uvEnable );

			// z value is z0
			//vZPixel32 = ivec4( z0 );
			vZPixel32 = uvec4( viZ >> 16 );

			//ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( StartY + ivLine ) & 0x3f ) << 7 );
			ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( Line ) & 0x3f ) << 7 );

			
			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			//vOffset += ( ivLine & DYNAND ) * int( FBW );
			//vOffset += ( ( StartY + ivLine ) & DYNAND ) * int( FBW );
			vOffset += ( ( Line ) & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );
			//vOffset += int( FBP );



			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vDestPixel32 >>= ( ( vOffset & 1 ) << 4 );
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( (FPSM & 1) << 31 );
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );


			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;


			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			//vZOffset += ( ivLine & ZYNAND ) * int( FBW );
			//vZOffset += ( ( StartY + ivLine ) & ZYNAND ) * int( FBW );
			vZOffset += ( ( Line ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );
			//vZOffset += int( ZBP );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			//vZDestPixel32 >>= ( ( vZOffset & 1 ) << 4 );
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			//vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) );
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

			// ***TODO*** this is a PROBLEM, since iR, iG, iB, iA are signed 32-bit values, so below can easily get wrong colors!
			vrf = viR >> 16;
			vgf = viG >> 16;
			vbf = viB >> 16;
			vaf = viA >> 16;
			
			// clamp fragment color
			// *** NOTE *** need to clamp here since we are using s32 instead of s64 for iR,iG,iB,iA
			//vrf &= 0xff;
			//vgf &= 0xff;
			//vbf &= 0xff;
			//vaf &= 0xff;

#ifndef ENABLE_DRAW_TRIANGLE_COLOR

			//vPixel32 = ( vaf << 24 ) | ( vbf << 16 ) | ( vgf << 8 ) | vrf;
			vPixel32 = ( vaf << 24 ) | ( vrf << 16 ) | ( vgf << 8 ) | vbf;

			if ( subgroupAll( bTEXTURE ) )
#endif
			{

#ifdef ENABLE_TEXTURE_MAPPING_TRIANGLE_TEXTURE

			// get viU, viV //
			vTexCoordX = viU >> 16;
			vTexCoordY = viV >> 16;
			if ( FST == 0 )
			{
				vTexCoordX = ivec4(vfS / vfQ);
				vTexCoordY = ivec4(vfT / vfQ);
			}


			//vTexCoordX = mix( vTexCoordX, ivec4( TexX_Min ), lessThan( vTexCoordX, ivec4( TexX_Min ) ) );
			//vTexCoordX = mix( vTexCoordX, ivec4( TexX_Max ), greaterThan( vTexCoordX, ivec4( TexX_Max ) ) );
			vTexCoordX = clamp( vTexCoordX, TexX_Min, TexX_Max );
			vTexCoordX &= TexX_And;
			vTexCoordX |= TexX_Or;

			//TexCoordY = ( ( TexCoordY < TexY_Min ) ? TexY_Min : TexCoordY );
			//TexCoordY = ( ( TexCoordY > TexY_Max ) ? TexY_Max : TexCoordY );
			vTexCoordY = clamp( vTexCoordY, TexY_Min, TexY_Max );
			vTexCoordY &= TexY_And;
			vTexCoordY |= TexY_Or;

			vIdx = ( vTexCoordX & 0x7f ) | ( ( vTexCoordY & 0x7f ) << 7 ) | ( TEXPSM << 14 );
			vTOffset[0] = LUT_XYOFFSET [ vIdx[0] ];
			vTOffset[1] = LUT_XYOFFSET [ vIdx[1] ];
			vTOffset[2] = LUT_XYOFFSET [ vIdx[2] ];
			vTOffset[3] = LUT_XYOFFSET [ vIdx[3] ];


			// iAnd1= 32-bit: 0, 16-bit: 0, 8-bit: 0x1, 4-bit: 0x3
			// iShift1= 32-bit: 0, 16-bit: 0, 8-bit: 3, 4-bit: 2
			// get the amount to shift pixel
			vPixelShift = ( vTOffset & iAnd1 ) << iShift1;

			// if looking up 32-bit pixels, then need to multiply by 2 in x-direction
			// pixels stored normally now
			//vTOffset <<= 1;

			// put in the remainder of the x-bits that don't get swizzled
			// ***TODO*** need to get value to nand with and value to shift with
			vTOffset |= ( ( vTexCoordX ) & TXNAND ) << TXSHIFT;

			// add in the bits for the y
			vTOffset += ( ( vTexCoordY ) & TYNAND ) * int( TBW );

			//vTOffset += TextureBufferStartOffset32;
			//vTOffset += TBP;
			vTOffset += ( TBP << iShift2 );

			// iShift2= 32-bit: 0, 16-bit: 1, 8-bit: 2, 4-bit: 3
			// get the remainder of the offset (for 32-bit lookup after already shifting left 1)
			//vTOffset >>= iShift2;
			vIdx = vTOffset >> iShift2;


			// load 32-bit pixel data

			// pixels stored normally now
			vPixel32[0] = VRAM [ vIdx[0] ];
			vPixel32[1] = VRAM [ vIdx[1] ];
			vPixel32[2] = VRAM [ vIdx[2] ];
			vPixel32[3] = VRAM [ vIdx[3] ];

			if ( ( TPSM & 7 ) > 2 )
			{
				// lookup pixel //

				// iAnd3= 32-bit: -1, 16-bit: 0xffff, 8-bit: 0xff, 4-bit: 0xf
				// iShift3= 32-bit: 0, 16-bit: 0, 8-bit: 0, 4-bit: 0, 8h-bit: 24, 4hh-bit: 28, 4hl-bit: 24
				// shift/mask pixel (need mask value and right shift value for offset)
				vPixel32 = ( ( vPixel32 >> vPixelShift ) >> iShift3 ) & iAnd3;

				vIdx = ivec4( vPixel32 ) + CSA;
				//vIdx = ivec4( vPixel32 ) + ( CSA & 0xf );

				// lookup pixel in CLUT (and load 16-bit chunks)

				vPixel32[0] = LOCAL_CLUT[subgroup_local_id][ vIdx[0] ];
				vPixel32[1] = LOCAL_CLUT[subgroup_local_id][ vIdx[1] ];
				vPixel32[2] = LOCAL_CLUT[subgroup_local_id][ vIdx[2] ];
				vPixel32[3] = LOCAL_CLUT[subgroup_local_id][ vIdx[3] ];

				// shift pixel if 16-bit pixel in upper part
				vPixel32 >>= ( CSA >> 4 ) & 0x10;
			}
			else
			{
				// shift pixel right if in upper part of pixel
				vPixel32 >>= ( ( vTOffset & TEXPSM & 1 ) << 4 );
			}


			// check if 32-bit pixel format or not for texture
			if ( ( CPSM & 7 ) != 0 )
			{
				// 24 or 16 bit pixel //

				// mask pixel if 24-bit or 16-bit
				vPixel32 = ( vPixel32 & ( (-1u) >> ( (CPSM & 3) << 3 ) ) );

				// if a=0, then a=texa0 if either rgb!=0 or aem=0, otherwise a=0
				//vPixel24 = TEXA_0 & ( ( AEM ) | ~( vPixel32 - 1 ) );
				vPixel24 = uvec4( TEXA_0 );

				if ( ( CPSM & 7 ) == 2 )
				{
					// 16 bit pixel //

					// select alpha
					vPixel16 = -( vPixel32 >> 15 );
					vPixel24 = ( TEXA_1 & vPixel16 ) | ( vPixel24 & ~vPixel16 );

					// convert 16-bit pixels to 32-bit pixels
					//vPixel32 = ( ( vPixel32 << 3 ) & ( 0xf8 << 0 ) ) | ( ( vPixel32 << 6 ) & ( 0xf8 << 8 ) ) | ( ( vPixel32 << 9 ) & ( 0xf8 << 16 ) );
					//vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vZero, vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vPixel32, 10, 5 ), 19, 5 );
					vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vPixel32, 10, 5 ), 19, 5 );

				}

				// if rgb==0 and aem==1, then a=0, otherwise a=1
				//vPixel24 = vPixel24 & ( ( AEM ) | ~( vPixel32 - 1 ) );
				//vPixel32 |= vPixel24;
				vPixel32 |= vPixel24 & ( ( AEM ) | ~( vPixel32 - 1 ) );
			}


#endif	// end #ifdef ENABLE_TEXTURE_MAPPING_TRIANGLE_TEXTURE




#ifdef ENABLE_TEXTURE_FUNC_TRIANGLE_TEXTURE

			// set fragment color //


			// fragment color should already be in vaf, vrf, vgf, vbf
			// split into rgba
			vat = ivec4( vPixel32 >> 24 ) & 0xff;
			vrt = ivec4( vPixel32 >> 16 ) & 0xff;
			vgt = ivec4( vPixel32 >> 8 ) & 0xff;
			vbt = ivec4( vPixel32 >> 0 ) & 0xff;

			// tfx, tcc

			if ( TFX == 1 )
			{
				vav = vat;
				vrv = vrt;
				vgv = vgt;
				vbv = vbt;

				if ( TCC == 0 )
				{
					vav = vaf;
				}
			}
			else
			{

				// handle alpha first

				// do the multiply and add
				vmul = ( vat * vaf ) >> 7;
				vadd = vat + vaf;


				// select multiply/add
				//vat = ( TFX == 0 ) ? vmul : vat;
				//vat = ( TFX == 2 ) ? vadd : vat;
				vmul = bitfieldInsert( vmul, vadd, 0, ( TFX << 3 ) );
				vat = bitfieldInsert( vat, vmul, 0, ( TFX - 3 ) & 0x1f );

				// select af,at
				//vav = ( TCC == 0 ) ? vaf : vat;
				vav = bitfieldInsert( vaf, vat, 0, TCC << 5 );

				// COLCLAMP ??
				//vav &= COLCLAMP;

				vav = clamp( vav, 0, 255 );


				// handle the colors next


				//vadd = ( ( TFX & 0x2 ) == 0 ) ? vZero : vaf;
				//vadd = vaf & -( ( TFX >> 1 ) & 1 );
				vadd = vaf & -( TFX >> 1 );

				// red
				vmul = ( ( vrt * vrf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vrv = ( TFX == 1 ) ? vrt : vmul;
				vrv = clamp( vmul, 0, 255 );

				// green
				vmul = ( ( vgt * vgf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vgv = ( TFX == 1 ) ? vgt : vmul;
				vgv = clamp( vmul, 0, 255 );

				// blue
				vmul = ( ( vbt * vbf ) >> 7 ) + vadd;
				//vmul &= COLCLAMP;

				//vmul = clamp( vmul, 0, 255 );
				//vbv = ( TFX == 1 ) ? vbt : vmul;
				vbv = clamp( vmul, 0, 255 );

			}

	// re-form pixel //
	//vPixel32 = ( vav << 24 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
	vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbv, vav, 24, 8 ), vrv, 16, 8 ), vgv, 8, 8 );

#endif	// end #ifdef ENABLE_TEXTURE_FUNC_TRIANGLE_TEXTURE



#ifdef ENABLE_FOGGING_TRIANGLE_TEXTURE

	if ( FGE == 1 )
	{
	// get f0, rf0 //
	vf0 = viF >> 16;
	vrf0 = 0xff - vf0;

	// should do fogging here
	// but pixel is bgr
	vrv = ( ( vrv * vf0 ) >> 8 ) + ( ( vrf0 * FCR ) >> 8 );
	vgv = ( ( vgv * vf0 ) >> 8 ) + ( ( vrf0 * FCG ) >> 8 );
	vbv = ( ( vbv * vf0 ) >> 8 ) + ( ( vrf0 * FCB ) >> 8 );

	//vrv = ivec4 ( ( ( ( ( vPixel32 & 0x00ff00ff ) * uint( vf0 ) ) & 0xff00ff00 ) + ( uint( FCR | ( FCB << 16 ) ) * uint( vrf0 ) ) & 0xff00ff00 ) >> 8 );
	//vgv = ivec4( ( ( ( vPixel32 >> 8 ) & 0x000000ff ) * uint( vf0 ) ) + ( ( uint( FCG ) * uint( vrf0 ) ) & 0x0000ff00 ) ) & 0x0000ff00;
	//vPixel32 = bitfieldInsert( vPixel32, uvec4( vrv | vgv ), 0, 24 );


	// COLCLAMP ??
	//vrv &= COLCLAMP;
	//vgv &= COLCLAMP;
	//vbv &= COLCLAMP;

	// fogging clamp (***todo*** COLCLAMP??)
	//vrv = clamp ( vrv, 0, 255 );
	//vgv = clamp ( vgv, 0, 255 );
	//vbv = clamp ( vbv, 0, 255 );

	// re-form pixel //
	//vPixel32 = ( vav << 24 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
	vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbv, vav, 24, 8 ), vrv, 16, 8 ), vgv, 8, 8 );
	}

#endif	// end #ifdef ENABLE_FOGGING_TRIANGLE_TEXTURE

	}	// end if ( bTEXTURE )

	// will use this for the source alpha test
	vTestPixel32 = vPixel32 >> 24;


#ifdef ENABLE_ALPHA_BLEND_TRIANGLE_TEXTURE

		if ( subgroupAll( ABE == 1 ) )
		{
			// alpha blend //


			// A pixel //

			// select
			//uvAlphaSelect [ 0 ] = vPixel32;
			//uvAlphaSelect [ 1 ] = vDestPixel32;

			//vPixelA = uvAlphaSelect [ ALPHA_A ];
			//vPixelB = uvAlphaSelect [ ALPHA_B ];
			//vPixelC = uvAlphaSelect [ ALPHA_C ];
			//vPixelD = uvAlphaSelect [ ALPHA_D ];

			//vPixelA = ( ( vPixel32 & (ALPHA_A-1) ) | ( vDestPixel32 & -ALPHA_A ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			//vPixelB = ( ( vPixel32 & (ALPHA_B-1) ) | ( vDestPixel32 & -ALPHA_B ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			//vPixelD = ( ( vPixel32 & (ALPHA_D-1) ) | ( vDestPixel32 & -ALPHA_D ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			//vPixelC = ( ( ( vPixel32 & (ALPHA_C-1) ) | ( vDestPixel32 & -ALPHA_C ) ) & ( ( ALPHA_C >> 1 ) - 1 ) ) | ( uvALPHA_FIX & -(ALPHA_C >> 1) );
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );



			// perform alpha blend calculation //

			// get alpha
			ivc = ivec4( vPixelC >> 24 ) & 0xff;

			// do r
			//iva = ivec4( vPixelA >> 16 ) & 0xff;
			//ivb = ivec4( vPixelB >> 16 ) & 0xff;
			//ivd = ivec4( vPixelD >> 16 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			//iva = ivec4( vPixelA >> 8 ) & 0xff;
			//ivb = ivec4( vPixelB >> 8 ) & 0xff;
			//ivd = ivec4( vPixelD >> 8 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			//iva = ivec4( vPixelA >> 0 ) & 0xff;
			//ivb = ivec4( vPixelB >> 0 ) & 0xff;
			//ivd = ivec4( vPixelD >> 0 ) & 0xff;
			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );
		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_TRIANGLE_TEXTURE

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle

			// alpha test //


#ifdef ENABLE_SRCALPHA_TEST_TRIANGLE_TEXTURE

		//if ( ATE != 0 )
		{
			//vTestPixel32 = vTPixel32 >> 24;

			
			//uvATSelect = uvec4( ( ( sign( ivec4( vTestPixel32 - vAREF ) ) & iATMask ) + iATOffset ) >> 31 );
			//uvATSelect = uvec4( ivec4( ( sign( ivec4( vTestPixel32 - vAREF ) ) & AMASK ) + AOFFSET ) >> 31 );
			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );

		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_TRIANGLE_TEXTURE


#ifdef ENABLE_DSTALPHA_TEST_TRIANGLE_TEXTURE

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_TRIANGLE_TEXTURE


#ifdef ENABLE_DEPTH_TEST_TRIANGLE_TEXTURE

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			//uvZSelect = ( sign( ivec4( uvZTST_EQUAL ) ) ^ ZTST_EQUAL ) | uvZTST_GREATER | ZTST_LESS;
			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_TRIANGLE_TEXTURE


			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );


			// if storing to 24-bit buffer, combine pixel with destination
			//vPixel32 = ( vPixel32 & ( (-1u) >> ( (FPSM & 1) << 3 ) ) ) | ( vDPixelX & ( (-(FPSM & 1)) << 24 ) );
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			//vPixel32_0 = ( ( vPixel32 >> 3 ) & 0x001f ) | ( ( vPixel32 >> 6 ) & 0x03e0 ) | ( ( vPixel32 >> 9 ) & 0x7c00 ) | ( ( vPixel32 >> 16 ) & 0x8000 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			// select whether to draw 32-bit or 16-bit pixels
			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );
			
			// write frame buffer //

			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //

				// store the pixels //
				VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				VRAM [ vOffset[3] ] = vPixel32 [ 3 ];

			}
			else
			{
				// 16-bit pixels

				// store the pixels //

				VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}



#ifdef ENABLE_WRITE_ZBUFFER_TRIANGLE_TEXTURE

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				//vZPixel32 = ( vZPixel32 & ( (-1u) >> ( (ZPSM & 1) << 3 ) ) ) | ( vZPixelX & ( (-(ZPSM & 1)) << 24 ) );
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, (ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					VRAM [ vZOffset[0] ] = vZPixel32[0];
					VRAM [ vZOffset[1] ] = vZPixel32[1];
					VRAM [ vZOffset[2] ] = vZPixel32[2];
					VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}

			}	// end if ( ZMSK == 0 )

#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_TRIANGLE_TEXTURE


				//viR += drdx << group_vxinc_shift;
				//viG += dgdx << group_vxinc_shift;
				//viB += dbdx << group_vxinc_shift;
				//viA += dadx << group_vxinc_shift;
				viR += drgbadx.r * ( iXInc );
				viG += drgbadx.g * ( iXInc );
				viB += drgbadx.b * ( iXInc );
				viA += drgbadx.a * ( iXInc );

				//viU += dudx << group_vxinc_shift;
				//viV += dvdx << group_vxinc_shift;
				//viF += dfdx << group_vxinc_shift;
				viU += duvfdx.x * ( iXInc );
				viV += duvfdx.y * ( iXInc );
				viF += duvfdx.z * ( iXInc );

				//vfS += dsdx * float( group_vxinc );
				//vfT += dtdx * float( group_vxinc );
				//vfQ += dqdx * float( group_vxinc );
				//vfS += vxdsdx;
				//vfT += vxdtdx;
				//vfQ += vxdqdx;
				vfS += dstqdx.x * float( iXInc );
				vfT += dstqdx.y * float( iXInc );
				vfQ += dstqdx.z * float( iXInc );

				// *** todo ***
				//viZ += dzdx * double( group_vxinc );
				//viZ += vxdzdx;
				//viZ += dzdx * double( iXInc );
				viZ += dzdx * int64_t( iXInc );
			}
			
		}
		
		
		/////////////////////////////////////
		// update x on left and right
		//vdx += vdxdy * group_yinc;
		//vdx += vdxdy << group_yinc_shift;
		//vdx.xy += vdx.zw * iYInc;
		
		//vdrgba += vdrgbady << group_yinc_shift;
		//vdrgba += vdrgbady * iYInc;

		//vduvf += vduvfdy << group_yinc_shift;
		//vduvf += vduvfdy * iYInc;

		//vdstq += vyvdstqdy;
		//vdstq += vdstqdy * float( iYInc );

		// *** todo ***
		//vdz += vdzdy * double( group_yinc );
		//vdz += vyvdzdy;
		//vdz += vdzdy * double( iYInc );
	}
	
	} // end if ( EndY >= StartY )


	}	// end for ( uLoop = 0; uLoop < 60; uLoop += 32 )


	}	// end if ( bDraw == 1 )


//#undef StartY
//#undef EndY
//#undef StartX
//#undef EndX

#undef StartY
#undef EndY
#undef StartY1
#undef EndY1

//#undef Z0

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

//#undef WIDTH
//#undef BGR32

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ZTST_LESS
#undef ZTST_EQUAL

#undef AMASK
#undef AOFFSET

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX

#undef TEXA_0
#undef TEXA_1
#undef AEM

#undef TexX_And
#undef TexX_Or
#undef TexX_Min
#undef TexX_Max

#undef TexY_And
#undef TexY_Or
#undef TexY_Min
#undef TexY_Max

#undef TBP
#undef TBW
#undef TPSM
#undef TEXPSM

#undef FCR	
#undef FCG
#undef FCB

//#undef F0
//#undef RF0

//#undef VU
//#undef VV
//#undef DUDX
//#undef DVDY

#undef And1
#undef iShift2
#undef iAnd3
#undef iShift3

#undef TCC
#undef TFX
#undef CPSM
#undef CSA



#ifdef DRAW_TRIANGLE_TEXTURE_MULTI

		uIndex += 64;

		uIdx += 128;

		Comm = inputdata [ uIndex + ( 15 << 1 ) + 0 ];

		//PRIM = Comm & 0x17;
		//Comm >>= 24;

		Comm &= 0xff000017;

	} while ( ( Comm >= 0x13 ) && ( Comm <= 0x15 ) && ( uIndex < ( COMMAND_LIST_SIZE << 6 ) ) );

	return ( uIndex >> 6 ) - 1;

#else

	return;

#endif

}


#endif	// end #ifdef ENABLE_DRAW_TRIANGLE_TEXTURE



#ifdef ENABLE_DRAW_LINE_COLOR

void Draw_Line_Color ( uint uIndex )
{

	uint lxid = gl_SubgroupInvocationID;
	uint lxinc = subgroup_size;

	uint subgroup_local_id = gl_SubgroupID;
	uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );

	int yid;

	int DrawArea_BottomRightX, DrawArea_TopLeftX, DrawArea_BottomRightY, DrawArea_TopLeftY;
	
	int x_distance, y_distance, line_length;
	
	int ix, iy, dx, dy;
	ivec4 vx_across;

	int h, sh;
	int w;
	ivec4 ivIndex;
	ivec4 ivDitherValue;
	ivec4 vLine;
	ivec4 ivR, ivG, ivB, ivA;
	ivec4 vix;
	ivec4 viy;
	//ivec4 vxid;
	//ivec4 vyid;
	ivec4 ivPtr;
	//uvec4 uvDestPixel;
	//uvec4 uvbgr16, uvbgr_temp;
	bvec4 bvEnable;

	int iCount;
	ivec4 vCount;

	uint DATE;

	//const ivec4 vZero = ivec4( 0 );

	ivec4 ivRedB, ivGreenB, ivBlueB;
	ivec4 ivRedF, ivGreenF, ivBlueF;
	

	int dr, dg, db;
	int DitherValue;
	
	int oR, oG, oB;
	
	int iEndpointX, iEndpointY;
	uint uIdx;
	uint uIdx4;
	int bDraw;

	int64_t iDitherValues64;
	i64vec4 ivDitherValues64;

	//ivec4 ivDitherValues32;

	uvec4 uvFRAME_FBP_FBW_FPSM_FBMSK;
	uvec4 uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK;
	uvec4 uvTEST_ATE_AREF_ATST_AFAIL;
	uvec4 uvTEST_ZTE_ZTST_DATE_DATM;
	uvec4 uvALPHA_ABCD_FIX;

	uvec4 uvAFAIL_FBMASK_ZBMASK;
	//uvec4 uvZTST_LESS_EQUAL_GREATER;
	//uvec4 uvATST_LEG_OFFSET_MASK;

	//uvec4 uvATST_LESS_EQUAL_GREATER;

	uvec4 uvALPHA_ABCD;

	//uvec4 uvFOGCOL_FCR_FCG_FCB;


	//uvec4 uv_dzdx0_dzdx1_bDraw_sync;

	//uvec4 uv_And1_Shift1_Shift2_And3_Shift3;

	ivec4 iv_StartX_StartY_EndX_EndY;

	//ivec4 iv_vaf_vrf_vgf_vbf;

	int iZMASK, iAMASK;

	bool bFRAME32, bZBUF32;

	uint ctx;

	ivec4 vdz;
	int64_t dz;
	ivec4 dc;
	int64_t oZ;
	ivec4 oC;

	uint PRIM;
	uint ABE, AA1;
	int COLCLAMP;
	uint PABE;
	uint FBA;

	int DRAWPSM;
	uvec4 uvALPHA_FIX;

	i64vec4 viZ;
	uvec4 vZPixel32;
	ivec4 vIdx;
	ivec4 vOffset;
	int DYNAND, ZYNAND;
	uvec4 vDestPixel32;
	uvec4 vDestPixel32_0;
	uvec4 vDPixelX;
	ivec4 vZOffset;
	uvec4 vZDestPixel32;
	uvec4 vZPixelX;
	ivec4 vaf, vrf, vgf, vbf;
	uvec4 vPixel32;
	uvec4 vPixel32_0;
	uvec4 vTestPixel32;
	uvec4 vPixelA, vPixelB, vPixelC, vPixelD;
	ivec4 iva, ivb, ivc, ivd;
	ivec4 vrv, vgv, vbv;
	uvec4 uvATSelect, uvDASelect, uvZSelect;
	uvec4 uvEnable;
	uvec4 uvZTST_EQUAL, uvZTST_GREATER;

		uIndex <<= 5;


		uIdx = uIndex << 1;

		uIdx4 = uIdx >> 2;

		bDraw = data [ uIdx + 2 ];

	if ( subgroupAll( bDraw != 0 ) )
	{
		vdz.x = data [ uIdx + 0 ];
		vdz.y = data [ uIdx + 1 ];
		dz = packInt2x32( vdz.xy );

		//da = data [ uIdx + 4 ];
		//dr = data [ uIdx + 5 ];
		//dg = data [ uIdx + 6 ];
		//db = data [ uIdx + 7 ];
		dc = data4 [ uIdx4 + 1 ];

		DrawArea_TopLeftX = data [ uIdx + 8 ];
		DrawArea_BottomRightX = data [ uIdx + 9 ];
		DrawArea_TopLeftY = data [ uIdx + 10 ];
		DrawArea_BottomRightY = data [ uIdx + 11 ];

		ix = data [ uIdx + 12 ];
		iy = data [ uIdx + 13 ];
		dx = data [ uIdx + 14 ];
		dy = data [ uIdx + 15 ];

		x_distance = data [ uIdx + 16 ];
		y_distance = data [ uIdx + 17 ];
		iEndpointX = data [ uIdx + 18 ];
		iEndpointY = data [ uIdx + 19 ];

		//StartX = data [ uIdx + 20 ];
		//StartY = data [ uIdx + 21 ];
		//EndX = data [ uIdx + 22 ];
		//EndY = data [ uIdx + 23 ];
		iv_StartX_StartY_EndX_EndY = data4 [ uIdx4 + 5 ];

		vdz.x = data [ uIdx + 24 ];
		vdz.y = data [ uIdx + 25 ];
		oZ = packInt2x32( vdz.xy );

		//oA = data [ uIdx + 28 ];
		//oR = data [ uIdx + 29 ];
		//oG = data [ uIdx + 30 ];
		//oB = data [ uIdx + 31 ];
		oC = data4 [ uIdx4 + 7 ];


		// only dither if dithering is enabled
		//ivDitherValues64 = ( GPU_CTRL_Read_DTD != 0 ) ? ivDitherValues64 : i64vec4( 0 );


		PRIM = inputdata [ uIndex + 0 ];

		ABE = bitfieldExtract( PRIM, 6, 1 );
		AA1 = bitfieldExtract( PRIM, 7, 1 );
		ctx = bitfieldExtract( PRIM, 9, 1 );
		//FGE = bitfieldExtract( PRIM, 5, 1 );
		//FST = bitfieldExtract( PRIM, 8, 1 );

		// for now treating AA1 as alpha
		ABE |= AA1;

		uvFRAME_FBP_FBW_FPSM_FBMSK = uvFRAME_FBP_FBW_FPSM_FBMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK = uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ATE_AREF_ATST_AFAIL = uvTEST_ATE_AREF_ATST_AFAIL_LUT [ subgroup_local_id ] [ ctx ];
		uvTEST_ZTE_ZTST_DATE_DATM = uvTEST_ZTE_ZTST_DATE_DATM_LUT [ subgroup_local_id ] [ ctx ];
		uvALPHA_ABCD_FIX.xy = uvALPHA_ABCD_FIX_LUT [ subgroup_local_id ] [ ctx ];

		// lookups
		uvAFAIL_FBMASK_ZBMASK = c_uvLUT_TEST_AFAIL [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[3] ];

		// if FPSM is zero, then use the second set of mask in AFAIL_FBMASK_ZBMASK
		uvAFAIL_FBMASK_ZBMASK.xy = ( uvFRAME_FBP_FBW_FPSM_FBMSK[2] == 0 ) ? uvAFAIL_FBMASK_ZBMASK.zw : uvAFAIL_FBMASK_ZBMASK.xy;

		// unpack up ABCD
		uvALPHA_ABCD = uvec4( unpack8( uvALPHA_ABCD_FIX[0] ) );


		//uvZTST_LESS_EQUAL_GREATER = c_uvLUT_TEST_ZTST [ uvTEST_ZTE_ZTST_DATE_DATM[0] ] [ uvTEST_ZTE_ZTST_DATE_DATM[1] ];
		//uvATST_LEG_OFFSET_MASK = c_uvLUT_TEST_ATST [ uvTEST_ATE_AREF_ATST_AFAIL[0] ] [ uvTEST_ATE_AREF_ATST_AFAIL[2] ];
		// unpack ATST LESS EQUAL GREATER
		// casting as an int so that it fills in the bits
		//uvATST_LESS_EQUAL_GREATER = uvec4( unpack8( int( uvATST_LEG_OFFSET_MASK[0] ) ) );


#define StartY		(iv_StartX_StartY_EndX_EndY[1])
#define EndY		(iv_StartX_StartY_EndX_EndY[3])
#define StartX		(iv_StartX_StartY_EndX_EndY[0])
#define EndX		(iv_StartX_StartY_EndX_EndY[2])

#define FBP			(uvFRAME_FBP_FBW_FPSM_FBMSK[0])
#define FBW			(uvFRAME_FBP_FBW_FPSM_FBMSK[1])
#define FPSM		(uvFRAME_FBP_FBW_FPSM_FBMSK[2])
#define FBMSK		(uvFRAME_FBP_FBW_FPSM_FBMSK[3])

#define ZBP			(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[0])
#define ZPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[1])
#define ZBUFPSM		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[2])
#define ZMSK		(uvZBUF_ZBP_ZPSM_ZBUFPSM_ZMSK[3])

#define ATE			(uvTEST_ATE_AREF_ATST_AFAIL[0])
#define AREF		(uvTEST_ATE_AREF_ATST_AFAIL[1])
#define ATST		(uvTEST_ATE_AREF_ATST_AFAIL[2])

#define ZTE			(uvTEST_ZTE_ZTST_DATE_DATM[0])
#define ZTST		(uvTEST_ZTE_ZTST_DATE_DATM[1])
//#define DATE		(uvTEST_ZTE_ZTST_DATE_DATM[2])
#define DATM		(uvTEST_ZTE_ZTST_DATE_DATM[3])

#define uvFBMASK	(uvAFAIL_FBMASK_ZBMASK[0])
#define uvZBMASK	(uvAFAIL_FBMASK_ZBMASK[1])

#define ALPHA_A		(uvALPHA_ABCD[0])
#define ALPHA_B		(uvALPHA_ABCD[1])
#define ALPHA_C		(uvALPHA_ABCD[2])
#define ALPHA_D		(uvALPHA_ABCD[3])
#define ALPHA_FIX	(uvALPHA_ABCD_FIX[1])

		// 24-bit pixels do not have destination alpha test
		DATE = uvTEST_ZTE_ZTST_DATE_DATM[2] & ~( FPSM << 31 );

		// this will come last
		COLCLAMP = ( -( COLCLAMP & 1 ) ) | 0xff;

		//PABE = inputdata [ uIndex + ( 16 << 1 ) + 0 ] << 31;
		PABE <<= 31;

		// FBA
		FBA <<= 31;

		// FOGCOL
		// DTHE/DIMX
		//DIMX &= -( DTHE & 1 );

		// if alpha is disabled then no alpha blending
		uvALPHA_ABCD &= -ABE;

		// drawpsm is fpsm shifted right one
		DRAWPSM = int( FPSM >> 1 );


		bFRAME32 = ( DRAWPSM & 1 ) == 0;
		bZBUF32 = ( ZBUFPSM & 1 ) == 0;

		
		uvALPHA_FIX = uvec4( ALPHA_FIX );


		//vAREF = uvec4( AREF );

		iZMASK = c_iLUT_TEST_ZMASK [ ZTE ] [ ZTST ];
		iAMASK = c_iLUT_TEST_AMASK [ ATE ] [ ATST ];

	DYNAND = LUT_YNAND[ DRAWPSM ];
	ZYNAND = LUT_YNAND[ ZBUFPSM ];

	yid = int( ( subgroup_global_id - StartY ) & subgroup_mask );

	h = EndY - StartY + 1;

	// sh - height for subgroup
	sh = int( h >> subgroup_shift ) + max( sign( int( h & subgroup_mask ) - yid ), 0 );

#ifdef ENABLE_LINE_SUBGROUP_SKIP

	// if nothing to draw, then done
	//if ( subgroupAll( sh <= 0 ) )
	//{
	//	return;
	//}

#endif


	// check if line is horizontal
	//if ( x_distance > y_distance )
	{
		if ( x_distance > y_distance )
		{
			w = EndX - StartX;
		}
		else
		{
			w = EndY - StartY;
		}

		// draw the line horizontally
		//for ( ix = int( lxid ) << 2; ix <= w; ix += int( lxinc ) << 2 )
		for ( iCount = int( lxid ) << 2; iCount <= w; iCount += int( lxinc ) << 2 )
		{
			vCount = iCount + ivec4( 0, 1, 2, 3 );

			viy = iy + (vCount * dy);
			vix = ix + (vCount * dx);

			//vLine >>= 16;
			//vx_across = vix;
			
			if ( x_distance > y_distance )
			{
				vx_across = vCount + StartX;
				vLine = viy >> 16;

				//vx_across = abs( vx_across - StartX );

				//bvEnable = bvec4( ivec4(greaterThanEqual( vLine, ivec4( ivDrawRange[subgroup_local_id].x ) )) & ivec4(lessThan( vLine, ivec4( ivDrawRange[subgroup_local_id].y ) )) & ivec4(lessThanEqual( uvec4( vx_across ), uvec4( w ) )) & ivec4(notEqual(vx_across+StartX,ivec4(iEndpointX))) );
				uvEnable = ( ivec4(greaterThanEqual( vLine, ivec4( ivDrawRange[subgroup_local_id].x ) )) & ivec4(lessThan( vLine, ivec4( ivDrawRange[subgroup_local_id].y ) )) & ivec4(lessThanEqual( uvec4( vCount ), uvec4( w ) )) & ivec4(notEqual(vx_across,ivec4(iEndpointX))) );
			}
			else
			{
				vx_across = vix >> 16;
				vLine = vCount + StartY;

				//vx_across = abs( vx_across - StartX );

				uvEnable = ( ivec4( greaterThanEqual( vLine, ivec4( ivDrawRange[subgroup_local_id].x ) ) ) & ivec4( lessThan( vLine, ivec4( ivDrawRange[subgroup_local_id].y ) ) ) & ivec4( greaterThanEqual( vx_across, ivec4( DrawArea_TopLeftX ) ) ) & ivec4( lessThanEqual( vx_across, ivec4( DrawArea_BottomRightX ) ) ) & ivec4( lessThanEqual( uvec4( vCount ), uvec4( w ) ) ) & ivec4( notEqual( vLine, ivec4( iEndpointY ) ) ) );
			}

			bvEnable = bvec4( uvEnable );

			if ( any( bvEnable ) )
			{
				viZ = oZ + ( i64vec4( vCount ) * dz );

			// z value is z0
			vZPixel32 = uvec4( viZ >> 16 );

			//ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( vLine ) & 0x3f ) << 7 );
			ivPtr = ( ( vx_across ) & 0x3f ) | ( ( ( vLine ) & 0x3f ) << 7 );

			
			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			//vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );
			vOffset |= ( ( vx_across ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			vOffset += ( ( vLine ) & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );

			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );

			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;

			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			//vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );
			vZOffset |= ( ( vx_across ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			vZOffset += ( ( vLine ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //


				vaf = oC.a + ( vCount * dc.a );
				vrf = oC.r + ( vCount * dc.r );
				vgf = oC.g + ( vCount * dc.g );
				vbf = oC.b + ( vCount * dc.b );

				// dither
				//ivDitherValue = ivec4( ( ivDitherValues64 << ( ( ( vLine & 3 ) << 4 ) + ( ( ( vix + StartX ) & 3 ) << 2 ) ) ) >> 60 );
				//ivDitherValue <<= 16;

				// perform dither
				//ivRedF = ivR + ivDitherValue;
				//ivGreenF = ivG + ivDitherValue;
				//ivBlueF = ivB + ivDitherValue;
				
				// perform shift
				vaf >>= 16;
				vrf >>= 16;
				vgf >>= 16;
				vbf >>= 16;
				
				//ivAlphaF = clamp ( ivA, 0, 255 );
				//ivRedF = clamp ( ivR, 0, 255 );
				//ivGreenF = clamp ( ivG, 0, 255 );
				//ivBlueF = clamp ( ivB, 0, 255 );

			//vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbf, vaf, 24, 8 ), vrf, 16, 8 ), vgf, 8, 8 );
			vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vrf, vaf, 24, 8 ), vbf, 16, 8 ), vgf, 8, 8 );

#ifdef ENABLE_ALPHA_BLEND_LINE_COLOR

		if ( ABE == 1 )
		{
			// alpha blend //


			// A pixel //

			// select
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );

			// perform alpha blend calculation //

			// get alpha
			ivc = ivec4( vPixelC >> 24 ) & 0xff;

			// do r
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );
		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_LINE_COLOR

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle

			// alpha test //


#ifdef ENABLE_SRCALPHA_TEST_LINE_COLOR

		//if ( ATE != 0 )
		{
			vTestPixel32 = vPixel32 >> 24;

			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );

		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_LINE_COLOR


#ifdef ENABLE_DSTALPHA_TEST_LINE_COLOR

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			//uvDASelect = ( uvDASelect >> 31 ) ^ 1;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_LINE_COLOR


#ifdef ENABLE_DEPTH_TEST_LINE_COLOR

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_LINE_COLOR

			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );

			// if storing to 24-bit buffer, combine pixel with destination
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, (int( FPSM ) & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			// select whether to draw 32-bit or 16-bit pixels
			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;

			bvEnable = bvec4( uvEnable );
			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );
			
			// write frame buffer //

			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //

				// store the pixels //
				if ( bvEnable.x ) VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				if ( bvEnable.y ) VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				if ( bvEnable.z ) VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				if ( bvEnable.w ) VRAM [ vOffset[3] ] = vPixel32 [ 3 ];

			}
			else
			{
				// 16-bit pixels

				// store the pixels //

				if ( bvEnable.x ) VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				if ( bvEnable.y ) VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				if ( bvEnable.z ) VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				if ( bvEnable.w ) VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}



#ifdef ENABLE_WRITE_ZBUFFER_LINE_COLOR

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, int(ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					if ( bvEnable.x ) VRAM [ vZOffset[0] ] = vZPixel32[0];
					if ( bvEnable.y ) VRAM [ vZOffset[1] ] = vZPixel32[1];
					if ( bvEnable.z ) VRAM [ vZOffset[2] ] = vZPixel32[2];
					if ( bvEnable.w ) VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					if ( bvEnable.x ) VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					if ( bvEnable.y ) VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					if ( bvEnable.z ) VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					if ( bvEnable.w ) VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}

			}	// end if ( ZMSK == 0 )

#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_LINE_COLOR

			}	// end if ( any( bvEnable ) )
			
		}	// end for ( iCount = int( lxid ) << 2; iCount <= w; iCount += int( lxinc ) << 2 )
		
	}
	/*
	else
	{
		// line is vertical //

		w = EndY - StartY;

		// draw the line vertically
		for ( iy = int( lxid ) << 2; iy <= w; iy += int( lxinc ) << 2 )
		{
			vix = iy + ivec4( 0, 1, 2, 3 );

			// TODO: problem here if line is cropped from off-screen, because vyid is offset from StartY and not ix
			vLine = ix + (vix * dx);
			vLine >>= 16;
			
			vx_across = vLine - StartX;
			vLine = StartY + vix;

			//bvEnable = bvec4( ivec4( greaterThanEqual( vLine, ivec4( ivDrawRange[subgroup_local_id].x ) ) ) & ivec4( lessThan( vLine, ivec4( ivDrawRange[subgroup_local_id].y ) ) ) & ivec4( greaterThanEqual( vx_across, ivec4( DrawArea_TopLeftX ) ) ) & ivec4( lessThanEqual( vx_across, ivec4( DrawArea_BottomRightX ) ) ) & ivec4( lessThanEqual( uvec4( vx_across ), uvec4( w ) ) ) & ivec4( notEqual( vLine, ivec4( iEndpointY ) ) ) );
			uvEnable = ( ivec4( greaterThanEqual( vLine, ivec4( ivDrawRange[subgroup_local_id].x ) ) ) & ivec4( lessThan( vLine, ivec4( ivDrawRange[subgroup_local_id].y ) ) ) & ivec4( greaterThanEqual( vx_across + StartX, ivec4( DrawArea_TopLeftX ) ) ) & ivec4( lessThanEqual( vx_across + StartX, ivec4( DrawArea_BottomRightX ) ) ) & ivec4( lessThanEqual( uvec4( vix ), uvec4( w ) ) ) & ivec4( notEqual( vLine, ivec4( iEndpointY ) ) ) );
			bvEnable = bvec4( uvEnable );

			if ( any( bvEnable ) )
			{
				viZ = oZ + ( i64vec4( vix ) * dz );

			// z value is z0
			vZPixel32 = uvec4( viZ >> 16 );

			ivPtr = ( ( StartX + vx_across ) & 0x3f ) | ( ( ( vLine ) & 0x3f ) << 7 );

			
			// need x/y/format
			vIdx = ivPtr | ( DRAWPSM << 14 );
			vOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( DRAWPSM & 1 ) );


			// add in the bits for the y
			vOffset += ( ( vLine ) & DYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vOffset += ( int( FBP ) << ( DRAWPSM & 1 ) );

			// x-bit pixels //

			// load pixels from framebuffer as 32-bit for simplicity //

			// shift offset right 1 if 16-bit pixels
			vIdx = vOffset >> ( DRAWPSM & 1 );

			// load pixels
			vDestPixel32[0] = VRAM [ vIdx[0] ];
			vDestPixel32[1] = VRAM [ vIdx[1] ];
			vDestPixel32[2] = VRAM [ vIdx[2] ];
			vDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vDestPixel32 >>= ( ( vOffset & DRAWPSM & 1 ) << 4 );

			// save raw destination pixel
			vDPixelX = vDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vDestPixel32 = ( vDestPixel32 & ( (-1u) >> ( (FPSM & 3) << 3 ) ) );

			// if destination pixel is 24-bit, then set alpha
			vDestPixel32 |= ( (FPSM & 1) << 31 );

			// convert from 16-bit to 32-bit
			vDestPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldInsert( uvec4(0), vDestPixel32, 3, 5 ), bitfieldExtract( vDestPixel32, 5, 5 ), 11, 5 ), bitfieldExtract( vDestPixel32, 10, 5 ), 19, 5 ), bitfieldExtract( vDestPixel32, 15, 1 ), 31, 1 );

			// select converted pixel if 16-bit frame buffer
			vDestPixel32 = ( bFRAME32 ) ? vDestPixel32 : vDestPixel32_0;

			// x-bit zpixels //

			vIdx = ivPtr | int( ZBUFPSM << 14 );
			vZOffset[0] = LUT_XYOFFSET[ vIdx[0] ];
			vZOffset[1] = LUT_XYOFFSET[ vIdx[1] ];
			vZOffset[2] = LUT_XYOFFSET[ vIdx[2] ];
			vZOffset[3] = LUT_XYOFFSET[ vIdx[3] ];

			// put in the remainder of the x-bits that don't get swizzled
			vZOffset |= ( ( vx_across + StartX ) & ~0x3f ) << ( 5 + ( ZBUFPSM & 1 ) );

			// add in the bits for the y
			vZOffset += ( ( vLine ) & ZYNAND ) * int( FBW );

			// shift left dst offset by one for 16-bit pixels
			vZOffset += ( int( ZBP ) << ( ZBUFPSM & 1 ) );

			// shift offset right 1 if 16-bit pixels
			vIdx = vZOffset >> ( ZBUFPSM & 1 );

			// load pixels
			vZDestPixel32[0] = VRAM [ vIdx[0] ];
			vZDestPixel32[1] = VRAM [ vIdx[1] ];
			vZDestPixel32[2] = VRAM [ vIdx[2] ];
			vZDestPixel32[3] = VRAM [ vIdx[3] ];


			// shift pixel right if 16-bit pixel and was in upper part of 32-bits
			vZDestPixel32 >>= ( ( vZOffset & ZBUFPSM & 1 ) << 4 );

			// save raw destination zpixel
			vZPixelX = vZDestPixel32;

			// mask pixel if 24-bit or 16-bit
			vZDestPixel32 = ( vZDestPixel32 & ( (-1u) >> ( (ZPSM & 3) << 3 ) ) );


			// load pixel to draw //

				vaf = oC.a + ( vix * dc.a );
				vrf = oC.r + ( vix * dc.r );
				vgf = oC.g + ( vix * dc.g );
				vbf = oC.b + ( vix * dc.b );

				// dither
				//ivDitherValue = ivec4( ( ivDitherValues64 << ( ( ( vLine & 3 ) << 4 ) + ( ( ( vix + StartX ) & 3 ) << 2 ) ) ) >> 60 );
				//ivDitherValue <<= 16;

				// perform dither
				//ivRedF = ivR + ivDitherValue;
				//ivGreenF = ivG + ivDitherValue;
				//ivBlueF = ivB + ivDitherValue;
				
				// perform shift
				vaf >>= 16;
				vrf >>= 16;
				vgf >>= 16;
				vbf >>= 16;
				
				//ivAlphaF = clamp ( ivA, 0, 255 );
				//ivRedF = clamp ( ivR, 0, 255 );
				//ivGreenF = clamp ( ivG, 0, 255 );
				//ivBlueF = clamp ( ivB, 0, 255 );

			//vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vbf, vaf, 24, 8 ), vrf, 16, 8 ), vgf, 8, 8 );
			vPixel32 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vrf, vaf, 24, 8 ), vbf, 16, 8 ), vgf, 8, 8 );

#ifdef ENABLE_ALPHA_BLEND_LINE_COLOR

		if ( ABE == 1 )
		{
			// alpha blend //


			// A pixel //

			// select
			vPixelA = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_A << 5 ) ) & ( ( ALPHA_A >> 1 ) - 1 );
			vPixelB = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_B << 5 ) ) & ( ( ALPHA_B >> 1 ) - 1 );
			vPixelD = bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_D << 5 ) ) & ( ( ALPHA_D >> 1 ) - 1 );
			vPixelC = bitfieldInsert( bitfieldInsert( vPixel32, vDestPixel32, 0, int( ALPHA_C << 5 ) ), uvALPHA_FIX, 0, int( (ALPHA_C >> 1) << 5 ) );

			// perform alpha blend calculation //

			// get alpha
			ivc = ivec4( vPixelC >> 24 ) & 0xff;

			// do r
			iva = ivec4( bitfieldExtract( vPixelA, 16, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 16, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 16, 8 ) );

			// calc ( a - b ) * c + d
			vrv = ( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// do g,b
			iva = ivec4( bitfieldExtract( vPixelA, 8, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 8, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 8, 8 ) );

			vgv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			iva = ivec4( bitfieldExtract( vPixelA, 0, 8 ) );
			ivb = ivec4( bitfieldExtract( vPixelB, 0, 8 ) );
			ivd = ivec4( bitfieldExtract( vPixelD, 0, 8 ) );

			vbv = ivec4( ( ( iva - ivb ) * ivc ) >> 7 ) + ivd;

			// ***todo*** dithering will use the values before clamping //




			// clamp (COLCLAMP??) //
			vrv &= COLCLAMP;
			vgv &= COLCLAMP;
			vbv &= COLCLAMP;

			vrv = clamp ( vrv, 0, 255 );
			vgv = clamp ( vgv, 0, 255 );
			vbv = clamp ( vbv, 0, 255 );

			// re-form pixel (with source alpha??)
			//vPixel32_0 = ( vPixel32 & 0xff000000 ) | ( vrv << 16 ) | ( vgv << 8 ) | ( vbv << 0 );
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( vPixel32, vrv, 16, 8 ), vgv, 8, 8 ), vbv, 0, 8 );


			// if alpha blending disabled, overwrite alpha blended pixel
			//vPixel32_0 = ( ABE == 0 ) ? vPixel32 : vPixel32_0;

			// if PABE is set and msb is set, then don't alpha blend pixel (overwrite?)
			vPixel32 = mix( vPixel32, vPixel32_0, equal( vPixel32 & PABE, ivec4( PABE ) ) );
		}

#endif	// end #ifdef ENABLE_ALPHA_BLEND_LINE_COLOR

			// select alpha blended pixel if alpha enabled //
			// not needed for rectangle

			// alpha test //


#ifdef ENABLE_SRCALPHA_TEST_LINE_COLOR

		//if ( ATE != 0 )
		{
			vTestPixel32 = vPixel32 >> 24;

			// equal | greater | less
			uvATSelect = sign( ivec4( vTestPixel32 - AREF ) );
			uvATSelect = ( uvATSelect + 1 ) | ( uvATSelect & 4 );
			uvATSelect = -sign( ivec4( uvATSelect ) & iAMASK );

		}

#endif	// end #ifdef ENABLE_SRCALPHA_TEST_LINE_COLOR


#ifdef ENABLE_DSTALPHA_TEST_LINE_COLOR

		//if ( DATE != 0 )
		{
			// destination alpha test //

			// da test
			uvDASelect = ( vDestPixel32 ^ DATM ) & DATE;
			//uvDASelect = ( uvDASelect >> 31 ) ^ 1;
			uvDASelect = ~( uvDASelect >> 31 );

			// all pixels pass if FPSM is 24-bit
			// (if component is zero, then passes)
			//uvDASelect |= FPSM & 1;

			uvEnable &= uvDASelect;

		}

#endif	// end #ifdef ENABLE_DSTALPHA_TEST_LINE_COLOR


#ifdef ENABLE_DEPTH_TEST_LINE_COLOR

		//if ( ZTE != 0 )
		{
			// depth test //

			uvZTST_EQUAL = usubBorrow( vZDestPixel32, vZPixel32, uvZTST_GREATER );

			// equal | not equal | greater
			uvZSelect = ( ( ( sign( ivec4( uvZTST_EQUAL ) ) & 1 ) + 1 ) | ( uvZTST_GREATER << 2 ) );
			uvZSelect = sign( ivec4( uvZSelect ) & iZMASK );

			uvEnable &= uvZSelect;

		}

#endif	// end #ifdef ENABLE_DEPTH_TEST_LINE_COLOR

			// should now be safe for FBA AND FBMSK //
			// set FBA
			vPixel32 |= FBA;

			// FBMSK
			vPixel32 = ( vDestPixel32 & FBMSK ) | ( vPixel32 & ~FBMSK );

			// if storing to 24-bit buffer, combine pixel with destination
			vPixel32 = bitfieldInsert( vPixel32, bitfieldExtract( vDPixelX, 24, 8 ), 24, int(FPSM & 1) << 3 );

			// convert 32-bit pixels to 16-bit
			vPixel32_0 = bitfieldInsert( bitfieldInsert( bitfieldInsert( bitfieldExtract( vPixel32, 3, 5 ), bitfieldExtract( vPixel32, 11, 5 ), 5, 5 ), bitfieldExtract( vPixel32, 19, 5 ), 10, 5 ), bitfieldExtract( vPixel32, 31, 1 ), 15, 1 );

			// select whether to draw 32-bit or 16-bit pixels
			vPixel32 = ( bFRAME32 ) ? vPixel32 : vPixel32_0;


			bvEnable = bvec4( uvEnable );
			uvEnable = -uvEnable;

			// and only the enabled pixels
			vPixel32 = ( vPixel32 & uvEnable ) | ( vDPixelX & ~uvEnable );

			// alpha fail //

			vPixel32 = ( vPixel32 & ( uvFBMASK | uvATSelect ) ) | ( vDPixelX & ~( uvFBMASK | uvATSelect ) );
			
			// write frame buffer //

			//if ( ( DRAWPSM & 1 ) == 0 )
			if ( bFRAME32 )
			{
				// 32-bit pixels //

				// store the pixels //
				if( bvEnable.x ) VRAM [ vOffset[0] ] = vPixel32 [ 0 ];
				if( bvEnable.y ) VRAM [ vOffset[1] ] = vPixel32 [ 1 ];
				if( bvEnable.z ) VRAM [ vOffset[2] ] = vPixel32 [ 2 ];
				if( bvEnable.w ) VRAM [ vOffset[3] ] = vPixel32 [ 3 ];

			}
			else
			{
				// 16-bit pixels

				// store the pixels //

				if( bvEnable.x ) VRAM16 [ vOffset[0] ] = uint16_t( vPixel32 [ 0 ] );
				if( bvEnable.y ) VRAM16 [ vOffset[1] ] = uint16_t( vPixel32 [ 1 ] );
				if( bvEnable.z ) VRAM16 [ vOffset[2] ] = uint16_t( vPixel32 [ 2 ] );
				if( bvEnable.w ) VRAM16 [ vOffset[3] ] = uint16_t( vPixel32 [ 3 ] );
			}

#ifdef ENABLE_WRITE_ZBUFFER_LINE_COLOR

			// write z buffer //

			if ( ZMSK == 0 )
			{
				// if storing to 24-bit z-buffer, combine top z-pixel with destination
				vZPixel32 = bitfieldInsert( vZPixel32, bitfieldExtract( vZPixelX, 24, 8 ), 24, int(ZPSM & 1) << 3 );

				vZPixel32 = ( vZPixel32 & uvEnable ) | ( vZPixelX & ~uvEnable );

				vZPixel32 = ( vZPixel32 & ( uvZBMASK | uvATSelect ) ) | ( vZPixelX & ~( uvZBMASK | uvATSelect ) );

				//if ( ( ZBUFPSM & 1 ) == 0 )
				if ( bZBUF32 )
				{
					// 32-bit pixels //


					// store the pixels //

					if( bvEnable.x ) VRAM [ vZOffset[0] ] = vZPixel32[0];
					if( bvEnable.y ) VRAM [ vZOffset[1] ] = vZPixel32[1];
					if( bvEnable.z ) VRAM [ vZOffset[2] ] = vZPixel32[2];
					if( bvEnable.w ) VRAM [ vZOffset[3] ] = vZPixel32[3];
				}
				else
				{
					// 16-bit pixels

					// store the pixels //

					if( bvEnable.x ) VRAM16[ vZOffset[0] ] = uint16_t( vZPixel32 [ 0 ] );
					if( bvEnable.y ) VRAM16[ vZOffset[1] ] = uint16_t( vZPixel32 [ 1 ] );
					if( bvEnable.z ) VRAM16[ vZOffset[2] ] = uint16_t( vZPixel32 [ 2 ] );
					if( bvEnable.w ) VRAM16[ vZOffset[3] ] = uint16_t( vZPixel32 [ 3 ] );
				}

			}	// end if ( ZMSK == 0 )

#endif	// end #ifdef ENABLE_WRITE_ZBUFFER_LINE_COLOR

			}	// end if ( any( bvEnable ) )
			
		}	// end for ( iy = int( lxid ) << 2; iy <= w; iy += int( lxinc ) << 2 )

	}	// end if else if ( x_distance > y_distance )
	*/
	
	}	// end if ( subgroupAll( bDraw != 0 ) )


#undef StartY
#undef EndY
#undef StartX
#undef EndX

#undef FBP
#undef FBW
#undef FPSM
#undef FBMSK

#undef ZBP
#undef ZPSM
#undef ZBUFPSM
#undef ZMSK

#undef ATE
#undef AREF
#undef ATST

#undef ZTE
#undef ZTST
#undef DATE
#undef DATM

#undef uvFBMASK
#undef uvZBMASK

#undef ALPHA_A
#undef ALPHA_B
#undef ALPHA_C
#undef ALPHA_D
#undef ALPHA_FIX


	return;
}


#endif	// end #ifdef ENABLE_DRAW_LINE_COLOR




void TransferPixelPacketIn ( uint uIndex )
{
	//int xxid = int( gl_LocalInvocationIndex );

	//int xid = int( gl_GlobalInvocationID.x );
	//int yid = int( gl_GlobalInvocationID.y );
	
	uint bgr2;
	uint pix0, pix1;
	uint DestPixel;
	uint Data;

	ivec4 ivPtr4;
	
	//int iX, iY;
	int CurX, CurY;

	int iPtr;
	int iCount;
	
	int xxpixel;
	int xximagepixel;


	uint GPU_CTRL_Read;
	int dX;
	int dY;
	int w;
	int h;
	int sX;
	int sY;
	
	int BS;

	int XferX, XferY;
	int XferWidth, XferHeight;
	int XferDstBufWidth;
	int XferDstX, XferDstY;
	int Count32;

	int XferDstOffset32;

	int XferCount32, XferCountX;

	uint XferId0, XferIdX;
	int iYOffset, iXOffset, iOffset;

	int xximagepixelstart;
	int SharedYMax;
	uint Comm;

	uint BITBLTBUF_1;
	uint DPSM;

	uint uStartIndex;

	int iShift0, iShift1, iShift2;
	int iMask0, iMask1, iMask2;
	int iPixelShift;

	ivec4 idx4;
	uvec4 pix4, dpix4;
	ivec4 CurX4, CurY4;
	ivec4 iOffset4, iXOffset4, iYOffset4;
	ivec4 iPixelBitOffset4;
	int iPixelBitOffset0;
	int iOffset0;

	int XNAND, XSHIFT, YNAND;

	bool bIsMove;

	bvec4 bWriteToSVRAM4;

	int gxxid;

	// global invocation index
	gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );


	//uIndex <<= 6;
	uIndex <<= 5;

	// test all the inputs
	//sVRAM[0] = uIndex;
	//for ( int i = xxid; i < 16; i++ )
	//{
	//	sVRAM[i+1] = inputdata [ uIndex + i ];
	//}

	
	//if ( xxid == 0 )
	//{

		//Count = 0;

		// need to check which instruction this is, transfer-in or transfer-move
		Comm = inputdata [ uIndex + 0 ];

#ifdef USE_TRANSFER_IN_WITH_MOVE

		bIsMove = ( Comm != 0xf8000000 );

#endif

		//BITBLTBUF_1 = inputdata [ uIndex + ( 1 << 1 ) + 1 ];
		BITBLTBUF_1 = inputdata [ uIndex + 3 ];
		DPSM = ( BITBLTBUF_1 >> 24 ) & 0x3f;

		// get count of items to transfer
		Count32 = int( inputdata [ uIndex + 5 ] );

		// XferX, XferY (6,7)
		//sX = int( inputdata [ uIndex + 6 ] );
		//sY = int( inputdata [ uIndex + 7 ] );

		// XferSrcX, XferSrcY (8,9)
		//sX = int( inputdata [ uIndex + 8 ] );
		//sY = int( inputdata [ uIndex + 9 ] );

		// XferDstX, XferDstY (10,11)
		dX = int( inputdata [ uIndex + 10 ] );
		dY = int( inputdata [ uIndex + 11 ] );
		
		// XferWidth, XferHeight (12,13)
		w = int( inputdata [ uIndex + 12 ] );
		h = int( inputdata [ uIndex + 13 ] );
		
		// XferSrcBufWidth,XferSrcOffset32 (14,15)
		//XferSrcBufWidth = int( inputdata [ uIndex + 14 ] );
		//XferSrcOffset32 = int( inputdata [ uIndex + 15 ] );

		// XferDstBufWidth,XferDstOffset32 (16,17)
		XferDstBufWidth = int( inputdata [ uIndex + 16 ] );
		XferDstOffset32 = int( inputdata [ uIndex + 17 ] );

		// get count of pixels
		// looks like this is the count of pixels that have already been transferred in the transfer already
		XferCount32 = int( inputdata [ uIndex + 18 ] );

		// id for the transfer
		XferId0 = int( inputdata [ uIndex + 19 ] );

		// count is per 2 pixels
		//BS <<= 1;
		

		// get start index for pixels in pixel input buffer
		//uStartIndex = inputdata [ uIndex + ( 16 << 1 ) + 0 ];
		uStartIndex = inputdata [ uIndex + 1 ];

	//}

#ifdef SYNC_BEFORE_TRANSFER

	barrier ();

#endif

	// load iShift0, iShift1, iShift2
	// load iMask0, iMask1, iMask2
	iShift0 = ( ( DPSM & 0x3 ) == 0x3 ) ? 2 : 3;
	iShift1 = ( ( DPSM & 0x3 ) == 0x3 ) ? 3 : 2;
	iShift2 = ( ( DPSM & 0x3 ) == 0x3 ) ? 1 : 2;

	iMask0 = ( ( DPSM & 0x3 ) == 0x3 ) ? 0xff : 0xf;
	iMask1 = ( ( DPSM & 0x3 ) == 0x3 ) ? 0x3 : 0x7;
	iMask2 = iMask1 >> 1;




	if ( subgroupAll( ( DPSM & 0xf ) == 0 ) )
	{
		// 32-bit pixels //

		SharedYMax = Count32;
		XferCountX = XferCount32;

		// shifted for the lookup later
		DPSM >>= 1;

		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < Count32; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = sVRAM4 [ iCount >> 2 ];
			}
			else
#endif
			{
				pix4.x = PixelInput32 [ uStartIndex + idx4.x ];
				pix4.y = PixelInput32 [ uStartIndex + idx4.y ];
				pix4.z = PixelInput32 [ uStartIndex + idx4.z ];
				pix4.w = PixelInput32 [ uStartIndex + idx4.w ];
			}


			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferDstBufWidth;

			iOffset4 = iOffset4 + XferDstOffset32;

			// store 32-bit data
			VRAM [ iOffset4.x ] = pix4.x;
			VRAM [ iOffset4.y ] = pix4.y;
			VRAM [ iOffset4.z ] = pix4.z;
			VRAM [ iOffset4.w ] = pix4.w;
		}


	}
	else if ( subgroupAll( ( DPSM & 0x3 ) == 1 ) )
	{
		// 24-bit pixels //

		SharedYMax = Count32;
		XferCountX = XferCount32;
		DPSM >>= 1;
		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < Count32; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = sVRAM4 [ iCount >> 2 ];
			}
			else
#endif
			{
				pix4.x = PixelInput32 [ uStartIndex + idx4.x ];
				pix4.y = PixelInput32 [ uStartIndex + idx4.y ];
				pix4.z = PixelInput32 [ uStartIndex + idx4.z ];
				pix4.w = PixelInput32 [ uStartIndex + idx4.w ];
			}

			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferDstBufWidth;

			iOffset4 = iOffset4 + XferDstOffset32;

			// read 32-bit data
			//dpix4.x = VRAM [ iOffset4.x ];
			//dpix4.y = VRAM [ iOffset4.y ];
			//dpix4.z = VRAM [ iOffset4.z ];
			//dpix4.w = VRAM [ iOffset4.w ];

			// put the 24-bit pixel data into the 32-bit value
			// I don't like this because could be writing to different parts of 32-bit value simultaneously
			//pix4 = bitfieldInsert( dpix4, pix4, 0, 24 );

			// store 32-bit data
			//VRAM [ iOffset + 0 ] = pix0 & 0xffff;
			//VRAM [ iOffset + 1 ] = pix0 >> 16;
			//VRAM [ iOffset4.x ] = pix4.x;
			//VRAM [ iOffset4.y ] = pix4.y;
			//VRAM [ iOffset4.z ] = pix4.z;
			//VRAM [ iOffset4.w ] = pix4.w;

			// store bottom 16-bits first
			iOffset4 <<= 1;
			VRAM16 [ iOffset4.x ] = uint16_t( pix4.x );
			VRAM16 [ iOffset4.y ] = uint16_t( pix4.y );
			VRAM16 [ iOffset4.z ] = uint16_t( pix4.z );
			VRAM16 [ iOffset4.w ] = uint16_t( pix4.w );

			// next store next 8-bits to make a total of 24-bits
			iOffset4 <<= 1;
			iOffset4 += 2;
			pix4 >>= 16;
			VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );

		}
	}
	else if ( subgroupAll( ( DPSM & 0x3 ) == 0x2 ) )
	{
		// 16-bit pixels //

		SharedYMax = Count32 << 1;
		XferCountX = XferCount32 << 1;
		DPSM >>= 1;
		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = uvec4( sVRAM16_4[ iCount >> 2 ] );
			}
			else
#endif
			{
				pix4.x = PixelInput32 [ uStartIndex + ( idx4.x >> 1 )];
				pix4.z = PixelInput32 [ uStartIndex + ( idx4.z >> 1 ) ];
			}

			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 16-bit pixel block is 64x64 (6bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];


			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 6 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x3f ) * XferDstBufWidth;

			// shift left dst offset by one for 16-bit pixels
			iOffset4 = iOffset4 + ( XferDstOffset32 << 1 );

			// prepare 16-bit pixels
			pix4.yw = pix4.xz >> 16;

			// store 16-bit data
			VRAM16 [ iOffset4.x ] = uint16_t( pix4.x );
			VRAM16 [ iOffset4.y ] = uint16_t( pix4.y );
			VRAM16 [ iOffset4.z ] = uint16_t( pix4.z );
			VRAM16 [ iOffset4.w ] = uint16_t( pix4.w );
		}
	}
	else if ( subgroupAll( ( DPSM & 3 ) == 3 ) )
	{
		// 8-bit pixels (either 8h (0x1b) or just 8-bit packed (0x13)) //

		// iShift0= 8h: 2, otherwise zero
		// iOffset0= 8h: 2, otherwise zero (same as iShift0)
		iShift0 = int( DPSM & 8 ) >> 2;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		SharedYMax = Count32 << 2;
		XferCountX = XferCount32 << 2;

		DPSM >>= 1;
		xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			// load 8-bit pixels
#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = uvec4( sVRAM8_4[ iCount >> 2 ] );
			}
			else
#endif
			{
				pix4 = uvec4( PixelInput32 [ uStartIndex + ( idx4.x >> 2 )] );
			}

			// need the pixel count in the image ( sX + sY * w )
			//xximagepixel = iCount + xximagepixelstart;
			idx4 = idx4 + xximagepixelstart;

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 8h: 2, otherwise zero
			// iOffset0= 8h: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

			// prepare 8-bit pixels
			// note: could do an unpack here
			pix4 >>= ( idx4 & 3 ) << 3;
			pix4 &= 0xff;

			// store 8-bit data
			VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
		}
	}
	else
	{
		// 4-bit pixels (4/4hl/4hh) //

#ifdef ENABLE_4BIT_ATOMICS

		// amount to shift address
		// 4 (0x14)/ 4hl (0x24)/ 4hh (0x2c)
		// iShift0= 4: 3, otherwise zero
		iShift0 = -sign( int( DPSM ) & 0x10 ) & 3;

		// amount to shift pixel in byte
		// iPixelBitOffset0= 4hh: 24 + 4, 4/4hl: 24 + 0, otherwise zero
		iPixelBitOffset0 = ( 24 & -sign( int( DPSM ) & 0x20 ) ) + ( ( int( DPSM ) & 0x8 ) >> 1 );

		SharedYMax = Count32 << 3;
		XferCountX = XferCount32 << 3;

		DPSM >>= 1;
		xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			// load 4-bit pixels
#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = uvec4( sVRAM8_4[ iCount >> 2 ] );
			}
			else
#endif
			{
				pix4 = uvec4( PixelInput32 [ uStartIndex + ( idx4.x >> 3 )] );
			}

			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// get offset for pixel inside of 32-bit word
			iPixelBitOffset4 = ( ( ( iOffset4 & 7 ) << 2 ) & ( sign( iPixelBitOffset0 ) - 1 ) ) + iPixelBitOffset0;

			// get the address to the byte (in case of psmt4)
			// iShift0= 4: 3, 4hl/hh: 0
			iOffset4 = iOffset4 >> iShift0;

			iOffset4 = iOffset4 + XferDstOffset32;

			// load destination 8-bit data
			dpix4.x = VRAM [ iOffset4.x ];
			dpix4.y = VRAM [ iOffset4.y ];
			dpix4.z = VRAM [ iOffset4.z ];
			dpix4.w = VRAM [ iOffset4.w ];

			// prepare 4-bit pixels
			pix4 >>= ( idx4 & 7 ) << 2;

			// clear unwanted data in dest pixel
			pix4 = ( ( dpix4 >> iPixelBitOffset4 ) ^ pix4 ) & 0xf;

			// add new data into pixel (xor)
			pix4 <<= iPixelBitOffset4;

			// store 4-bit data in parallel (xor)??
			atomicXor ( VRAM [ iOffset4.x ], pix4.x );
			atomicXor ( VRAM [ iOffset4.y ], pix4.y );
			atomicXor ( VRAM [ iOffset4.z ], pix4.z );
			atomicXor ( VRAM [ iOffset4.w ], pix4.w );

		}

#else

		// iShift0= 4h/l: 2, otherwise zero
		// iOffset0= 4h/l: 3, otherwise zero
		iShift0 = int( DPSM & 0x20 ) >> 4;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		SharedYMax = Count32 << 3;
		XferCountX = XferCount32 << 3;

		DPSM >>= 1;
		xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			// load 8-bit pixels
#ifdef USE_TRANSFER_IN_WITH_MOVE
			if ( bIsMove )
			{
				pix4 = uvec4( sVRAM8_4[ iCount >> 2 ] );
			}
			else
#endif
			{
				pix4 = uvec4( PixelInput32 [ uStartIndex + ( idx4.x >> 3 )] );
			}

			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 4hh/l or regular 4-bit pixel
			// iShift0= 4hh/l: 2, otherwise zero
			// iOffset0= 4hh/l: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			// get offset for pixel inside of 8-bit value
			iPixelBitOffset4 = ivec4( ( iOffset4 | ( DPSM >> 2 ) ) & 1 ) << 2;

			// shift off the nibble offset
			iOffset4 >>= ( DPSM >> 3 ) & 1;

			// get actual offset to byte in vram
			iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

			// get destination pixels
			dpix4.x = uint( VRAM8 [ iOffset4.x ] );
			dpix4.y = uint( VRAM8 [ iOffset4.y ] );
			dpix4.z = uint( VRAM8 [ iOffset4.z ] );
			dpix4.w = uint( VRAM8 [ iOffset4.w ] );

			// prepare 4-bit pixels
			// note: could do an unpack here
			pix4 >>= ( idx4 & 7 ) << 2;
			pix4 &= 0xf;

			// store 4hh/4hl or lower nibble to vram, all else to svram
			bWriteToSVRAM4 = notEqual( ( iPixelBitOffset4 & ( DPSM >> 1 ) ), uvec4( 0 ) );

			// store 4-bit data to svram - doing it like this incase I want to do this in more parallel later, other option is to pack in at iCount
			if ( bWriteToSVRAM4.x ) sVRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			if ( bWriteToSVRAM4.y ) sVRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			if ( bWriteToSVRAM4.z ) sVRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			if ( bWriteToSVRAM4.w ) sVRAM8 [ iOffset4.w ] = uint8_t( pix4.w );

			// update high-nibble for 4hh, otherwise just update the low-nibble
			pix4 = bitfieldInsert( dpix4, pix4, int( DPSM ) & 4, 4 );

			// store 8-bit data if svram not updated
			if ( !bWriteToSVRAM4.x ) VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			if ( !bWriteToSVRAM4.y ) VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			if ( !bWriteToSVRAM4.z ) VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			if ( !bWriteToSVRAM4.w ) VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
		}

		// only need the next part if normal 4-bit transfer
		if ( subgroupAll( ( DPSM & 0x8 ) == 0x8 ) )
		{
			barrier ();

			for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
			{
				idx4 = iCount + ivec4( 0, 1, 2, 3 );

				// need the pixel count in the image ( sX + sY * w )
				idx4 = idx4 + xximagepixelstart;

				CurX4 = idx4 % w;
				CurY4 = idx4 / w;

				// get the offset to the pixel
				CurY4 += dY;
				CurX4 += dX;

				// coords wrap at 2048
				CurY4 &= 0x7ff;
				CurX4 &= 0x7ff;

				// the x wraps around the buffer
				CurX4 %= XferDstBufWidth;


				// 8-bit pixel block is 128x64 (7bitsx6bits)
				ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
				iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
				iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
				iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
				iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

				// put in the remainder of the x-bits that don't get swizzled
				iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

				// add in the bits for the y
				iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

				// adjust offset based on whether 4hh/l or regular 4-bit pixel
				// iShift0= 4hh/l: 2, otherwise zero
				// iOffset0= 4hh/l: 3, otherwise zero
				iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

				// get offset for pixel inside of 8-bit value
				iPixelBitOffset4 = ivec4( ( iOffset4 | ( DPSM >> 2 ) ) & 1 ) << 2;

				// shift off the nibble offset
				iOffset4 >>= ( DPSM >> 3 ) & 1;

				// get actual offset to byte in vram
				iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

				// get input pixels (high nibble)
				pix4.x = uint( sVRAM8 [ iOffset4.x ] );
				pix4.y = uint( sVRAM8 [ iOffset4.y ] );
				pix4.z = uint( sVRAM8 [ iOffset4.z ] );
				pix4.w = uint( sVRAM8 [ iOffset4.w ] );

				// get destination pixels
				dpix4.x = uint( VRAM8 [ iOffset4.x ] );
				dpix4.y = uint( VRAM8 [ iOffset4.y ] );
				dpix4.z = uint( VRAM8 [ iOffset4.z ] );
				dpix4.w = uint( VRAM8 [ iOffset4.w ] );

				// prepare 8-bit pixels
				// note: could do an unpack here
				//pix4 >>= ( idx4 & 7 ) << 2;
				//pix4 &= 0xf;

				// combine high nibble into the dest pixel
				pix4 = bitfieldInsert( dpix4, pix4, 4, 4 );

				// store 4hh/4hl or lower nibble to vram, all else to svram
				bWriteToSVRAM4 = notEqual( ( iPixelBitOffset4 & ( DPSM >> 1 ) ), uvec4( 0 ) );
				//bWriteNormal4 = equal( ( iPixelBitOffset4 & ( DPSM >> 1 ) ), uvec4( 0 ) );

				// store 8-bit data to vram if high-nibble needs updating
				if ( bWriteToSVRAM4.x ) VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
				if ( bWriteToSVRAM4.y ) VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
				if ( bWriteToSVRAM4.z ) VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
				if ( bWriteToSVRAM4.w ) VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
			}

		}	// end if ( subgroupAll( ( DPSM & 0x8 ) == 0x8 ) )

#endif	// end else #ifdef ENABLE_4BIT_ATOMICS

	}
	

#ifdef SYNC_AFTER_TRANSFER

	barrier ();

#endif

	return;
	//return ( ( uIndex >> 4 ) + ( ( SharedYMax + 0xf ) >> 4 ) - 1 );
}




#ifdef ENABLE_DRAW_PIXEL_MOVE


void TransferPixelPacketMove ( uint uIndex )
{
	int xxid = int( gl_LocalInvocationIndex );

	//int xid = int( gl_GlobalInvocationID.x );
	//int yid = int( gl_GlobalInvocationID.y );

	// global invocation index
	int gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );

	uint CurBarrierSync;

	int idx;
	ivec4 idx4;

	ivec4 CurX4, CurY4;
	ivec4 ivPtr4;
	ivec4 iOffset4;
	uvec4 pix4;
	ivec4 iPixelBitOffset4;
	bvec4 vbEnable;

	int iOffset0;
	int YNAND, XNAND, XSHIFT;
	int iPixelBitOffset0;

	uint DPSM24;
	
	//uint bgr2;
	uint pix0, pix1;
	uint DestPixel;
	//uint Data;

	
	int CurX, CurY;
	int CurX2, CurY2;

	ivec4 ivCurX, ivCurY;
	ivec4 ivCurX2, ivCurY2;

	int iPtr;
	//int iCount;
	
	//int xxpixel;
	//int xximagepixel;


	int dX;
	int dY;
	int w;
	int h;
	int sX;
	int sY;
	
	//int BS;

	int XferX, XferY;
	int XferWidth, XferHeight;
	int XferDstBufWidth;
	int XferSrcBufWidth;
	//int XferDstX, XferDstY;
	//int XferSrcX, XferSrcY;
	//int Count32;

	int XferDstOffset32;
	int XferSrcOffset32;

	//int XferCount32, XferCountX;

	//uint XferId0, XferIdX;
	//int iYOffset_xor, iYOffset_add, iXOffset, iOffset;
	//ivec4 ivYOffset_xor, ivYOffset_add, ivXOffset, ivOffset;

	//int xximagepixelstart;
	//int SharedYMax;
	//uint Comm;

	uint BITBLTBUF_0;
	uint BITBLTBUF_1;
	uint DPSM;
	uint SPSM;

	uvec2 pix2;

	uvec4 vPixel;

	//uint uStartIndex;

	int iShift0, iShift1, iShift2;
	int iMask0, iMask1, iMask2;
	int iPixelShift;

	int iCount;
	ivec4 ivIndex;
	ivec4 vIdx;

	uvec4 dpix4;
	ivec4 ivPixelShift4;
	int iPixelShift0;
	bvec4 bWriteToSVRAM4;


	uIndex <<= 5;

		//((u64*)inputdata_ptr)[1] = GPURegsGp.BITBLTBUF.Value;
		//inputdata_ptr [ 4 ] = XferSrcX;
		//inputdata_ptr [ 5 ] = XferSrcY;
		//inputdata_ptr [ 6 ] = XferDstX;
		//inputdata_ptr [ 7 ] = XferDstY;
		//inputdata_ptr [ 8 ] = XferWidth;
		//inputdata_ptr [ 9 ] = XferHeight;
		//inputdata_ptr [ 10 ] = XferDstBufWidth;
		//inputdata_ptr [ 11 ] = XferDstOffset32;
		//inputdata_ptr [ 12 ] = XferSrcBufWidth;
		//inputdata_ptr [ 13 ] = XferSrcOffset32;

		BITBLTBUF_0 = inputdata [ uIndex + 2 ];
		SPSM = ( BITBLTBUF_0 >> 24 ) & 0x3f;

		BITBLTBUF_1 = inputdata [ uIndex + 3 ];
		DPSM = ( BITBLTBUF_1 >> 24 ) & 0x3f;

		// get count of items to transfer
		iCount = int( inputdata [ uIndex + 5 ] );

		// XferX, XferY (6,7)
		//sX = int( inputdata [ uIndex + 6 ] );
		//sY = int( inputdata [ uIndex + 7 ] );

		// XferSrcX, XferSrcY (8,9)
		sX = int( inputdata [ uIndex + 8 ] );
		sY = int( inputdata [ uIndex + 9 ] );

		// XferDstX, XferDstY (10,11)
		dX = int( inputdata [ uIndex + 10 ] );
		dY = int( inputdata [ uIndex + 11 ] );
		
		// XferWidth, XferHeight (12,13)
		w = int( inputdata [ uIndex + 12 ] );
		h = int( inputdata [ uIndex + 13 ] );
		
		// XferSrcBufWidth,XferSrcOffset32 (14,15)
		XferSrcBufWidth = int( inputdata [ uIndex + 14 ] );
		XferSrcOffset32 = int( inputdata [ uIndex + 15 ] );

		// XferDstBufWidth,XferDstOffset32 (16,17)
		XferDstBufWidth = int( inputdata [ uIndex + 16 ] );
		XferDstOffset32 = int( inputdata [ uIndex + 17 ] );


		//iCount = w * h;


#ifdef SYNC_BEFORE_MOVE

	barrier ();

#endif


	// *** SOURCE *** //

	if ( subgroupAll( ( SPSM & 0xe ) == 0 ) )
	{
		// 24/32-bit pixels //

		SPSM >>= 1;

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += sY;
			CurX4 += sX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferSrcBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( SPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferSrcBufWidth;

			iOffset4 = iOffset4 + XferSrcOffset32;

			// store 32-bit data
			pix4.x = VRAM [ iOffset4.x ];
			pix4.y = VRAM [ iOffset4.y ];
			pix4.z = VRAM [ iOffset4.z ];
			pix4.w = VRAM [ iOffset4.w ];

			sVRAM4 [ idx >> 2 ] = pix4;
		}


	}	// end if ( ( SPSM & 0xf ) == 0 )
	else if ( subgroupAll( ( SPSM & 0x3 ) == 0x2 ) )
	{
		// 16-bit pixels //

		SPSM >>= 1;

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += sY;
			CurX4 += sX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferSrcBufWidth;

			// 16-bit pixel block is 64x64 (6bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( SPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 6 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x3f ) * XferSrcBufWidth;

			// shift left dst offset by one for 16-bit pixels
			iOffset4 = iOffset4 + ( XferSrcOffset32 << 1 );

			// prepare 16-bit pixels
			//pix4.yw = pix4.xz >> 16;

			// store 16-bit data
			pix4.x = uint( VRAM16 [ iOffset4.x ] );
			pix4.y = uint( VRAM16 [ iOffset4.y ] );
			pix4.z = uint( VRAM16 [ iOffset4.z ] );
			pix4.w = uint( VRAM16 [ iOffset4.w ] );
		}

	}
	else if ( subgroupAll( ( SPSM & 3 ) == 3 ) )
	{
		// 8-bit pixels (either 8h (0x1b) or just 8-bit packed (0x13)) //

		// iShift0= 8h: 2, otherwise zero
		// iOffset0= 8h: 2, otherwise zero (same as iShift0)
		iShift0 = int( SPSM & 8 ) >> 2;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		SPSM >>= 1;

		YNAND = LUT_YNAND[ SPSM ];
		XNAND = LUT_XNAND[ SPSM ];
		XSHIFT = LUT_XSHIFT[ SPSM ];

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += sY;
			CurX4 += sX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferSrcBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( SPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferSrcBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 8h: 2, otherwise zero
			// iOffset0= 8h: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			iOffset4 = iOffset4 + ( XferSrcOffset32 << 2 );


			// store 8-bit data
			pix4.x = VRAM8 [ iOffset4.x ];
			pix4.y = VRAM8 [ iOffset4.y ];
			pix4.z = VRAM8 [ iOffset4.z ];
			pix4.w = VRAM8 [ iOffset4.w ];

			sVRAM8_4[ idx >> 2 ] = u8vec4( pix4 );
		}

	}
	else
	{
		// 4-bit pixels 4/4hl/4hh (0x14/0x24/0x2c) //

		// amount to shift address
		// 4 (0x14)/ 4hl (0x24)/ 4hh (0x2c)
		// iShift0= 4: 3, otherwise zero
		iShift0 = -sign( int( SPSM ) & 0x10 ) & 3;

		// amount to shift pixel in byte
		// iPixelBitOffset0= 4hh: 24 + 4, 4/4hl: 24 + 0, otherwise zero
		iPixelBitOffset0 = ( 24 & -sign( int( SPSM ) & 0x20 ) ) + ( ( int( SPSM ) & 0x8 ) >> 1 );

		SPSM >>= 1;

		YNAND = LUT_YNAND[ SPSM ];
		XNAND = LUT_XNAND[ SPSM ];
		XSHIFT = LUT_XSHIFT[ SPSM ];

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += sY;
			CurX4 += sX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferSrcBufWidth;

			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( SPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferSrcBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4h: 3, otherwise zero
			// iOffset0= 4h: 2, otherwise zero (same as iShift0)
			//iOffset4 = ( iOffset4 << iShift0 ) + iShift0;



			// ***TODO*** RE-WRITE TO USE 32-BIT MEMORY

			// get offset for pixel inside of 32-bit word
			iPixelBitOffset4 = ( ( ( iOffset4 & 7 ) << 2 ) & ( sign( iPixelBitOffset0 ) - 1 ) ) + iPixelBitOffset0;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4hl/hh: 2, otherwise zero
			// iOffset0= 4hl/hh: 3, otherwize zero
			// don't add offset until after getting pixel offset
			//iOffset4 = ( iOffset4 << iShift0 );


			// get the address to the byte (in case of psmt4)
			// iShift0= 4: 3, 4hl/hh: 0
			//iOffset4 = ( iOffset4 >> iShift0 ) & ~( 3 & -iShift0 );
			iOffset4 = iOffset4 >> iShift0;

			iOffset4 = iOffset4 + XferSrcOffset32;

			// add the fixed byte offset to the address (in case of 4hl/4hh)
			//iOffset4 += iOffset0;

			// load destination 8-bit data
			pix4.x = VRAM [ iOffset4.x ];
			pix4.y = VRAM [ iOffset4.y ];
			pix4.z = VRAM [ iOffset4.z ];
			pix4.w = VRAM [ iOffset4.w ];

			// clear unwanted data in dest pixel
			pix4 = ( pix4 >> iPixelBitOffset4 ) & 0xf;

			sVRAM8_4 [ idx >> 2 ] = u8vec4( pix4 );

		}

	}


#ifdef USE_MEMORY_BARRIER_BUFFER

			memoryBarrierBuffer ();
			memoryBarrierShared ();
			groupMemoryBarrier ();
			memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS

		if ( subgroupElect() )
		{

			CurBarrierSync = atomicAdd( auCounter, 1 );
			//atomicAdd( auCounter, 1 );

			if ( xxid == 0 )
			{
				CurBarrierSync++;

				// would probably need to be a less than comparison due to possible race conditions
				//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
				while ( CurBarrierSync < NextBarrierSync )
				{
					//CurBarrierSync = atomicAdd( auCounter, 0 );
					CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
				}

				// at the next sync point, need all subgroups
				NextBarrierSync += subgroup_global_count;

			}	// end if ( xxid == 0 )


		}	// end if ( subgroupElect() )


#endif	// end #ifdef ENABLE_MULTIPLE_WORKGROUPS

		// synchronize the workgroup subgroups locally
		barrier ();


#ifdef USE_TRANSFER_IN_WITH_MOVE

	TransferPixelPacketIn ( uIndex >> 5 );

#else

	// *** DESTINATION *** //

	if ( subgroupAll( ( DPSM & 0xe ) == 0 ) )
	{
		// 32-bit or 24-bit pixels //

		DPSM24 = DPSM;
		DPSM >>= 1;
		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			//pix4.x = PixelInput32 [ uStartIndex + idx4.x ];
			//pix4.y = PixelInput32 [ uStartIndex + idx4.y ];
			//pix4.z = PixelInput32 [ uStartIndex + idx4.z ];
			//pix4.w = PixelInput32 [ uStartIndex + idx4.w ];

			pix4 = sVRAM4 [ idx >> 2 ];

			// need the pixel count in the image ( sX + sY * w )
			//idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferDstBufWidth;

			iOffset4 = iOffset4 + XferDstOffset32;

			// get destination pixel
			dpix4.x = VRAM [ iOffset4.x ];
			dpix4.y = VRAM [ iOffset4.y ];
			dpix4.z = VRAM [ iOffset4.z ];
			dpix4.w = VRAM [ iOffset4.w ];

			// if 24-bit pixel, then copy upper 8-bits
			pix4 = bitfieldInsert( pix4, dpix4, 24, int( DPSM24 & 1 ) << 3 );

			// only transfer pixels within count
			pix4 = mix( dpix4, pix4, lessThan( idx4, ivec4( iCount ) ) );

			// store 32-bit data
			VRAM [ iOffset4.x ] = pix4.x;
			VRAM [ iOffset4.y ] = pix4.y;
			VRAM [ iOffset4.z ] = pix4.z;
			VRAM [ iOffset4.w ] = pix4.w;
		}


	}	// end if ( ( DPSM & 0xe ) == 0 )
	else if ( subgroupAll( ( DPSM & 0x3 ) == 0x2 ) )
	{
		// 16-bit pixels //

		DPSM >>= 1;
		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			//pix4.x = PixelInput32 [ uStartIndex + ( idx4.x >> 1 )];
			//pix4.z = PixelInput32 [ uStartIndex + ( idx4.z >> 1 ) ];

			pix4 = uvec4( sVRAM16_4[ idx >> 2 ] );

			// need the pixel count in the image ( sX + sY * w )
			//idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 16-bit pixel block is 64x64 (6bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];


			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 6 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x3f ) * XferDstBufWidth;

			// shift left dst offset by one for 16-bit pixels
			iOffset4 = iOffset4 + ( XferDstOffset32 << 1 );

			// get destination pixel
			dpix4.x = uint( VRAM16 [ iOffset4.x ] );
			dpix4.y = uint( VRAM16 [ iOffset4.y ] );
			dpix4.z = uint( VRAM16 [ iOffset4.z ] );
			dpix4.w = uint( VRAM16 [ iOffset4.w ] );

			// only transfer pixels within count
			pix4 = mix( dpix4, pix4, lessThan( idx4, ivec4( iCount ) ) );

			// store 16-bit data
			VRAM16 [ iOffset4.x ] = uint16_t( pix4.x );
			VRAM16 [ iOffset4.y ] = uint16_t( pix4.y );
			VRAM16 [ iOffset4.z ] = uint16_t( pix4.z );
			VRAM16 [ iOffset4.w ] = uint16_t( pix4.w );
		}

	}	// end if ( ( DPSM & 0x3 ) == 0x2 )
	else if ( subgroupAll( ( DPSM & 3 ) == 3 ) )
	{
		// 8-bit pixels //

		// iShift0= 8h: 2, otherwise zero
		// iOffset0= 8h: 2, otherwise zero (same as iShift0)
		iShift0 = int( DPSM & 8 ) >> 2;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		DPSM >>= 1;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			pix4 = uvec4( sVRAM8_4[ idx >> 2 ] );


			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 8h: 2, otherwise zero
			// iOffset0= 8h: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );


			vbEnable = lessThan( idx4, ivec4( iCount ) );

			// store 8-bit data
			VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			if ( vbEnable.y ) VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			if ( vbEnable.z ) VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			if ( vbEnable.w ) VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
		}

	}
	else
	{
		// 4-bit pixels 4/4hl/4hh (0x14/0x24/0x2c) //

#ifdef ENABLE_4BIT_ATOMICS

		// amount to shift address
		// 4 (0x14)/ 4hl (0x24)/ 4hh (0x2c)
		// iShift0= 4: 3, otherwise zero
		iShift0 = -sign( int( DPSM ) & 0x10 ) & 3;

		// amount to shift pixel in byte
		// iPixelBitOffset0= 4hh: 24 + 4, 4/4hl: 24 + 0, otherwise zero
		iPixelBitOffset0 = ( 24 & -sign( int( DPSM ) & 0x20 ) ) + ( ( int( DPSM ) & 0x8 ) >> 1 );

		DPSM >>= 1;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];
		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			pix4 = uvec4( sVRAM8_4[ idx >> 2 ] );


			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4h: 3, otherwise zero
			// iOffset0= 4h: 2, otherwise zero (same as iShift0)
			//iOffset4 = ( iOffset4 << iShift0 ) + iShift0;



			// ***TODO*** RE-WRITE TO USE 32-BIT MEMORY

			// get offset for pixel inside of 32-bit word
			iPixelBitOffset4 = ( ( ( iOffset4 & 7 ) << 2 ) & ( sign( iPixelBitOffset0 ) - 1 ) ) + iPixelBitOffset0;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4hl/hh: 2, otherwise zero
			// iOffset0= 4hl/hh: 3, otherwize zero
			// don't add offset until after getting pixel offset
			//iOffset4 = ( iOffset4 << iShift0 );


			// get the address to the byte (in case of psmt4)
			// iShift0= 4: 3, 4hl/hh: 0
			//iOffset4 = ( iOffset4 >> iShift0 ) & ~( 3 & -iShift0 );
			iOffset4 = iOffset4 >> iShift0;

			iOffset4 = iOffset4 + XferDstOffset32;

			// add the fixed byte offset to the address (in case of 4hl/4hh)
			//iOffset4 += iOffset0;

			// load destination 8-bit data
			dpix4.x = VRAM [ iOffset4.x ];
			dpix4.y = VRAM [ iOffset4.y ];
			dpix4.z = VRAM [ iOffset4.z ];
			dpix4.w = VRAM [ iOffset4.w ];


			// clear unwanted data in dest pixel
			pix4 = ( ( dpix4 >> iPixelBitOffset4 ) ^ pix4 ) & 0xf;

			// add new data into pixel (xor)
			pix4 <<= iPixelBitOffset4;

			// store 4-bit data in parallel (xor)??
			atomicXor ( VRAM [ iOffset4.x ], pix4.x );
			atomicXor ( VRAM [ iOffset4.y ], pix4.y );
			atomicXor ( VRAM [ iOffset4.z ], pix4.z );
			atomicXor ( VRAM [ iOffset4.w ], pix4.w );
		}

#else

		// iShift0= 4h/l: 2, otherwise zero
		// iOffset0= 4h/l: 3, otherwise zero
		iShift0 = int( DPSM & 0x20 ) >> 4;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		//SharedYMax = Count32 << 3;
		//XferCountX = XferCount32 << 3;

		DPSM >>= 1;
		//xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
		{
			idx4 = idx + ivec4( 0, 1, 2, 3 );

			// load 8-bit pixels
			pix4 = uvec4( sVRAM8_4[ idx >> 2 ] );

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 4hh/l or regular 4-bit pixel
			// iShift0= 4hh/l: 2, otherwise zero
			// iOffset0= 4hh/l: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			// get offset for pixel inside of 8-bit value
			iPixelBitOffset4 = ivec4( ( iOffset4 | ( DPSM >> 2 ) ) & 1 ) << 2;

			// shift off the nibble offset
			iOffset4 >>= ( DPSM >> 3 ) & 1;

			// get actual offset to byte in vram
			iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

			// get destination pixels
			dpix4.x = uint( VRAM8 [ iOffset4.x ] );
			dpix4.y = uint( VRAM8 [ iOffset4.y ] );
			dpix4.z = uint( VRAM8 [ iOffset4.z ] );
			dpix4.w = uint( VRAM8 [ iOffset4.w ] );

			// prepare 4-bit pixels
			// note: could do an unpack here
			//pix4 >>= ( idx4 & 7 ) << 2;
			//pix4 &= 0xf;

			// store 4hh/4hl or lower nibble to vram, all else to svram
			bWriteToSVRAM4 = notEqual( ( iPixelBitOffset4 & ( DPSM >> 1 ) ), uvec4( 0 ) );

			// store 4-bit data to svram - doing it like this incase I want to do this in more parallel later, other option is to pack in at iCount
			if ( bWriteToSVRAM4.x ) sVRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			if ( bWriteToSVRAM4.y ) sVRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			if ( bWriteToSVRAM4.z ) sVRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			if ( bWriteToSVRAM4.w ) sVRAM8 [ iOffset4.w ] = uint8_t( pix4.w );

			// update high-nibble for 4hh, otherwise just update the low-nibble
			pix4 = bitfieldInsert( dpix4, pix4, int( DPSM ) & 4, 4 );

			// store 8-bit data if svram not updated
			if ( !bWriteToSVRAM4.x ) VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
			if ( !bWriteToSVRAM4.y ) VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
			if ( !bWriteToSVRAM4.z ) VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
			if ( !bWriteToSVRAM4.w ) VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
		}

		// only need the next part if normal 4-bit transfer
		if ( subgroupAll( ( DPSM & 0x8 ) == 0x8 ) )
		{
			barrier ();

			for ( idx = gxxid << 2; idx < iCount; idx += gxxinc << 2 )
			{
				idx4 = idx + ivec4( 0, 1, 2, 3 );

				CurX4 = idx4 % w;
				CurY4 = idx4 / w;

				// get the offset to the pixel
				CurY4 += dY;
				CurX4 += dX;

				// coords wrap at 2048
				CurY4 &= 0x7ff;
				CurX4 &= 0x7ff;

				// the x wraps around the buffer
				CurX4 %= XferDstBufWidth;


				// 8-bit pixel block is 128x64 (7bitsx6bits)
				ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
				iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
				iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
				iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
				iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

				// put in the remainder of the x-bits that don't get swizzled
				iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

				// add in the bits for the y
				iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

				// adjust offset based on whether 4hh/l or regular 4-bit pixel
				// iShift0= 4hh/l: 2, otherwise zero
				// iOffset0= 4hh/l: 3, otherwise zero
				iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

				// get offset for pixel inside of 8-bit value
				iPixelBitOffset4 = ivec4( ( iOffset4 | ( DPSM >> 2 ) ) & 1 ) << 2;

				// shift off the nibble offset
				iOffset4 >>= ( DPSM >> 3 ) & 1;

				// get actual offset to byte in vram
				iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

				// get input pixels (high nibble)
				pix4.x = uint( sVRAM8 [ iOffset4.x ] );
				pix4.y = uint( sVRAM8 [ iOffset4.y ] );
				pix4.z = uint( sVRAM8 [ iOffset4.z ] );
				pix4.w = uint( sVRAM8 [ iOffset4.w ] );

				// get destination pixels
				dpix4.x = uint( VRAM8 [ iOffset4.x ] );
				dpix4.y = uint( VRAM8 [ iOffset4.y ] );
				dpix4.z = uint( VRAM8 [ iOffset4.z ] );
				dpix4.w = uint( VRAM8 [ iOffset4.w ] );

				// prepare 8-bit pixels
				// note: could do an unpack here
				//pix4 >>= ( idx4 & 7 ) << 2;
				//pix4 &= 0xf;

				// combine high nibble into the dest pixel
				pix4 = bitfieldInsert( dpix4, pix4, 4, 4 );

				// store 4hh/4hl or lower nibble to vram, all else to svram
				bWriteToSVRAM4 = notEqual( ( iPixelBitOffset4 & ( DPSM >> 1 ) ), uvec4( 0 ) );

				// store 8-bit data to vram if high-nibble needs updating
				if ( bWriteToSVRAM4.x ) VRAM8 [ iOffset4.x ] = uint8_t( pix4.x );
				if ( bWriteToSVRAM4.y ) VRAM8 [ iOffset4.y ] = uint8_t( pix4.y );
				if ( bWriteToSVRAM4.z ) VRAM8 [ iOffset4.z ] = uint8_t( pix4.z );
				if ( bWriteToSVRAM4.w ) VRAM8 [ iOffset4.w ] = uint8_t( pix4.w );
			}

		}	// end if ( subgroupAll( ( DPSM & 0x8 ) == 0x8 ) )

#endif	// end else #ifdef ENABLE_4BIT_ATOMICS


	}

#endif


#ifdef SYNC_AFTER_MOVE

	barrier ();

#endif


	//}	// end if local_id

	//	uIndex += 16;
	//	Comm = inputdata [ uIndex + 7 ] >> 24;
	//} while ( ( Comm == 0x80 ) && ( uIndex < ( ( 1 << 16 ) << 4 ) ) );

	return;
	//return ( uIndex >> 4 ) - 1;
}


#endif	// end #ifdef ENABLE_DRAW_PIXEL_MOVE









#ifdef ENABLE_DRAW_PIXEL_OUTPUT

// transfer out
void TransferPixelPacketOut ( uint uIndex )
{
	int xxid = int( gl_LocalInvocationIndex );

	//int xid = int( gl_GlobalInvocationID.x );
	//int yid = int( gl_GlobalInvocationID.y );
	
	uint bgr2;
	uint pix0, pix1;
	uint DestPixel;
	uint Data;

	ivec4 ivPtr4;
	
	//int iX, iY;
	int CurX, CurY;

	int iPtr;
	int iCount;
	
	int xxpixel;
	int xximagepixel;


	uint GPU_CTRL_Read;
	int dX;
	int dY;
	int w;
	int h;
	int sX;
	int sY;
	
	int BS;

	int XferX, XferY;
	int XferWidth, XferHeight;
	int XferDstBufWidth;
	int XferDstX, XferDstY;
	int Count32;

	int XferDstOffset32;

	int XferCount32, XferCountX;

	uint XferId0, XferIdX;
	int iYOffset, iXOffset, iOffset;

	int xximagepixelstart;
	int SharedYMax;
	uint Comm;

	uint BITBLTBUF_1;
	uint DPSM;

	uint uStartIndex;

	int iShift0, iShift1, iShift2;
	int iMask0, iMask1, iMask2;
	int iPixelShift;

	ivec4 idx4;
	uvec4 pix4, dpix4;
	ivec4 CurX4, CurY4;
	ivec4 iOffset4, iXOffset4, iYOffset4;
	ivec4 iPixelBitOffset4;
	int iPixelBitOffset0;
	int iOffset0;

	int XNAND, XSHIFT, YNAND;

	int gxxid;

	// global invocation index
	gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );


	//uIndex <<= 6;
	uIndex <<= 5;

	// test all the inputs
	//sVRAM[0] = uIndex;
	//for ( int i = xxid; i < 16; i++ )
	//{
	//	sVRAM[i+1] = inputdata [ uIndex + i ];
	//}

	
	//if ( xxid == 0 )
	//{

		//Count = 0;

		//BITBLTBUF_1 = inputdata [ uIndex + ( 1 << 1 ) + 1 ];
		BITBLTBUF_1 = inputdata [ uIndex + 3 ];
		DPSM = ( BITBLTBUF_1 >> 24 ) & 0x3f;

		//Count32 = int( inputdata [ uIndex + ( 5 << 1 ) + 0 ] );
		Count32 = int( inputdata [ uIndex + 5 ] );

		// XferX, XferY
		//sX = int( inputdata [ uIndex + ( 6 << 1 ) + 0 ] );
		//sY = int( inputdata [ uIndex + ( 7 << 1 ) + 0 ] );
		sX = int( inputdata [ uIndex + 6 ] );
		sY = int( inputdata [ uIndex + 7 ] );

		// XferDstX, XferDstY
		//dX = int( inputdata [ uIndex + ( 8 << 1 ) + 0 ] );
		//dY = int( inputdata [ uIndex + ( 9 << 1 ) + 0 ] );
		dX = int( inputdata [ uIndex + 8 ] );
		dY = int( inputdata [ uIndex + 9 ] );
		
		// XferWidth, XferHeight
		//w = int( inputdata [ uIndex + ( 10 << 1 ) + 0 ] );
		//h = int( inputdata [ uIndex + ( 11 << 1 ) + 0 ] );
		w = int( inputdata [ uIndex + 10 ] );
		h = int( inputdata [ uIndex + 11 ] );
		
		// XferDstBufWidth
		//XferDstBufWidth = int( inputdata [ uIndex + ( 12 << 1 ) + 0 ] );
		XferDstBufWidth = int( inputdata [ uIndex + 12 ] );

		//XferDstOffset32 = int( inputdata [ uIndex + ( 13 << 1 ) + 0 ] );
		XferDstOffset32 = int( inputdata [ uIndex + 13 ] );


		// get count of pixels
		// looks like this is the count of pixels that have already been transferred in the transfer already
		//XferCount32 = int( inputdata [ uIndex + ( 14 << 1 ) + 0 ] );
		XferCount32 = int( inputdata [ uIndex + 14 ] );

		// id for the transfer
		//XferId0 = int( inputdata [ uIndex + ( 15 << 1 ) + 0 ] );
		XferId0 = int( inputdata [ uIndex + 15 ] );

		// count is per 2 pixels
		//BS <<= 1;
		

		// get start index for pixels in pixel input buffer
		//uStartIndex = inputdata [ uIndex + ( 16 << 1 ) + 0 ];
		uStartIndex = inputdata [ uIndex + 1 ];



	//}



#ifdef SYNC_BEFORE_TRANSFER_OUT

	barrier ();

#endif

	// load iShift0, iShift1, iShift2
	// load iMask0, iMask1, iMask2
	iShift0 = ( ( DPSM & 0x3 ) == 0x3 ) ? 2 : 3;
	iShift1 = ( ( DPSM & 0x3 ) == 0x3 ) ? 3 : 2;
	iShift2 = ( ( DPSM & 0x3 ) == 0x3 ) ? 1 : 2;

	iMask0 = ( ( DPSM & 0x3 ) == 0x3 ) ? 0xff : 0xf;
	iMask1 = ( ( DPSM & 0x3 ) == 0x3 ) ? 0x3 : 0x7;
	iMask2 = iMask1 >> 1;

	if ( subgroupAll( ( DPSM & 0xf ) == 0 ) )
	{
		// 32-bit pixels //

		SharedYMax = Count32;
		XferCountX = XferCount32;

		// shifted for the lookup later
		DPSM >>= 1;

		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < Count32; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			// need the pixel count in the image ( sX + sY * w )
			//idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferDstBufWidth;

			iOffset4 = iOffset4 + XferDstOffset32;

			// store 32-bit data
			pix4.x = VRAM [ iOffset4.x ];
			pix4.y = VRAM [ iOffset4.y ];
			pix4.z = VRAM [ iOffset4.z ];
			pix4.w = VRAM [ iOffset4.w ];

			// output pixel from VRAM
			sVRAM4 [ iCount >> 2 ] = pix4;

		}


	}
	else if ( subgroupAll( ( DPSM & 0x3 ) == 1 ) )
	{
		// 24-bit pixels //

		SharedYMax = Count32;
		XferCountX = XferCount32;
		DPSM >>= 1;
		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < Count32; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			//pix4.x = PixelInput32 [ uStartIndex + idx4.x ];
			//pix4.y = PixelInput32 [ uStartIndex + idx4.y ];
			//pix4.z = PixelInput32 [ uStartIndex + idx4.z ];
			//pix4.w = PixelInput32 [ uStartIndex + idx4.w ];

			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 32-bit pixel block is 64x32 (6bitsx5bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x1f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 5 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x1f ) * XferDstBufWidth;

			iOffset4 = iOffset4 + XferDstOffset32;

			// read 32-bit data
			pix4.x = VRAM [ iOffset4.x ];
			pix4.y = VRAM [ iOffset4.y ];
			pix4.z = VRAM [ iOffset4.z ];
			pix4.w = VRAM [ iOffset4.w ];

			// store as 24-bit data
			idx4 = ( idx4 << 1 ) + idx4;

			sVRAM8[ idx4.x ] = uint8_t( pix4.x );
			sVRAM8[ idx4.y ] = uint8_t( pix4.y );
			sVRAM8[ idx4.z ] = uint8_t( pix4.z );
			sVRAM8[ idx4.w ] = uint8_t( pix4.w );

			idx4++;
			pix4 >>= 8;
			sVRAM8[ idx4.x ] = uint8_t( pix4.x );
			sVRAM8[ idx4.y ] = uint8_t( pix4.y );
			sVRAM8[ idx4.z ] = uint8_t( pix4.z );
			sVRAM8[ idx4.w ] = uint8_t( pix4.w );

			idx4++;
			pix4 >>= 8;
			sVRAM8[ idx4.x ] = uint8_t( pix4.x );
			sVRAM8[ idx4.y ] = uint8_t( pix4.y );
			sVRAM8[ idx4.z ] = uint8_t( pix4.z );
			sVRAM8[ idx4.w ] = uint8_t( pix4.w );
		}
	}
	else if ( subgroupAll( ( DPSM & 0x3 ) == 0x2 ) )
	{
		// 16-bit pixels //

		SharedYMax = Count32 << 1;
		XferCountX = XferCount32 << 1;
		DPSM >>= 1;
		xximagepixelstart = XferCountX;
		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );


			// need the pixel count in the image ( sX + sY * w )
			//idx4 = idx4 + xximagepixelstart;

			CurY4 = idx4 / w;
			CurX4 = idx4 % w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;

			// 16-bit pixel block is 64x64 (6bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x3f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];


			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & ~0x3f ) << 6 );

			// add in the bits for the y
			iOffset4 += ( CurY4 & ~0x3f ) * XferDstBufWidth;

			// shift left dst offset by one for 16-bit pixels
			iOffset4 = iOffset4 + ( XferDstOffset32 << 1 );

			// prepare 16-bit pixels
			//pix4.yw = pix4.xz >> 16;

			// store 16-bit data
			pix4.x = uint( VRAM16 [ iOffset4.x ] );
			pix4.y = uint( VRAM16 [ iOffset4.y ] );
			pix4.z = uint( VRAM16 [ iOffset4.z ] );
			pix4.w = uint( VRAM16 [ iOffset4.w ] );

			// output 16-bit pixels from VRAM
			sVRAM16_4 [ iCount >> 2 ] = u16vec4( pix4 );
		}
	}
	else if ( subgroupAll( ( DPSM & 3 ) == 3 ) )
	{
		// 8-bit pixels (either 8h (0x1b) or just 8-bit packed (0x13)) //

		// iShift0= 8h: 2, otherwise zero
		// iOffset0= 8h: 2, otherwise zero (same as iShift0)
		iShift0 = int( DPSM & 8 ) >> 2;
		iOffset0 = iShift0 | ( iShift0 >> 1 );

		SharedYMax = Count32 << 2;
		XferCountX = XferCount32 << 2;

		DPSM >>= 1;
		xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );


			// need the pixel count in the image ( sX + sY * w )
			idx4 = idx4 + xximagepixelstart;

			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			CurX4 %= XferDstBufWidth;


			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x3f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 8h: 2, otherwise zero
			// iOffset0= 8h: 3, otherwise zero
			iOffset4 = ( iOffset4 << iShift0 ) + iOffset0;

			iOffset4 = iOffset4 + ( XferDstOffset32 << 2 );

			// prepare 8-bit pixels
			// note: could do an unpack here
			//pix4 >>= ( idx4 & 3 ) << 3;
			//pix4 &= 0xff;

			// store 8-bit data
			pix4.x = uint( VRAM8 [ iOffset4.x ] );
			pix4.y = uint( VRAM8 [ iOffset4.y ] );
			pix4.z = uint( VRAM8 [ iOffset4.z ] );
			pix4.w = uint( VRAM8 [ iOffset4.w ] );

			// write pixels from vram
			sVRAM8_4 [ iCount >> 2 ] = u8vec4( pix4 );
		}
	}
	else
	{
		// 4-bit pixels (4/4hl/4hh) //
		// *** TODO ***

		// amount to shift address
		// 4 (0x14)/ 4hl (0x24)/ 4hh (0x2c)
		// iShift0= 4: 3, otherwise zero
		iShift0 = -sign( int( DPSM ) & 0x10 ) & 3;

		// amount to shift pixel in byte
		// iPixelBitOffset0= 4hh: 24 + 4, 4/4hl: 24 + 0, otherwise zero
		iPixelBitOffset0 = ( 24 & -sign( int( DPSM ) & 0x20 ) ) + ( ( int( DPSM ) & 0x8 ) >> 1 );

		// amount to offset address
		// iOffset0 = 4hl/hh: 3, otherwise zero
		//iOffset0 = int( DPSM & 0x20 ) >> 4;
		//iOffset0 |= iOffset0 >> 1;

		// amount to shift address right in case of psmt4 (because it contains position in byte which needs to be removed)
		// iShift1= 4: 1, 4hl/hh: 0
		//iShift1 = int( DPSM & 0x10 ) >> 4;

		SharedYMax = Count32 << 3;
		XferCountX = XferCount32 << 3;

		DPSM >>= 1;
		xximagepixelstart = XferCountX;

		YNAND = LUT_YNAND[ DPSM ];
		XNAND = LUT_XNAND[ DPSM ];
		XSHIFT = LUT_XSHIFT[ DPSM ];

		for ( iCount = gxxid << 2; iCount < SharedYMax; iCount += gxxinc << 2 )
		{
			idx4 = iCount + ivec4( 0, 1, 2, 3 );

			// load 4-bit pixels
			//pix0 = PixelInput32 [ uStartIndex + ( iCount >> 1 ) ];
			//pix0 = ( pix0 >> ( ( iCount & 1 ) << 4 ) ) & 0xffff;
			pix4 = uvec4( PixelInput32 [ uStartIndex + ( idx4.x >> 3 )] );

			// need the pixel count in the image ( sX + sY * w )
			//xximagepixel = iCount + xximagepixelstart;
			idx4 = idx4 + xximagepixelstart;

			//CurX = xximagepixel % w;
			//CurY = xximagepixel / w;
			CurX4 = idx4 % w;
			CurY4 = idx4 / w;

			// get the offset to the pixel
			//CurY += dY;
			//CurX += dX;
			CurY4 += dY;
			CurX4 += dX;

			// coords wrap at 2048
			//CurY &= 0x7ff;
			//CurX &= 0x7ff;
			CurY4 &= 0x7ff;
			CurX4 &= 0x7ff;

			// the x wraps around the buffer
			//CurX %= XferDstBufWidth;
			CurX4 %= XferDstBufWidth;

			// 8-bit pixel block is 128x64 (7bitsx6bits)
			ivPtr4 = ( ( ( CurX4 & 0x7f ) << 0 ) | ( ( CurY4 & 0x7f ) << 7 ) ) | int( DPSM << 14 );
			iOffset4.x = LUT_XYOFFSET [ ivPtr4.x ];
			iOffset4.y = LUT_XYOFFSET [ ivPtr4.y ];
			iOffset4.z = LUT_XYOFFSET [ ivPtr4.z ];
			iOffset4.w = LUT_XYOFFSET [ ivPtr4.w ];

			// put in the remainder of the x-bits that don't get swizzled
			iOffset4 |= ( ( CurX4 & XNAND ) << XSHIFT );

			// add in the bits for the y
			iOffset4 += ( CurY4 & YNAND ) * XferDstBufWidth;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4h: 3, otherwise zero
			// iOffset0= 4h: 2, otherwise zero (same as iShift0)
			//iOffset4 = ( iOffset4 << iShift0 ) + iShift0;



			// ***TODO*** RE-WRITE TO USE 32-BIT MEMORY

			// get offset for pixel inside of 32-bit word
			iPixelBitOffset4 = ( ( ( iOffset4 & 7 ) << 2 ) & ( sign( iPixelBitOffset0 ) - 1 ) ) + iPixelBitOffset0;

			// adjust offset based on whether 8h or regular 8-bit pixel
			// iShift0= 4hl/hh: 2, otherwise zero
			// iOffset0= 4hl/hh: 3, otherwize zero
			// don't add offset until after getting pixel offset
			//iOffset4 = ( iOffset4 << iShift0 );


			// get the address to the byte (in case of psmt4)
			// iShift0= 4: 3, 4hl/hh: 0
			//iOffset4 = ( iOffset4 >> iShift0 ) & ~( 3 & -iShift0 );
			iOffset4 = iOffset4 >> iShift0;

			iOffset4 = iOffset4 + XferDstOffset32;

			// add the fixed byte offset to the address (in case of 4hl/4hh)
			//iOffset4 += iOffset0;

			// load destination 8-bit data
			dpix4.x = VRAM [ iOffset4.x ];
			dpix4.y = VRAM [ iOffset4.y ];
			dpix4.z = VRAM [ iOffset4.z ];
			dpix4.w = VRAM [ iOffset4.w ];

			// prepare 4-bit pixels
			pix4 >>= ( idx4 & 7 ) << 2;
			//pix4 &= 0xf;

			// clear unwanted data in dest pixel
			pix4 = ( ( dpix4 >> iPixelBitOffset4 ) ^ pix4 ) & 0xf;

			// add new data into pixel (xor)
			pix4 <<= iPixelBitOffset4;

			// store 4-bit data in parallel (xor)??
			//VRAM [ iOffset + 0 ] = pix0 & 0xffff;
			//VRAM [ iOffset + 1 ] = pix0 >> 16;
			atomicXor ( VRAM [ iOffset4.x ], pix4.x );
			atomicXor ( VRAM [ iOffset4.y ], pix4.y );
			atomicXor ( VRAM [ iOffset4.z ], pix4.z );
			atomicXor ( VRAM [ iOffset4.w ], pix4.w );
		}


	}
	

#ifdef SYNC_AFTER_TRANSFER

	barrier ();

#endif

	return;
	//return ( ( uIndex >> 4 ) + ( ( SharedYMax + 0xf ) >> 4 ) - 1 );
}

#endif	// end #ifdef ENABLE_DRAW_PIXEL_OUTPUT






void main ()
{
	uint uIdx;
	uint uCommand;
	uint uIndex;

	uint PRIM, OBJ;

	uint uStartIdx, uEndIdx;

	uint CurBarrierSync;

	uint workgroup_id;
	uint subgroup_id;
	uint gxxid;
	uint lxid;
	uint lxinc;
	uint subgroup_global_id;
	int h;

	float fsh;

	ivec4 ivWindowCur0;

	// sometimes want to arrange things in the x direction only
	uint xxid = gl_LocalInvocationIndex;

	uint xid = gl_GlobalInvocationID.x;
	uint yid = gl_GlobalInvocationID.y;

	uint subgroup_local_id = gl_SubgroupID;
	//uint subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );


	// get start index
	uStartIdx = guStartIndex;

	// get end index
	uEndIdx = guEndIndex;

#ifdef ENABLE_WRITE_BACK_DEVICE_DATA

	guSubgroupSize = gl_SubgroupSize;
	guNumSubgroups = gl_NumSubgroups;
	guWorkgroupSize = gl_WorkGroupSize.x;
	guNumWorkgroups = gl_NumWorkGroups.x;

#endif


	group_x = int( gl_WorkGroupID.x );
	group_y = int( gl_WorkGroupID.y );
	group_xcount = int( gl_NumWorkGroups.x );
	group_ycount = int( gl_NumWorkGroups.y );


	// shift for the x direction should be zero
	//group_xshift = findMSB( group_xcount );
	group_xshift = 0;

	// shift for the y direction depends on number of groups in x direction
	//group_yshift = findMSB( group_ycount );
	group_yshift = findMSB( group_xcount );




	workgroup_id = gl_WorkGroupID.x;
	subgroup_id = gl_SubgroupID;

#ifdef ENABLE_MULTIPLE_WORKGROUPS

	workgroup_count = gl_NumWorkGroups.x * gl_NumWorkGroups.y * gl_NumWorkGroups.z;

#else

	workgroup_count = 1;

	// kill all other workgroups
	if ( gl_WorkGroupID.x > 0 )
	{
		return;
	}
#endif

	// size of each subgroup
	subgroup_size = gl_SubgroupSize;

	// number of subgroups in shader
	subgroup_local_count = 1 << findMSB( gl_NumSubgroups );

	// number of subgroups being used total
	// note: this doesn't have to be a power of 2 for drawing, just for transfers (transfer-in,transfer-move,frame buffer clear)
	//subgroup_global_count = 1 << findMSB( subgroup_local_count * workgroup_count );
	subgroup_global_count = subgroup_local_count * workgroup_count;

 	// subgroup global vars
#ifdef ENABLE_MULTIPLE_WORKGROUPS

	subgroup_count = subgroup_global_count;
	subgroup_shift = findMSB( subgroup_count );

#else

	subgroup_count = subgroup_local_count;
	subgroup_shift = findMSB( subgroup_count );
#endif


	subgroup_mask = ( 1 << subgroup_shift ) - 1;




#ifdef ENABLE_MULTIPLE_WORKGROUPS
	if ( xxid == 0 )
	{
		// initialize next synchronization point if multiple workgroups
		NextBarrierSync = subgroup_global_count;
	}
#endif

	// get the increments
	//if ( xid + yid == 0 )
	//{

		xxinc = int( gl_WorkGroupSize.x ) * int( gl_WorkGroupSize.y );

		// global count of shader invocations
		gxxinc = int( xxinc * workgroup_count );
	//}

	// global invocation index
	gxxid = int( gl_LocalInvocationIndex + ( gl_WorkGroupID.x * xxinc ) );


	xxmask = xxinc - 1;

	xinc = int( gl_WorkGroupSize.x );
	yinc = int( gl_WorkGroupSize.y );

	group_xinc = ( xinc << group_xshift );
	group_yinc = ( yinc << group_yshift );

#ifdef USE_NEW_SCANLINE_DRAW_VARS

	//group_vxinc = 4;
	//group_vyinc = xxinc;
	group_vxinc = group_xinc << 2;
	group_vyinc = group_yinc;
#else


	// for vector operations -> vector will be going in x-direction
	// 4 components per vector
	group_vxinc = group_xinc << 2;
	group_vyinc = group_yinc;
#endif

	group_xmask = group_xinc - 1;
	group_ymask = group_yinc - 1;

	group_vxmask = group_vxinc - 1;


	// get ids for the invocation (for drawing, like if inlining)
	lxid = gl_SubgroupInvocationID;
	lxinc = subgroup_size;
	subgroup_local_id = gl_SubgroupID;
	subgroup_global_id = subgroup_local_id + ( gl_WorkGroupID.x * subgroup_local_count );


	//for ( uIndex = xxid; i < 32; i += xxinc )
	//{
	//	LUT_YNAND [ i ] = cLUT_YNAND [ i ];
	//}


	// testing //




	// update GPU VARS (ps2 only) //

	for ( uIndex = lxid; uIndex < 128; uIndex += lxinc )
	{
		// note: subgroup local id for storing to local shared memory
		//uvps2gpu_vars[subgroup_local_id][uIndex] = global_gpu_vars[uIndex];
		uvps2gpu_vars[subgroup_local_id][uIndex] = ivec2( global_gpu_vars[ (uIndex<<1) + 0 ], global_gpu_vars[ (uIndex<<1) + 1 ] );
	}

	// context 0/1
	update_ALPHA(0);
	update_FRAME(0);
	update_ZBUF(0);
	update_TEX0(0);
	update_TEST(0);
	update_CLAMP(0);

	// the other context
	update_ALPHA(1);
	update_FRAME(1);
	update_ZBUF(1);
	update_TEX0(1);
	update_TEST(1);
	update_CLAMP(1);

	// also update TEXA
	// TEXA (0x3b)
	uvec2 TEXA2;
	TEXA2 = uvps2gpu_vars [subgroup_local_id][0x3b];
	//AEM = ( TEXA_0 >> 15 ) & 1;
	//AEM -= 1;
	//TEXA_0 <<= 24;
	//TEXA_1 <<= 24;
	uvTEXA_TA0_TA1_AEM_LUT [ subgroup_local_id ] = ivec4( TEXA2[0] << 24, TEXA2[1] << 24, ( ( TEXA2[0] >> 15 ) & 1 ) - 1, 0 );


	// update CLUT (ps2 only) //
	// probably need to update CLUT after updating variables since setting TEX0 updates CLUT

	/*
	// test the clut
	//for ( uint i = lxid; i < 256; i += lxinc )
	//{
	//	sVRAM[i+64] = cLOCAL_CLUT [ i ];
	//}

	// test the vars
	for ( uint i = xxid; i < 128; i += xxinc )
	{
		sVRAM[(i<<1)+1024+0] = global_gpu_vars [ ( i << 1 ) + 0 ];
		sVRAM[(i<<1)+1024+1] = global_gpu_vars [ ( i << 1 ) + 1 ];
	}

	// test alignment
	for ( uint i = xxid; i < 1024; i += xxinc )
	{
		sVRAM[i+2048] = uScatchSpace[i];
	}
	*/


	//CBPX2 [subgroup_local_id] = cCBPX2;
	CBPX2 [subgroup_local_id] = ivec2( cCBPX2_0, cCBPX2_1 );

#ifdef READ_BACK_CLUT_SPLIT
	//for ( uIndex = lxid; uIndex < 512; uIndex += lxinc )
	for ( uIndex = lxid; uIndex < 256; uIndex += lxinc )
	{
		//LOCAL_CLUT [subgroup_local_id][ uIndex ] = cLOCAL_CLUT [ uIndex ];
		LOCAL_CLUT [subgroup_local_id][ uIndex ] = bitfieldInsert( cLOCAL_CLUT [ uIndex ], cLOCAL_CLUT [ uIndex + 256 ], 16, 16 );
	}
#else
	for ( uIndex = lxid; uIndex < 512; uIndex += lxinc )
	{
		LOCAL_CLUT [subgroup_local_id][ uIndex ] = cLOCAL_CLUT [ uIndex ];
	}
#endif


	//barrier ();


#ifdef ENABLE_PRECOMPUTE_DATA

	// all global subgroups can run this now
	precompute_data ();

#endif

	//barrier ();




#ifdef USE_MEMORY_BARRIER_BUFFER

	memoryBarrierBuffer ();
	memoryBarrierShared ();
	groupMemoryBarrier ();
	memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS


	// if multiple workgroups, need a barrier before the sync ?
	//barrier ();

	// need to do subgroupElect because all subgroups need to synchronize globally before they synchronize locally
	if ( subgroupElect() )
	{

		// count global subgroups that have completed the work
		CurBarrierSync = atomicAdd( auCounter, 1 );
		//atomicAdd( auCounter, 1 );

		// only need the first shader of the entire workgroup to spin wait though
		if ( xxid == 0 )
		{
			// returned the previous value above before the +1
			CurBarrierSync++;

			// would probably need to be a less than comparison due to possible race conditions
			//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
			while ( CurBarrierSync < NextBarrierSync )
			{
				//CurBarrierSync = atomicAdd( auCounter, 0 );
				CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
			}
		
			// at the next sync point, need all subgroups
			NextBarrierSync += subgroup_global_count;

		}	// end if ( xxid == 0 )

	}	// end if ( subgroupElect() )


#endif	// end ENABLE_MULTIPLE_WORKGROUPS


	// an extra barrier
	// this should execute after precompute_data
	barrier ();


#ifdef ENABLE_RANGE_DRAW
	// calculate draw ranges //

	// get pixels between window y start and end
	// adding +1 to be inclusive of window y end
	ivWindowCur0[0] = int( inputdata [ ( uStartIdx << 5 ) + 3 ] );
	ivWindowCur0[1] = ( ivWindowCur0[0] >> 16 ) & 0x7ff;
	ivWindowCur0[0] = ( ivWindowCur0[0] >> 0 ) & 0x7ff;
	h = ivWindowCur0[1] - ivWindowCur0[0] + 1;

	// divide by count of global subgroups
	if ( h > 0 )
	{
		fsh = ( float( h ) / float( subgroup_global_count ) );
		//sh = ( ( h ) / int( subgroup_global_count ) ) + 1;
	}

	// fsh should be at least one pixel
	fsh = max( fsh, 1.0f );
	//sh = max( sh, 1 );

	// determine range based on global subgroup# (start=windowx + (subgroup# * roundup(result))) (end=windowx + ((subgroup#+1) * roundup(result)))
	ivDrawRange [ subgroup_local_id ] = ivec2( ivWindowCur0[0] + int(ceil(float(subgroup_global_id) * fsh)), min( ivWindowCur0[0] + int(ceil(float(subgroup_global_id+1) * fsh)), ivWindowCur0[1] + 1 ) );
	//ivDrawRange [ subgroup_local_id ] = ivec2( ivWindowCur0[0] + ( int(subgroup_global_id) * sh ), min( ivWindowCur0[0] + ( int(subgroup_global_id+1) * sh ), ivWindowCur0[1] + 1 ) );
#endif


	// init uCommand incase there is no data at all (test/sync run)
	uCommand = 0;


//#ifdef ENABLE_DRAW_MAIN_LOOP


	for ( uIndex = uStartIdx; uIndex < uEndIdx; uIndex++ )
	{

		// get the next command
		//PRIM = inputdata [ ( uIndex << 6 ) + ( 15 << 1 ) + 0 ];
		PRIM = inputdata [ ( uIndex << 5 ) + 0 ];
		uCommand = PRIM >> 24;


#ifdef USE_NEW_SYNC_BEFORE_RUN

#ifndef ENABLE_GLOBAL_SYNC_ALL
		// synchronize if needed
		if ( subgroupAll( data [ ( uIndex << 6 ) + 3 ] != 0 ) )
#endif
		{

#ifdef USE_MEMORY_BARRIER_BUFFER

	memoryBarrierBuffer ();
	memoryBarrierShared ();
	groupMemoryBarrier ();
	memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS

			// if multiple workgroups, need a barrier before the sync ?
			//barrier ();

			if ( subgroupElect() )
			{

				CurBarrierSync = atomicAdd( auCounter, 1 );
				//atomicAdd( auCounter, 1 );

				if ( xxid == 0 )
				{
					CurBarrierSync++;

					// would probably need to be a less than comparison due to possible race conditions
					//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
					while ( CurBarrierSync < NextBarrierSync )
					{
						//CurBarrierSync = atomicAdd( auCounter, 0 );
						CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
					}

					// at the next sync point, need all subgroups
					NextBarrierSync += subgroup_global_count;

				}	// end if ( xxid == 0 )


			}	// end if ( subgroupElect() )


#endif	// end #ifdef ENABLE_MULTIPLE_WORKGROUPS

			// synchronize the workgroup subgroups locally
			barrier ();

#ifdef ENABLE_RANGE_DRAW
			// calculate draw ranges //

			// get pixels between window y start and end
			// adding +1 to be inclusive of window y end
			ivWindowCur0[0] = int( inputdata [ ( uIndex << 5 ) + 3 ] );
			ivWindowCur0[1] = ( ivWindowCur0[0] >> 16 ) & 0x7ff;
			ivWindowCur0[0] = ( ivWindowCur0[0] >> 0 ) & 0x7ff;
			h = ivWindowCur0[1] - ivWindowCur0[0] + 1;

			// divide by count of global subgroups
			if ( h > 0 )
			{
				fsh = ( float( h ) / float( subgroup_global_count ) );
				//sh = ( ( h ) / int( subgroup_global_count ) ) + 1;
			}

			// fsh should be at least one pixel
			fsh = max( fsh, 1.0f );
			//sh = max( sh, 1 );

			// determine range based on global subgroup# (start=windowx + (subgroup# * roundup(result))) (end=windowx + ((subgroup#+1) * roundup(result)))
			ivDrawRange [ subgroup_local_id ] = ivec2( ivWindowCur0[0] + int(ceil(float(subgroup_global_id) * fsh)), min( ivWindowCur0[0] + int(ceil(float(subgroup_global_id+1) * fsh)), ivWindowCur0[1] + 1 ) );
			//ivDrawRange [ subgroup_local_id ] = ivec2( ivWindowCur0[0] + ( int(subgroup_global_id) * sh ), min( ivWindowCur0[0] + ( int(subgroup_global_id+1) * sh ), ivWindowCur0[1] + 1 ) );


#endif



		}	// end if ( subgroupAll( data [ ( uIndex << 6 ) + 3 ] != 0 ) )

#endif	// end #ifdef USE_NEW_SYNC_BEFORE_RUN


#ifdef ENABLE_SUBGROUP_SYNC_ALL

	subgroupBarrier();

#endif


#ifdef ENABLE_LOCAL_SYNC_ALL

	barrier ();

#endif

		
//#ifdef ENABLE_DRAW_INNER_LOOP

		if ( subgroupAll( uCommand == 0x00 ) )
		{
			// check prim
			OBJ = PRIM & 0x7;

			if ( subgroupAll( OBJ < 1 ) )
			{
				// point (1x1 sprite)

#ifdef ENABLE_DRAW_PIXEL_COLOR

				Draw_Pixel_Color ( uIndex );

#endif
			}
			else if ( subgroupAll( OBJ < 3 ) )
			{
				// line //

#ifdef ENABLE_DRAW_LINE_COLOR

				Draw_Line_Color ( uIndex );

#endif
			}
			else if ( subgroupAll( OBJ < 6 ) )
			{
				// triangle //

#ifdef ENABLE_DRAW_TRIANGLE_COLOR
				// check if texture mapped
				if ( subgroupAll( ( PRIM & 0x10 ) == 0 ) )
				{
					// NOT-texture //


					Draw_Triangle_Color ( uIndex );

				}
				else
#endif
				{
					// texture //

#ifdef ENABLE_DRAW_TRIANGLE_TEXTURE

					Draw_Triangle_Texture ( uIndex );

#endif
				}
			}
			else if ( subgroupAll( OBJ < 7 ) )
			{
				// sprite //

				// check if texture mapped
#ifdef ENABLE_DRAW_RECTANGLE
				if ( subgroupAll( ( PRIM & 0x10 ) == 0 ) )
				{

					Draw_Rectangle ( uIndex );

				}
				else
#endif
				{
					// sprite //
#ifdef ENABLE_DRAW_SPRITE

					Draw_Sprite ( uIndex );

#endif
				}
			}


			//else
			//{
			//	// error ?? //
			//}
		}
		else if ( subgroupAll( uCommand == 0xf0 ) )
		{
#ifdef ENABLE_DRAW_VARIABLE

			// write variable(s) //
			update_vars( uIndex );

#endif
		}
		else if ( subgroupAll( uCommand == 0xf1 ) )
		{
#ifdef ENABLE_DRAW_PIXEL_MOVE

			// move //
			TransferPixelPacketMove ( uIndex );

#endif
		}
		else if ( subgroupAll( uCommand == 0xf8 ) )
		{
#ifdef ENABLE_DRAW_PIXEL_INPUT

			// import //
			//uIndex = TransferPixelPacketIn ( uIndex );
			TransferPixelPacketIn ( uIndex );

#endif
		}



//#endif	// end #ifdef ENABLE_DRAW_INNER_LOOP

		
	}	// end for ( uIndex = uStartIdx; uIndex < uEndIdx; uIndex++ )

//#endif	// end #ifdef ENABLE_DRAW_MAIN_LOOP


#ifdef ENABLE_DRAW_PIXEL_OUTPUT

		if ( subgroupAll( uCommand == 0xf9 ) )
		{

#ifdef USE_MEMORY_BARRIER_BUFFER

	memoryBarrierBuffer ();
	memoryBarrierShared ();
	groupMemoryBarrier ();
	memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS

			if ( subgroupElect() )
			{

				CurBarrierSync = atomicAdd( auCounter, 1 );
				//atomicAdd( auCounter, 1 );

				if ( xxid == 0 )
				{
					CurBarrierSync++;

					// would probably need to be a less than comparison due to possible race conditions
					//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
					while ( CurBarrierSync < NextBarrierSync )
					{
						//CurBarrierSync = atomicAdd( auCounter, 0 );
						CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
					}

					// at the next sync point, need all subgroups
					NextBarrierSync += subgroup_global_count;

				}	// end if ( xxid == 0 )


			}	// end if ( subgroupElect() )


#endif	// end #ifdef ENABLE_MULTIPLE_WORKGROUPS

			// synchronize the workgroup subgroups locally
			barrier ();

			// command 0xf9
			// note: there's a problem here if they switch to software renderer in the middle of transfer
			TransferPixelPacketOut ( uIndex - 1 );

		}

#endif	// end #ifdef ENABLE_DRAW_PIXEL_OUTPUT



#ifdef ENABLE_DRAW_SCREEN

		if ( subgroupAll( uCommand == 0xfe ) )
		{

#ifdef USE_MEMORY_BARRIER_BUFFER

	memoryBarrierBuffer ();
	memoryBarrierShared ();
	groupMemoryBarrier ();
	memoryBarrier ();

#endif

#ifdef ENABLE_MULTIPLE_WORKGROUPS

			if ( subgroupElect() )
			{

				CurBarrierSync = atomicAdd( auCounter, 1 );
				//atomicAdd( auCounter, 1 );

				if ( xxid == 0 )
				{
					CurBarrierSync++;

					// would probably need to be a less than comparison due to possible race conditions
					//while ( atomicAdd( auCounter, 0 ) < NextBarrierSync )
					while ( CurBarrierSync < NextBarrierSync )
					{
						//CurBarrierSync = atomicAdd( auCounter, 0 );
						CurBarrierSync = atomicCompSwap( auCounter, 0, 0 );
					}

					// at the next sync point, need all subgroups
					NextBarrierSync += subgroup_global_count;

				}	// end if ( xxid == 0 )


			}	// end if ( subgroupElect() )


#endif	// end #ifdef ENABLE_MULTIPLE_WORKGROUPS

			// synchronize the workgroup subgroups locally
			barrier ();

			// command 0xfe
			draw_screen ( uIndex - 1 );

		}

#endif



	// invalidate all the entries
	//for ( uIdx = xxid; uIdx < uIndex; uIdx += xxinc )
	//{
	//	inputdata [ ( uIdx << 6 ) + ( 15 << 1 ) + 0 ] = -1;
	//}



	// write back clut //

	//cCBPX2 = CBPX2[0];
	cCBPX2_0 = CBPX2[0].x;
	cCBPX2_1 = CBPX2[0].y;

#ifdef WRITE_BACK_CLUT_SPLIT
	//for ( uIndex = xxid; uIndex < 512; uIndex += xxinc )
	for ( uIndex = xxid; uIndex < 256; uIndex += xxinc )
	{
		//cLOCAL_CLUT [ uIndex ] = LOCAL_CLUT [0][ uIndex ];
		cLOCAL_CLUT [ uIndex ] = LOCAL_CLUT [0][ uIndex ] & 0xffff;
		cLOCAL_CLUT [ uIndex + 256 ] = LOCAL_CLUT [0][ uIndex ] >> 16;
	}
#else
	// want to migrate to a combined clut rather than split into 16-bit pixels later
	for ( uIndex = xxid; uIndex < 256; uIndex += xxinc )
	{
		cLOCAL_CLUT [ uIndex ] = LOCAL_CLUT [0][ uIndex ];
		//cLOCAL_CLUT [ uIndex ] = LOCAL_CLUT [0][ uIndex ] & 0xffff;
		//cLOCAL_CLUT [ uIndex + 256 ] = LOCAL_CLUT [0][ uIndex ] >> 16;
	}

#endif

	// write back vars //

	for ( uIndex = xxid; uIndex < 128; uIndex += xxinc )
	{
		//global_gpu_vars[uIndex] = uvps2gpu_vars[0][uIndex];
		global_gpu_vars[ (uIndex<<1) + 0 ] = uvps2gpu_vars[0][uIndex].x;
		global_gpu_vars[ (uIndex<<1) + 1 ] = uvps2gpu_vars[0][uIndex].y;
	}


	// testing //

	/*
	// test the vars
	for ( uint i = xxid; i < 128; i += xxinc )
	{
		global_gpu_vars [ (i<<1)+0 ] = (i<<1) + 4096;
		global_gpu_vars [ (i<<1)+1 ] = (i<<1) + 4097;
	}

	// test the clut
	for ( uint i = xxid; i < 512; i += xxinc )
	{
		cLOCAL_CLUT [ i ] = i+1024;
	}


	// test alignment
	for ( uint i = xxid; i < 1024; i += xxinc )
	{
		sVRAM[i+2048] = uScatchSpace[i];
	}
	*/


}

